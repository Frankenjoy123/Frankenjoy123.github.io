<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spark原理案例及搭建]]></title>
    <url>%2F2019%2F08%2F02%2FSpark%E5%8E%9F%E7%90%86%E6%A1%88%E4%BE%8B%E5%8F%8A%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[本文基于Spark 2.3.1 scala 2.11 RDD算子a resilient distributed dataset (RDD), which is a collection of elements partitioned across the nodes of the cluster that can be operated on in parallel Transformation算子http://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations 懒执行，返回值依然是RDD map filter flatMap groupByKey reduceByKey mapValues sort Action算子http://spark.apache.org/docs/latest/rdd-programming-guide.html#actions 触发真正执行，返回值不再是RDD reduce不需要根据key分组，直接进行聚合，reduce双子没必要必须作用在KV格式的RDD上 collect将RDD的元素收集回来，收集到一个集合中。慎用，一般在测试环境使用 countRDD持久化http://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence cache cache算子将数据保存到内存中 cache算子是懒加载算子，需要Action算子触发执行 cache 是 persist简化版 StorageLevel 半生对象 deseriliezd 不序列化的意思， 序列化，占用空间小 persistStorageLevel优先级 MEMORY_ONLY 只放内存，不够放弃。释放：1.自动ttl，2.手动释放内存 unpersist。 MEMORY_ONLY_SER MEMORY_AND_DISK_SER 内存放不了，再放磁盘 DISK_ONLY 不建议使用 一个action算子，就是一个Job standlone部署spark-env.sh 修改123456789101112131415161718# masterIPSPARK_MASTER_HOST=node01# master通信端口SPARK_MASTER_PORT=7077# 心跳超时时间SPARK_MASTER_OPTS="-Dspark.worker.timeout=100"# webUI端口SPARK_MASTER_WEBUI_PORT=8888# 日志存放位置SPARK_LOCAL_DIRS="/var/zfg/spark"# worker进程所管理的核心数SPARK_WORKER_CORES=2# worker进程所管理的内存数SPARK_WORKER_MEMORY=3G# 计算工作区SPARK_WORKER_DIR="/var/zfg/spark/work"# 工作区文件的有效期SPARK_WORKER_OPTS="-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.appDataTtl=259200" slave修改123node02node03node04 sbin的目录下的spark-config.sh 文件下添加 1export JAVA_HOME=/usr/install/jdk/jdk1.8.0_171 环境变量配置环境变量，sbin bin添加到path start-all.sh 改名start-spark.sh scp到node02 node03 node04启动启动 start-spark.sh 访问 http://node01:8888 动态添加worker1./sbin/start-slave.sh &lt;master-spark-URL&gt; spark shell集群方式 1./bin/spark-shell --master spark://IP:PORT 本地方式 1./bin/spark-shell REPL读、执行、打印、循环 standalone HA部署Spark Standalone Mode - Spark 2.4.3 Documentation Configuration - Spark 2.4.3 Documentation 处于active状态的master，会将收集的元信息放到zookeeper，包括worker个数，地址。 备用master监听zk，通知active挂了。备用master会从zk中读取元数据到内存，通知worker以后的主、心跳发送 配置SPARK_DAEMON_JAVA_OPTS in spark-env by configuring spark.deploy.recoveryMode and related spark.deploy.zookeeper.* configurations. 1SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER spark.deploy.zookeeper.url=node02:2181,node03:2181,node04:2181 -Dspark.deploy.zookeeper.dir=spark201908" 将spark-env.sh 同步到其他节点 启动start-spark.sh，发现只有一个master 在node02中，修改SPARK_MASTER_HOST=node02，再 start-master启动 备用 node02 start-master.shMaster=node02 RECAVering 准备切换状态 术语 Master(standalone)：资源管理的主节点(进程) Cluster Manager：在集群上获取资源的外部服务(例如standalone,Mesos,Yarn ) Worker Node(standalone)：资源管理的从节点(进程) 或者说管理本机资源的进程 Application：基于Spark的⽤用户程序，包含了driver程序和运行在集群上的executor程序 Driver Program：用来连接工作进程（Worker）的程序 Executor：是在一个worker进程所管理的节点上为某Application启动的⼀一个进程，该进 程负责运行任务，并且负责将数据存在内存或者磁盘上。每个应⽤用都有各自独⽴立的 executors Task：被送到某个executor上的工作单元 Job：包含很多任务(Task)的并行计算，可以看做和action对Job：包含很多任务(Task)的并行计算，可以看做和action对v应 Stage：⼀个Job会被拆分很多组任务，每组任务被称为Stage(就像Mapreduce分map task 和reduce task一样) 宽依赖 宽依赖：父RDD的分区：子RDD的分区，1对多 导致宽依赖的算子: groupByKey 宽依赖和shuffle是一一对应的 窄依赖 map fitler union 不会导致宽依赖 窄依赖一般不会发生shuffle Stage切割规则 按宽依赖进行划分，连着的窄依赖为一个stage 正是有了宽窄依赖，才能将job切分成一个个stage 一个stage的task个数（并发数），以最后一个RDD的分区数为准 pipeline操作 一个stage内（都是窄依赖）进行pipeline操作 计算向数据移动，C、D、F的计算都可以移动到C操作 为什么有懒执行算子，就是为了构建pipeline，增加并行度 举例12345val RDD = sc.textFile(hdfs)val filterRDD = RDD.filter(x =&gt; x.contains("Ab"))val mapRDD = filterRDD.map(x =&gt; x+"~")val flatMapRDD = mapRDD.flatMap(x =&gt; x.split(" "))flatMapRDD.collect task1最好在B1执行 task2最好在B2执行 持久化管道中的数据什么时候持久化到磁盘 shuttle 的write的阶段（stage和stage之间，shuttfle write 和 shuttfle read） 对一个RDD执行了持久化算子(persist) 任务调度 任务重试 默认值重试3次 ， 加上1次，一共4次。重试次数为4-1=3 http://spark.apache.org/docs/latest/configuration.html#scheduling spark.task.maxFailures 4 Number of failures of any particular task before giving up on the job. The total number of failures spread across different tasks will not cause the job to fail; a particular task has to fail this number of attempts. Should be greater than or equal to 1. Number of allowed retries = this value - 1. 1.代码配置 2.spark-default.xml配置文件 3.提交Application的时候，常用 1spark-submit --conf spark.task.maxFailures=10 挣扎的任务TaskScheduler负责任务的重试，和挣扎的任务(推测执行) 推测过程 75%的任务都执行完成后，会每隔100ms来鉴定一次剩余的task是否是挣扎的task。鉴定过程：25task的执行时间，按照执行时间来排序，取中位数10s，10s*1.5倍数=15s。25task中大于这个15s的任务就是挣扎的任务。 spark.speculation false If set to “true”, performs speculative execution of tasks. This means if one or more tasks are running slowly in a stage, they will be re-launched. spark.speculation.interval 100ms How often Spark will check for tasks to speculate. spark.speculation.multiplier 1.5 How many times slower a task is than the median to be considered for speculation. spark.speculation.quantile 0.75 Fraction of tasks which must be complete before speculation is enabled for a particular stage. stage重试DAGScheduler负责重试stage，默认重试次数为4 spark.stage.maxConsecutiveAttempts 4 Number of consecutive stage attempts allowed before a stage is aborted. 单机执行3h，Spark并行执行却要12h？？ 可能发生数据倾斜，99task 100M，1task 1T-100M 可能开启了推测执行，那么很有可能1task为挣扎的task，那么TaskScheduler会新起一个task和挣扎的task比赛执行 解决方案： 关闭推测执行 解决数据倾斜问题 资源调度 DAGScheduler taskshceduler 存在于driver中 为了防止master压力过大，都要增加client client spark-submit 通过执行Main函数，启动一个driver进程。创建sparkContext，同时创建两个对象，DAGScheduler,TaskScheduler。 资源调度过程 TaskScheduler创建成功后，会找master，给当前application申请资源。 master会查看自己的资源情况，告诉worker节点，启动一个executor进程。默认使用1G内存，所有核。 excutor启动成功后，会反向注册给TaskScheduler DAGScheduler，根据RDD的宽窄依赖切分stage，将一个个stage提交给taskSehduler TaskScheduler，接收到stage之后，遍历拿到每个task，调用HDFS的方法，得到block位置。将task分发到数据节点执行。 备注 完全一致部署，也不能避免数据移动。也有可能从其他节点拉取数据，在节点计算。 启动Exetor或者申请资源，不会考虑数据的位置。 对比 Spark MR on YARN 类型 粗粒度的资源调度 细粒度的资源调度 过程 在提交Application的时候，taskScheduler先去申请资源。然后taskScheduler分发任务，执行所有task执行完毕，才释放这部分资源。 在提交Applicaiton的时候，先向数据节点分发task，task自己去申请资源。如果申请到了资源，立即执行。否则一直等待。当task执行完毕，立即释放资源。 优点 1. 每一个task的等待时间变短了 2.可以资源复用 集群资源能充分利用 缺点 10000task 9999task 1task没执行完，无法充分利用集群资源 task的等待时间太长 源码解读 worker进程启动成功后，会向master注册，发送worker的管理的资源信息 当worker启动完毕后，会定期向master发送心跳，此时不会携带worker的资源信息，只会携带当前worker的id号。 默认情况下，每一个worker节点为当前的Application指定启动一个1executor，这个executor默认使用1G 所有的core client指定driver不在本地执行，为Driver申请资源，1G 1core master查询workers信息，随机指定worker2启动启动Driver进程。 1spark-submit --class org.apache.spark.examples.SparkPi --master spark://node01:7077 --deploy-mode cluster --driver-memory 1g --num-executors 2 --executor-memory 1g --executor-cores 1 /opt/sxt/spark-2.3.1/examples/jars/spark-examples_2.11-2.3.1.jar 1spark-submit --class org.apache.spark.examples.SparkPi --master spark://node01:7077 --deploy-mode cluster --total-executor-cores=6 --executor-memory 1g --executor-cores 1 /opt/sxt/spark-2.3.1/examples/jars/spark-examples_2.11-2.3.1.jar ` 1spark.deploy.spreadOut=true 默认情况下（在提交Application的时候，没有指定–executor-cores），每一个worker节点为当前的Application只启动1个Executor，这个Executor使用所有的核 如果想要一个Worker节点上启动多个Executor，那么在提交Application的时候需要指定--executor-cores这个选项 spark.deploy.spreadOut默认为true，表示轮询在workers启动executor 1spark-submit --class org.apache.spark.examples.SparkPi --master spark://node01:7077 --deploy-mode cluster --total-executor-cores=6 --executor-memory 1g --executor-cores 1 --spark.deploy.spreadOut false /opt/sxt/spark-2.3.1/examples/jars/spark-examples_2.11-2.3.1.jar 参考 https://spark.apache.org/docs/latest/spark-standalone.html]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[storm搭建及原理分析]]></title>
    <url>%2F2019%2F06%2F23%2Fstorm%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[http://storm.apache.org/ 编程模型 DAG （Topology）有向无环图Spout – 数据源 nextTuple Spout中最核心的方法是nextTuple，该方法会被Storm线程不断调用、主动从数据源拉取数据，再通过emit方法将数据生成元组（Tuple）发送给之后的Bolt计算 OutputFieldsDeclarer 可先通过OutputFieldsDeclarer中的declare方法声明定义的不同数据流，发送数据时通过SpoutOutputCollector中的emit方法指定数据流Id（streamId）参数将数据发送出去 Bolt – 数据流处理组件Bolt：处理者，可以有多个。多个bolt可以并行执行。 一个Bolt可以发送多个数据流（Stream） OutputFieldsDeclarer 可先通过OutputFieldsDeclarer中的declare方法声明定义的不同数据流，发送数据时通过SpoutOutputCollector中的emit方法指定数据流Id（streamId）参数将数据发送出去 execute Bolt中最核心的方法是execute方法，该方法负责接收到一个元组（Tuple）数据、真正实现核心的业务逻辑 Stream Grouping – 数据流分组（即数据分发策略）高可靠性异常处理 消息可靠性保障机制(ACK) 流式处理异步方式 流式处理（异步 与 同步） 客户端提交数据进行结算，并不会等待数据计算结果 逐条处理 例：ETL（数据清洗）extracted transform load 统计分析 例：计算PV、UV、访问热点 以及 某些数据的聚合、加和、平均等 ​ 客户端提交数据之后，计算完成结果存储到Redis、HBase、MySQL或者其他MQ当中， ​ 客户端并不关心最终结果是多少。 同步方式客户端提交数据请求之后，立刻取得计算结果并返回给客户端 客户端通过和DRPC server交互，立刻取得返回结果 和MapReduce比较 Storm：进程、线程常驻内存运行，数据不进入磁盘，数据通过网络传递。 MapReduce：为TB、PB级别数据设计的批处理计算框架。 和Spark Streaming比较 Storm：纯流式处理，毫秒级 专门为流式处理设计 数据传输模式更为简单，很多地方也更为高效 并不是不能做批处理，它也可以来做微批处理，来提高吞吐 Spark Streaming：微批处理，秒级 将RDD做的很小来用小的批处理来接近流式处理 基于内存和DAG可以把处理任务做的很快 数据累加demo代码参考eclipse-hadoop-workspace/ws 集群安装1python -V nimbus supervisor zookeeper node01 * node02 * * node03 * * node04 * scp安装包到node01 apache-storm-0.10.0.tar.gz 12345678910111213141516$ vim conf/storm.yamlstorm.zookeeper.servers: - "node02" - "node03" - "node04"storm.local.dir: "/tmp/storm"nimbus.host: "node01"# slot 代表一个进程supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 12scp -r apache-storm-0.10.0 root@node02:`pwd`scp -r apache-storm-0.10.0 root@node03:`pwd` 123环境变量配置export STORM_HOME=/opt/sxt/stormexport PATH=$PATH:$STORM_HOME/bin 在storm目录中创建logs目录12cd $STORM_HOMEmkdir logs node01上启动Nimbus1234storm nimbus &gt;&gt; ./logs/nimbus.out 2&gt;&amp;1 &amp;tail -f logs/nimbus.logstorm ui &gt;&gt; ./logs/ui.out 2&gt;&amp;1 &amp;tail -f logs/ui.log 节点node2和node3启动supervisor，按照配置，每启动一个supervisor就有了4个slots1234cd $STORM_HOMEmkdir logsstorm supervisor &gt;&gt; ./logs/supervisor.out 2&gt;&amp;1 &amp;tail -f logs/supervisor.log 帮助命令12storm helpstorm help jar kill1storm kill test web运维页面 http://node01:8080/ 集群提交提交任务到Storm集群当中运行：代码参考(eclipse-hadoop-workspace/wordcount) src打包，test为参数表示集群方式运行，作为topology名称 1storm jar wordcount.jar com.sxt.storm.test.Test test 123456789101112131415if (args.length&gt;0) &#123; try &#123; StormSubmitter.submitTopology(args[0], config, tb.createTopology()); &#125; catch (AlreadyAliveException e) &#123; e.printStackTrace(); &#125; catch (InvalidTopologyException e) &#123; e.printStackTrace(); &#125;&#125; else &#123; LocalCluster lc = new LocalCluster(); lc.submitTopology("wordcount", config, tb.createTopology());&#125; 流程： spout —&gt; bolt(切分单词)—&gt; bolt(计数) 架构设计 Nimbus 资源调度 任务分配 接收jar包 Supervisor 接收nimbus分配的任务 启动、停止自己管理的worker进程（当前supervisor上worker数量由配置文件设定） Worker 运行具体处理运算组件的进程（每个Worker对应执行一个Topology的子集） worker任务类型，即spout任务、bolt任务两种 启动executor ​ （executor即worker JVM进程中的一个java线程，一般默认每个executor负责执行一个task任务） 与hadoop yarn对比 Hadoop Storm 主节点 ResourceManager Nimbus 从节点 NodeManager Supervisor 应用程序 Job Topology 工作进程 Child Worker 计算模型 Map/Reduce(split,map,shuffle,reduce) Spout/Bolt 运行过程 提交jar包到nimbus/inbox目录下 对topology进行校验处理 nimbus/stormdist/${topology-id}下，包含jar包、stormcode序列化方法、stormconf运行配置 nimbus初始化spout/bolt的task，写到zookeeper的/tasks节点下 nimbus创建/taskbeats的zk节点，监控task心跳 将任务分配信息，写到zk assignment/${topology-id}节点中，此时认为任务提交完毕 在zk的storms/${topology-id}下存放任务的运行时间、状态信息 本地目录树 zookeeper目录树 Storm DRPC原理 DRPC (Distributed RPC) remote procedure call 分布式远程过程调用 DRPC 是通过一个 DRPC 服务端(DRPC server)来实现分布式 RPC 功能的。 DRPC Server 负责接收 RPC 请求，并将该请求发送到 Storm中运行的 Topology，等待接收 Topology 发送的处理结果，并将该结果返回给发送请求的客户端。 （其实，从客户端的角度来说，DPRC 与普通的 RPC 调用并没有什么区别。） DRPC设计目的： 为了充分利用Storm的计算能力实现高密度的并行实时计算。 （Storm接收若干个数据流输入，数据在Topology当中运行完成，然后通过DRPC将结果进行输出。） 部署1vi storm.yaml 12drpc.servers: - "node01" 12scp storm.yaml root@node02:`pwd`scp storm.yaml root@node03:`pwd` node01执行 123456nohup storm nimbus &gt;&gt; ./logs/nimbus.out 2&gt;&amp;1 &amp;tail -f logs/nimbus.lognohup storm drpc &gt;&gt; ./logs/drpc.out 2&gt;&amp;1 &amp;tail -f logs/drpc.lognohup storm ui &gt;&gt; ./logs/ui.out 2&gt;&amp;1 &amp;tail -f logs/ui.log node02 node03执行 123cd $STORM_HOMEnohup storm supervisor &gt;&gt; ./logs/supervisor.out 2&gt;&amp;1 &amp;tail -f logs/supervisor.log 代码参考eclipse-hadoop-workspace/StormDemo 1scp drpc.jar root@node01:/root/ 1storm jar drpc.jar com.sxt.storm.drpc.BasicDRPCTopology test 客户端执行结果 123456789101112131415public class MyDRPCclient &#123; public static void main(String[] args) &#123; DRPCClient client = new DRPCClient("node01", 3772); try &#123; String result = client.execute("exclamation", "11,22"); System.out.println(result); &#125; catch (TException e) &#123; e.printStackTrace(); &#125; catch (DRPCExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Storm 容错机制集群节点宕机 Nimbus服务器 单点故障？ 非Nimbus服务器 故障时，该节点上所有Task任务都会超时，Nimbus会将这些Task任务重新分配到其他服务器上运行 进程挂掉Worker挂掉时，Supervisor会重新启动这个进程。如果启动过程中仍然一直失败，并且无法向Nimbus发送心跳，Nimbus会将该Worker重新分配到其他服务器上 Supervisor无状态（所有的状态信息都存放在Zookeeper中来管理） 快速失败（每当遇到任何异常情况，都会自动毁灭） Nimbus无状态（所有的状态信息都存放在Zookeeper中来管理） 快速失败（每当遇到任何异常情况，都会自动毁灭） 消息的完整性 从Spout中发出的Tuple，以及基于他所产生Tuple（例如上个例子当中Spout发出的句子，以及句子当中单词的tuple等） 由这些消息就构成了一棵tuple树 当这棵tuple树发送完成，并且树当中每一条消息都被正确处理，就表明spout发送消息被“完整处理”，即消息的完整性 中国移动项目代码参考cmccstormjk02 和cmcc02_hbase hbase1create 'cell_monitor_table','cf']]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hadoop日志分析实战项目搭建及分析]]></title>
    <url>%2F2019%2F06%2F21%2Fhadoop%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[整体项目流程 js或者java sdk访问nginx提供的接口，nginx写入访问日志文件 flume tail -F监控日志文件，存储日志到hdfs 通过Mapper Reducer 任务，清洗日志为标准的数据，存储到hbase 通过map reduce 任务，按不同的维度，统计数据，写入到mysql。或者使用hive建立外部表，关联hbase，通过spoop，转换hive数据到mysql。 tengine安装参考 http://tengine.taobao.org/document/install.html Nginx文档ngx_http_log_module模块 安装1234yum install gcc openssl-devel pcre-devel zlib-devel -y# 搜索yum search 配置nginx.conf的http模块下配置 1log_format my_format '$remote_addr^A$msec^A$http_host^A$request_uri'; server配置访问日志的格式和文件地址 1234location = /log.gif &#123; default_type image/gif; access_log /opt/data/access.log my_format;&#125; 启动1./n flume安装单节点参考文档 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#a-simple-example 上传解压123scp apache-flume-1.6.0-bin.tar.gz root@node02:/roottar -zxvf apache-flume-1.6.0-bin.tar.gzmv apache-flume-1.6.0-bin/ /usr/install/ 配置环境变量12vi /etc/profilesource /etc/profile 12export FLUME_HOME=/usr/install/apache-flume-1.6.0-binexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin:$HBASE_HOME/bin:$FLUME_HOME/bin 修改conf/flume-env.sh 文件中的JDK目录12cp flume-env.sh.template flume-env.shvi flume-env.sh 1export JAVA_HOME=/usr/install/jdk/jdk1.8.0_171 验证安装是否成功1flume-ng version 修改配置12cd conf/vi simple.conf 12345678910111213141516171819202122# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = node02a1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动flume1flume-ng agent -n a1 -c conf -f simple.conf -Dflume.root.logger=INFO,console 发送数据1telnet node02 44444 两个flume做集群参考文档 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#setting-multi-agent-flow 右侧节点(node03)参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#avro-source 1vi double-flume.conf 123456789101112131415161718192021# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.bind = node03a1.sources.r1.port = 60000# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f double-flume.conf -Dflume.root.logger=INFO,console 左侧节点(node02)参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#avro-sink 1scp -r apache-flume-1.6.0-bin/ root@node03:/usr/install 1vi double-flume.conf 1234567891011121314151617181920212223a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = node02a1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.hostname = node03a1.sinks.k1.port = 60000# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f double-flume.conf -Dflume.root.logger=INFO,console 发送数据1telnet node02 44444 Exec Source方式，监控文件tail命令参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#exec-source 配置1vi exec.conf 12345678910111213141516171819a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F /root/test.txt# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f exec.conf -Dflume.root.logger=INFO,console 添加数据循环添加数据 1for i in &#123;1..50&#125;; do echo "$i hi flume" &gt;&gt; /root/test.txt ; sleep 0.1; done Spooling Directory Source监控目录参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source 配置1vi spool.conf 1234567891011121314151617181920a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = spooldira1.sources.r1.spoolDir = /root/logsa1.sources.r1.fileHeader = true# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f spool.conf -Dflume.root.logger=INFO,console 拷贝文件演示mkdir logs mv aa logs/ flume和kafka两者经常配对使用，谁在前后都可以 hdfs sink方式参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#hdfs-sink 配置1vi hdfs-sink.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = spooldira1.sources.r1.spoolDir = /root/logsa1.sources.r1.fileHeader = true# Describe the sink 文件目录格式a1.sinks.k1.type=hdfsa1.sinks.k1.hdfs.path=hdfs://mycluster/flume/%Y-%m-%d/%H%M##每隔60s或者文件大小超过10M的时候产生新文件，roll对文件设置# hdfs有多少条消息时新建文件，0不基于消息个数a1.sinks.k1.hdfs.rollCount=0# hdfs创建多长时间新建文件，0不基于时间a1.sinks.k1.hdfs.rollInterval=60# hdfs多大时新建文件，0不基于文件大小a1.sinks.k1.hdfs.rollSize=10240# 当目前被打开的临时文件在该参数指定的时间（秒）内，没有任何数据写入，则将该临时文件关闭并重命名成目标文件a1.sinks.k1.hdfs.idleTimeout=3a1.sinks.k1.hdfs.fileType=DataStreama1.sinks.k1.hdfs.useLocalTimeStamp=true## 每五分钟生成一个目录，round对目录设置# 是否启用时间上的”舍弃”，这里的”舍弃”，类似于”四舍五入”，后面再介绍。如果启用，则会影响除了%t的其他所有时间表达式a1.sinks.k1.hdfs.round=true# 时间上进行“舍弃”的值；a1.sinks.k1.hdfs.roundValue=5# 时间上进行”舍弃”的单位，包含：second,minute,houra1.sinks.k1.hdfs.roundUnit=minute# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f hdfs-sink.conf -Dflume.root.logger=INFO,console 拷贝文件演示12mkdir logsmv aa logs/ tengine和flume集成配置1vi tengine_project.conf 12345678910111213141516171819202122232425a1.sources = r1a1.sinks = k1a1.channels = c1## 监听tengine的access log文件a1.sources.r1.type = execa1.sources.r1.command = tail -F /opt/data/access.loga1.sinks.k1.type=hdfsa1.sinks.k1.hdfs.path=hdfs://mycluster/log/%Y%m%da1.sinks.k1.hdfs.rollCount=0a1.sinks.k1.hdfs.rollInterval=0a1.sinks.k1.hdfs.rollSize=10240a1.sinks.k1.hdfs.idleTimeout=5a1.sinks.k1.hdfs.fileType=DataStreama1.sinks.k1.hdfs.useLocalTimeStamp=truea1.sinks.k1.hdfs.callTimeout=40000a1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100a1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f tengine_project.conf -Dflume.root.logger=INFO,console 拷贝文件演示12mkdir logsmv aa logs/ 经过ETL清洗存储到hbase目标 过滤脏数据 分析IP，得到省、市区 分析useragent，得到浏览器版本 AnalyserLogDataRunner123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152package com.sxt.etl.mr.ald;import java.io.IOException;import org.apache.commons.lang.StringUtils;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.util.Tool;import org.apache.hadoop.util.ToolRunner;import org.apache.log4j.Logger;import com.sxt.common.EventLogConstants;import com.sxt.common.GlobalConstants;import com.sxt.util.TimeUtil;/** * 编写mapreduce的runner类 * * @author root * */public class AnalyserLogDataRunner implements Tool &#123; private static final Logger logger = Logger .getLogger(AnalyserLogDataRunner.class); private Configuration conf = null; public static void main(String[] args) &#123; try &#123; ToolRunner.run(new Configuration(), new AnalyserLogDataRunner(), args); &#125; catch (Exception e) &#123; logger.error("执行日志解析job异常", e); throw new RuntimeException(e); &#125; &#125; @Override public void setConf(Configuration conf) &#123; conf.set("fs.defaultFS", "hdfs://node01:8020");// conf.set("yarn.resourcemanager.hostname", "node3"); conf.set("hbase.zookeeper.quorum", "node02,node03,node04"); this.conf = HBaseConfiguration.create(conf); &#125; @Override public Configuration getConf() &#123; return this.conf; &#125; @Override public int run(String[] args) throws Exception &#123; Configuration conf = this.getConf(); this.processArgs(conf, args); Job job = Job.getInstance(conf, "analyser_logdata"); // 设置本地提交job，集群运行，需要代码 // File jarFile = EJob.createTempJar("target/classes"); // ((JobConf) job.getConfiguration()).setJar(jarFile.toString()); // 设置本地提交job，集群运行，需要代码结束 job.setJarByClass(AnalyserLogDataRunner.class); job.setMapperClass(AnalyserLogDataMapper.class); job.setMapOutputKeyClass(NullWritable.class); job.setMapOutputValueClass(Put.class); // 设置reducer配置 // 1. 集群上运行，打成jar运行(要求addDependencyJars参数为true，默认就是true) // TableMapReduceUtil.initTableReducerJob(EventLogConstants.HBASE_NAME_EVENT_LOGS, // null, job); // 2. 本地运行，要求参数addDependencyJars为false TableMapReduceUtil.initTableReducerJob( EventLogConstants.HBASE_NAME_EVENT_LOGS, null, job, null, null, null, null, false); job.setNumReduceTasks(0); // 设置输入路径 this.setJobInputPaths(job); return job.waitForCompletion(true) ? 0 : -1; &#125; /** * 处理参数 * * @param conf * @param args */ private void processArgs(Configuration conf, String[] args) &#123; String date = null; for (int i = 0; i &lt; args.length; i++) &#123; if ("-d".equals(args[i])) &#123; if (i + 1 &lt; args.length) &#123; date = args[++i]; break; &#125; &#125; &#125; System.out.println("-----" + date); // 要求date格式为: yyyy-MM-dd if (StringUtils.isBlank(date) || !TimeUtil.isValidateRunningDate(date)) &#123; // date是一个无效时间数据 date = TimeUtil.getYesterday(); // 默认时间是昨天 System.out.println(date); &#125; conf.set(GlobalConstants.RUNNING_DATE_PARAMES, date); &#125; /** * 设置job的输入路径 * * @param job */ private void setJobInputPaths(Job job) &#123; Configuration conf = job.getConfiguration(); FileSystem fs = null; try &#123; fs = FileSystem.get(conf); String date = conf.get(GlobalConstants.RUNNING_DATE_PARAMES); // Path inputPath = new Path("/flume/" + // TimeUtil.parseLong2String(TimeUtil.parseString2Long(date), // "MM/dd/")); Path inputPath = new Path("/log/" + TimeUtil.parseLong2String( TimeUtil.parseString2Long(date), "yyyyMMdd") + "/"); if (fs.exists(inputPath)) &#123; FileInputFormat.addInputPath(job, inputPath); &#125; else &#123; throw new RuntimeException("文件不存在:" + inputPath); &#125; &#125; catch (IOException e) &#123; throw new RuntimeException("设置job的mapreduce输入路径出现异常", e); &#125; finally &#123; if (fs != null) &#123; try &#123; fs.close(); &#125; catch (IOException e) &#123; // nothing &#125; &#125; &#125; &#125;&#125; AnalyserLogDataMapper123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package com.sxt.etl.mr.ald;import java.io.IOException;import java.util.Map;import java.util.zip.CRC32;import org.apache.commons.lang.StringUtils;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.util.Bytes;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import org.apache.log4j.Logger;import com.sxt.common.EventLogConstants;import com.sxt.common.EventLogConstants.EventEnum;import com.sxt.etl.util.LoggerUtil;/** * 自定义数据解析map类 * * @author root * */public class AnalyserLogDataMapper extends Mapper&lt;LongWritable, Text, NullWritable, Put&gt; &#123; private final Logger logger = Logger.getLogger(AnalyserLogDataMapper.class); private int inputRecords, filterRecords, outputRecords; // 主要用于标志，方便查看过滤数据 private byte[] family = Bytes.toBytes(EventLogConstants.EVENT_LOGS_FAMILY_NAME); private CRC32 crc32 = new CRC32(); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; this.inputRecords++; this.logger.debug("Analyse data of :" + value); try &#123; // 解析日志 Map&lt;String, String&gt; clientInfo = LoggerUtil.handleLog(value.toString()); // 过滤解析失败的数据 if (clientInfo.isEmpty()) &#123; this.filterRecords++; return; &#125; // 获取事件名称 String eventAliasName = clientInfo.get(EventLogConstants.LOG_COLUMN_NAME_EVENT_NAME); EventEnum event = EventEnum.valueOfAlias(eventAliasName); switch (event) &#123; case LAUNCH: case PAGEVIEW: case CHARGEREQUEST: case CHARGEREFUND: case CHARGESUCCESS: case EVENT: // 处理数据 this.handleData(clientInfo, event, context); break; default: this.filterRecords++; this.logger.warn("该事件没法进行解析，事件名称为:" + eventAliasName); &#125; &#125; catch (Exception e) &#123; this.filterRecords++; this.logger.error("处理数据发出异常，数据:" + value, e); &#125; &#125; @Override protected void cleanup(Context context) throws IOException, InterruptedException &#123; super.cleanup(context); logger.info("输入数据:" + this.inputRecords + "；输出数据:" + this.outputRecords + "；过滤数据:" + this.filterRecords); &#125; /** * 具体处理数据的方法 * * @param clientInfo * @param context * @param event * @throws InterruptedException * @throws IOException */ private void handleData(Map&lt;String, String&gt; clientInfo, EventEnum event, Context context) throws IOException, InterruptedException &#123; String uuid = clientInfo.get(EventLogConstants.LOG_COLUMN_NAME_UUID); String memberId = clientInfo .get(EventLogConstants.LOG_COLUMN_NAME_MEMBER_ID); String serverTime = clientInfo .get(EventLogConstants.LOG_COLUMN_NAME_SERVER_TIME); if (StringUtils.isNotBlank(serverTime)) &#123; // 要求服务器时间不为空 clientInfo.remove(EventLogConstants.LOG_COLUMN_NAME_USER_AGENT); // 浏览器信息去掉 String rowkey = this.generateRowKey(uuid, memberId, event.alias, serverTime); // timestamp // + // (uuid+memberid+event).crc Put put = new Put(Bytes.toBytes(rowkey)); for (Map.Entry&lt;String, String&gt; entry : clientInfo.entrySet()) &#123; if (StringUtils.isNotBlank(entry.getKey()) &amp;&amp; StringUtils.isNotBlank(entry.getValue())) &#123; put.add(family, Bytes.toBytes(entry.getKey()), Bytes.toBytes(entry.getValue())); &#125; &#125; context.write(NullWritable.get(), put); this.outputRecords++; &#125; else &#123; this.filterRecords++; &#125; &#125; /** * 根据uuid memberid servertime创建rowkey * * @param uuid * @param memberId * @param eventAliasName * @param serverTime * @return */ private String generateRowKey(String uuid, String memberId, String eventAliasName, String serverTime) &#123; StringBuilder sb = new StringBuilder(); sb.append(serverTime).append("_"); this.crc32.reset(); if (StringUtils.isNotBlank(uuid)) &#123; this.crc32.update(uuid.getBytes()); &#125; if (StringUtils.isNotBlank(memberId)) &#123; this.crc32.update(memberId.getBytes()); &#125; this.crc32.update(eventAliasName.getBytes()); sb.append(this.crc32.getValue() % 100000000L); return sb.toString(); &#125;&#125; map reduce分析hbase的数据，落到mysql经过不同维度 mysql数据库准备1create database 'result_db'; 使用mysql_表设计.sql创建表 新用户模块NewInstallUserMapper经过1次map，输出多个维度，减少网络IO 输出的key StatsUserDimension，包含以下两个维度。分别是普通统计用户 新用户访问数据： 时间 访问平台(js浏览器) 访问浏览器 这样浏览器新用户KPI，可以经过笛卡尔积2*2，统计4个维度的信息。 当前浏览器(全部版本) 当前浏览器(版本1.0) 当前平台(js浏览器端或者手机安卓) 全部平台 另外，只统计新用户KPI，平台信息支持输出，不带浏览器，有2种结果。这样4+2=6种结果。 12private StatsCommonDimension statsCommon = new StatsCommonDimension();private BrowserDimension browser = new BrowserDimension(); 12private StatsUserDimension statsUserDimension = new StatsUserDimension(); private TimeOutputValue timeOutputValue = new TimeOutputValue(); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.sxt.transformer.mr.nu;import java.io.IOException;import java.util.List;import org.apache.commons.lang.StringUtils;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableMapper;import org.apache.hadoop.hbase.util.Bytes;import org.apache.log4j.Logger;import com.sxt.common.DateEnum;import com.sxt.common.EventLogConstants;import com.sxt.common.KpiType;import com.sxt.transformer.model.dim.StatsCommonDimension;import com.sxt.transformer.model.dim.StatsUserDimension;import com.sxt.transformer.model.dim.base.BrowserDimension;import com.sxt.transformer.model.dim.base.DateDimension;import com.sxt.transformer.model.dim.base.KpiDimension;import com.sxt.transformer.model.dim.base.PlatformDimension;import com.sxt.transformer.model.value.map.TimeOutputValue;public class NewInstallUserMapper extends TableMapper&lt;StatsUserDimension, TimeOutputValue&gt;&#123; private static final Logger logger = Logger.getLogger(NewInstallUserMapper.class); private StatsUserDimension statsUserDimension = new StatsUserDimension(); private TimeOutputValue timeOutputValue = new TimeOutputValue(); private byte[] family = Bytes.toBytes(EventLogConstants.EVENT_LOGS_FAMILY_NAME); //代表用户分析模块的统计 private KpiDimension newInstallUserKpi = new KpiDimension(KpiType.NEW_INSTALL_USER.name); //浏览器分析模块的统计 private KpiDimension newInstallUserOfBrowserKpi = new KpiDimension(KpiType.BROWSER_NEW_INSTALL_USER.name); @Override protected void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException &#123; String uuid = Bytes.toString(value.getValue(family, Bytes.toBytes(EventLogConstants.LOG_COLUMN_NAME_UUID))); String serverTime = Bytes.toString(value.getValue(family, Bytes.toBytes(EventLogConstants.LOG_COLUMN_NAME_SERVER_TIME))); String platform = Bytes.toString(value.getValue(family, Bytes.toBytes(EventLogConstants.LOG_COLUMN_NAME_PLATFORM))); System.out.println(uuid + "-" + serverTime +"-"+ platform); if (StringUtils.isBlank(uuid) || StringUtils.isBlank(serverTime) || StringUtils.isBlank(platform)) &#123; logger.warn("uuid&amp;servertime&amp;platform不能为空"); return; &#125; long longOfTime = Long.valueOf(serverTime.trim()); timeOutputValue.setTime(longOfTime); timeOutputValue.setId(uuid); DateDimension dateDimension = DateDimension.buildDate(longOfTime, DateEnum.DAY); // 设置date维度 StatsCommonDimension statsCommonDimension = this.statsUserDimension.getStatsCommon(); statsCommonDimension.setDate(dateDimension); List&lt;PlatformDimension&gt; platformDimensions = PlatformDimension.buildList(platform); String browserName = Bytes.toString(value.getValue(family, Bytes.toBytes(EventLogConstants.LOG_COLUMN_NAME_BROWSER_NAME))); String browserVersion = Bytes.toString(value.getValue(family, Bytes.toBytes(EventLogConstants.LOG_COLUMN_NAME_BROWSER_VERSION))); List&lt;BrowserDimension&gt; browserDimensions = BrowserDimension.buildList(browserName, browserVersion); //空浏览器维度，不考虑浏览器维度 BrowserDimension defaultBrowser = new BrowserDimension("", ""); for(PlatformDimension pfDimension : platformDimensions) &#123; statsUserDimension.setBrowser(defaultBrowser); statsCommonDimension.setKpi(newInstallUserKpi); statsCommonDimension.setPlatform(pfDimension); context.write(statsUserDimension, timeOutputValue); for(BrowserDimension browserDimension : browserDimensions) &#123; statsUserDimension.setBrowser(browserDimension); statsCommonDimension.setKpi(newInstallUserOfBrowserKpi); context.write(statsUserDimension, timeOutputValue); &#125; &#125; &#125;&#125; NewInstallUserReducer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.sxt.transformer.mr.nu;import java.io.IOException;import org.apache.hadoop.mapreduce.Reducer;import com.sxt.transformer.model.dim.StatsUserDimension;import com.sxt.transformer.model.value.map.TimeOutputValue;import com.sxt.transformer.model.value.reduce.MapWritableValue;import java.io.IOException;import java.util.HashSet;import java.util.Set;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.MapWritable;import org.apache.hadoop.mapreduce.Reducer;import com.sxt.common.KpiType;public class NewInstallUserReducer extends Reducer&lt;StatsUserDimension, TimeOutputValue, StatsUserDimension, MapWritableValue&gt;&#123; private MapWritableValue outputValue = new MapWritableValue(); private Set&lt;String&gt; unique = new HashSet&lt;String&gt;(); @Override protected void reduce(StatsUserDimension key, Iterable&lt;TimeOutputValue&gt; values, Reducer&lt;StatsUserDimension, TimeOutputValue, StatsUserDimension, MapWritableValue&gt;.Context context) throws IOException, InterruptedException &#123; this.unique.clear(); for(TimeOutputValue value : values) &#123; this.unique.add(value.getId()); &#125; MapWritable map = new MapWritable(); map.put(new IntWritable(-1), new IntWritable(unique.size())); outputValue.setValue(map); String kpiName = key.getStatsCommon().getKpi().getKpiName(); if (KpiType.NEW_INSTALL_USER.name.equals(kpiName)) &#123; outputValue.setKpi(KpiType.NEW_INSTALL_USER); &#125;else if (KpiType.BROWSER_NEW_INSTALL_USER.name.equals(kpiName)) &#123; outputValue.setKpi(KpiType.BROWSER_NEW_INSTALL_USER); &#125; context.write(key, outputValue); &#125;&#125; 注意检查配置jdbc:mysql://node01:3306/result_db zk配置 和 hdfs配置正确。 TransformerOutputFormat123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161package com.sxt.transformer.mr;import java.io.IOException;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.SQLException;import java.util.HashMap;import java.util.Map;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.mapreduce.JobContext;import org.apache.hadoop.mapreduce.OutputCommitter;import org.apache.hadoop.mapreduce.OutputFormat;import org.apache.hadoop.mapreduce.RecordWriter;import org.apache.hadoop.mapreduce.TaskAttemptContext;import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.log4j.Logger;import com.sxt.common.GlobalConstants;import com.sxt.common.KpiType;import com.sxt.transformer.model.dim.base.BaseDimension;import com.sxt.transformer.model.value.BaseStatsValueWritable;import com.sxt.transformer.service.IDimensionConverter;import com.sxt.transformer.service.impl.DimensionConverterImpl;import com.sxt.util.JdbcManager;/** * 自定义输出到mysql的outputformat类 * BaseDimension:reducer输出的key * BaseStatsValueWritable：reducer输出的value * @author root * */public class TransformerOutputFormat extends OutputFormat&lt;BaseDimension, BaseStatsValueWritable&gt; &#123; private static final Logger logger = Logger.getLogger(TransformerOutputFormat.class); /** * 定义每条数据的输出格式，一条数据就是reducer任务每次执行write方法输出的数据。 */ @Override public RecordWriter&lt;BaseDimension, BaseStatsValueWritable&gt; getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException &#123; Configuration conf = context.getConfiguration(); Connection conn = null; IDimensionConverter converter = new DimensionConverterImpl(); try &#123; conn = JdbcManager.getConnection(conf, GlobalConstants.WAREHOUSE_OF_REPORT); conn.setAutoCommit(false); &#125; catch (SQLException e) &#123; logger.error("获取数据库连接失败", e); throw new IOException("获取数据库连接失败", e); &#125; return new TransformerRecordWriter(conn, conf, converter); &#125; @Override public void checkOutputSpecs(JobContext context) throws IOException, InterruptedException &#123; // 检测输出空间，输出到mysql不用检测 &#125; @Override public OutputCommitter getOutputCommitter(TaskAttemptContext context) throws IOException, InterruptedException &#123; return new FileOutputCommitter(FileOutputFormat.getOutputPath(context), context); &#125; /** * 自定义具体数据输出writer * * @author root * */ public class TransformerRecordWriter extends RecordWriter&lt;BaseDimension, BaseStatsValueWritable&gt; &#123; private Connection conn = null; private Configuration conf = null; private IDimensionConverter converter = null; private Map&lt;KpiType, PreparedStatement&gt; map = new HashMap&lt;KpiType, PreparedStatement&gt;(); private Map&lt;KpiType, Integer&gt; batch = new HashMap&lt;KpiType, Integer&gt;(); public TransformerRecordWriter(Connection conn, Configuration conf, IDimensionConverter converter) &#123; super(); this.conn = conn; this.conf = conf; this.converter = converter; &#125; @Override /** * 当reduce任务输出数据是，由计算框架自动调用。把reducer输出的数据写到mysql中 */ public void write(BaseDimension key, BaseStatsValueWritable value) throws IOException, InterruptedException &#123; if (key == null || value == null) &#123; return; &#125; try &#123; KpiType kpi = value.getKpi(); PreparedStatement pstmt = null;//每一个pstmt对象对应一个sql语句 int count = 1;//sql语句的批处理，一次执行10 if (map.get(kpi) == null) &#123; // 使用kpi进行区分，返回sql保存到config中 pstmt = this.conn.prepareStatement(conf.get(kpi.name)); map.put(kpi, pstmt); &#125; else &#123; pstmt = map.get(kpi); count = batch.get(kpi); count++; &#125; batch.put(kpi, count); // 批量次数的存储 String collectorName = conf.get(GlobalConstants.OUTPUT_COLLECTOR_KEY_PREFIX + kpi.name); Class&lt;?&gt; clazz = Class.forName(collectorName); IOutputCollector collector = (IOutputCollector) clazz.newInstance();//把value插入到mysql的方法。由于kpi维度不一样。插入到不能表里面。 collector.collect(conf, key, value, pstmt, converter); if (count % Integer.valueOf(conf.get(GlobalConstants.JDBC_BATCH_NUMBER, GlobalConstants.DEFAULT_JDBC_BATCH_NUMBER)) == 0) &#123; pstmt.executeBatch(); conn.commit(); batch.put(kpi, 0); // 对应批量计算删除 &#125; &#125; catch (Throwable e) &#123; logger.error("在writer中写数据出现异常", e); throw new IOException(e); &#125; &#125; @Override public void close(TaskAttemptContext context) throws IOException, InterruptedException &#123; try &#123; for (Map.Entry&lt;KpiType, PreparedStatement&gt; entry : this.map.entrySet()) &#123; entry.getValue().executeBatch(); &#125; &#125; catch (SQLException e) &#123; logger.error("执行executeUpdate方法异常", e); throw new IOException(e); &#125; finally &#123; try &#123; if (conn != null) &#123; conn.commit(); // 进行connection的提交动作 &#125; &#125; catch (Exception e) &#123; // nothing &#125; finally &#123; for (Map.Entry&lt;KpiType, PreparedStatement&gt; entry : this.map.entrySet()) &#123; try &#123; entry.getValue().close(); &#125; catch (SQLException e) &#123; // nothing &#125; &#125; if (conn != null) try &#123; conn.close(); &#125; catch (Exception e) &#123; // nothing &#125; &#125; &#125; &#125; &#125;&#125; 运行run as java application 添加 运行参数 -d 2019-06-15 跑出结果，dimension_开头为维度表，stats_开头为真正的统计数据 hive和hbase整合参考 https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration 配置lib把hive-hbase-handler-1.2.1.jar cp到hbase/lib 下 1cp hive-hbase-handler-1.2.1.jar $HBASE_HOME/lib/ 同时把hbase中的所有的jar，cp到hive/lib 1cp -r $HBASE_HOME/lib/* ./ 在hive的配置文件增加属性：1234&lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node02,node03,node04&lt;/value&gt;&lt;/property&gt; 在hive中创建临时表12345678910CREATE EXTERNAL TABLE tmp_order(key string, id string, user_id string)STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,order:order_id,order:user_id")TBLPROPERTIES ("hbase.table.name" = "t_order");CREATE TABLE hbasetbl(key int, value string)STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")TBLPROPERTIES ("hbase.table.name" = "xyz", "hbase.mapred.output.outputtable" = "xyz"); hive分析sqoop输出到mysql在hive中创建hbase的event_log对应表123456CREATE EXTERNAL TABLE event_logs(key string, pl string, en string, s_time bigint, p_url string, u_ud string, u_sd string) ROW FORMAT SERDE 'org.apache.hadoop.hive.hbase.HBaseSerDe'STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'with serdeproperties('hbase.columns.mapping'=':key,log:pl,log:en,log:s_time,log:p_url,log:u_ud,log:u_sd')tblproperties('hbase.table.name'='eventlog'); 创建mysql在hive中的对应表123456789101112131415161718-- 2. 创建mysql在hive中的对应表，hive中的表，执行HQL之后分析的结果保存该表，然后通过sqoop工具导出到mysqlCREATE TABLE `stats_view_depth` ( `platform_dimension_id` bigint , `data_dimension_id` bigint , `kpi_dimension_id` bigint , `pv1` bigint , `pv2` bigint , `pv3` bigint , `pv4` bigint , `pv5_10` bigint , `pv10_30` bigint , `pv30_60` bigint , `pv60_plus` bigint , `created` string) row format delimited fields terminated by '\t';-- 3. hive创建临时表:把hql分析之后的中间结果存放到当前的临时表。CREATE TABLE `stats_view_depth_tmp`(`pl` string, `date` string, `col` string, `ct` bigint); 编写UDF编写UDF(platformdimension &amp; datedimension)需要注意，要删除DimensionConvertClient类中所有FileSystem关闭的操作 node03执行 1hive 1add jar /root/transform_date.jar; 创建hive的function 1create function date_convert as 'com.sxt.transformer.hive.DateDimensionUDF'; 统计用户角度的浏览深度分析得到临时表stats_view_depth_tmp tmp表 可以将tmp，拆分了看比较清晰。 统计每个用户、每个平台，在当天的访问次数 stats_view_depth_tmp groupby pl,day,pv数，将u_ud distinct求和，得出当天的平台的某个pv数的用户数，即pv 123456789101112131415161718192021222324-- 7. hql编写(统计用户角度的浏览深度)&lt;注意：时间为外部给定&gt;from ( select pl, from_unixtime(cast(s_time/1000 as bigint),'yyyy-MM-dd') as day, u_ud, (case when count(p_url) = 1 then "pv1" when count(p_url) = 2 then "pv2" when count(p_url) = 3 then "pv3" when count(p_url) = 4 then "pv4" when count(p_url) &gt;= 5 and count(p_url) &lt;10 then "pv5_10" when count(p_url) &gt;= 10 and count(p_url) &lt;30 then "pv10_30" when count(p_url) &gt;=30 and count(p_url) &lt;60 then "pv30_60" else 'pv60_plus' end) as pv from event_logs where en='e_pv' and p_url is not null and pl is not null and s_time &gt;= unix_timestamp('2019-06-15','yyyy-MM-dd')*1000 and s_time &lt; unix_timestamp('2019-06-16','yyyy-MM-dd')*1000 group by pl, from_unixtime(cast(s_time/1000 as bigint),'yyyy-MM-dd'), u_ud) as tmpinsert overwrite table stats_view_depth_tmp select pl,day,pv,count(distinct u_ud) as ct where u_ud is not null group by pl,day,pv; 多行转1行平台 日期 pv1 用户数 展开转换为 pv2 pv5 pv10 等都为0 平台 日期 pv1 0 0 0 0 用户数 pl date pv1 pv2 pv3 pv4 pv5 pv10 pv30 pv60 web_site 2019-06-15 5 0 0 0 0 0 0 0 1select pl,`date` as date1,ct as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv1' 这样之后，pv1到pv60，都合并求和。合并成1行。 12345678910111213141516171819202122232425--把临时表的多行数据，转换一行with tmp as(select pl,`date` as date1,ct as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv1' union allselect pl,`date` as date1,0 as pv1,ct as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv2' union allselect pl,`date` as date1,0 as pv1,0 as pv2,ct as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv3' union allselect pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,ct as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv4' union allselect pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,ct as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv5_10' union allselect pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,ct as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv10_30' union allselect pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,ct as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv30_60' union allselect pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,ct as pv60_plus from stats_view_depth_tmp where col='pv60_plus' union allselect 'all' as pl,`date` as date1,ct as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv1' union allselect 'all' as pl,`date` as date1,0 as pv1,ct as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv2' union allselect 'all' as pl,`date` as date1,0 as pv1,0 as pv2,ct as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv3' union allselect 'all' as pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,ct as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv4' union allselect 'all' as pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,ct as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv5_10' union allselect 'all' as pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,ct as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv10_30' union allselect 'all' as pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,ct as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv30_60' union allselect 'all' as pl,`date` as date1,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,ct as pv60_plus from stats_view_depth_tmp where col='pv60_plus')from tmpinsert overwrite table stats_view_depthselect 2,3,6,sum(pv1),sum(pv2),sum(pv3),sum(pv4),sum(pv5_10),sum(pv10_30),sum(pv30_60),sum(pv60_plus),'2019-06-15' group by pl,date1; 上面sql中的2，3，6要先计算出来，这里先手工填入。 sqoop脚本编写(统计用户角度)1sqoop export --connect jdbc:mysql://node01:3306/result_db --username root --password 123 --table stats_view_depth --export-dir /user/hive/warehouse/stats_view_depth/* --input-fields-terminated-by "\t" --update-mode allowinsert --update-key platform_dimension_id,data_dimension_id,kpi_dimension_id –export-dir hive表对应的hdfs位置 –input-fields-terminated-by hive表的字段分隔符 –update-mode 更新模式 –update-key 更新key 成功输出到mysql 12 3 6 0 0 0 0 1 0 0 0 2019-06-15 shell定时任务使用cron 定时执行sqoop命令 参考 `` 统计会话角度的浏览深度统计当天每个会话数段的tmp表： group by pl,date , u_sd 每个会话id的 pv数 stats_view_depth_tmp： 每个会话数段的 会话数 12345678-- 8. hql编写(统计会话角度的浏览深度)&lt;注意：时间为外部给定&gt;from (select pl, from_unixtime(cast(s_time/1000 as bigint),'yyyy-MM-dd') as day, u_sd, (case when count(p_url) = 1 then "pv1" when count(p_url) = 2 then "pv2" when count(p_url) = 3 then "pv3" when count(p_url) = 4 then "pv4" when count(p_url) &gt;= 5 and count(p_url) &lt;10 then "pv5_10" when count(p_url) &gt;= 10 and count(p_url) &lt;30 then "pv10_30" when count(p_url) &gt;=30 and count(p_url) &lt;60 then "pv30_60" else 'pv60_plus' end) as pvfrom event_logswhere en='e_pv' and p_url is not null and pl is not null and s_time &gt;= unix_timestamp('2019-06-15','yyyy-MM-dd')*1000 and s_time &lt; unix_timestamp('2019-06-16','yyyy-MM-dd')*1000group by pl, from_unixtime(cast(s_time/1000 as bigint),'yyyy-MM-dd'), u_sd) as tmpinsert overwrite table stats_view_depth_tmp select pl,day,pv,count(distinct u_sd) as ct where u_sd is not null group by pl,day,pv; 多行转1行date_convert 日期转换函数 platform_convert 平台转化函数 1234567891011121314151617181920212223242526272829with tmp as(select pl,date,ct as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv1' union allselect pl,date,0 as pv1,ct as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv2' union allselect pl,date,0 as pv1,0 as pv2,ct as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv3' union allselect pl,date,0 as pv1,0 as pv2,0 as pv3,ct as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv4' union allselect pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,ct as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv5_10' union allselect pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,ct as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv10_30' union allselect pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,ct as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv30_60' union allselect pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,ct as pv60_plus from stats_view_depth_tmp where col='pv60_plus' union allselect 'all' as pl,date,ct as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv1' union allselect 'all' as pl,date,0 as pv1,ct as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv2' union allselect 'all' as pl,date,0 as pv1,0 as pv2,ct as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv3' union allselect 'all' as pl,date,0 as pv1,0 as pv2,0 as pv3,ct as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv4' union allselect 'all' as pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,ct as pv5_10,0 as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv5_10' union allselect 'all' as pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,ct as pv10_30,0 as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv10_30' union allselect 'all' as pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,ct as pv30_60,0 as pv60_plus from stats_view_depth_tmp where col='pv30_60' union allselect 'all' as pl,date,0 as pv1,0 as pv2,0 as pv3,0 as pv4,0 as pv5_10,0 as pv10_30,0 as pv30_60,ct as pv60_plus from stats_view_depth_tmp where col='pv60_plus')from tmpinsert overwrite table stats_view_depthselect platform_convert(pl),date_convert(date),6,sum(pv1),sum(pv2),sum(pv3),sum(pv4),sum(pv5_10),sum(pv10_30),sum(pv30_60),sum(pv60_plus),'2019-06-15' group by pl,date;-- 9. sqoop脚步编写(统计会话角度)sqoop export --connect jdbc:mysql://node01:3306/result_db --username root --password 123 --table stats_view_depth --export-dir /user/hive/warehouse/stats_view_depth/* --input-fields-terminated-by "\t" --update-mode allowinsert --update-key platform_dimension_id,data_dimension_id,kpi_dimension_id-- 10. shell脚步编写 sqoop 将关系数据库（oracle、mysql、postgresql等）数据与hadoop数据进行转换的工具 sqoop由client端直接接入hadoop，任务通过解析生成对应的maprecue执行 安装node04中解压安装，注意下载完整版 http://www.apache.org/dyn/closer.lua/sqoop/1.4.7 1scp /Users/zhouxiaowu/big-data/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz root@node04:/root/ 12mv sqoop-1.4.7.tar.gz /usr/install/tar -zxvf sqoop-1.4.7.tar.gz 配置环境变量 123456vi /etc/profileexport SQOOP_HOME=/usr/install/sqoop-1.4.7export PATH=$PATH:$JAVA_HOME/bin:$ZOOKEEPER_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HBASE_HOME/bin:$SQOOP_HOME/binsource /etc/profile 添加数据库驱动包 1scp /Users/zhouxiaowu/big-data/hadoop项目1/01资料/mysql-connector-java-5.1.26-bin.jar root@node04:/root/ 1mv ~/mysql-connector-java-5.1.26-bin.jar lib/ 重命名配置文件 1mv sqoop-env-template.sh sqoop-env.sh 测试 12sqoop versionsqoop list-databases -connect jdbc:mysql://node01:3306/ -username root -password 123 去除警告 1vi configure-sqoop 去掉未安装服务相关内容， 例如（HBase、HCatalog、Accumulo） 1234#if [ ! -d "$&#123;HBASE_HOME&#125;" ]; then# echo "Error: $HBASE_HOME does not exist!"# echo 'Please set $HBASE_HOME to the root of your HBase installation.'# exit 1 http://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html 导入 命令行方式 文件配置方式 123$ sqoop import --connect jdbc:mysql://localhost/db --username foo --table TEST$ sqoop --options-file /users/homer/work/import.txt --table TEST 参考 http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html#_literal_sqoop_import_literal 123456create table t_test( id int default '0' null, name varchar(100) default '' null); mysql导入到hdfsvi option1 1234567891011121314151617import--connectjdbc:mysql://node01:3306/test--usernameroot--password123--as-textfile--columnsid,name--tablet_test--delete-target-dir--target-dir/sqoop/data-m1 1sqoop --options-file /root/sqoop_option/option1 mysql导入到hdfs，带查询1vi option2 123456789101112131415161718192021import--connectjdbc:mysql://node01/test--usernameroot--password123--as-textfile--query'select id, name, msg from psn where id like "1%" and $CONDITIONS'--delete-target-dir--target-dir/sqoop/tmp-m1--hive-home/home/hive-1.2.1--hive-import--create-hive-table--hive-tablet_test 导出参考 http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html#_literal_sqoop_export_literal 创建mysql表 12345create table t_test2( id int default '0' null, name varchar(100) default '' null) 创建命令配置 1vi option3 123456789101112131415export--connectjdbc:mysql://node01/test--usernameroot--password123-m1--columnsid,name--export-dir/sqoop/data--tablet_test2 执行 1sqoop --options-file /root/sqoop_option/option3]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java线程池设置指南]]></title>
    <url>%2F2019%2F06%2F12%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AE%BE%E7%BD%AE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[线程数设置公式1最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目 服务器CPU核数为4核，一个任务线程cpu耗时为20ms，线程等待（网络IO、磁盘IO）耗时80ms，那最佳线程数目：( 80 + 20 )/20 * 4 = 20。也就是设置20个线程数最佳。 从这个公式上面我们就得出，线程的等待时间越大，线程数就要设置越大，这个正好符合我们上面的分析，可提升CPU利用率。那从另一个角度上面说，线程数设置多大，是根据我们自身的业务的，需要自己去压力测试，设置一个合理的数值。 常用标准设置CPU密集型：操作内存处理的业务，一般线程数设置为：CPU核数 + 1 或者 CPU核数2核数为4的话，一般设置 5 或 8*IO密集型： 文件操作，网络操作，数据库操作，一般线程设置为：cpu核数 / (1-0.9)核数为4的话，一般设置 40]]></content>
      <categories>
        <category>java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[jfr采集使用及jmc分析]]></title>
    <url>%2F2019%2F06%2F11%2Fjfr%E9%87%87%E9%9B%86%E4%BD%BF%E7%94%A8%E5%8F%8Ajmc%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[找到java进程1ps -ef | grep java 解锁Java程序的商业特性1234jcmd 12174 VM.check_commercial_features12174:Commercial Features are locked. 采集JFR固定时长采集123jcmd $pid JFR.start name=myrec settings=temple delay=20s duration=2m filename=/tmp/$pid.jfrjcmd 12174 JFR.start name=10min.jfr settings=profile delay=3s duration=5m 持续采集JFR1jcmd 12174 JFR.start name=endless settings=profile delay=3s duration=0 compress=true 对于这种持续采集的任务，我们需要手动转存： 1jcmd 12174 JFR.dump recording=3 filename="/Users/jianyuan/Personal/dump_endless.jfr" compress=true 分析JFR文件线下输入jmc 1jmc 打开java mission control 选择打开导出的jfr文件 分析角度一般来说可以从下面几个方式来入手： 应用异常 热点线程和方法 不合预期的IO 过长的GC 参考 https://blog.csdn.net/yue530tomtom/article/details/80805412 http://www.manongjc.com/article/7589.html]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Arthas使用文档]]></title>
    <url>%2F2019%2F06%2F11%2FArthas%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[安装手动安装推荐https://alibaba.github.io/arthas/manual-install.html 使用命令watch 查看方法的返回值12watch demo.MathGame primeFactors returnObjwatch stack 查看方法调用栈参考 https://alibaba.github.io/arthas/stack.html 1stack demo.MathGame primeFactors thread参考 https://alibaba.github.io/arthas/thread.html 当前最忙的前N个线程1thread -n 3 找出当前阻塞其他线程的线程1thread -b]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HBase原理案例及搭建]]></title>
    <url>%2F2019%2F06%2F08%2FHBase%E5%8E%9F%E7%90%86%E6%A1%88%E4%BE%8B%E5%8F%8A%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[HBase 数据模型 Row Key Time Stamp CF1 CF2 CF3 11248112 t6 CF2:q1=val1 CF3:q3=val3 t3 t2 CF1:q2=val2 ROW KEY 决定一行数据 按照字典顺序排序的。 Row key只能存储64k的字节数据 Column Family列族 HBase表中的每个列都归属于某个列族，列族必须作为表模式(schema)定义的一部分预先给出。如create &#39;tbl&#39;, ‘cf’ 列名以列族作为前缀，cf:name 权限控制、存储以及调优都是在列族层面进行的； HBase把同一列族里面的数据存储在同一目录下，由几个文件保存。 Timestamp时间戳 在HBase每个cell存储单元对同一份数据有多个版本，根据唯一的时间戳来区分每个版本之间的差异，不同版本的数据按照时间倒序排序，最新的数据版本排在最前面。 时间戳的类型是 64位整型。 时间戳可以由HBase(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。 时间戳也可以由客户显式赋值，如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。 Cell单元格 由{row key， column(&lt;family&gt; +&lt;qualifier&gt;)， version}唯一确定的单元。 cell中的数据是没有类型的，全部是字节码形式存贮。 HLog(WAL log) HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是” 写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。 类似binlog HBase 架构 写流程 client记录写入数据，到Hlog memstore memstore达到阈值,写入到store file Client 包含访问HBase的接口并维护cache来加快对HBase的访问 Zookeeper 保证任何时候，集群中只有一个master 存贮所有Region的寻址入口。 实时监控Region server的上线和下线信息。并实时通知Master 存储HBase的schema和table元数据 Master 为Region server分配region 负责Region server的负载均衡 发现失效的Region server并重新分配其上的region 管理用户对table的增删改操作 RegionServer Region server维护region，处理对这些region的IO请求 Region server负责切分在运行过程中变得过大的region Region HBase自动把表水平划分成多个区域(region)，每个region会保存一个表里面某段连续的数据 每个表一开始只有一个region，随着数据不断插入表，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region（裂变） 当table中的行不断增多，就会有越来越多的region。这样一张完整的表被保存在多个Regionserver 上。 HRegion是HBase中分布式存储和负载均衡的最小单元。最小单元就表示不同的HRegion可以分布在不同的 HRegion server上。 HRegion由一个或者多个Store组成，每个store保存一个columns family。 每个Strore又由一个memStore和0至多个StoreFile组成。如图：StoreFile以HFile格式保存在HDFS上。 memstore 与 storefile 一个region由多个store组成，一个store对应一个CF（列族） store包括位于内存中的memstore和位于磁盘的storefile写操作先写入memstore，当memstore中的数据达到某个阈值，hregionserver会启动flashcache进程写入storefile，每次写入形成单独的一个storefile 当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、major compaction），在合并过程中会进行版本合并和删除工作（majar），形成更大的storefile 当一个region所有storefile的大小和数量超过一定阈值后，会把当前的region分割为两个，并由hmaster分配到相应的regionserver服务器，实现负载均衡 客户端检索数据，先在memstore找，找不到再找storefile SequeceFile的Value是HBase的KeyValue对象，即对应HFile中的KeyValue StoreFile 等价于hdfs file 读顺序 1.读memstore，没有则下一步 2.读block cache，没有则下一步 3.读store file 写顺序 1.写memstore，达到阈值，下一步 2.写store file HBase 完全HA分布式搭建 zookeeper master region server master backup node01 * node02 * * node03 * * node04 * * hbase-env.sh 配置conf中 jdk地址 使用自己配置zk，不适用hbase自带内置的zk 1234vi hbase-env.shexport JAVA_HOME=/usr/install/jdk/jdk1.8.0_171/export HBASE_MANAGES_ZK=false hbase-site.xml配置 hbase在hdfs的目录 是否分布式 zk地址 123456789101112131415vi hbase-site.xml&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node02,node03,node04&lt;/value&gt;&lt;/property&gt; regionservers配置123vi regionserversnode02 node03 backup-masters配置添加 backup-masters 123vi backup-mastersnode04 hdfs-site.xml复制1cp /opt/sxt/hadoop-2.6.5/etc/hadoop/hdfs-site.xml ./ 环境变量配置123456vi /etc/profileexport HBASE_HOME=/root/hbase-0.98.12.1-hadoop2export PATH=$PATH:$ZOOKEEPER_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HBASE_HOME/binsource /etc/profile 注意各节点的时间一致 给其他节点scp一份123scp -r hbase-0.98.12.1-hadoop2 root@node02:/root/scp -r hbase-0.98.12.1-hadoop2 root@node03:/root/scp -r hbase-0.98.12.1-hadoop2 root@node04:/root/ 启动start-hbase.sh需要提前启动node02、03、04的zk，start-hdfs.sh服务 1start-hbase.sh 验证是否启动成功123hbase shellhelpcreate 'tbl','cf' 123456hbase(main):023:0&gt; scan 'tbl'ROW COLUMN+CELL 1111 column=cf:age, timestamp=1559984836555, value=12 1111 column=cf:name, timestamp=1559984734803, value=zhangsan 2222 column=cf:sex, timestamp=1559984896283, value=boy2 row(s) in 0.0480 seconds 1get 'tbl','1111' 数据内容先写到memstore 执行flush，查看filestore http://node02:50070/explorer.html#/hbase/data/default/tbl/78a2935308b5f14d4c23a999ee797ed2/cf 1flush 'tbl' http://node02:50070/explorer.html#/hbase/data/default/tbl 1node01:60010 DDL操作进入client shell1hbase shell 帮助1help 创建表列族数量2到3个 1create 'tbl','cf1','cf2' 描述表1desc 'tbl' 列表list1list 删除表12disable 'tbl'drop 'tbl' 插入数据123put 'tbl','1111','cf:name','zhangsan'put 'tbl','1111','cf:age','12'put 'tbl','2222','cf:sex','boy' flush数据，memstore立即到store file，到hdfs中 1flush 'tbl' 查看数据查看全表1scan 'tbl' 查看单条1get 'tbl','1111' 溢写数据hbase shell执行 1flush 'eventlog' 查看hdfs的存储文件hdfs查看目录 /hbase/data/default/eventlog/43169c43dc06d3e24836e3291149f8e5/log 直接服务器执行 1hbase hfile -p -f /hbase/data/default/eventlog/43169c43dc06d3e24836e3291149f8e5/log/9bb18168d5e2437491a5adeaae62f864 hbase java实战表创建1234567891011121314151617181920private static void createTable() &#123; try &#123; Configuration conf = new Configuration(); conf.set("hbase.zookeeper.quorum", "node02,node03,node04"); admin = new HBaseAdmin(conf); HTableDescriptor desc = new HTableDescriptor(tableName); HColumnDescriptor columnDescriptor = new HColumnDescriptor("cf"); desc.addFamily(columnDescriptor); admin.createTable(desc); if (admin != null) &#123; admin.close(); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;&#125; 插入12345678910111213141516171819202122private static void insertTable() &#123; try &#123; Configuration conf = new Configuration(); conf.set("hbase.zookeeper.quorum", "node02,node03,node04"); HTable hTable = new HTable(conf, tableName); Put put = new Put("1111".getBytes()); put.add("cf".getBytes(), "name".getBytes(), "zhangsan".getBytes()); put.add("cf".getBytes(), "age".getBytes(), "12".getBytes()); put.add("cf".getBytes(), "sex".getBytes(), "boy".getBytes()); hTable.put(put); if (admin != null) &#123; admin.close(); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;&#125; 查询12345678910111213141516171819202122232425262728293031 private static void getTable() &#123; try &#123; Configuration conf = new Configuration(); conf.set("hbase.zookeeper.quorum", "node02,node03,node04"); HTable hTable = new HTable(conf, tableName); Get get = new Get("1111".getBytes()); // define return columns in family get.addColumn("cf".getBytes(), "name".getBytes()); get.addColumn("cf".getBytes(), "age".getBytes()); get.addColumn("cf".getBytes(), "sex".getBytes()); Result result = hTable.get(get); Cell cell = result.getColumnLatestCell("cf".getBytes(), "name".getBytes()); Cell cell2 = result.getColumnLatestCell("cf".getBytes(), "age".getBytes()); Cell cell3 = result.getColumnLatestCell("cf".getBytes(), "sex".getBytes());// System.out.println(new String( cell.getValue())); System.out.println(new String(CellUtil.cloneValue(cell))); System.out.println(new String(CellUtil.cloneValue(cell2))); System.out.println(new String(CellUtil.cloneValue(cell3))); if (admin != null) &#123; admin.close(); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125; &#125; Hbase出现ServerNotRunningYetException的解决方案因为hadoop处在安全模式下。所以hbase的操作会出现异常。 1hadoop dfsadmin -safemode leave hbase shell中使用list命令报错 https://blog.csdn.net/hll19950830/article/details/80022676]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hive原理案例及搭建]]></title>
    <url>%2F2019%2F05%2F21%2FHive%E5%8E%9F%E7%90%86%E6%A1%88%E4%BE%8B%E5%8F%8A%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Hive搭建in-memory derby内存数据库，实际不用 远程服务器模式 前面为hadoop部分 元数据 保存在MySQL namenode 主备 ZKFC datanode zookeeper JNN mysql hive Metastore Server hive client node01 * * * * node02 * * * * * * node03 * * * * node04 * * Thrift MetaStore Server mysql安装123解决无包可用，下载地址 http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpmrpm -ivh mysql-community-release-el7-5.noarch.rpmyum install -y mysql-server 服务mysql启动 1service mysqld start 12345mysqlshow databasesuse mysqlshow tablesdesc user; 修改授权用户密码 123456789select Host , User , Password from user;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123' WITH GRANT OPTION;delete from user where Host != '%';flush privileges;quitmysql -uroot -p;含义：ALL PRIVILEGES所有权限，*.*所有库所有表， %任何host root用户名 123密码 hive Metastore Server1234服务端需要连接mysqlscp apache-hive-1.2.1-bin.tar.gz mysql-connector-java-5.1.32-bin.jar root@node02:/root/tar zxvf apache-hive-1.2.1-bin.tar.gzcp mysql-connector-java-5.1.32-bin.jar apache-hive-1.2.1-bin/lib/ 环境变量 1234vi /etc/profileexport HIVE_HOME=/root/apache-hive-1.2.1-binexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/binsource /etc/profile 配置文件 参考 https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+Administration https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+Administration#AdminManualMetastoreAdministration-RemoteMetastoreServer 12345cd conf/mv hive-default.xml.template hive-site.xmlvi hive-site.xml从当前行 &lt;configuration&gt;下面一行， 删除到倒数-1行:.,$-1d 123456789101112131415161718192021222324&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://node01:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123&lt;/value&gt; &lt;/property&gt; 启动metastore server1hive --service metastore 也可使用hiveserver2 beeline方式 hive clientvi hive-site.xml 1:.,$-1d 连接metastore 环境变量 ./hive 1234567891011121314&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.local&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://node02:9083&lt;/value&gt; &lt;/property&gt; 12345&lt;property&gt; &lt;name&gt;hive.metastore.local&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; 可以去掉,避免waringMetastore is remote. Note: This is no longer needed as of Hive 0.10. Setting hive.metastore.uri is sufficient. 避免jline报错 123cd /opt/sxt/hadoop-2.6.5/share/hadoop/yarn/librm jline-0.9.94.jarcp /root/apache-hive-1.2.1-bin/lib/jline-2.12.jar ./ 启动 1hive hive操作12create table tbl(id int,age int);show tables; 1insert into tbl values(1,1); Time taken: 175.393 seconds 查看map reduece 执行job状态 http://node03:8088/cluster 1select * from tbl; 查看hdfs存储 http://node01:50070/explorer.html#/user/hive/warehouse/tbl 1hdfs dfs -cat /user/hive/warehouse/tbl/* hive数据类型: primitive_type | array_type 数组 | map_type map类型 | struct_type 结构体 ：primitive_type |TINYINT | SMALLINT | INT | BIGINT | BOOLEAN | FLOAT | DOUBLE | STRING 参考 https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-CreateTable 创建表内部表12345678910create table psn(id int,name string,likes array&lt;string&gt;,address map&lt;string,string&gt;)row format DELIMITEDFIELDS TERMINATED BY ','COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'; 1234人员表id,姓名,爱好，住址1,小明1,lol-book-movie,zhejiang:hangzhou-guangdong:shenzhen2,小明2,lol-book,zhejiang:hangzhou-guangdong:shenzhen 描述表1234desc psn;desc formatted psn;Table Type: MANAGED_TABLE 内部表 数据插入参考 https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Loadingfilesintotables 文件导入 1LOAD DATA LOCAL INPATH '/root/persondata' INTO TABLE psn; 1234hive&gt; select * from psn;OK1 小明1 ["lol","book","movie"] &#123;"zhejiang":"hangzhou","guangdong":"shenzhen"&#125;2 小明2 ["lol","book"] &#123;"zhejiang":"hangzhou","guangdong":"shenzhen"&#125; 外部表persondata为数据txt 12hdfs dfs mkdir /external_tablehdfs dfs -put persondata /external_table/ 创建table 1234567891011create EXTERNAL table psn_external(id int,name string,likes array&lt;string&gt;,address map&lt;string,string&gt;)row format DELIMITEDFIELDS TERMINATED BY ','COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'LOCATION '/external_table'; 123select * from psn_external;desc formatted psn_external;Table Type: EXTERNAL_TABLE 内部：删除元数据，及目录 外部：只删除元数据，存放目录不会删除 其他创建表方式1create table like table; 1create table psn2 as select id,name,likes from psn; 分区表单个字段分区按年龄分区 123id,年龄爱好，住址1,小明1,lol-book-movie,zhejiang:hangzhou-guangdong:shenzhen2,小明2,lofl-book,zhejiang:hangzhou-guangdong:shenzhen 1234567891011create table psn_partition(id int,name string,likes array&lt;string&gt;,address map&lt;string,string&gt;)PARTITIONED BY (age int)row format DELIMITEDFIELDS TERMINATED BY ','COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'; 通过分区指定年龄 12LOAD DATA LOCAL INPATH '/root/persondata' INTO TABLE psn_partition partition(age=10);LOAD DATA LOCAL INPATH '/root/persondata' INTO TABLE psn_partition partition(age=20); 多个字段分区按年龄和性别分区 1234567891011create table psn_partition_multi(id int,name string,likes array&lt;string&gt;,address map&lt;string,string&gt;)PARTITIONED BY (age int,sex string)row format DELIMITEDFIELDS TERMINATED BY ','COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'; 通过分区指定年龄、性别 123LOAD DATA LOCAL INPATH '/root/persondata' INTO TABLE psn_partition_multi partition(age=10,sex='boy');LOAD DATA LOCAL INPATH '/root/persondata' INTO TABLE psn_partition_multi partition(age=10,sex='girl');LOAD DATA LOCAL INPATH '/root/persondata' INTO TABLE psn_partition_multi partition(age=20,sex='girl'); 删除分区参考文档 https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-DropPartitions 10和20的girl二级分区都删掉 1ALTER TABLE psn_partition_multi DROP PARTITION (sex='girl'); 添加分区必须指定第一级分区年龄 1ALTER TABLE psn_partition_multi ADD PARTITION (age=10,sex='girl'); DMLfrom insert select方式1create table psn_copy like psn; 123FROM psnINSERT OVERWRITE TABLE psn_copySELECT id,name,likes,address; Hive Beelinehiveserver2node02 1hiveserver2 beelinenode03 1beeline 生产环境用 用户名、密码不校验 123!connect jdbc:hive2://node02:10000/default; root 123show tables; 123456780: jdbc:hive2://node02:10000/default&gt; select * from psn;+---------+-----------+-------------------------+-------------------------------------------------+--+| psn.id | psn.name | psn.likes | psn.address |+---------+-----------+-------------------------+-------------------------------------------------+--+| 1 | 小明1 | ["lol","book","movie"] | &#123;"zhejiang":"hangzhou","guangdong":"shenzhen"&#125; || 2 | 小明2 | ["lol","book"] | &#123;"zhejiang":"hangzhou","guangdong":"shenzhen"&#125; |+---------+-----------+-------------------------+-------------------------------------------------+--+2 rows selected (3.391 seconds) 退出 1!quit hive jdbc demo参考hivedemo 1234567891011121314151617181920public class HiveJdbcClient &#123; private static String driverName = "org.apache.hive.jdbc.HiveDriver"; public static void main(String[] args) throws SQLException &#123; try &#123; Class.forName(driverName); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; Connection conn = DriverManager.getConnection("jdbc:hive2://node02:10000/default", "root", ""); Statement stmt = conn.createStatement(); String sql = "select * from psn limit 5"; ResultSet res = stmt.executeQuery(sql); while (res.next()) &#123; System.out.println(res.getString(1) + "-" + res.getString("name")); &#125; &#125;&#125; hive 函数UDF 用户自定义函数12345678910111213141516package cn.laolian;import org.apache.hadoop.hive.ql.exec.UDF;import org.apache.hadoop.io.Text;public class TuoMin extends UDF &#123; public Text evaluate(final Text s) &#123; if (s == null) &#123; return null; &#125; String str = s.toString().substring(0, 3) + "***"; return new Text(str); &#125;&#125; eclipse 导出jar 包export jar node02 1hive --service metastore node03 12345hiveadd jar /root/tuomin.jar;create temporary function tm AS 'cn.laolian.TuoMin';select tm(name) from psn; 临时函数，当前会话有效 1234hive&gt; select tm(name) from psn;OK小明1***小明2*** UDAFUDTF 一进多出1select explode(likes) from psn; 12345678910: jdbc:hive2://node02:10000/default&gt; select explode(likes) from psn;+--------+--+| col |+--------+--+| lol || book || movie || lol || book |+--------+--+ hive参数打印头信息 方式一12hiveset hive.cli.print.header=true; 1set; 进行提示，导出配置 方式二 启动时设置1hive --hiveconf hive.cli.print.header=true; 只在当前会话有效 12345hive&gt; select * from psn;OKpsn.id psn.name psn.likes psn.address1 小明1 ["lol","book","movie"] &#123;"zhejiang":"hangzhou","guangdong":"shenzhen"&#125;2 小明2 ["lol","book"] &#123;"zhejiang":"hangzhou","guangdong":"shenzhen"&#125; 方式三 所有会话有效123vi .hiverchive.cli.print.header=true; 历史命令1cat .hivehistory Hive 动态分区严格模式：至少保证有一个静态分区 12set hive.exec.dynamic.partition=true;set hive.exec.dynamic.partition.mode=nostrict; 1vi persondata_daynamic_partition 12345id,姓名，年龄，性别，爱好，住址1,小明1,10,boy,lol-book-movie,zhejiang:hangzhou-guangdong:shenzhen2,小明2,10,man,lofl-book,zhejiang:hangzhou-guangdong:shenzhen3,小明3,20,boy,lofl-book,zhejiang:hangzhou-guangdong:shenzhen2,小明3,20,man,lofl-book,zhejiang:hangzhou-guangdong:shenzhen 原始表123456789101112create table psn_dynamic_partition(id int,name string,age int,sex string,likes array&lt;string&gt;,address map&lt;string,string&gt;)row format DELIMITEDFIELDS TERMINATED BY ','COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'; 1load data local inpath '/root/persondata_daynamic_partition' into table psn_dynamic_partition; 分区表1234567891011create table psn_dynamic_partition_r(id int,name string,likes array&lt;string&gt;,address map&lt;string,string&gt;)PARTITIONED BY (age int , sex string)row format DELIMITEDFIELDS TERMINATED BY ','COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'; 从原始表导入到分区表注意age,sex的顺序 123from psn_dynamic_partitioninsert overwrite table psn_dynamic_partition_r partition(age,sex)select id,name,likes,address,age,sex distribute by age,sex; Hive脚本运行方式12345hive -e "select * from psn"重定向hive -e "select * from psn" &gt; aaa静默输出hive -S -e "select * from psn" &gt; aaa 文件脚本12vi sqlselect * from psn 1hive -f sql hive client终端交互hdfs交互1234567hive&gt; dfs -ls / ;Found 5 itemsdrwxr-xr-x - root supergroup 0 2019-04-17 22:08 /datadrwxr-xr-x - root supergroup 0 2019-06-02 19:25 /external_table-rw-r--r-- 2 root supergroup 118 2019-06-02 19:10 /persondatadrwx------ - root supergroup 0 2019-06-02 11:55 /tmpdrwxr-xr-x - root supergroup 0 2019-06-02 12:06 /user linux交互12hive&gt; !pwd;/root Hive优化核心思想：hive SQL 当做Map Reduce程序去优化两种不会转化为Mapreduce执行 select仅查询本表字段 1select * from psn; select仅对本表字段做条件过滤 1select * from psn where id=1; Explain执行计划12explain select * from psn;explain extended select * from psn; 抓取策略这样会执行mapreduce，默认值more 12set hive.fetch.task.conversion=none;select * from psn; hive运行方式本地模式本地模式，开发测试用，生产不要用 12set hive.exec.mode.local.auto=true;select count(*) from psn; hive.exec.mode.local.inputbytes.max 默认值128M，大于该配置，也会以集群方法运行 并行计算]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring framwork技术体系目录]]></title>
    <url>%2F2019%2F05%2F15%2FSpring-framwork%E6%8A%80%E6%9C%AF%E4%BD%93%E7%B3%BB%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[异常处理在Spring中常见的全局异常处理，主要有三种： 注解 @ExceptionHandler 在 Controller 内部，用 @ExceptionHandler注解的方法，就会作为该Controller内部的异常处理方法。 该方式需要在每个类中处理异常，不适合全局异常处理。 继承HandlerExceptionResolver接口 1234567891011121314151617181920212223@Component@Slf4jpublic class CustomHandlerExceptionResolver implements HandlerExceptionResolver &#123; @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; Method method = null; if (handler != null &amp;&amp; handler instanceof HandlerMethod) &#123; method = ((HandlerMethod) handler).getMethod(); &#125; log.error("[&#123;&#125;] system error", method, ex); ResponseDTO response = ResponseDTO.builder() .errorCode(ErrorCode.SYSTEM_ERROR) .build(); byte[] bytes = JSON.toJSONString(response).getBytes(StandardCharsets.UTF_8)); try &#123; FileCopyUtils.copy(bytes, response.getOutputStream()); &#125; catch (IOException e) &#123; log.error("error", e); throw new RuntimeException(e); &#125; return new ModelAndView(); &#125;&#125; 函数还可以返回一个 ModelAndView 对象，表示渲染一个视图，比方说错误页面。不过，在前后端分离为主流架构的今天，这个很少用了。如果函数返回的视图为空，则表示不需要视图。 注解 @ControllerAdvice 1234567891011@ControllerAdvice(assignableTypes = &#123;GlobalExceptionHandlerMixin.class&#125;)public class ExceptionAdvice &#123; @ExceptionHandler(ErrorCodeWrapperException.class) @ResponseBody public ResponseDTO&lt;?&gt; exceptionHandler(ErrorCodeWrapperException e) &#123; if ((errCodeException.getErrorCode().equals(ErrorCode.SYSTEM_ERROR))) &#123; log.error(e); &#125; return ResponseDTO.ofErroCodeWrapperException(errCodeException); &#125;&#125; ControllerAdvice 支持的限定范围 按注解：@ControllerAdvice(annotations = RestController.class) 按包名：@ControllerAdvice(&quot;org.example.controllers&quot;) 按类型：@ControllerAdvice(assignableTypes = {ControllerInterface.class, AbstractController.class}) 源码对应 ExceptionHandlerExceptionResolver @ExceptionHandler @ControllerAdvice ResponseStatusExceptionResolver DefaultHandlerExceptionResolver MyHandlerExceptionResolver 参考文档 常见的Spring异常分析及处理 https://my.oschina.net/u/4007037/blog/3049044 Spring中的统一异常处理 http://www.importnew.com/29962.html Spring全局异常处理的三种方式 https://www.jianshu.com/p/f968b8dcf95a Spring RestFul API统一异常处理 http://daobin.wang/2017/05/spring-restful-api/]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[单点登录实现——基于OAuth2.0协议的接入方案]]></title>
    <url>%2F2019%2F04%2F16%2F%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E5%AE%9E%E7%8E%B0%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8EOAuth2-0%E5%8D%8F%E8%AE%AE%E7%9A%84%E6%8E%A5%E5%85%A5%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[参考 单点登录实现——基于OAuth2.0协议的接入方案 Spring Security Oauth2 单点登录案例实现和执行流程剖析 单点登录原理与简单实现 CAS实现单点登录SSO执行原理探究]]></content>
      <categories>
        <category>单点登录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hadoop MapReduce原理案例及搭建]]></title>
    <url>%2F2019%2F04%2F14%2FHadoop-MapReduce%E5%8E%9F%E7%90%86%E6%A1%88%E4%BE%8B%E5%8F%8A%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[MapReduce语义 MapTask(左边) a. block和切片：block是物理的存储，偏移量和位置信息；切片是逻辑概念。1:1 1:N N:1关系 b. 切片和map：1：1关系 。 数据多个切片，多个map。一个map有多个key。 c. 同一个map，根据partion的分区信息排序，再根据key，进行一次快排。 ReduceTask(右边) a. reduce最终数量由人，默认一个reduce。map和reduce的关系数目不固定。 b. 从其他map拿到相同的key，做归并排序。1个key不能分割，只能在一个分区partition（原语）。 shuffer洗牌 a. 一个切片split =&gt; 一个map=&gt; 内存根据分区和Key做一次快排 , (partition,key,value) 环形缓冲区，达到80%，产生溢写，快排 b. reduceTask是在一个分区partition，从不同的map，拿到相同的key。内部有序，外部无序，进行归并排序。 如上图 a. split进行逻辑分割，默认是一个block为一个split b. map操作，(key,value,partition)信息，排序可选 c. shuffler，洗牌，从不同的map拿到相同的Key，归并 d. reduce计算 e. 合并拿到最后结果 YARN HA部署 a. client提交任务，包含计算清单 b. ResourceManager根据NodeManager的状态，挑选一台，作为App Master c. App Master向ResourceManger发起资源请求，分配Container。当Container失败后，ResourceManager又会重新分配。 HDFS范围 YARN范围 namenode 主备 ZKFC datanode zookeeper JNN ResourceMangager NodeManager node01 * * * node02 * * * * * * node03 * * * * * node04 * * * * HDFS 分布式HA搭建参考上篇文档 hdfs1.0 就有了，考虑兼容，增加zkfc保证HA 。yarn是在2.0开发的，resourcemanger不用zkfc nodeManageer 和 dataNode 1比1关系 mapred-site.xml 1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; 标识mapreduce的框架为yarn yarn-site.xml 12345678910111213141516171819202122232425262728 &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;cluster1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;node03&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;node04&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;node02:2181,node03:2181,node04:2181&lt;/value&gt; &lt;/property&gt; a. mapreduce_shuffle标识，从多个map取出相同的key，shuffle过程 b.开启ha c. yarn的resourcemanager的逻辑和物理关系 d. yarn的resourcemanager的zk配置 分别复制到node02 node03 node04 1scp -r mapred-site.xml yarn-site.xml node02:/`pwd` node01上启动NodeManager，node02 node03 node04 1start-yarn.sh node03 node04手工启用resourcemanager 1yarn-daemon.sh start resourcemanager http://node03:8088/cluster/cluster 查看yarn resourcemanager状态 执行example单词计数 12345cd /opt/sxt/hadoop-2.6.5/share/hadoop/mapreduce#执行任务hadoop jar hadoop-mapreduce-examples-2.6.5.jar wordcount /user/root/test.txt /data/output/#从hdfs到本地hdfs dfs -get /data/output/part-r-00000 ~/result_count.txt 开发MapReduce，单词计数hadoop-2.6.5/share/hadoop 中的jar包，根目录及lib，复制到hadoop-user-lib中。配置成全局的user-libaray ，添加hadoop-2.6.5/share/hadoop/mapreduce/sources等作为source源码。 启动Main 12345678910111213141516171819202122232425262728293031323334353637public class MyWC &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(true); Job job =Job.getInstance(conf); job.setJarByClass(MyWC.class); job.setJobName("sxt-wc"); Path path = new Path("/user/root/test.txt"); FileInputFormat.addInputPath(job,path); Path output = new Path("/data/wc/output"); //存在删除文件 if (output.getFileSystem(conf).exists(output))&#123; output.getFileSystem(conf).delete(output,true); &#125; FileOutputFormat.setOutputPath(job,output); job.setMapperClass(MyMapper.class); job.setReducerClass(MyReducer.class); //map的kev vaule类型 job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(IntWritable.class); //output的key value类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); // Submit the job, then poll for progress until the job is complete job.waitForCompletion(true); &#125;&#125; Mapper 123456789101112131415public class MyMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;&#123; private final static IntWritable one = new IntWritable(1); private Text word = new Text(); //hello sxt 1 public void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123; StringTokenizer itr = new StringTokenizer(value.toString()); while (itr.hasMoreTokens()) &#123; word.set(itr.nextToken()); context.write(word, one); &#125; &#125;&#125; Reducer 12345678910111213public class MyReducer extends Reducer&lt;Text,IntWritable, Text,IntWritable&gt; &#123; private IntWritable result = new IntWritable(); public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123; int sum = 0; for (IntWritable val : values) &#123; sum += val.get(); &#125; result.set(sum); context.write(key, result); &#125;&#125; Build Artifact jar包，上传到服务器node01 1hadoop jar wordcount.jar com.sxt.hadoop.mapreduce.MyWC http://node04:8088 查看job执行 MapReduce Job运行源码解读客户端源码解读 入口 job.waitForCompletion(true); 1submit(); -&gt; submitter.submitJobInternal(Job.this, cluster); org.apache.hadoop.mapreduce.JobSubmitter#submitJobInternal 方法 计算切片和map，JobSubmitter197行 123int maps = writeSplits(job, submitJobDir);maps = writeNewSplits(job, jobSubmitDir); ReflectionUtils.newInstatnce 默认 TextInputFormat.class 继承 FileInputFormat input.getSplits(jb) FileInputFormat#getSplits 得到 blocklocations 1blkLocations = fs.getFileBlockLocations(file, 0, length); 计算切片的大小 若要切片比块大，配置minSize 比块大，得出的切片大小大于块 123long splitSize = computeSplitSize(blockSize, minSize, maxSize);Math.max(minSize, Math.min(maxSize, blockSize)); 123456789101112131415161718long blockSize = file.getBlockSize();long splitSize = computeSplitSize(blockSize, minSize, maxSize);long bytesRemaining = length;while (((double) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123; int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining); splits.add(makeSplit(path, length-bytesRemaining, splitSize, blkLocations[blkIndex].getHosts(), blkLocations[blkIndex].getCachedHosts())); bytesRemaining -= splitSize;&#125;if (bytesRemaining != 0) &#123; int blkIndex = getBlockIndex(blkLocations, length-bytesRemaining); splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining, blkLocations[blkIndex].getHosts(), blkLocations[blkIndex].getCachedHosts()));&#125; bytesRemaining剩余的字节数 length-bytesRemaining 得出的就是每个切片的偏移量 getBlockIndex 用切片的偏移量，在哪个块的偏移量和终止偏移量之间，得到第几个块 1234567for (int i = 0 ; i &lt; blkLocations.length; i++) &#123; // is the offset inside this block? if ((blkLocations[i].getOffset() &lt;= offset) &amp;&amp; (offset &lt; blkLocations[i].getOffset() + blkLocations[i].getLength()))&#123; return i; &#125;&#125; makeSplit 完成切片，传递path，切片的偏移量，切片的大小，block的locations的主机信息 1234protected FileSplit makeSplit(Path file, long start, long length, String[] hosts, String[] inMemoryHosts) &#123; return new FileSplit(file, start, length, hosts, inMemoryHosts);&#125; waitForCompletion submit() -&gt; submitter.submitJob -&gt; 197 line -&gt; writeSplites -&gt; writeNewSplits -&gt; ReflectionUtils.newInstatnce 默认 TextInputFormat.class input.getSplits(jb) -&gt; FileInputFormat继承 -&gt; minSize最小1 maxSize Long最大值 -》 file.getLen blkLocatons -&gt; fs.getFileSystem -&gt; fs.getFileBlockLocations(file ,0 ,length) 拿到文件的block清单 可切片 -》 splitSize = computeSpliteSize() 默认切片大小，minSize 比块大小大，得出的切片大小大于块 =》 FileInputFormt.setMinInputSplitSize(job,128) getBlockIndex 得到属于第几个块 lenth-byteRemainging 切片的偏移量 ， 切片的偏移量 在块的偏移量 和 块的结束偏移量之间，得到block的index 文件 切片偏移量 大小 getHosts主机 Thread.sleep -&gt; .tmp/haddp-yarn/staging/root.stagging/_003/ -&gt; jar包 job.split ; job.xml 运行配置清单 Mapper class Reduce.class TextFormat.minSize Map Task过程 Mapper.java 12345678910public void run(Context context) throws IOException, InterruptedException &#123; setup(context); try &#123; while (context.nextKeyValue()) &#123; map(context.getCurrentKey(), context.getCurrentValue(), context); &#125; &#125; finally &#123; cleanup(context); &#125;&#125; MapTask.java 12345678910111213141516171819202122232425262728293031323334353637public void run(final JobConf job, final TaskUmbilicalProtocol umbilical) throws IOException, ClassNotFoundException, InterruptedException &#123; this.umbilical = umbilical; if (isMapTask()) &#123; if (conf.getNumReduceTasks() == 0) &#123; mapPhase = getProgress().addPhase("map", 1.0f); &#125; else &#123; mapPhase = getProgress().addPhase("map", 0.667f); sortPhase = getProgress().addPhase("sort", 0.333f); &#125; &#125; TaskReporter reporter = startReporter(umbilical); boolean useNewApi = job.getUseNewMapper(); initialize(job, getJobID(), reporter, useNewApi); if (jobCleanup) &#123; runJobCleanupTask(umbilical, reporter); return; &#125; if (jobSetup) &#123; runJobSetupTask(umbilical, reporter); return; &#125; if (taskCleanup) &#123; runTaskCleanupTask(umbilical, reporter); return; &#125; if (useNewApi) &#123; runNewMapper(job, splitMetaInfo, umbilical, reporter); &#125; else &#123; runOldMapper(job, splitMetaInfo, umbilical, reporter); &#125; done(umbilical, reporter);&#125; a. conf.getNumReduceTasks() == 0 没有reduce环节，map时间占比100% 比如数据过滤，不经过reducer b. 否则的话， 经过 map、 排序 12mapPhase = getProgress().addPhase("map", 0.667f);sortPhase = getProgress().addPhase("sort", 0.333f); c. 最后runNewMapper(job, splitMetaInfo, umbilical, reporter); runNewMapper 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667void runNewMapper(final JobConf job, final TaskSplitIndex splitIndex, final TaskUmbilicalProtocol umbilical, TaskReporter reporter ) throws IOException, ClassNotFoundException, InterruptedException &#123; // make a task context so we can get the classes org.apache.hadoop.mapreduce.TaskAttemptContext taskContext = new org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl(job, getTaskID(), reporter); // make a mapper org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt; mapper = (org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;) ReflectionUtils.newInstance(taskContext.getMapperClass(), job); // make the input format org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt; inputFormat = (org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt;) ReflectionUtils.newInstance(taskContext.getInputFormatClass(), job); // rebuild the input split org.apache.hadoop.mapreduce.InputSplit split = null; split = getSplitDetails(new Path(splitIndex.getSplitLocation()), splitIndex.getStartOffset()); LOG.info("Processing split: " + split); org.apache.hadoop.mapreduce.RecordReader&lt;INKEY,INVALUE&gt; input = new NewTrackingRecordReader&lt;INKEY,INVALUE&gt; (split, inputFormat, reporter, taskContext); job.setBoolean(JobContext.SKIP_RECORDS, isSkipping()); org.apache.hadoop.mapreduce.RecordWriter output = null; // get an output object if (job.getNumReduceTasks() == 0) &#123; output = new NewDirectOutputCollector(taskContext, job, umbilical, reporter); &#125; else &#123; output = new NewOutputCollector(taskContext, job, umbilical, reporter); &#125; org.apache.hadoop.mapreduce.MapContext&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt; mapContext = new MapContextImpl&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;(job, getTaskID(), input, output, committer, reporter, split); org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;.Context mapperContext = new WrappedMapper&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;().getMapContext( mapContext); try &#123; input.initialize(split, mapperContext); mapper.run(mapperContext); mapPhase.complete(); setPhase(TaskStatus.Phase.SORT); statusUpdate(umbilical); input.close(); input = null; output.close(mapperContext); output = null; &#125; finally &#123; closeQuietly(input); closeQuietly(output, mapperContext); &#125;&#125; 反射初始化Mapper，业务实现的Mapper。JobContextImpl查看默认实现。 123org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt; mapper = (org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;) ReflectionUtils.newInstance(taskContext.getMapperClass(), job); 反射工具 Mapper 实例化 InputFormat实例化，JobContextImpl 默认TextINputFormat 12345public Class&lt;? extends InputFormat&lt;?,?&gt;&gt; getInputFormatClass() throws ClassNotFoundException &#123; return (Class&lt;? extends InputFormat&lt;?,?&gt;&gt;) conf.getClass(INPUT_FORMAT_CLASS_ATTR, TextInputFormat.class);&#125; 实例化NewTrakingRecordReader 123org.apache.hadoop.mapreduce.RecordReader&lt;INKEY,INVALUE&gt; input = new NewTrackingRecordReader&lt;INKEY,INVALUE&gt; (split, inputFormat, reporter, taskContext); MapTask.NewTrackingRecordReaderline 512 创建 RecordReader 1this.real = inputFormat.createRecordReader(split, taskContext); TextInputFormat实现 ， 参数为字节数组，返回 LineRecordReader 12345678910public RecordReader&lt;LongWritable, Text&gt; createRecordReader(InputSplit split, TaskAttemptContext context) &#123; String delimiter = context.getConfiguration().get( "textinputformat.record.delimiter"); byte[] recordDelimiterBytes = null; if (null != delimiter) recordDelimiterBytes = delimiter.getBytes(Charsets.UTF_8); return new LineRecordReader(recordDelimiterBytes);&#125; MapContextImpl的实现都是委托给LIneRecordReder reader.getCurrentKey reader.nestKeyValue() LineRecordReader1234567891011121314151617181920212223242526public LineRecordReader(Configuration job, FileSplit split, byte[] recordDelimiter) throws IOException &#123; this.maxLineLength = job.getInt(org.apache.hadoop.mapreduce.lib.input. LineRecordReader.MAX_LINE_LENGTH, Integer.MAX_VALUE); start = split.getStart(); end = start + split.getLength(); final Path file = split.getPath(); compressionCodecs = new CompressionCodecFactory(job); codec = compressionCodecs.getCodec(file); final FileSystem fs = file.getFileSystem(job); fileIn = fs.open(file); if (isCompressedInput()) &#123; ... &#125; else &#123; fileIn.seek(start); in = new UncompressedSplitLineReader( fileIn, job, recordDelimiter, split.getLength()); filePosition = fileIn; &#125; if (start != 0) &#123; start += in.readLine(new Text(), 0, maxBytesToConsume(start)); &#125; this.pos = start;&#125; fileIn.seek(start)直接从切片的偏移量开始读 start !=0 第二个切片开始都要处理， in.readLine(new Text(),0,) 读出第一行，换行符，不用，算出字节数 start = start + 数值 ，这样处理一行文本，被拆分到多个block的情况。 mappper -&gt; map 重写 -&gt; 输入 输出 context.write 340行 runNewMapper try finally 初始化 mapper.run 排序 释放 关闭 反射工具 Mapper 实例化 InputFormat实例化，默认TextINputFormat hadoop中spilte spark中是partition NewTrakingRecordReader 512行 inputFormat.createRecordReader -&gt; new LIneRecordReder 重要 MapContextImpl的实现 都是LIneRecordReder reader.getCurrentKey reader.nestKeyValue() LIneRecordReader initlize host信息已经在分配container做了，fileIn.seek(start)直接冲切片的偏移量开始读 start !=0 第二个切片开始都要处理， in.readLine(new Text(),0,) 读出第一行，换行符，不适用，算出字节数，start = start + 数值 每个切片都会多读1行，LineRecordReader ， 数据移动都是小量的 计算都是和fs拿文件，不是block块 this.pos = start 切片的第二行的偏移量 LIneRecordReader nextKeyValue key value赋值 output reducer数据为0 直接速出 NewOUtputCollerctor reduce数量就是partition数 只有1个分区，Partioner分区器，0 大于1的时候，morning hashPartitioner key.hashCOde &amp; Integer.max % reducetaskNum 输出 k ,v ，变为 k,v,p createSorting MapoutBuffer 初始化 sortmb 内存缓冲区 sorter 快排 comparotor 默认 设置排序器，没有取key的Text的默认 MapTask combiner: 被移植到map阶段的reducerTask 小reducer map输出一次，归并一次 MapoutBuffer 80%溢出写，中间20%继续，不会阻塞 map的输出 到 环形缓冲器 key和索引都放进去去 赤道 比较，索引换位置即可 MapTask&amp;MapOutBuffer spillyixie 次数 小于 SplliThread run Reducer 过程 ReducerTask ReducerTask run方法 line 376 触发shuffer过程 拉取数据。RawKeyValueIterator rIter 获取真迭代器，传入到reducerContext中。 1234567891011121314 org.apache.hadoop.mapreduce.Reducer.Context reducerContext = createReduceContext(reducer, job, getTaskID(), rIter, reduceInputKeyCounter, reduceInputValueCounter, trackedRW, committer, reporter, comparator, keyClass, valueClass);try &#123; reducer.run(reducerContext); &#125; finally &#123; trackedRW.close(reducerContext); &#125; 627 reduce.run 创建上下文 Reducer 1234567891011121314public void run(Context context) throws IOException, InterruptedException &#123; setup(context); try &#123; while (context.nextKey()) &#123; reduce(context.getCurrentKey(), context.getValues(), context); Iterator&lt;VALUEIN&gt; iter = context.getValues().iterator(); if(iter instanceof ReduceContext.ValueIterator) &#123; ((ReduceContext.ValueIterator&lt;VALUEIN&gt;)iter).resetBackupStore(); &#125; &#125; &#125; finally &#123; cleanup(context); &#125;&#125; reduce方法用户重写 ReduceContextImpl nextKeyValue() 从真迭代器取值，line138 1DataInputBuffer nextKey = input.getKey(); line 158 nextKeyIsSame根据分组比较器，比较下一次的key是否相同。 123456789101112hasMore = input.next();if (hasMore) &#123; nextKey = input.getKey(); nextKeyIsSame = comparator.compare(currentRawKey.getBytes(), 0, currentRawKey.getLength(), nextKey.getData(), nextKey.getPosition(), nextKey.getLength() - nextKey.getPosition() ) == 0;&#125; else &#123; nextKeyIsSame = false;&#125; 假迭代器，getValues方法返回 1private ValueIterable iterable = new ValueIterable(); doc文档 map中是无序到有序 reducer都是归并排序 ReduceTask run line 376 触发shuffer过程 拉取数据，没有spark优美,，真迭代器rIter 386 map task 环形缓冲区 的 。 分区比较器 map task 用户设置，没有则取key自身的排序器 reduce task 用户设置，分组比较器-》 排序比较器，没有取value自身的排序 627 reduce.run 创建上下文 Reducer.class run nexyKye nextKey 放空过 ReduceContestImpl.class nextKeyValue() 从真迭代器取值 hasMore nextKeyIsSmae 分组比较器 当前和取下一次的比较 getValues iterable ValueIterrable 假。迭代器 239行 案例 每个月最高气温的2天 MyMain 主入口 TMapper TSorterComparator 排序比较器。MapTask阶段用，80%环形缓冲区溢写，快排。 TPartition 分区比较器，决定key到哪个分区。分区数即reducerTask数。要么重写key的hash equals ,否则重写分区器。 TGroupComparator 分组比较器，ReducerTask阶段用。决定key是不是一组。 案例 词频搜索 TF*IDF微博账号总数、一个词有多少个微博包含 addCacheFile 每个map发送过去，作为本地文件 TF * idF LastJob LastMapper setup 数据集不是很大，很其他map都要关联 cmap : count 微博总数 df： 一个词有多少个微博包含 案例 电商广告推荐UserCF 用户的相似性，协同过滤 ItemCF 基于物品的协同过滤 MapReducer 用户评分向量 u1 : i1 i2 i3 u2: i2 i3 setp1 NullWrite.get() 不写 Run as java Application setp2 用户评分向量 setp3 同现矩阵 对称矩阵 setp4 setup 矩阵 * 向量 reduce相同的key为一组，物品作为Key]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[centos7虚拟机配置及网络配置]]></title>
    <url>%2F2019%2F03%2F31%2Fcentos7%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE%E5%8F%8A%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[虚拟机配置 添加虚拟机，选择centos7镜像 移除原有的网络适配器，添加网络适配器，选择桥接方式 静态ip配置1.ip addr查看网卡配置 2.cd /etc/sysconfig/network-scripts 修改ifcfg-ens33文件，注意NAME和DEVICE的名称同步。 12345678910111213141516171819202122232425TYPE="Ethernet"#BOOTPROTO="dhcp"DEFROUTE="yes"PEERDNS="yes"PEERROUTES="yes"IPV4_FAILURE_FATAL="no"IPV6INIT="yes"IPV6_AUTOCONF="yes"IPV6_DEFROUTE="yes"IPV6_PEERDNS="yes"IPV6_PEERROUTES="yes"IPV6_FAILURE_FATAL="no"NAME="ens33"UUID="157c8fb5-23b3-414c-8519-25bef9b20a54"DEVICE="ens33"#ONBOOT="yes"#static assignmentNM_CONTROLLED=no #表示该接口将通过该配置文件进行设置，而不是通过网络管理器进行管理ONBOOT=yes #开机启动BOOTPROTO=static #静态IPIPADDR=192.168.0.151 #本机地址NETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.0.255 #默认网关 3.配置/etc/sysconfig/network 123NETWORKING=yesHOSTNAME=node01GATEWAY=192.168.0.255 4.重启服务 service network restart]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[flume集群安装部署文档]]></title>
    <url>%2F2019%2F03%2F28%2Fflume%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[安装单节点参考文档 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#a-simple-example 上传解压123scp apache-flume-1.6.0-bin.tar.gz root@node02:/roottar -zxvf apache-flume-1.6.0-bin.tar.gzmv apache-flume-1.6.0-bin/ /usr/install/ 配置环境变量12vi /etc/profilesource /etc/profile 12export FLUME_HOME=/usr/install/apache-flume-1.6.0-binexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin:$HBASE_HOME/bin:$FLUME_HOME/bin 修改conf/flume-env.sh 文件中的JDK目录12cp flume-env.sh.template flume-env.shvi flume-env.sh 1export JAVA_HOME=/usr/install/jdk/jdk1.8.0_171 验证安装是否成功1flume-ng version 修改配置12cd conf/vi simple.conf 12345678910111213141516171819202122# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = node02a1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动flume1flume-ng agent -n a1 -c conf -f simple.conf -Dflume.root.logger=INFO,console 发送数据1telnet node02 44444 两个flume做集群参考文档 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#setting-multi-agent-flow 右侧节点(node03)参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#avro-source 1vi double-flume.conf 123456789101112131415161718192021# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.bind = node03a1.sources.r1.port = 60000# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f double-flume.conf -Dflume.root.logger=INFO,console 左侧节点(node02)参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#avro-sink 1scp -r apache-flume-1.6.0-bin/ root@node03:/usr/install 1vi double-flume.conf 1234567891011121314151617181920212223a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = node02a1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.hostname = node03a1.sinks.k1.port = 60000# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f double-flume.conf -Dflume.root.logger=INFO,console 发送数据1telnet node02 44444 Exec Source方式，监控文件tail命令参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#exec-source 配置1vi exec.conf 12345678910111213141516171819a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F /root/test.txt# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f exec.conf -Dflume.root.logger=INFO,console 添加数据循环添加数据 1for i in &#123;1..50&#125;; do echo "$i hi flume" &gt;&gt; /root/test.txt ; sleep 0.1; done Spooling Directory Source监控目录参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source 配置1vi spool.conf 1234567891011121314151617181920a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = spooldira1.sources.r1.spoolDir = /root/logsa1.sources.r1.fileHeader = true# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f spool.conf -Dflume.root.logger=INFO,console 拷贝文件演示mkdir logs mv aa logs/ flume和kafka两者经常配对使用，谁在前后都可以 hdfs sink方式参考 http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#hdfs-sink 配置1vi hdfs-sink.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = spooldira1.sources.r1.spoolDir = /root/logsa1.sources.r1.fileHeader = true# Describe the sink 文件目录格式a1.sinks.k1.type=hdfsa1.sinks.k1.hdfs.path=hdfs://mycluster/flume/%Y-%m-%d/%H%M##每隔60s或者文件大小超过10M的时候产生新文件，roll对文件设置# hdfs有多少条消息时新建文件，0不基于消息个数a1.sinks.k1.hdfs.rollCount=0# hdfs创建多长时间新建文件，0不基于时间a1.sinks.k1.hdfs.rollInterval=60# hdfs多大时新建文件，0不基于文件大小a1.sinks.k1.hdfs.rollSize=10240# 当目前被打开的临时文件在该参数指定的时间（秒）内，没有任何数据写入，则将该临时文件关闭并重命名成目标文件a1.sinks.k1.hdfs.idleTimeout=3a1.sinks.k1.hdfs.fileType=DataStreama1.sinks.k1.hdfs.useLocalTimeStamp=true## 每五分钟生成一个目录，round对目录设置# 是否启用时间上的”舍弃”，这里的”舍弃”，类似于”四舍五入”，后面再介绍。如果启用，则会影响除了%t的其他所有时间表达式a1.sinks.k1.hdfs.round=true# 时间上进行“舍弃”的值；a1.sinks.k1.hdfs.roundValue=5# 时间上进行”舍弃”的单位，包含：second,minute,houra1.sinks.k1.hdfs.roundUnit=minute# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f hdfs-sink.conf -Dflume.root.logger=INFO,console 拷贝文件演示12mkdir logsmv aa logs/ tengine和flume集成项目配置1vi tengine_project.conf 12345678910111213141516171819202122232425a1.sources = r1a1.sinks = k1a1.channels = c1## 监听tengine的access log文件a1.sources.r1.type = execa1.sources.r1.command = tail -F /opt/data/access.loga1.sinks.k1.type=hdfsa1.sinks.k1.hdfs.path=hdfs://mycluster/log/%Y%m%da1.sinks.k1.hdfs.rollCount=0a1.sinks.k1.hdfs.rollInterval=0a1.sinks.k1.hdfs.rollSize=10240a1.sinks.k1.hdfs.idleTimeout=5a1.sinks.k1.hdfs.fileType=DataStreama1.sinks.k1.hdfs.useLocalTimeStamp=truea1.sinks.k1.hdfs.callTimeout=40000a1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100a1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动1flume-ng agent -n a1 -c conf -f tengine_project.conf -Dflume.root.logger=INFO,console 拷贝文件演示12mkdir logsmv aa logs/]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop HDFS集群安装部署文档]]></title>
    <url>%2F2019%2F03%2F28%2Fhadoop%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[伪集群安装方式1.JAVA_HOME配置编辑/etc/profile，配置如下 12export JAVA_HOME=/usr/install/jdk/jdk1.8.0_171export PATH=$PATH:$&#123;JAVA_HOME&#125;/bin 2.HADOOP_HOME配置编辑/etc/profile，配置如下 12export HADOOP_HOME=/opt/sxt/hadoop-2.6.5export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 3.配置hostname编辑/etc/hostname 1node01 编辑/etc/sysconfig\network，配置如下 123NETWORKING=yesHOSTNAME=node01GATEWAY=192.168.0.255 配置静态ip，参考“centos7虚拟机配置” 配置hosts vi /etc/hosts 1234192.168.0.151 node01192.168.0.152 node02192.168.0.153 node03192.168.0.154 node04 执行hostname node01 执行uname -n，查看hostname ，为node1配置正常。 4.配置ssh12ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsacat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys 执行ssh node01，正常连接。 5.配置core-site.xml编辑/opt/sxt/hadoop-2.6.5/etc/hadoop/core-site.xml 配置namenode的内存持久化存储地址，hdfs是其中一种。 1234&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node01:9000&lt;/value&gt;&lt;/property&gt; vi命令,4yy复制4行，np再进行粘贴 配置hadoop.tmp.dir，根据core-default.xml的配置，默认配置是临时tmp目录/tmp/hadoop-${user.name}，会有被删除的风险。根据hdfs-default.xml的配置，dfs.namenode.name.dir的默认配置为file://${hadoop.tmp.dir}/dfs/name，dfs.datanode.data.dir的默认配置为file://${hadoop.tmp.dir}/dfs/data。 1234&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/var/sxt/hadoop/local&lt;/value&gt;&lt;/property&gt; 6.配置hdfs-site.xml编辑/opt/sxt/hadoop-2.6.5/etc/hadoop/hdfs-site.xml 配置dfs.replication block的副本为1，因为伪集群只有一个节点。 1234&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt; vi 4yy，再np粘贴 配置secondary的地址 1234&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node01:50090&lt;/value&gt;&lt;/property&gt; 7.配置hadoop-env.sh编辑/opt/sxt/hadoop-2.6.5/etc/hadoop/hadoop-env.xml，因为ssh免登会读不到JAVA_HOME的环境变量。 12# The java implementation to use.export JAVA_HOME=/usr/install/jdk/jdk1.8.0_171 8.hdfs格式化格式化namenode，/var/sxt/hadoop/local目录下会出现。生产环境，谨慎操作 data name namesecondary 1hdfs namenode -format 1start-dfs.sh 此时jps查看启动NameNode DataNode SecondaryNameNode 三个进程 cat /var/sxt/hadoop/local/dfs/data/current/VERSION，clusterID为集群id，一个集群的相同。 1234567#Fri Mar 29 23:44:23 CST 2019storageID=DS-ecfbb1c3-3054-432b-adc1-3d0420278192clusterID=CID-56727752-38bd-4609-8a00-e3166867c072cTime=0datanodeUuid=43d62867-0669-4277-b37f-859f7194bc51storageType=DATA_NODElayoutVersion=-56 9.为root用户创建用户目录hdfs dfs -mkdir /user/root 浏览器查看[http://192.168.0.117:50070](http://192.168.0.117:50070/) 10. 上传文件到用户目录1hdfs dfs -put hadoop-2.6.5.tar.gz /user/root 查看上传的文件 生成文件 1for i in ` seq 100000 `; do echo "hello sxt $i" &gt;&gt; test.txt;done 配置blocksize的大小，上传文件 1hdfs dfs -D dfs.blocksize=1048576 -put test.txt /user/root block块以文件的形式存储 1/var/sxt/hadoop/local/dfs/data/current/BP-280976167-127.0.0.1-1553874062300/current/finalized/subdir0/subdir0 1234567891011# hadoop-2.6.5.tar.gz两个block-rw-r--r--. 1 root root 134217728 3月 29 23:56 blk_1073741825-rw-r--r--. 1 root root 1048583 3月 29 23:56 blk_1073741825_1001.meta-rw-r--r--. 1 root root 49377148 3月 29 23:56 blk_1073741826-rw-r--r--. 1 root root 385767 3月 29 23:56 blk_1073741826_1002.meta# test.txt的两个block-rw-r--r--. 1 root root 1048576 3月 30 21:31 blk_1073741827-rw-r--r--. 1 root root 8199 3月 30 21:31 blk_1073741827_1003.meta-rw-r--r--. 1 root root 540319 3月 30 21:31 blk_1073741828-rw-r--r--. 1 root root 4231 3月 30 21:31 blk_1073741828_1004.meta 分布式集群部署方式 namenode datanode secondarynode node01(192.168.0.151) * node02(192.168.0.152) * * node03(192.168.0.153) * node04(192.168.0.154) * 1. ssh配置node01到node02 node03 node04切换到node01 12cd .sshscp id_dsa.pub root@192.168.0.152:`pwd`/node01.pub 切换到node02 12cd .sshcat node01.pub &gt;&gt; authorized_keys 如此配置node03 node04 2.hosts配置4台机器1vi /etc/hosts 配置如下 1234192.168.0.151 node01192.168.0.152 node02192.168.0.153 node03192.168.0.154 node04 3. 配置core-site.xml12cd /opt/sxt/hadoop-2.6.5/etc/hadoopvi core-site.xml 配置如下 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; # namenode启动节点及端口 &lt;value&gt;hdfs://node01:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/var/sxt/hadoop/full&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 4.配置datanode的slave节点12cd /opt/sxt/hadoop-2.6.5/etc/hadoopvi slaves 配置如下 123node02node03node04 5.配置hdfs-site.xml，datanode数据数量，secondarynode的启动节点1vi hdfs-site.xml 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; # datanode副本数量 &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; #secondarynode的启动节点 &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node02:50090&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 6.scp配置好的安装目录到其他3台12cd /optscp -r sxt root@192.168.0.152:/opt/ 7.format和启动在node01format和启动 http://192.168.0.151:50070/dfshealth.html#tab-datanode 可以查看datanode节点 12hdfs namenode -formatstart-dfs.sh ha高可用集群部署方式 namenode 主备，fsimage + editLog JournalNode 更新日志 ZKFC争抢锁，为namenode判断主节点 namenode 主备 ZKFC datanode zookeeper JNN node01 * * * node02 * * * * * node03 * * * node04 * * 需要配置node01 和 node02之间的相互免密 需要配置node01 到 node02 node03 node04的免密 需要配置node02 到 node01 node03 node04的免密 1.zookeeper安装(node02 node03 node04)编辑启用node02(192.168.0.152) 12345dataDir=/var/sxt/zkserver.1=192.168.0.152:2888:3888server.2=192.168.0.153:2888:3888server.3=192.168.0.154:2888:3888 12mkdir -p /var/sxt/zkecho "1" &gt; /var/sxt/zk/myid 依次启动node03 node04 会发现node03作为leader节点，比较版本最新，版本一次比较myid的大小。 启动完node02，node03的myid比较大，作为leader。启动node04的时候，leader节点已存在。 12zkServer.sh startzkServer.sh status 2.配置hdfs-site.xml配置逻辑和物理的关系 123456789101112131415161718192021222324&lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;node01:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;node02:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;node01:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;node02:50070&lt;/value&gt;&lt;/property&gt; 配置journalnode 和 ssh 123456789101112131415161718192021222324&lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://node01:8485;node02:8485;node03:8485/mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/var/sxt/hadoop/ha/jn&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_dsa&lt;/value&gt;&lt;/property&gt; 启用zkfc配置 1234&lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; 3.配置core-site.xml配置namenode的存储配置，以及zookeeper的配置 1234567891011121314&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/var/sxt/hadoop/ha&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node02:2181,node03:2181,node04:2181&lt;/value&gt; &lt;/property&gt; 复制配置文件到node02 node03 node04 1scp hdfs-site.xml core-site.xml node02:`pwd` 4.启动journalnode，node01 node02 node031hadoop-daemon.sh start journalnode 5.格式化namenode 格式化zkfczookeeper 启动namenode123hdfs namenode -formathdfs zkfc -formtZKhadoop-daemon.sh start namenode 查看zkCli.sh 1ls /hadoop-ha/mycluster 6.node02 复制配置，以standby方式启动1hdfs namenode -bootstrapStandby 7.最后启动 hdfs1start-dfs.sh 8.重启只需要启动zk，启动start-dfs.sh9.验证hahttp://node01:50070/dfshealth.html#tab-overview 查看node01为active状态 杀掉node01kill -9 namenode http://node02:50070/dfshealth.html#tab-overview node02变为active状态 从zk节点查看争抢锁状态 1get /hadoop-ha/mycluster/ActiveStandbyElectorLock 123456789101112 myclusternn2node02cZxid = 0x100000175ctime = Sat Apr 06 23:58:59 EDT 2019mZxid = 0x100000175mtime = Sat Apr 06 23:58:59 EDT 2019pZxid = 0x100000175cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x269f5aa4c8b003adataLength = 30numChildren = 0 重新启用node01 1hadoop-daemon.sh start namenode zkFC down之后，应该是zk争抢锁节点，失去心跳链接 服务器down之后的后果，也可正常切换 开发分布式存储windows eclipse开发配置1.使用eclipse mars解压，解压hadoop-2.6.5， 2.复制hadoop-2.6.5\sharre\hadoop中comon、hdfs、mapreduce、tools、yarn中的根目录的jar包，以及lib目录下的jar包，统一复制到目录，共121个，配置成user-library 3.配置HADOOP_HOME环境变量，HADOOP_USER_NAME环境变量为root，配置path 4.hadoop.dll 放到 c:/windows/system32下 5.复制服务机器配置中的core-site.xml hdfs-site.xml 到conf目录下，并将文件夹设置为resource 测试用例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package com.sxt.hadoop.hdfs;import java.io.BufferedInputStream;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.IOException;import java.io.InputStream;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.BlockLocation;import org.apache.hadoop.fs.FSDataOutputStream;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IOUtils;import org.junit.After;import org.junit.Before;import org.junit.Test;public class TetsHDFS &#123; Configuration conf = null; FileSystem fs = null; @Before public void connect() throws IOException&#123; conf = new Configuration(true); fs = FileSystem.get(conf); &#125; @After public void close() throws IOException&#123; fs.close(); &#125; @Test public void mkdir() throws IOException&#123; Path dirs = new Path("/data"); if(fs.exists(dirs))&#123; fs.delete(dirs,true); &#125; fs.mkdirs(dirs); &#125; @Test public void upload() throws IOException&#123; InputStream input = new BufferedInputStream(new FileInputStream( new File("D:\\uninstall\\redis\\redis\\redis.windows.conf"))); Path f = new Path("/data/ooxx.txt"); FSDataOutputStream out = fs.create(f); IOUtils.copyBytes(input, out, conf , true); &#125; @Test public void blocksize() throws IOException&#123; Path path = new Path("/user/root/test.txt"); FileStatus fileStatus = fs.getFileStatus(path); BlockLocation[] lcts = fs.getFileBlockLocations(fileStatus, 0, fileStatus.getLen()); for(BlockLocation lct : lcts)&#123; System.out.println(lct); &#125; &#125;&#125; 1234567891011121314for i in `seq 100` ;do echo "" &gt;&gt; test.txt;donefs.getFileStatus(f);Boclocatin[] fs.getFileBOckeLocations(file,0.file.getLen);sout(locaiton);FSInput fs.open(f);sout((cahr)in.redfByte());第二个块indexin.seek(1048576);跳过]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty ByteBuf]]></title>
    <url>%2F2019%2F03%2F08%2FNetty-ByteBuf%2F</url>
    <content type="text"><![CDATA[本章主要内容ByteBufByteBufHolderByteBufAllocator使用上述接口传输数据时一般都会使用一个缓冲区包装数据。Java的NIO有自己的Buffer类，，它们实现的功能有限并且没有优化过。使用JDK的ByteBuffer往往是比较麻烦也比较复杂的。缓冲区是网络应用非常重要的一个组件，有必要提供给开发者，并且应该是API的一部分。幸运的是，Netty提供了功能强大的缓冲区实现，它用来表示一个字节序列，帮助开发者操作原始字节数据或者自定义的Java对象。Netty中的缓冲区叫ByteBuf，实际上等价于JDK的ByteBuffer。ByteBuf的作用是通过Netty的管道传输数据。它从根本上解决了JDK缓冲区的问题，并且Netty应用开发者经常会使用到它，这些因素都让它有很强的生产力。在与JDK的缓冲期相比有很大优势。因为缓冲区传送数据都是通过Netty的ChannelPipeline和ChannelHandler，所以Netty应用都会使用到缓冲区API。 一、Buffer APINetty的Buffer API主要有两个接口：ByteBufByteBufHolderNetty缓冲API有以下几个优点：如果有需要你可以自定义缓冲类型内置复合缓冲类型实现零拷贝容量是按需扩展的，类似StringBuffer不需要通过调用flip()方法切换读写模式读索引和写索引是分开的方法调用是链式结构的引用技术功能自动释放资源池优化技术上面这些我们后面都会介绍，包括池优化技术。现在我们先从最常用的字节容器开始。 二、字节容器ByteBuf当你需要通过网络与对端如数据库交换数据时，都是通过字节来沟通的 ByteBuf是一个可以让你有效的读写字节数据的数据容器。为了易于操作，它使用了两个索引：一个用来读一个用来写。这样你只需要调整读索引就可以很方便的重复读取容器内的数据了。 2.1、工作方式当向ByteBuf写数据时，写索引会根据根据写入的字符数增加同样数值。当你开始读数据时，读索引也会增加，只有读写索引处于同一位置。然后ByteBuf就不可读了，如果继续读的话就会抛出IndexOutOfBoundsException异常，类似读数组越界一样。当调用任何以read或write开头的方法时，读写索引都会自动增长。也有一些相对操作方法如get或set，这些方法不会去移动索引，但会去操作给定的相对索引。ByteBuf是有容量上限的，如果将写索引移到超过容量上限的位置就会出现异常。默认的容量上限是Integer.MAX_VALUE。下图展示了ByteBuf的基本结构图。从上图可以看出，ByteBuf很类似字节数组，最明显的区别就是ByteBuf有分开了读写索引进行访问数据。 2.2、不同类型的ByteBuf常用的ByteBuf一共有三种，其他的也有不少，不过一般开发者很少会用到，都是Netty内部使用。可能你还会实现自己的缓冲区，不过这个不在本章内容之内。首先来看看你可能最感兴趣的缓冲。 堆缓冲最常用的ByteBuf是存储数据在JVM堆内存上的缓冲区。这种缓冲区内部实现就是一个数组。下面展示一下它的基本用法。 123456789101112ByteBuf heapBuf = ...;//检测ByteBuf是否有数组if (heapBuf.hasArray()) &#123; //获取数组引用 byte[] array = heapBuf.array(); //计算第一个字节所在位置 int offset = heapBuf.arrayOffset() + heapBuf.position(); //获取可读字节总数 int length = heapBuf.readableBytes(); //使用自己的业务逻辑处理数据 YourImpl.method(array, offset, length);&#125; 如果访问非堆内存ByteBuf的数组，就会抛出UnsupportedOperationException。因此访问ByteBuf数组之前应该使用hasArray()方法检测此缓冲区是否支持数组。 直接缓冲区另一个ByteBuf的实现是直接缓冲区。直接的意思就是这个缓冲区分配的内存是在JVM堆内存外部。使用直接内存时你不会在JVM堆空间中看见它的使用量。所以你计算你的应用内存使用量时，直接内存区域也要算上，然后限制它的最大使用量，防止系统内存不够用出现错误。通过网络传输数据时使用直接缓冲性能是很高的。下面的一部分代码展示了如何通过数组的方式访问直接缓冲区的数据。 123456789101112ByteBuf directBuf = ...;//检查缓冲区是否有数组，返回flase就是直接缓冲if (!directBuf.hasArray()) &#123;//获取可读字节数量int length = directBuf.readableBytes();//初始化相同长度的直接数组byte[] array = new byte[length];//读取数据到数组中directBuf.getBytes(array);//用户业务逻辑操作字节数组YourImpl.method(array, 0, array.length);&#125; 可以看出，直接缓冲区需要将数据复制到数组，如果你想直接通过字节数组访问数据，用堆缓冲区更好一些。 组合缓冲区现在来介绍一个组合缓冲区，它的名字叫CompositeByteBuf。人如其名，它允许你将不同类型的ByteBuf组合在一起并且提供访问他们的方式。CompositeByteBuf也像是各种类型ByteBuf的视图，它的hasArray()方法返回的false，因为它里面可能包含多个堆缓冲或直接缓冲。例如，一条消息可能由两个部分组成：消息头和消息体。模块化应用中，这两部分可能是由不同模块的产生并组合在一起然后再发送。很多时候，你发送的消息往往只修改一部分，比如消息体一样，改变消息头。这里就不用每次都重新分配缓存了 上面这种场景就很适合CompositeByteBuf，不需要内存拷贝，而且使用的是和非组合缓冲相同的API。下图展示了下面的伪代码展示这两个方式。 12345678//第一种使用数组组合ByteBuffer[] message = new ByteBuffer[] &#123; header, body &#125;;//第二种将头尾都复制到新的ByteBufferByteBuffer message2 = ByteBuffer.allocate(header.remaining()+ body.remaining());message2.put(header);message2.put(body);message2.flip(); 上面的方式都有很明显的缺点：使用数组处理，代码量及API都比较复杂。使用数据复制代价有很大，浪费时间和资源。下面我们看看Netty的CompositeByteBuf怎么处理这种情况。 CompositeByteBuf组合消息头和消息体的结构 CompositeBytebuf也是不能通过数组的方式直接访问其里面的数据。下面展示CompositeBytebuf怎么访问数据 123456789101112CompositeByteBuf compBuf = ...;ByteBuf heapBuf = ...;ByteBuf directBuf = ...;//将数据都放入到CompositeByteBufcompBuf.addComponent(heapBuf, directBuf).....//移除索引是0的数据，就像ListcompBuf.removeComponent(0);//遍历组合缓冲中的缓冲实例for (ByteBuf buf: compBuf) &#123; System.out.println(buf.toString());&#125; 三、ByteBuf的字节操作ByteBuf提供了很多读写内容的方法。 3.1、随机访问和原始字节数组一样，ByteBuf的索引也是从0开始的。也就是说它的第一个字节的位置是0，最后一个字节的位置是容量-1。例如下面的代码，可以直接遍历ByteBuf的所有字节，而不用去管它内部如何实现的。前面说过，使用set或get开头的方法不会增长它的读写索引，所以如果你使用上面的方式读取数据，可以写代码更新读写索引。 12345ByteBuf buffer = ...;for (int i = 0; i &lt; buffer.capacity(); i ++) &#123; byte b = buffer.getByte(i); System.out.println((char) b);&#125; 3.2、顺序访问ByteBuf提供了两个索引来支持顺序访问的需求，一个是readerIndex读索引支持读操作的，一个是writerIndex写索引支持写操作的，各自之间分工很明确。而JDK的ByteBuffer只有一个索引，所以每次切换读写模式的时候你都需要调用一下flip()方法。下图展示了ByteBuf被两个索引分成三个区域的结构。 3.3、可读字节内容(实际内容)ByteBuf中的实际内容存储在可读字节区域。以read或skip开头的方法，你读了多少数量的字节，相应的读索引就会增加多少下面的代码展示了如何读取ByteBuf中的所有可读内容。 1234ByteBuf buffer = ...;while (buffer.readable()) &#123; System.out.println(buffer.readByte());&#125; 3.4、可写字节这块区域是需要填充的未定义区域。以write开头的方法会从当前的writerIndex位置写入数据，并且写了多少数据,这个writerIndex也会增加相应的数量。如果写操作方法的参数也是一个ByteBuf并且没有指定源索引，则这个参数的读索引也会增长相应的数量。如果没有足够的可写区域了还继续使用写操作就会抛出IndexOutOfBoundException异常。新分配的ByteBuf的写索引默认值也是0。下面的代码展示了用Int类型数据填满可写区域。 1234ByteBuf buffer = ...;while (buffer.writableBytes() &gt;= 4) &#123; buffer.writeInt(random.nextInt());&#125; 3.5、派生缓冲区派生缓冲区，也就是创建一个已经存在的缓冲区的视图，可以调用duplicate(),slice(),slice(int, int),readOnly()和order(ByteOrder)等方法实现。派生缓冲区会产生自己的读写索引和其他标记索引，但是他们共享内部的数据。因为它们共享内部的数据，所以创建派生缓冲是没有什么性能损耗的，而且是比较好的方式，例如你想拥有一个缓冲区的切片。如果需要复制一个缓冲区，可以使用copy()或copy(int, int)方法。下面的代码展示了怎么获取一个ByteBuf的切片。 1234567891011Charset utf8 = Charset.forName(“UTF-8“);//根据给定的字符串内容创建一个ByteBufByteBuf buf = Unpooled.copiedBuffer(“xxxx“, utf8);//创建ByteBuf的切片，起始位置是0，截止位置是14ByteBuf sliced = buf.slice(0, 14);//打印切片内容，正常应该是"xxxx"System.out.println(sliced.toString(utf8);//修改索引0内容buf.setByte(0, (byte) ’J’);//断言会成功，因为他们共享内部的数据，其实修改的就是他们内部指向的共同数据块assert buf.get(0) == sliced.get(0); 可以发现，切片和原始ByteBuf里面的内容其实是同一块内存区域。现在我们来看看怎么复制ByteBuf，以及它和切片ByteBuf有什么不同，请看下面的代码。 1234567891011Charset utf8 = Charset.forName(“UTF-8“);//同样根据给定字符串创建ByteBufByteBuf buf = Unpooled.copiedBuffer(“xxx!“, utf8);//复制ByteBuf 0-14位置的内容ByteBuf copy = buf.copy(0, 14);//输出复制的ByteBuf内容，正常应该是"xxx"System.out.println(copy.toString(utf8);//同样修改内容buf.setByte(0, (byte) ’J’);//断言会成功，因为复制缓冲和原始缓冲并没有共享数据assert buf.get(0) != copy.get(0); API基本上都是一样的，不过不同的方式派生的ByteBuf，内部也会有细微差别一般情况下建议使用切片，除非必须不共享数据才使用复制方式。因为复制ByteBuf需要进行内存复制操作，不仅消耗更多资源，执行方法也会更耗时。 3.6、读写操作ByteBuf的读写操作共有两大类：基于索引的，指定索引读写相应位置的数据从当前索引读写数据，然后增长读写索引先来看一下这些方法，下面列出来的都是比较常用的方法，如果想看其他方法，请参考API DOC。先看一下读操作的。 名称描述getBoolean(int) 获取指定位置的Boolean类型数据getByte(int) 获取指定位置的字节内容getUnsignedByte(int) 获取指定位置的无符号字节内容getMedium(int) 获取指定位置的24位整数内容getUnsignedMedium(int) 获取指定位置的无符号24位整数内容getInt(int) 获取指定位置的Int类型内容getUnsignedInt(int) 获取指定位置的无符号Int类型内容getLong(int) 获取指定位置的Long类型内容getUnsignedLong(int) 获取指定位置的无符号Long类型内容getShort(int) 获取指定位置的Short类型内容getUnsignedShort(int) 获取指定位置的无符号Short类型内容getBytes(int, …) 从给定位置开始将数据转换到目标容器中名称描述setBoolean(int, boolean) 设置指定位置的Boolean类似数据setByte(int, int) 设置指定位置字节数据setMedium(int, int) 设置指定位置24位整数数据setInt(int, int) 设置指定位置Int类型数据setLong(int, long) 设置指定位置Long类型数据setShort(int, int) 设置指定位置Short类型数据setBytes(int,…) 从指定位置将源数据容器中转换过来它的set操作和get操作都很类似，请看下面的表格。你可能会发现set方法没有无符号类型的。这是因为在设置数据的时候没有无符号的概念。上面已经介绍了相关的方法，现在我们来看看怎么在实际代码中使用它们。Charset utf8 = Charset.forName(“UTF-8”);//根据字符串创建ByteBufByteBuf buf = Unpooled.copiedBuffer(“Netty in Action rocks!”, utf8);//打印位置0的字符，正常输出’N’System.out.println((char) buf.getByte(0));//查询现在的读写索引名称描述readBoolean() 读取当前读索引Boolean数据，同时读索引会加1readByte() 读取当前读索引Byte数据，同时读索引会加1readUnsignedByte() 读取当前读索引无符号Byte数据，同时读索引会加1readMedium() 读取当前读索引24位整数数据，同时读索引会加1readUnsignedMedium() 读取当前读索引无符号24位整数数据，同时读索引会加1readInt() 读取当前读索引Int类型数据，同时读索引会加1readUnsignedInt() 读取当前读索引无符号Int类型数据，同时读索引会加1readLong() 读取当前读索引Long类型数据，同时读索引会加1readUnsignedLong() 读取当前读索引无符号Long类型数据，同时读索引会加1readShort() 读取当前读索引Short类型数据，同时读索引会加1readUnsignedShort() 读取当前读索引无符号Short类型数据，同时读索引会加1readBytes(int) 从当前读索引读取指定长度的字节内容，读索引也会增加指定长度接下来介绍到的读写操作就是read和write开头的方法，前面说过，这些方法也会影响到缓冲的读写索引。这里面用到最多的方法就是把ByteBuf当成一个流来读取数据。同样，write方法相当于在ByteBuf上追加数据。常用的read方法如下表格。它的write方法基本上和read方法也是一一对应的。int readerIndex = buf.readerIndex();int writerIndex = buf.writerIndex();//修改位置0的数据buf.setByte(0, (byte)”B”);//再次打印位置0的数据，这次应该是’B’System.out.println((char) buf.getByte(0));//set或get方法不会改变读写索引assert readerIndex = buf.readerIndex();assert writerIndex = buf.writerIndex();名称描述writeBoolean(boolean) 在当前写索引位置写入Boolean类型数据，同时写索引加1writeByte(int) 当前写索引写入Byte类型数据，同时写索引加1writeMedium(int) 当前写索引写入24位整数数据，同时写索引会加3，24位=3字节writeInt(int) 在当前写索引写入32位整数数据，同时写索引加4，32位=4字节writeLong(long) 当前写索引写入64位整数数据，同时写索引加8，64位=8字节writeShort(int) 当前写索引写入Short类型数据，同时写索引加2writeBytes(ByteBuf src, intlength)从源数据中转换指定长度数据到当前写索引，同时写索引增加相应数量现在我们来看看上面这些read和write方法在实际项目中的应用。一直忘记了说一件事，获取当前读写索引的方法是不会修改读写索引。上面已经介绍了很多读写数据的方法，当然还有一些其他很有用的方法，下面会介绍这些方法。3.11、其他常用方法还有一些常用的方法我们没有介绍到，下表列出来这些常用方法，并简要介绍它们的用法。Charset utf8 = Charset.forName(“UTF-8”);//根据字符串创建ByteBufByteBuf buf = Unpooled.copiedBuffer(“xxx”, utf8);//打印首位置字符，正常是’x’System.out.println((char) buf.readByte());//获取当前的读写索引int readerIndex = buf.readerIndex();int writerIndex = buf.writerIndex();//修改写索引0位置的数据buf.writeByte( (byte) ‘?’);//写数据读索引不会变化，写索引会加1assert readerIndex = buf.readerIndex();assert writerIndex != buf.writerIndex();名称描述isReadable() 有一个字节可读就会返回trueisWritable() 有一个可写字节空间就会返回truereadableBytes() 返回可读字节内容总数writablesBytes() 返回可写内容区域总数capacity()返回缓冲区目前容量，如果超过这个数值，缓冲区会扩容， 只到达到maxCapacity()的限制maxCapacity() 返回缓冲区最大容量hasArray() 如果缓冲区内部以数组存储返回truearray() 返回内部存储的数组，如果没有数组则 抛出UnsupportedOperationException名称描述content() 返回它存储的内容的ByteBufcopy() 返回一个深拷贝的ByteBufHolder，也就是他们的数据不共享前面介绍的都是Java基础类型，但很多时候我们网络应用需要处理普通Java对象，也就是Java Bean。需要存储和检查，而且在容器中按照顺序存储也很重要。因此，Netty提供了另一个数据容器MessageBuf。 四、ByteBufHolder你有一个对象，里面很多属性，但是都是通过字节去传输的。例如，HTTP协议中的相应数据就很符合这种情况。HTTP响应数据有很多属性，如果状态码，Cookie等等，而且它实际的内容都是以字节方式传输的。因为这种情况很普遍，所以Netty抽象了一个接口ByteBufHolder。这样做的好处就是Netty可以优化分配ByteBuf，例如使用池技术，也能够自动释放这部分资源。ByteBufHolder实际上比较有用的方法就是访问它里面存储的数据以及使用引用计数功能。下表展示了它常用的方法。如果你传输的数据存储的是ByteBuf，那么使用ByteBufHolder是一个不错的选择。 4.1、Netty缓冲区帮助类使用JDK的NIO API的一个困难是完成一个简单的任务有很多重复性的代码。虽然Netty提供的缓冲区API已经很容易使用了，但是Netty还是提供了很多工具类方便开发者创建或使用缓冲区。名称描述buffer() 创建ByteBuf，类似可能是堆或直接的，依赖具体的实现buffer(int)buffer(int, int)heapBuffer() 创建堆类型ByteBufheapBuffer(int)heapBuffer(int, int)directBuffer() 创建直接类型ByteBufdirectBuffer(int)directBuffer(int, int)compositeBuffer() 创建复合类型缓冲区compositeBuffer(int)heapCompositeBuffer() 内部为堆类型ByteBuf的复合缓冲区heapCompositeBuffer(int)directCompositeBuffer() 内部为直接类型ByteBuf的复合缓冲区directCompositeBuffer(int)ioBuffer() 创建用于IO操作的ByteBuf 4.2、ByteBufAllocator前面提到过，Netty提供了池技术优化了各种ByteBuf。为了实现这个功能Netty抽象了一个ByteBufAllocator接口。它主要是用来分配ByteBuf实例的。我们先来看一下ByteBufAllocator提供了哪些操作。有些方法后面带了一个或两个Int类型参数，这两个参数就是指定ByteBuf的初始容量和最大容量的。你应该记得ByteBuf是可以扩容的。ByteBuf可以不断扩容只到达到了最大容量。获取ByteBufAllocator的引用也是很容易的事情。通过Channel或者你实现的ChannelHandler的方法中的ChannelHandlerContext。更多关于ChannelHandlerContext和ChannelHandler的知识将会在第六章介绍。下面的代码展示了获取ByteBufAllocator的方式。名称描述buffer() 创建未使用池技术的堆缓冲ByteBufbuffer(int)buffer(int, int)directBuffer() 创建未使用池技术的直接缓冲ByteBufdirectBuffer(int)directBuffer(int, int)wrappedBuffer() 创建包含给定数据的ByteBufcopiedBuffer() 复制给定数据然后创建ByteBuf 4.3、Unpooled有时候你没办法获取ByteBufAllocator的实例，也就是没办法使用上一节介绍的方式创建ByteBuf实例。为了应对这种情况，Netty提供了一个工具类Unpooled。这个工具类提供了很多静态方法帮助我们创建ByteBuf实例，不过没有使用池技术。 先来看看它提供了哪些常用方法给我们使用。你也可以在非Netty项目中使用Unpooled，因为它的API很简单，性能也很高，项目中如果需要这种高性能缓冲区的地方可以尝试一下。 4.4、ByteBufUtil另一个比较有用的类是ByteBufUtil。这个类提供了很多静态方法直接操作ByteBuf。相比较上面的Unpooled，这个类提供的方法是比较通用的并且不用关心你的ByteBuf是使用了池技术的还是没有使用。 例如它最常用的方法hexdump()，这个方法返回ByteBuf内容的十六进制格式。这个方法可以使用在很多场景，例如日志场景。十六进制格式的内容也很容易转成字节表示。你也许奇怪为什么不直接显示字节内容。主要是因为字节内容人类难以阅读，而16进制就比较友好了。 这个类提供了很多ByteBuf相关的静态方法，例如复制、编码、解码等等，这个大家在以后开发中会慢慢用到，甚至当你需要实现自己的ByteBuf的时候也会用到它们。 五、总结我们还学习了Netty的数据容器有哪些类型的实现，已经各自的使用场景和性能高低，还有分配或释放需要的资源代价。Channel channel = …;ByteBufAllocator allocator = channel.alloc();….ChannelHandlerContext ctx = …;ByteBufAllocator allocator2 = ctx.alloc();]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DES、AES、RSA等常用加密算法介绍与比较]]></title>
    <url>%2F2019%2F03%2F04%2FDES%E3%80%81AES%E3%80%81RSA%E7%AD%89%E5%B8%B8%E7%94%A8%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[加密算法分对称加密和非对称算法，其中对称加密算法的加密与解密密钥相同，非对称加密算法的加密密钥与解密密钥不同，此外，还有一类不需要密钥的散列算法。 ​ 常见的对称加密算法主要有DES、3DES、AES等，常见的非对称算法主要有RSA、DSA等，散列算法主要有SHA-1、MD5等。 非对称算法非对称加密算法的加密密钥与解密密钥不同 非对称加密，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。 通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。 既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密； 同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。 非对称式加密就是加密和解密所使用的不是同一个密钥，通常有两个密钥，称为”公钥”和”私钥”，它们两个必需配对使用，否则不能打开加密文件。发送双方A,B事先均生成一堆密匙，然后A将自己的公有密匙发送给B，B将自己的公有密匙发送给A，如果A要给B发送消 息，则先需要用B的公有密匙进行消息加密，然后发送给B端，此时B端再用自己的私有密匙进行消息解密，B向A发送消息时为同样的道理。 RSA非对称加密，公钥加密，私钥解密，反之亦然。由于需要大数的乘幂求模等算法，运行速度慢，不易于硬件实现。 通常私钥长度有512bit，1024bit，2048bit，4096bit，长度越长，越安全，但是生成密钥越慢，加解密也越耗时。 既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密； 同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。 DSADSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准），严格来说不算加密算法。 ECCECC（Elliptic Curves Cryptography）：椭圆曲线密码编码学。ECC和RSA相比，具有多方面的绝对优势，主要有：抗攻击性强。相同的密钥长度，其抗攻击性要强很多倍。计算量小，处理速度快。ECC总的速度比RSA、DSA要快得多。存储空间占用小。ECC的密钥尺寸和系统参数与RSA、DSA相比要小得多，意味着它所占的存贮空间要小得多。这对于加密算法在IC卡上的应用具有特别重要的意义。带宽要求低。当对长消息进行加解密时，三类密码系统有相同的带宽要求，但应用于短消息时ECC带宽要求却低得多。带宽要求低使ECC在无线网络领域具有广泛的应用前景。 对称加密算法对称式加密就是加密和解密使用同一个密钥。信息接收双方都需事先知道密匙和加解密算法且其密匙是相同的，之后便是对数据进行加解密了。对称加密算法用来对敏感数据等信息进行加密。 对称加密算法的加密与解密密钥相同 AESAES（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别高；AES是一个使用128为分组块的分组加密算法，分组块和128、192或256位的密钥一起作为输入，对4×4的字节数组上进行操作。众所周之AES是种十分高效的算法，尤其在8位架构中，这源于它面向字节的设计。AES 适用于8位的小型单片机或者普通的32位微处理器,并且适合用专门的硬件实现，硬件实现能够使其吞吐量（每秒可以到达的加密/解密bit数）达到十亿量级。同样，其也适用于RFID系统。 对称加密，密钥最长只有256个bit，执行速度快，易于硬件实现。由于是对称加密，密钥需要在传输前通讯双方获知。 基于以上特点，通常使用RSA来首先传输AES的密钥给对方，然后再使用AES来进行加密通讯。 DESDES（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。 3DES3DES（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。 散列算法散列算法，又称哈希函数，是一种单向加密算法。在信息安全技术中，经常需要验证消息的完整性，散列(Hash)函数提供了这一服务，它对不同长度的输入消息，产生固定长度的输出。这个固定长度的输出称为原输入消息的”散列”或”消息摘要”(Message digest)。散列算法不算加密算法，因为其结果是不可逆的，既然是不可逆的，那么当然不是用来加密的，而是签名。 散列算法主要有SHA-1、MD5等 MD5输出128bit、SHA1输出160bit、SHA256输出256bitSHA-1是160位的哈希值，而SHA-2是组合值，有不同的位数，其中最受欢迎的是256位。 因为SHA-2有多种不同的位数，导致这个名词有一些混乱。但是无论是“SHA-2”，“SHA-256”或“SHA-256位”，其实都是指同一种加密算法。但是SHA-224，“SHA-384”或“SHA-512”，表示SHA-2的二进制长度。还要另一种就是会把算法和二进制长度都写上，如“SHA-2 384”。 SSL行业选择SHA作为数字签名的散列算法，从2011到2015，一直以SHA-1位主导算法。但随着互联网技术的提升，SHA-1的缺点越来越突显。从去年起，SHA-2成为了新的标准，所以现在签发的SSL证书，必须使用该算法签名。 也许有人偶尔会看到SHA-2 384位的证书，很少会看到224位，因为224位不允许用于公共信任的证书，512位，不被软件支持。初步预计，SHA-2的使用年限为五年，但也许会被提前淘汰。这需要时间来验证。 以一个60M的文件为测试样本，经过1000次的测试平均值，三种算法的表现为： 123MD5算法运行1000次的平均时间为：226msSHA1算法运行1000次的平均时间为：308msSHA256算法运行1000次的平均时间为：473ms123 安全性方面，显然SHA256（又称SHA2）的安全性最高，但是耗时要比其他两种多很多。MD5相对较容易破解，因此，SHA1应该是这三种中性能最好的一款加密算法。]]></content>
      <categories>
        <category>安全</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用Spring5的Webflux开发Reactive应用（SSE 、Websocket)]]></title>
    <url>%2F2019%2F02%2F26%2F%E4%BD%BF%E7%94%A8Spring5%E7%9A%84Webflux%E5%BC%80%E5%8F%91Reactive%E5%BA%94%E7%94%A8%EF%BC%88SSE-%E3%80%81Websocket%2F</url>
    <content type="text"><![CDATA[对 Java 开发者来说，2017 年 9 月是个热闹的月份，Java SE 9、Java EE 8 相继发布，而 Spring 也在这段时间，发布了 5.0 正式版本。 身为 Java 开发者，对于 Spring 框架并不陌生。Spring 在 Rod Johnson 十几年前一个人单挑 J2EE 体系开始，到十年前开始大行其道至今，基本上已是 Java 开发领域的事实标准了。 Spring 5 中最重要改动是把反应式编程的思想应用到了框架的各个方面，Spring 5 的反应式编程以 Reactor 库为基础。Spring 5 框架所包含的内容很多，这里只重点介绍其中新增的 WebFlux 模块。我们可以使用 WebFlux 创建高性能的 Web 应用和客户端。本文对 WebFlux 模块进行了详细介绍，包括其中的 HTTP、服务器推送事件（SSE）和 WebSocket 支持。 WebFlux 简介WebFlux 模块的名称是 spring-webflux，名称中的 Flux 来源于 Reactor 中的类 Flux。该模块中包含了对反应式 HTTP、服务器推送事件和 WebSocket 的客户端和服务器端的支持。对于开发人员来说，比较重要的是服务器端的开发，这也是本文的重点。在服务器端，WebFlux 支持两种不同的编程模型：第一种是 Spring MVC 中使用的基于 Java 注解的方式；第二种是基于 Java 8 的 Lambda 表达式的函数式编程模型。这两种编程模型只是在代码编写方式上存在不同。它们运行在同样的反应式底层架构之上，因此在运行时是相同的。WebFlux 需要底层提供运行时的支持，WebFlux 可以运行在支持 Servlet 3.1 非阻塞 IO API 的 Servlet 容器上，或是其他异步运行时环境，如 Netty 和 Undertow。 Spring Boot 2 是基于 Spring 5 的，其中一个比较大的更新就在于支持包括 spring-webflux 和响应式的 spring-data 在内的响应式模块，下边的例子我们就用 Spring Boot 2 在进行搭建。 本文从三个方面对 WebFlux 进行介绍。首先是使用经典的基于 Java 注解的编程模型来进行开发，其次是使用 WebFlux 新增的函数式编程模型来进行开发，最后介绍 WebFlux 应用的测试。通过这样循序渐进的方式让读者了解 WebFlux 应用开发的细节。 Java 注解编程模型基于 Java 注解的编程模型，对于使用过 Spring MVC 的人来说是再熟悉不过的。在 WebFlux 应用中使用同样的模式，容易理解和上手。我们先从最经典的 Hello World 开始说明。 我们通过 Spring Initializ 创建一个 Spring Boot 工程，因为目前我们还不涉及 DAO 层，所以只选择 Reactive Web 就行了 也可以使用网页版的 https://start.spring.io 来创建项目： 创建后的项目 POM 中，包含下边的依赖，即表示基于 Spring WebFlux： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt; 创建 Controller 类HelloController，仅提供一个 Endpoint/hello： 123456789@RestControllerpublic class HelloController &#123; @GetMapping("/hello") public Mono&lt;String&gt; sayHello()&#123; return Mono.just("Hello World!"); &#125;&#125; 我们启动应用，通过访问 http://localhost:8080/hello 可以得到返回值Hello World!。 通过这个简单的 Hello World 示例我们可以看到使用 WebFlux 与 Spring MVC 的不同在于，WebFlux 所使用的类型是与反应式编程相关的 Flux 和 Mono 等，而不是简单的对象。对于简单的 Hello World 示例来说，这两者之间并没有什么太大的差别。对于复杂的应用来说，反应式编程和负压的优势会体现出来，可以带来整体的性能的提升。 RESTful API简单的 Hello World 示例并不足以说明 WebFlux 的用法。在下面的小节中，本文将介绍其他具体的实例。先从 RESTful API 开始说起。RESTful API 在 Web 服务器端应用中占据了很大的一部分。我们通过一个具体的实例来说明如何使用 WebFlux 来开发 RESTful API，该 RESTful API 用来对用户数据进行基本的 CRUD 操作。 作为领域对象的User类中包含了id、name和email三个基本的属性。 123456789101112@Data // 生成无参构造方法 getter setter hashCode equals toString@AllArgsConstructor // 生成所有参数构造方法@NoArgsConstructor // @AllArgsConstructor 会导致 @Data 不生成无参构造方法，需要手动添加 @NoArgsConstructor，如果没有无参构造方法，可能会导致比如 com.fasterxml.jackson 在序列化处理时报错public class User &#123; private Integer id; private String name; private String email;&#125; 为了对User类进行操作，我们需要提供服务类UserService。UserService使用一个 Map 来保存所有用户的信息，并不是一个持久化的实现，这对于示例应用来说已经足够了。 123456789101112131415161718192021222324252627282930313233343536373839@Servicepublic class UserService &#123; private final Map&lt;Integer, User&gt; data = new ConcurrentHashMap&lt;&gt;(); @PostConstruct private void init() &#123; data.put(1, new User(1, "张三", "z3@qq.com")); data.put(2, new User(2, "李四", "l4@qq.com")); data.put(3, new User(3, "王五", "w5@qq.com")); &#125; public Flux&lt;User&gt; list() &#123; return Flux.fromIterable(this.data.values()); &#125; public Flux&lt;User&gt; getByIds(Flux&lt;Integer&gt; ids) &#123; return ids.flatMap(id -&gt; Mono.justOrEmpty(this.data.get(id))); &#125; public Mono&lt;User&gt; getById(Integer id) &#123; return Mono.justOrEmpty(this.data.get(id)) .switchIfEmpty(Mono.error(new ResourceNotFoundException())); &#125; public Flux&lt;User&gt; createOrUpdate(Flux&lt;User&gt; users) &#123; return users.doOnNext(user -&gt; this.data.put(user.getId(), user)); &#125; public Mono&lt;User&gt; createOrUpdate(User user) &#123; this.data.put(user.getId(), user); return Mono.just(user); &#125; public Mono&lt;User&gt; delete(Integer id) &#123; return Mono.justOrEmpty(this.data.remove(id)); &#125;&#125; UserController是具体的 Spring MVC 控制器类，它使用UserService来完成具体的功能。UserController中使用了注解@ExceptionHandler来添加了ResourceNotFoundException异常的处理方法，并返回 404 错误。UserController中的方法都很简单，只是简单地代理给UserService中的对应方法。 123456789101112131415161718192021222324252627282930313233343536373839@RestController@RequestMapping("/user")public class UserController &#123; @Autowired private UserService userService; @ExceptionHandler(ResourceNotFoundException.class) @ResponseStatus(code = HttpStatus.NOT_FOUND, reason = "User not found") public void notFound()&#123;&#125; @GetMapping("") public Flux&lt;User&gt; list() &#123; return userService.list(); &#125; @GetMapping("/&#123;id&#125;") public Mono&lt;User&gt; getById(@PathVariable Integer id)&#123; return userService.getById(id); &#125; @PostMapping("") public Flux&lt;User&gt; create(@RequestBody Flux&lt;User&gt; users)&#123; return userService.createOrUpdate(users); &#125; @PutMapping("/&#123;id&#125;") public Mono&lt;User&gt; update(@PathVariable Integer id, @RequestBody User user)&#123; Objects.requireNonNull(user); user.setId(id); return userService.createOrUpdate(user); &#125; @DeleteMapping("/&#123;id&#125;") public Mono&lt;User&gt; delete(@PathVariable Integer id)&#123; return userService.delete(id); &#125;&#125; 我们可以通过访问 http://127.0.0.1:8080/user 获取到用户信息，其他的 CRUD 操作可以自行测试 1234567891011121314151617[ &#123; "id": 1, "name": "张三", "email": "z3@qq.com" &#125;, &#123; "id": 2, "name": "李四", "email": "l4@qq.com" &#125;, &#123; "id": 3, "name": "王五", "email": "w5@qq.com" &#125;] 服务器推送事件（SSE）服务器推送事件（Server-Sent Events，SSE）允许服务器端不断地推送数据到客户端。相对于 WebSocket 而言，服务器推送事件只支持服务器端到客户端的单向数据传递。虽然功能较弱，但优势在于 SSE 在已有的 HTTP 协议上使用简单易懂的文本格式来表示传输的数据。作为 W3C 的推荐规范，SSE 在浏览器端的支持也比较广泛，除了 IE 之外的其他浏览器都提供了支持。在 IE 上也可以使用 polyfill 库来提供支持。在服务器端来说，SSE 是一个不断产生新数据的流，非常适合于用反应式流来表示。在 WebFlux 中创建 SSE 的服务器端是非常简单的。只需要返回的对象的类型是 Flux，就会被自动按照 SSE 规范要求的格式来发送响应。 下面的SseController是一个使用 SSE 的控制器的示例。 123456789101112131415161718@RestController@RequestMapping("/sse")public class SseController &#123; @GetMapping("/random") public Flux&lt;ServerSentEvent&lt;Integer&gt;&gt; random() &#123; return Flux.interval(Duration.ofSeconds(1)) // 1 .map(seq -&gt; &#123; return ServerSentEvent.&lt;Integer&gt;builder() // 2 .event("random") .id(seq.toString()) .data(ThreadLocalRandom.current().nextInt()) .build(); &#125; ); &#125;&#125; 每 1 秒发出一个自增的 Long 值 使用ServerSentEvent.Builder来创建ServerSentEvent对象 在测试 SSE 时，我们只需要使用 curl 来访问即可。 123456789101112$ curl http://localhost:8080/sse/randomid:0event:randomdata:-244762412id:1event:randomdata:-1757349679id:2event:randomdata:496598301 WebSocketWebSocket 支持客户端与服务器端的双向通讯。当客户端与服务器端之间的交互方式比较复杂时，可以使用 WebSocket。WebSocket 在主流的浏览器上都得到了支持。WebFlux 也对创建 WebSocket 服务器端提供了支持。在服务器端，我们需要实现接口org.springframework.web.reactive.socket.WebSocketHandler来处理 WebSocket 通讯，其handle方法的参数是WebSocketSession对象，可以用来获取客户端信息、接送消息和发送消息。 下面的EchoHandler对于每个接收到的消息，都会在其前边添加一个前缀Echo -&gt;再发送出去。WebSocketSession的receive()方法的返回值是一个Flux&lt;WebSocketMessage&gt;对象，表示的是接收到的消息流，而send()方法的参数是一个Publisher&lt;WebSocketMessage&gt;对象，表示要发送的消息流。 12345678910@Componentpublic class EchoHandler implements WebSocketHandler &#123; @Override public Mono&lt;Void&gt; handle(WebSocketSession session) &#123; return session.send( session.receive() .map(msg -&gt; session.textMessage("Echo -&gt; " + msg.getPayloadAsText()))); &#125;&#125; 仅创建一个WebSocketHandler是不够的，我们还需要把它注册到 WebFlux 中。我们再来需要创建一个WebSocketHandlerAdapter对象，该对象负责把 WebSocketHandler 关联到 WebFlux 中。其中我们使用HandlerMapping把EchoHandler映射到/echo端点。 123456789101112131415161718192021@Configurationpublic class WebSocketConfiguration &#123; @Autowired @Bean public HandlerMapping webSocketMapping(EchoHandler echoHandler)&#123; Map&lt;String, WebSocketHandler&gt; map = new HashMap&lt;&gt;(1); map.put("/echo", echoHandler); SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE); mapping.setUrlMap(map); return mapping; &#125; @Bean public WebSocketHandlerAdapter webSocketHandlerAdapter()&#123; return new WebSocketHandlerAdapter(); &#125;&#125; 运行应用之后，可以使用工具来测试该 WebSocket 服务。打开工具页面，然后连接到ws://localhost:8080/echo可以发送消息并查看服务器端返回的结果。 函数式编程模型前面介绍了基于 Java 注解的编程模型，WebFlux 还支持基于 Lambda 表达式的函数式编程模型。与基于 Java 注解的编程模型相比，函数式编程模型的抽象层次更低，代码编写更灵活，可以满足一些对动态性要求更高的场景。不过在编写时的代码复杂度也较高，学习曲线也较陡。 目前 Spring Boot 已支持在一个应用中同时使用两种不同的编程模式，我们可以根据实际的需要来选择合适的编程模型。 在函数式编程模型中，每个请求是由一个函数来处理的， 通过接口org.springframework.web.reactive.function.server.HandlerFunction来表示。HandlerFunction是一个函数式接口，其中只有一个方法，因此可以用 Labmda 表达式来实现该接口： 1Mono&lt;T extends ServerResponse&gt; handle(ServerRequest request); 然后通过函数式接口org.springframework.web.reactive.function.server.RouterFunction来为这些HandlerFunction提供路由信息，输入为请求，输出为装在 Mono 里边的Handlerfunction 1Mono&lt;HandlerFunction&lt;T&gt;&gt; route(ServerRequest request); 我们看到，在 WebFlux 中，请求和响应不再是 WebMVC 中的ServletRequest和ServletResponse，而是ServerRequest和ServerResponse。后者是在响应式编程中使用的接口，它们提供了对非阻塞和回压特性的支持，以及 HTTP 消息体与响应式类型 Mono 和 Flux 的转换方法。 下面我们用函数式的方式开发一个简单的计算器，有add、subtract、multiply和divide四个方法，都是接口HandlerFunction的实现，分别对应加、减、乘、除四种运算。 对于这个需求，HandlerFunction 很容易写： 12345678910HandlerFunction&lt;ServerResponse&gt; add = request -&gt; ServerResponse.ok() .body(Mono.just(parseOperand(request, "v1") + parseOperand(request, "v2")), Integer.class);private int parseOperand(final ServerRequest request, final String param) &#123; try &#123; return Integer.parseInt(request.queryParam(param).orElse("0")); &#125; catch (final NumberFormatException e) &#123; return 0; &#125;&#125; 那么 RouterFunction 为： 1234@Beanpublic RouterFunction&lt;ServerResponse&gt; routerFunction() &#123; return RouterFunctions.route(RequestPredicates.GET("/add"), add);&#125; 启动服务，访问 http://localhost:8080/add?v1=2&amp;v2=3 即计算 2+3 得到返回值5。 不过这么写在业务逻辑复杂的时候不太好组织，我们通常采用跟 MVC 类似的代码组织方式，将同类业务的 HandlerFunction 放在一个类中，然后在 Java Config 中将 RouterFunction 配置为 Spring 容器的 Bean。我们继续在这个计算器的代码上开发： 12345678910111213141516171819202122232425262728293031323334353637383940@Componentpublic class CalculatorHandler &#123; public Mono&lt;ServerResponse&gt; add(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 + v2); &#125; public Mono&lt;ServerResponse&gt; subtract(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 - v2); &#125; public Mono&lt;ServerResponse&gt; multiply(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 * v2); &#125; public Mono&lt;ServerResponse&gt; divide(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 / v2); &#125; private Mono&lt;ServerResponse&gt; calculate(final ServerRequest request, final BiFunction&lt;Integer, Integer, Integer&gt; calculateFunc) &#123; final Tuple2&lt;Integer, Integer&gt; operands = extractOperands(request); return ServerResponse .ok() .body(Mono.just(calculateFunc.apply(operands.getT1(), operands.getT2())), Integer.class); &#125; private Tuple2&lt;Integer, Integer&gt; extractOperands(final ServerRequest request) &#123; return Tuples.of(parseOperand(request, "v1"), parseOperand(request, "v2")); &#125; private int parseOperand(final ServerRequest request, final String param) &#123; try &#123; return Integer.parseInt(request.queryParam(param).orElse("0")); &#125; catch (final NumberFormatException e) &#123; return 0; &#125; &#125;&#125; 我们采用 Spring 现在比较推荐的 Java Config 的配置 Bean 的方式，创建用于存放 Router 的配置类RouterConfig.java： 123456789101112131415@Configurationpublic class RouterConfig &#123; @Bean @Autowired public RouterFunction&lt;ServerResponse&gt; routerFunction(final CalculatorHandler calculatorHandler) &#123; return RouterFunctions.route(RequestPredicates.path("/calculator"), request -&gt; request.queryParam("operator").map(operator -&gt; Mono.justOrEmpty(ReflectionUtils.findMethod(CalculatorHandler.class, operator, ServerRequest.class)) .flatMap(method -&gt; (Mono&lt;ServerResponse&gt;) ReflectionUtils.invokeMethod(method, calculatorHandler, request)) .switchIfEmpty(ServerResponse.badRequest().build()) .onErrorResume(ex -&gt; ServerResponse.status(HttpStatus.INTERNAL_SERVER_ERROR).build())) .orElse(ServerResponse.badRequest().build())); &#125;&#125; 在上边的代码中，我们首先用RouterFunctions.route来根据Predicate是否匹配来确定HandlerFunction是否被应用。RequestPredicates中包含了很多静态方法来创建常用的基于不同匹配规则的Predicate，如RequestPredicates.path用来根据 HTTP 请求的路径来进行匹配，此处我们检查请求的路径是/calculator。然后使用ServerRequest的queryParam方法来获取到参数operator的值，然后通过反射 API 在CalculatorHandler中找到与参数operator的值名称相同的方法来确定要调用的HandlerFunction的实现，最后调用查找到的方法来处理该请求。如果找不到参数operator，服务器端返回 400 错误；如果反射 API 的方法调用中出现错误，服务器端返回 500 错误。 重启服务然后我们访问 http://127.0.0.1:8080/calculator?operator=add&amp;v1=2&amp;v2=3 得到返回值5。 客户端除了服务器端实现之外，WebFlux 也提供了反应式客户端，可以访问 HTTP、SSE 和 WebSocket 服务器端。 HTTP对于 HTTP 和 SSE，可以使用 WebFlux 模块中的类org.springframework.web.reactive.function.client.WebClient。下面的代码中我们将用RESTClient来访问前面小节中创建的 REST API。 1234567891011121314@Testpublic void testRESTClient() throws InterruptedException &#123; User user = new User(4, "赵六", "z6@qq.com"); WebClient client = WebClient.create("http://localhost:8080/user"); // 1 Flux&lt;User&gt; createdUser = client.post() // 2 .uri("") // 3 .accept(MediaType.APPLICATION_JSON) // 4 .body(Mono.just(user), User.class) // 5 .retrieve() // 6 .bodyToFlux(User.class); // 7 createdUser.subscribe(System.out::println); // 8 TimeUnit.SECONDS.sleep(1); // 9&#125; 使用WebClient.create方法来创建一个新的WebClient对象 使用post方法来创建一个 POST 请求 指定 baseUrl 配置请求 Header：Content-Type: application/json 使用body()方法来设置 POST 请求的内容 异步地获取 response 信息，返回值为WebClient.ResponseSpec，retrive()可以看做是exchange()方法的 “快捷版”（exchange()的返回值为ClientResponse） WebClient.ResponseSpec的bodyToFlux方法把响应内容转换成User对象，最终得到的结果是Flux&lt;User&gt; 打印出来 由于是异步的，我们将测试线程 sleep 1 秒确保拿到 response，也可以用CountDownLatch SEEWebClient 还可以用同样的方式来访问 SSE 服务。这里我们访问的是在之前的小节中创建的生成随机数的 SSE 服务。使用 WebClient 访问 SSE 在发送请求部分与访问 REST API 是相同的，所不同的地方在于对 HTTP 响应的处理。 1234567891011121314151617181920@Testpublic void testSEEClient() &#123; final WebClient client = WebClient.create(); client.get() .uri("http://localhost:8080/sse/random") .accept(MediaType.TEXT_EVENT_STREAM) .exchange() .flatMapMany(response -&gt; // 1 response.body( BodyExtractors.toFlux( new ParameterizedTypeReference&lt;ServerSentEvent&lt;String&gt;&gt;() &#123;&#125; ) ) ) .filter(sse -&gt; Objects.nonNull(sse.data())) .map(ServerSentEvent::data) .buffer(10) // 2 .doOnNext(System.out::println) // 3 .blockFirst(); // 4&#125; 由于 SSE 服务的响应是一个消息流，我们需要使用flatMapMany把 Mono&lt;ServerResponse&gt;转换成一个Flux&lt;ServerSentEvent&gt;对象，这是通过方法BodyExtractors.toFlux来完成的，其中的参数new ParameterizedTypeReference&lt;ServerSentEvent&lt;String&gt;&gt;() {}表明了响应消息流中的内容是ServerSentEvent对象 由于 SSE 服务器会不断地发送消息，这里我们只是通过buffer方法来获取前 10 条消息并输出 只读地 peek 每个元素，然后打印出来，它并不是 subscribe，所以不会触发流 blockFirst方法，顾名思义，在收到第一个元素前会阻塞，响应式业务场景中慎用 运行效果如下： 或者也可以像下边这样 123456789101112@Testpublic void testSEEClient2() &#123; WebClient client = WebClient.create(); client.get() .uri("http://localhost:8080/sse/random") .accept(MediaType.TEXT_EVENT_STREAM) .retrieve() .bodyToFlux(String.class) .log() .take(10) .blockLast();&#125; 运行效果如下： WebSocket访问 WebSocket 不能使用 WebClient，而应该使用专门的 WebSocketClient 客户端。Spring Boot 的 WebFlux 模板中默认使用的是 Reactor Netty 库。Reactor Netty 库提供了 WebSocketClient 的实现。我们这里访问前面创建的 WebSocket 服务。 12345678910@Testpublic void testWSClient() &#123; WebSocketClient client = new ReactorNettyWebSocketClient(); // 1 client.execute(URI.create("ws://localhost:8080/echo"), session -&gt; // 2 session.send(Flux.just(session.textMessage("Hello"))) // 3 .thenMany(session.receive().take(1).map(WebSocketMessage::getPayloadAsText)) // 4 .doOnNext(System.out::println) .then()) .block(Duration.ofMillis(5000));&#125; 创建一个 WebSocketClient 实例 使用 WebSocketClient 的execute方法与 WebSocket 服务器建立连接，并执行给定的 WebSocketHandler 对象 通过 WebSocketSession 的send方法来发送字符串”Hello” 到服务器端 通过receive方法来等待服务器端的响应并输出，take(1)的作用是表明客户端只获取服务器端发送的第一条消息 运行效果如下： 测试在 spring-test 模块中也添加了对 WebFlux 的支持。通过类 org.springframework.test.web.reactive.server.WebTestClient可以测试 WebFlux 服务器。进行测试时既可以通过 mock 的方式来进行，也可以对实际运行的服务器进行集成测试。 我们通过一个集成测试来测试UserController中的创建用户的功能。方法 WebTestClient.bindToServer绑定到一个运行的服务器并设置了基础 URL。发送 HTTP 请求的方式与之前的代码相同，不同的是exchange方法的返回值是ResponseSpec对象，其中包含了expectStatus和expectBody等方法来验证 HTTP 响应的状态码和内容。方法jsonPath可以根据 JSON 对象中的路径来进行验证。 1234567891011121314151617public class UserControllerTest &#123; private final WebTestClient client = WebTestClient.bindToServer().baseUrl("http://localhost:8080").build(); @Test public void testCreateUser() throws Exception &#123; User user = new User(5, "钱七", "q7@qq.com"); client.post().uri("/user") .contentType(MediaType.APPLICATION_JSON) .body(Mono.just(user), User.class) .exchange() .expectStatus().isOk() .expectBody().jsonPath("$[0].name") .isEqualTo("钱七"); &#125;&#125; JsonPath 的语法可以看 https://github.com/json-path/JsonPath 总结反应式编程范式为开发高性能 Web 应用带来了新的机会和挑战。Spring 5 中的 WebFlux 模块可以作为开发反应式 Web 应用的基础。由于 Spring 框架的流行，WebFlux 会成为开发 Web 应用的重要趋势之一。本文对 Spring 5 中的 WebFlux 模块进行了详细的介绍，包括如何用 WebFlux 开发 HTTP、SSE 和 WebSocket 服务器端应用，以及作为客户端来访问 HTTP、SSE 和 WebSocket 服务。对于 WebFlux 的基于 Java 注解和函数式编程等两种模型都进行了介绍。最后介绍了如何测试 WebFlux 应用。 示例代码：Github 参考Web on Reactive Stack23. WebFlux framework使用 Spring 5 的 WebFlux 开发反应式 Web 应用使用 Reactor 进行反应式编程Reactor NettySpring WebFlux 快速上手]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>SSE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java nio常用方法]]></title>
    <url>%2F2019%2F02%2F23%2Fjava-nio%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[ByteBuffer1、实例化java.nio.Buffer类是一个抽象类，不能被实例化。Buffer类的直接子类，如ByteBuffer等也是抽象类，所以也不能被实例化。 但是ByteBuffer类提供了4个静态工厂方法来获得ByteBuffer的实例： 方法 描述 allocate(int capacity) 从堆空间中分配一个容量大小为capacity的byte数组作为缓冲区的byte数据存储器 allocateDirect(int capacity) 是不使用JVM堆栈而是通过操作系统来创建内存块用作缓冲区，它与当前操作系统能够更好的耦合，因此能进一步提高I/O操作速度。但是分配直接缓冲区的系统开销很大，因此只有在缓冲区较大并长期存在，或者需要经常重用时，才使用这种缓冲区 wrap(byte[] array) 这个缓冲区的数据会存放在byte数组中，bytes数组或buff缓冲区任何一方中数据的改动都会影响另一方。其实ByteBuffer底层本来就有一个bytes数组负责来保存buffer缓冲区中的数据，通过allocate方法系统会帮你构造一个byte数组 wrap(byte[] array, int offset, int length) 在上一个方法的基础上可以指定偏移量和长度，这个offset也就是包装后byteBuffer的position，而length呢就是limit-position的大小，从而我们可以得到limit的位置为length+position(offset) 2、另外一些常用的方法 方法 描述 limit(), limit(10)等 其中读取和设置这4个属性的方法的命名和jQuery中的val(),val(10)类似，一个负责get，一个负责set reset() 把position设置成mark的值，相当于之前做过一个标记，现在要退回到之前标记的地方 clear() position = 0;limit = capacity;mark = -1; 有点初始化的味道，但是并不影响底层byte数组的内容 flip() limit = position;position = 0;mark = -1; 翻转，也就是让flip之后的position到limit这块区域变成之前的0到position这块，翻转就是将一个处于存数据状态的缓冲区变为一个处于准备取数据的状态 rewind() 把position设为0，mark设为-1，不改变limit的值 remaining() return limit - position; 返回limit和position之间相对位置差 hasRemaining() return position &lt; limit返回是否还有未读内容 compact() 把从position到limit中的内容移到0到limit-position的区域内，position和limit的取值也分别变成limit-position、capacity。如果先将positon设置到limit，再compact，那么相当于clear() get() 相对读，从position位置读取一个byte，并将position+1，为下次读写作准备 get(int index) 绝对读，读取byteBuffer底层的bytes中下标为index的byte，不改变position get(byte[] dst, int offset, int length) 从position位置开始相对读，读length个byte，并写入dst下标从offset到offset+length的区域 put(byte b) 相对写，向position的位置写入一个byte，并将postion+1，为下次读写作准备 put(int index, byte b) 绝对写，向byteBuffer底层的bytes中下标为index的位置插入byte b，不改变position put(ByteBuffer src) 用相对写，把src中可读的部分（也就是position到limit）写入此byteBuffer put(byte[] src, int offset, int length) 从src数组中的offset到offset+length区域读取数据并使用相对写写入此byteBuffer 代码参考https://github.com/Frankenjoy123/nettystudy java.nio.charset.Charsetencode(java.nio.CharBuffer)FileChanneljava.nio.file.Paths##get(java.lang.String, java.lang.String…) ​]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常用函数]]></title>
    <url>%2F2019%2F02%2F21%2FMySQL%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[字符串截取1. 字符串截取：left(str, length)123456mysql&gt; select left('sqlstudy.com', 3);+-------------------------+| left('sqlstudy.com', 3) |+-------------------------+| sql |+-------------------------+ 2. 字符串截取：right(str, length)123456mysql&gt; select right('sqlstudy.com', 3);+--------------------------+| right('sqlstudy.com', 3) |+--------------------------+| com |+--------------------------+ 3. 字符串截取：substring(str, pos); substring(str, pos, len)3.1 从字符串的第 4 个字符位置开始取，直到结束。 123456mysql&gt; select substring('sqlstudy.com', 4);+------------------------------+| substring('sqlstudy.com', 4) |+------------------------------+| study.com |+------------------------------+ 3.2 从字符串的第 4 个字符位置开始取，只取 2 个字符。 123456mysql&gt; select substring('sqlstudy.com', 4, 2);+---------------------------------+| substring('sqlstudy.com', 4, 2) |+---------------------------------+| st |+---------------------------------+ 3.3 从字符串的第 4 个字符位置（倒数）开始取，直到结束。 123456mysql&gt; select substring('sqlstudy.com', -4);+-------------------------------+| substring('sqlstudy.com', -4) |+-------------------------------+| .com |+-------------------------------+ 3.4 从字符串的第 4 个字符位置（倒数）开始取，只取 2 个字符。 123456mysql&gt; select substring('sqlstudy.com', -4, 2);+----------------------------------+| substring('sqlstudy.com', -4, 2) |+----------------------------------+| .c |+----------------------------------+ 我们注意到在函数 substring(str,pos, len)中， pos 可以是负值，但 len 不能取负值。 4. 字符串截取：substring_index(str,delim,count)4.1 截取第二个 ‘.’ 之前的所有字符。 123456mysql&gt; select substring_index('www.sqlstudy.com.cn', '.', 2);+------------------------------------------------+| substring_index('www.sqlstudy.com.cn', '.', 2) |+------------------------------------------------+| www.sqlstudy |+------------------------------------------------+ 4.2 截取第二个 ‘.’ （倒数）之后的所有字符。 123456mysql&gt; select substring_index('www.sqlstudy.com.cn', '.', -2);+-------------------------------------------------+| substring_index('www.sqlstudy.com.cn', '.', -2) |+-------------------------------------------------+| com.cn |+-------------------------------------------------+ 4.3 如果在字符串中找不到 delim 参数指定的值，就返回整个字符串 123456mysql&gt; select substring_index('www.sqlstudy.com.cn', '.coc', 1);+---------------------------------------------------+| substring_index('www.sqlstudy.com.cn', '.coc', 1) |+---------------------------------------------------+| www.sqlstudy.com.cn |+---------------------------------------------------+]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务的解决方案]]></title>
    <url>%2F2019%2F02%2F17%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[分布式事务的解决方案数据一致性（zk） 为什么会有分布式事务我们假设有如下一个架构，这是一个简单的电商架构平台，两个应用节点，一个数据库，一个负载均衡器。这个架构下，每天会产生将近100W的订单量。那么一个月的数据量就会超过3000W。而随着数据量的不断扩大，对于订单表的相关查询操作的性能开销就越来越大。并且响应耗时也越来越长。这个时候我们需要考虑到数据库的优化问题。也就是对数据库进行分表分库，达到分摊数据库压力以及减少数据库单表数据量的目的。 分库分表以后带来的问题分库分表以后，一方面分担了单库带来的性能压力；另一方面，减少了单表的数据量。完美的解决了我们遇到的性能问题。但是，随着而来的又有另外的问题。 比如有这样一个场景，订单支付成功以后需要扣减库存。在数据库分库分表之前，所有数据都在同一个库里面，可以通过事务操作就很容易达到数据一致性的目的。但是在数据库做了拆分后，订单状态更新是属于订单的数据库，而库存扣减是属于库存的数据库。原本单库的事务操作就变成了多库的事务操作。 但是每个库的事务只有自己知道，订单库并不知道库存库的事务执行结果，库存库也不知道订单库的修改结果。所以就造成了分布式事务的问题。其实也叫分布式数据一致性。 认识分布式事务既然存在分布式事务的问题，那就一定有成熟的解决方案，那么接下来我们了解下业内的常用解决方法及原理 经典的X/OpenDTP事务模型 X/Open DTP(X/Open Distributed Transaction Processing Reference Model) 是X/Open这个组织定义的一套分布式事务的标准，也就是定义了规范和API接口，由各个厂商进行具体的实现。 这个标准提出了使用二阶段提交(2PC – Two-Phase-Commit)来保证分布式事务的完整性。后来J2EE也遵循了X/OpenDTP规范，设计并实现了java里的分布式事务编程接口规范-JTA X/OpenDTP角色 在X/OpenDTP事务模型中，定义了三个角色 AP: application, 应用程序，也就是业务层。哪些操作属于一个事务，就是AP定义的 RM： Resource Manager，资源管理器。一般是数据库，也可以是其他资源管理器，比如消息队列，文件系统 TM： Transaction Manager ，事务管理器、事务协调者，负责接收来自用户程序（AP）发起的XA事务指令，并调度和协调参与事务的所有RM（数据库），确保事务正确完成 在分布式系统中，每一个机器节点虽然都能够明确知道自己在进行事务操作过程中的结果是成功还是失败，但却无法直接获取到其他分布式节点的操作结果。因此当一个事务操作需要跨越多个分布式节点的时候，为了保持事务处理的ACID特性，就需要引入一个“协调者”（TM）来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为AP。TM负责调度AP的行为，并最终决定这些AP是否要把事务真正进行提交到（RM） 参与分布式事务的应用程序(AP)先到TM上注册全局事务 然后各个AP直接在相应的资源管理器(RM)上进行事务操作 操作完成以后，各个AP反馈事务的处理结果给到TM TM收到所有AP的反馈以后，通过数据库提供的XA接口进行数据提交或者回滚操作 2pc提交（two -phaseCommit）在X/OpenDTP模型中，一个分布式事务所涉及的SQL逻辑都执行完成，并到了（RM）要最后提交事务的关键时刻，为了避免分布式系统所固有的不可靠性导致提交事务意外失败，TM 果断决定实施两步走的方案，这个就称为二阶提交 二阶段提交，是计算机网络尤其是在数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务处理过程中能够保持原子性和一致性而设计的一种算法。 通常，二阶段提交协议也被认为是一种一致性协议，用来保证分布式系统数据的一致性。目前，绝大部分的关系型数据库都是采用二阶段提交协议来完成分布式事务处理的，利用该协议能够非常方便地完成所有分布式事务AP的协调，统一决定事务的提交或回滚，从而能够有效保证分布式数据一致性，因此2pc也被广泛运用在许多分布式系统中 第一阶段 事务询问 TM向所有的AP发送事务内容，询问是否可以执行事务提交操作，并开始等待各AP的响应 执行事务 各个AP节点执行事务操作，并将Undo和Redo信息记录到事务日志中，尽量把提交过程中所有消耗时间的操作和准备都提前完成确保后面100%成功提交事务 各个AP向TM反馈事务询问的响应 如果各个AP成功执行了事务操作，那么就反馈给AP yes的响应，表示事务可以执行；如果AP没有成功执行事务，就反馈给TM no的响应，表示事务不可以执行 上面这个阶段有点类似TM组织各个AP对一次事务操作的投票表态过程，因此2pc协议的第一个阶段称为“投票阶段”，即各AP投票表名是否需要继续执行接下去的事务提交操作。 第二阶段事务提交在这个阶段，TM会根据各AP的反馈情况来决定最终是否可以进行事务提交操作，正常情况下包含两种可能 假如TM从所有参与者获得的反馈都是yes响应，那么就会执行事务提交 发送提交请求 TM向所有AP节点发出commit请求 事务提交 AP接收到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源 反馈事务提交结果 AP在完成事务提交之后，向TM发送Ack消息 完成事务 TM接收到所有AP反馈的ack消息后，完成事务 事务回滚如果第一个阶段中的某一个资源预提交失败，那么第二个阶段就回滚第一阶段已经预提交成功的资源 假设任何一个AP向TM反馈了NO的响应，或者在等待超时之后，TM无法接收到所有AP的反馈响应，那么就会中断事务 发送回滚请求 TM向所有AP发出abort请求 事务回滚 AP收到abort请求后，会利用在第一阶段记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源 反馈事务回滚结果 各AP在完成事务回滚之后，向TM发送Ack消息 中端事务 TM 接收到所有AP反馈的ack消息后，完成事务中断 二阶段提交将一个事务的处理过程分为投票和执行两个阶段. 二阶段提交的优点在于，它充分考虑到了分布式系统的不可靠因素，并且采用非常简单的方式（两阶段提交）就把由于系统不可靠从而导致事务提交失败的概率降到最小 假如一个事务的提交过程总共需要30秒的操作，其中prepare阶段需要28秒（主要是确保事务日志落地磁盘等各种耗时的I/O操作），真正的commit阶段只需要花费两秒，那么Commit阶段发生错误的概率与Prepare阶段相比，只是它的2/28(&lt;10%)，也就是说，如果Prepare阶段成功了，则Commit阶段由于时间非常端，失败概率小，会大大增加分布式事务成功的概率。 2pc协议的优缺点 原理简单，实现很方便 每一个阶段都是同步阻塞，会造成性能损耗。 协调者存在单点问题，如果协调者在第二阶段出现故障，那么其他参与者会一直处于锁定状态。 太过保守，任意一个节点失败都会导致数据回滚 数据不一致问题: 在阶段二中，当协调者向所有的参与者发送commit请求后，发生了网络异常导致协调者在尚未发完commit请求之前崩溃，可能会导致只有部分的参与者接收到commit请求，剩下没收到commit请求的参与者将无法提交事务，也就可能导致数据不一致的问题 3PC3PC协议主要用来解决2PC的同步阻塞问题的一种优化方案，3pc分为3个阶段分别为：cancommit、Precommit、doCommit。 和2阶段提交的区别在于： (1) 在协调者和参与者中引入了超时机制，2pc只有在协调者拥有超时机制,协调者在一定时间内没受到参与者的信息则默认为失败； (2) 把2阶段提交的第一个阶段拆分成了两个步骤。 cancommit阶段协调者向参与者发送commit请求，参与者如果可以提交就返回yes的响应，否则返回No的响应。这一阶段主要是确定分布式事务的参与者是否具备了完成commit的条件，并不会执行事务操作。 询问参与者是否可以执行事务提交操作 正常情况下只要能够顺利执行事务，就返回yes的响应，并进入预备状态。 precommit阶段事务协调者根据参与者的反馈情况来决定是否继续执行事务的precommit操作，在这一个阶段，会有两种可能性，第一种是，在cancommit阶段所有参与者都反馈的是yes，则会进行事务预执行 协调者TM向参与者AP发送precommit请求 参与者收到precommit请求后，执行事务操作，并把事务的undo和redo信息记录到事务日志中 返回事务的执行结果给到协调者，并等待最终的提交指令 如果任意一个事务参与者在第一阶段返回了no，则执行事务中断请求 向所有事务参与者发送事务中断请求 对于事务参与者来说，无论是收到协调者的中断请求，还是等待协调者指令之前出现超时，参与者都会中断事务 doCommit阶段这个阶段同样存在两种情况，正常情况下，precommit都响应了ack给到协调者，那么协调者会发起事务提交请求。 协调者向所有参与者发送docommit请求 参与者收到docommit请求后，执行事务提交操作，并释放所有事务资源 事务提交以后返回ack给到协调者 协调者收到所有参与者的响应后，完成事务 如果在precommit阶段，有参与者没有发送ack给到协调者，那么则执行事务中断指令 协调者向所有参与者发送中断事务的请求 参与者收到请求以后，利用在第二个阶段记录的undo信息来执行事务回滚操作 向协调者发送ack消息，协调者收到消息以后，执行事务中断操作 分布式事务一致性在java中，分布式事务主要的规范是JTA/XA . JTA是java的事务管理器规范，JTA全称为Java Transaction API, JTA定义了一组统一的事务编程的接口，基于X/OpenDTP规范设计的分布式事务编程接口规范。XA是工业标准的X/Open DTP规范 基于JTA规范的第三方分布式事务框架有Jotm和Atomikos JOTMJOTM （java open transaction manager）是ObjectWeb的一个开源JTA实现，提供JTA分布式事务的功能 但是JOTM存在一个问题，在使用中不能自动rollback，无论什么情况都commit。 Atomikos与JOTM相比，Atomikos 更加稳定，原本Atomikos是商业项目，后来开源。论坛比较活跃，有问题可以随时解决 互联网行业的数据一致性问题解决方案目前互联网领域里有几种流行的分布式解决方案，但都没有像之前所说的XA事务一样形成X/OpenDTP那样的工业规范，而是仅仅在具体的行业里获得较多的认可； 我们最早的时候讲过CAP和BASE理论，对于CAP来说，对于共享数据的系统，由于网络分区问题的存在，我们只能满足AP或者CP；对于BASE理论，满足基本可用。所以其实我们在落地数据一致性解决方案是，基本上都会选择一个平衡点，也就是酸碱平衡理论，ACID是酸、 BASE是碱；ACID是强一致性、BASE是弱一致性。强一致性代表数据库本身不会出现不一致，每个事务是原子的，或者成功或者失败，事物间是隔离的，互相完全不影响，而且最终状态是持久落盘的，因此，数据库会从一个明确的状态到另外一个明确的状态.; 而BASE体现的是最终一致性，允许出现中间状态。 所以对于对于服务来说，有很多的方案去选择： 提供查询服务确认数据状态、 幂等操作对于重发保证数据的安全性、 TCC事务操作、 补偿操作、 定期校对。 业务接口整合，避免分布式事务这个方案就是把一个业务流程中需要在一个事务里执行的多个相关业务接口包装整合到一个事务中，比如我们可以讲A/B/C整合为一个服务D来实现单一事务的业务流程服务 最终一致性方案eBay在2008年公布了一个关于BASE准则提到一个分布式事务解决方案。eBay的方案其实是一个最终一致性方案，它主要采用消息队列来辅助实现事务控制流程，方案的核心是将需要分布式处理的任务通过消息队列的方式来异步执行，如果事务失败，则可以发起人工重试的纠正流程。人工重试被更多的应用于支付场景，通过对账系统对事后问题进行处理 比如一个很常见的场景：某个用户产生了一笔交易，那么需要在交易表中增加记录，同时需要修改用户表的金额（余额），由于这两个表属于不同的远程服务，所以就会涉及到分布式事务与数据一致性的问题 关于状态机在使用最终一致性的方案时，一定要提到的一个概念是状态机。 什么是状态机？是一种特殊的组织代码的方式，用这种方式能够确保你的对象随时都知道自己所处的状态以及所能做的操作。它也是一种用来进行对象行为建模的工具，用于描述对象在它的生命周期内所经历的状态序列，以及如何响应来自外界的各种事件。 状态机这个概念大家都不陌生，比如TCP协议的状态机。同时我们在编写相关业务逻辑的时候经常也会需要处理各种事件和状态的切换，比如switch、if/else。所以我们其实一直在跟状态机打交道，只是可能没有意识到而已。在处理一些业务逻辑比较复杂的需求时，可以先看看是否适合用一个有限状态机来描述，如果可以把业务模型抽象成一个有限状态机，那么代码就会逻辑特别清晰，结构特别规整。 比如我们来简单描述一个订单 我们以支付为例，一笔订单可能会有等待支付、支付中、已支付等状态，那么我们就可以先去把可能出现的状态以及状态的流程画出来。 状态机的两个作用 实现幂等 通过状态驱动数据的变化 业务流程以及逻辑更加清晰，特别是应对复杂的业务场景 什么是幂等简单来说：重复调用多次产生的业务结果与调用一次产生的业务结果相同； 在分布式架构中，我们调用一个远程服务去完成一个操作，除了成功和失败以外，还有未知状态，那么针对这个未知状态，我们会采取一些重试的行为； 或者在消息中间件的使用场景中，消费者可能会重复收到消息。对于这两种情况，消费端或者服务端需要采取一定的手段，也就是考虑到重发的情况下保证数据的安全性。一般我们常用的手段 状态机实现幂等 数据库唯一约束实现幂等 通过tokenid的方式去识别每次请求判断是否重复 基于消息的最终一致性方案实践在最终一致性这个方案上，也有两种选择方案，一种是基于可靠消息中间件来实现异步的最终一致性、另一种就是通过MQ来实现最大努力通知型。这两种都比较常见，比如大家如果对接过支付宝支付的api，就应该能知道，当你调用支付支付 成功以后，支付宝会提供一个异步回调，调用配置好的指定的接口地址。在这个接口中，你可以获得支付宝的支付结果并根据结果做相应的处理。最后必须要返回一个ack给到支付宝的回调api，告诉他这边已经处理成功了。否则，支付宝的异步回调会不断重试，当然有重试次数，以及重试的间隔时间。那接下来，我们通过第一种方案来实现数据的最终一致性 通过异步消息执行方案的本质是，把两个事物转化成两个本地事务，然后依靠消息本身的可靠性，以及消息的重试机制达到最终一致性。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring session 与JWT、OAuth2]]></title>
    <url>%2F2019%2F02%2F17%2FSpring-session-%E4%B8%8EJWT%E3%80%81OAtuh2%2F</url>
    <content type="text"><![CDATA[spring-session-data-redissesssion存的值及属性get spring:session:sessions:expires:381be901-f399-443d-baf7-a274a98ac019 得到maxInactiveIntervallastAccessedTimecreationTimesessionAttr:Mic 1request.getSession().setAttribute("Mic","value"); 123456789127.0.0.1:6379&gt; hgetall spring:session:sessions:e8b7c9a1-8c4a-4f03-996f-619cfba91ea11) "maxInactiveInterval"2) "\xac\xed\x00\x05sr\x00\x11java.lang.Integer\x12\xe2\xa0\xa4\xf7\x81\x878\x02\x00\x01I\x00\x05valuexr\x00\x10java.lang.Number\x86\xac\x95\x1d\x0b\x94\xe0\x8b\x02\x00\x00xp\x00\x00\x02X"3) "lastAccessedTime"4) "\xac\xed\x00\x05sr\x00\x0ejava.lang.Long;\x8b\xe4\x90\xcc\x8f#\xdf\x02\x00\x01J\x00\x05valuexr\x00\x10java.lang.Number\x86\xac\x95\x1d\x0b\x94\xe0\x8b\x02\x00\x00xp\x00\x00\x01h\xf9\xbb\xcc\xff"5) "sessionAttr:Mic"6) "\xac\xed\x00\x05t\x00\x05value"7) "creationTime"8) "\xac\xed\x00\x05sr\x00\x0ejava.lang.Long;\x8b\xe4\x90\xcc\x8f#\xdf\x02\x00\x01J\x00\x05valuexr\x00\x10java.lang.Number\x86\xac\x95\x1d\x0b\x94\xe0\x8b\x02\x00\x00xp\x00\x00\x01h\xf9\xb6\xd0\xf5" 过期时间get spring:session:sessions:expires:e8b7c9a1-8c4a-4f03-996f-619cfba91ea1 1127.0.0.1:6379&gt; get spring:session:sessions:expires:e8b7c9a1-8c4a-4f03-996f-619cfba91ea1 JWT https://jwt.io 验证签名规范 header1234&#123; "alg": "HS256", "typ": "JWT"&#125; payload12345&#123; "sub": "1234567890", "name": "John Doe", "iat": 1516239022&#125; 签名算法 verify signature12345HMACSHA256( base64UrlEncode(header) + "." + base64UrlEncode(payload),"your-256-bit-secret") your-256-bit-secret 类似秘钥 12345HMACSHA256( base64UrlEncode(header) + "." + base64UrlEncode(payload), secret) 代码参考 https://gitee.com/Joey_z/vip-project-space/blob/master/user-service/user-provider/src/main/java/com/gupaoedu/user/utils/JwtTokenUtils.java 1234567891011121314151617181920212223242526272829303132333435363738394041public class JwtTokenUtils &#123; public static void main(String[] args) &#123; System.out.println(UUID.randomUUID(). toString().replace("-","")); &#125; //定义your-256-bit-secret private static Key generatorKey()&#123; SignatureAlgorithm saa=SignatureAlgorithm.HS256; byte[] bin=DatatypeConverter.parseBase64Binary ("f3973b64918e4324ad85acea1b6cbec5"); Key key=new SecretKeySpec(bin,saa.getJcaName()); return key; &#125; public static String generatorToken(Map&lt;String,Object&gt; payLoad)&#123; ObjectMapper objectMapper=new ObjectMapper(); try &#123; //定义payload return Jwts.builder().setPayload(objectMapper.writeValueAsString(payLoad)) //Jwt SignatureAlgorithm.HS256定义了header .signWith(SignatureAlgorithm.HS256,generatorKey()).compact(); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; return null; &#125; public static Claims phaseToken(String token)&#123; Jws&lt;Claims&gt; claimsJwt=Jwts.parser().setSigningKey(generatorKey()).parseClaimsJws(token); return claimsJwt.getBody(); &#125;&#125; OAuth2]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring-MVC DispatchServlet HanderInteceptor分析]]></title>
    <url>%2F2019%2F02%2F17%2FSpring-MVC-DispatchServlet-HanderInteceptor%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[DispatchServlet #doDispatch方法12345678910111213if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return;&#125;// Actually invoke the handler.mv = ha.handle(processedRequest, response, mappedHandler.getHandler());if (asyncManager.isConcurrentHandlingStarted()) &#123; return;&#125;applyDefaultViewName(processedRequest, mv);mappedHandler.applyPostHandle(processedRequest, response, mv); HandlerExecutionChain#applyPreHandle实际上责任链模式，分别执行每个HandlerInterceptor的preHandle方法 1private HandlerInterceptor[] interceptors; 1234567891011121314boolean applyPreHandle(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) &#123; for (int i = 0; i &lt; interceptors.length; i++) &#123; HandlerInterceptor interceptor = interceptors[i]; if (!interceptor.preHandle(request, response, this.handler)) &#123; triggerAfterCompletion(request, response, null); return false; &#125; this.interceptorIndex = i; &#125; &#125; return true;&#125; HandlerExecutionChain#applyPostHandle123456789void applyPostHandle(HttpServletRequest request, HttpServletResponse response, ModelAndView mv) throws Exception &#123; HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) &#123; for (int i = interceptors.length - 1; i &gt;= 0; i--) &#123; HandlerInterceptor interceptor = interceptors[i]; interceptor.postHandle(request, response, this.handler, mv); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring-MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精尽 Dubbo 源码分析 —— 01API 配置（一）之应用]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%B2%BE%E5%B0%BD-Dubbo-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E2%80%94%E2%80%94-01API-%E9%85%8D%E7%BD%AE%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[&gt; 友情提示，【配置】这块的内容，会相对比较枯燥。所以，如果看到一些很难懂的地方，建议先跳过。 对于 Dubbo ，重点是要去理解，多协议、RPC、容错等等模块，而不是【配置】。 1. 概述我们都“知道”，Dubbo 的配置是非常“灵活”的。 例如，目前提供了四种配置方式： API 配置 属性配置 XML 配置 注解配置 ps：🙂 后续的几篇文章也是按照这样的顺序，解析 Dubbo 配置的源码。 再例如，可灵活设置的配置项： FROM 《Dubbo 用户指南 —— schema 配置参考手册》 所有配置项分为三大类，参见下表中的”作用”一列。 服务发现：表示该配置项用于服务的注册与发现，目的是让消费方找到提供方。 服务治理：表示该配置项用于治理服务间的关系，或为开发测试提供便利条件。 性能调优：表示该配置项用于调优性能，不同的选项对性能会产生影响。 所有配置最终都将转换为 Dubbo URL 表示，并由服务提供方生成，经注册中心传递给消费方，各属性对应 URL 的参数，参见配置项一览表中的 “对应URL参数” 列。 ps：🙂 可能转换成 Dubbo URL 不太好理解。良心如笔者，后续有文章会贯串它。 当然，凡事都有两面性，在社区里也存在建议的声音，例如：《ISSUE#738：XML配置项重新梳理》 ： 目前有一些配置项存在暴露的位置不正确、暴露不全面、文档和含义不匹配等问题，期望在2.5.7版本将已知问题予以整理修复 如果使用中有遇到的配置问题，请在评论中列出以便改进 2. 配置一览我们来看看 dubbo-config-api 的项目结构，如下图所示： 一脸懵逼，好多啊。下面我们来整理下配置之间的关系，如下图所示： FROM 《Dubbo 用户指南 —— XML 配置》 从这张图中，可以看出分成四个部分： application-shared provider-side consumer-side sub-config 实际上，上图和目前版本的代码会存在一点点出入，我们在看看实际的类关系，如下图所示： 红勾部分，application-shared ，在本文进行分享。 黄框部分，provider-side ，在 《API 配置（二）之服务提供者》 分享。 红框部分，consumer-side ，在 《API 配置（三）之服务消费者》 分享。 其他部分，sub-config ，在 《API 配置（二）之服务提供者》 分享。 3. Config我们先来看一段 《Dubbo 用户指南 —— API 配置》 ，提供的消费者的初始化代码： 123456789101112131415161718192021// 当前应用配置ApplicationConfig application = new ApplicationConfig();application.setName("yyy");// 连接注册中心配置RegistryConfig registry = new RegistryConfig();registry.setAddress("10.20.130.230:9090");registry.setUsername("aaa");registry.setPassword("bbb");// 注意：ReferenceConfig为重对象，内部封装了与注册中心的连接，以及与服务提供方的连接// 引用远程服务ReferenceConfig&lt;XxxService&gt; reference = new ReferenceConfig&lt;XxxService&gt;(); // 此实例很重，封装了与注册中心的连接以及与提供者的连接，请自行缓存，否则可能造成内存和连接泄漏reference.setApplication(application);reference.setRegistry(registry); // 多个注册中心可以用setRegistries()reference.setInterface(XxxService.class);reference.setVersion("1.0.0");// 和本地bean一样使用xxxServiceXxxService xxxService = reference.get(); // 注意：此代理对象内部封装了所有通讯细节，对象较重，请缓存复用 可以看到，创建了 ApplicationConfig 和 RegistryConfig 对象，设置到 ReferenceConfig 对象。 如果创建 ModuleConfig 或 MonitorConfig 对象，也是可以设置到 ReferenceConfig 对象中。 3.1 AbstractConfigcom.alibaba.dubbo.config.AbstractConfig ，抽象配置类，除了 ArgumentConfig ，我们可以看到所有的配置类都继承该类。 AbstractConfig 主要提供配置解析与校验相关的工具方法。下面我们开始看看它的代码。 id 属性，配置对象的编号，适用于除了 API 配置之外的三种配置方式，标记一个配置对象，可用于对象之间的引用。例如 XML 的 &lt;dubbo:service provider=&quot;${PROVIDER_ID}&quot;&gt; ，其中 provider 为 &lt;dubbo:provider&gt; 的 ID 属性。 那为什么说不适用 API 配置呢？直接 #setXXX(config) 对象即可。 配置项校验的工具方法，例如属性值长度限制、格式限制等等，比较简单。相关代码如下： 静态属性 静态方法 #appendParameters(parameters, config, prefix) 方法，将配置对象的属性，添加到参数集合。代码如下 ： 在看具体代码之前，我们先来了解 「4. URL」 和 「5. @Parameter」 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970 1: protected static void appendParameters(Map&lt;String, String&gt; parameters, Object config, String prefix) &#123; 2: if (config == null) &#123; 3: return; 4: &#125; 5: Method[] methods = config.getClass().getMethods(); 6: for (Method method : methods) &#123; 7: try &#123; 8: String name = method.getName(); 9: if ((name.startsWith("get") || name.startsWith("is"))10: &amp;&amp; !"getClass".equals(name)11: &amp;&amp; Modifier.isPublic(method.getModifiers())12: &amp;&amp; method.getParameterTypes().length == 013: &amp;&amp; isPrimitive(method.getReturnType())) &#123; // 方法为获取基本类型，public 的 getting 方法。14: Parameter parameter = method.getAnnotation(Parameter.class);15: if (method.getReturnType() == Object.class || parameter != null &amp;&amp; parameter.excluded()) &#123;16: continue;17: &#125;18: // 获得属性名19: int i = name.startsWith("get") ? 3 : 2;20: String prop = StringUtils.camelToSplitName(name.substring(i, i + 1).toLowerCase() + name.substring(i + 1), ".");21: String key;22: if (parameter != null &amp;&amp; parameter.key() != null &amp;&amp; parameter.key().length() &gt; 0) &#123;23: key = parameter.key();24: &#125; else &#123;25: key = prop;26: &#125;27: // 获得属性值28: Object value = method.invoke(config, new Object[0]);29: String str = String.valueOf(value).trim();30: if (value != null &amp;&amp; str.length() &gt; 0) &#123;31: // 转义32: if (parameter != null &amp;&amp; parameter.escaped()) &#123;33: str = URL.encode(str);34: &#125;35: // 拼接，详细说明参见 `Parameter#append()` 方法的说明。36: if (parameter != null &amp;&amp; parameter.append()) &#123;37: String pre = parameters.get(Constants.DEFAULT_KEY + "." + key); // default. 里获取，适用于 ServiceConfig =》ProviderConfig 、ReferenceConfig =》ConsumerConfig 。38: if (pre != null &amp;&amp; pre.length() &gt; 0) &#123;39: str = pre + "," + str;40: &#125;41: pre = parameters.get(key); // 通过 `parameters` 属性配置，例如 `AbstractMethodConfig.parameters` 。42: if (pre != null &amp;&amp; pre.length() &gt; 0) &#123;43: str = pre + "," + str;44: &#125;45: &#125;46: if (prefix != null &amp;&amp; prefix.length() &gt; 0) &#123;47: key = prefix + "." + key;48: &#125;49: parameters.put(key, str);50: // System.out.println("kv:" + key + "\t" + str);51: &#125; else if (parameter != null &amp;&amp; parameter.required()) &#123;52: throw new IllegalStateException(config.getClass().getSimpleName() + "." + key + " == null");53: &#125;54: &#125; else if ("getParameters".equals(name)55: &amp;&amp; Modifier.isPublic(method.getModifiers())56: &amp;&amp; method.getParameterTypes().length == 057: &amp;&amp; method.getReturnType() == Map.class) &#123; // `#getParameters()` 方法58: Map&lt;String, String&gt; map = (Map&lt;String, String&gt;) method.invoke(config, new Object[0]);59: if (map != null &amp;&amp; map.size() &gt; 0) &#123;60: String pre = (prefix != null &amp;&amp; prefix.length() &gt; 0 ? prefix + "." : "");61: for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123;62: parameters.put(pre + entry.getKey().replace('-', '.'), entry.getValue());63: &#125;64: &#125;65: &#125;66: &#125; catch (Exception e) &#123;67: throw new IllegalStateException(e.getMessage(), e);68: &#125;69: &#125;70: &#125; parameters ，参数集合。实际上，该集合会用于 URL.parameters 。 config ，配置对象。 prefix ，属性前缀。用于配置项添加到 parameters 中时的前缀。 第 5 行：获得所有方法的数组，为下面通过反射获得配置项的值做准备。 第 6 行：循环每个方法。 第 9 至 13 行：方法为获得 基本类型 + 1public 的 getting 方法。 第 14 至 17 行：返回值类型为 Object 或排除( `@Parameter.exclue=true` )的配置项，跳过。 第 19 至 26 行：获得配置项名。 第 28 至 48 行：获得配置项值。中间有一些逻辑处理，胖友看下代码的注释。 第 49 行：添加配置项到 parameters 。 第 51 至 53 行：当 `@Parameter.required = true` 时，校验配置项非空。 第 54 至 57 行：当方法为 1#getParameters() 时， 例如 。 第 58 行：通过反射，获得 #getParameters() 的返回值为 map 。 第 59 至 64 行：将 map 添加到 parameters ，kv 格式为 prefix:entry.key entry.value 。 因此，通过 #getParameters() 对应的属性，动态设置配置项，拓展出非 Dubbo 内置好的逻辑。 #appendAttributes(parameters, config, prefix) 方法，将 @Parameter(attribute = true) 配置对象的属性，添加到参数集合。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738 1: protected static void appendAttributes(Map&lt;Object, Object&gt; parameters, Object config, String prefix) &#123; 2: if (config == null) &#123; 3: return; 4: &#125; 5: Method[] methods = config.getClass().getMethods(); 6: for (Method method : methods) &#123; 7: try &#123; 8: String name = method.getName(); 9: if ((name.startsWith("get") || name.startsWith("is"))10: &amp;&amp; !"getClass".equals(name)11: &amp;&amp; Modifier.isPublic(method.getModifiers())12: &amp;&amp; method.getParameterTypes().length == 013: &amp;&amp; isPrimitive(method.getReturnType())) &#123; // 方法为获取基本类型，public 的 getting 方法。14: Parameter parameter = method.getAnnotation(Parameter.class);15: if (parameter == null || !parameter.attribute())16: continue;17: // 获得属性名18: String key;19: if (parameter != null &amp;&amp; parameter.key() != null &amp;&amp; parameter.key().length() &gt; 0) &#123;20: key = parameter.key();21: &#125; else &#123;22: int i = name.startsWith("get") ? 3 : 2;23: key = name.substring(i, i + 1).toLowerCase() + name.substring(i + 1);24: &#125;25: // 获得属性值，存在则添加到 `parameters` 集合26: Object value = method.invoke(config, new Object[0]);27: if (value != null) &#123;28: if (prefix != null &amp;&amp; prefix.length() &gt; 0) &#123;29: key = prefix + "." + key;30: &#125;31: parameters.put(key, value);32: &#125;33: &#125;34: &#125; catch (Exception e) &#123;35: throw new IllegalStateException(e.getMessage(), e);36: &#125;37: &#125;38: &#125; 不同于 #appendAttributes(parameters, config, prefix) 方法，主要用于 《Dubbo 用户指南 —— 事件通知》 ，注解 @Parameter(attribute = true) 的属性如下图： 第 9 至 13 行：方法为获得基本类型 + public 的 getting 方法。 第 14 至 16 行：需要( `@Parameter.exclue=true` )的配置项。 第 17 至 24 行：获得配置项名。 第 26 至 30 行：获得配置项值。 第 31 行：添加配置项到 parameters 。 #appendProperties(config) 方法，读取环境变量和 properties 配置到配置对象。在 《精进 Dubbo 源码解析 —— 属性配置》 详细解析。 #appendAnnotation(annotationClass, annotation) 方法，读取注解配置到配置对象。在 《精进 Dubbo 源码解析 —— 注解配置》 详细解析。 3.2 ApplicationConfigcom.alibaba.dubbo.config.ApplicationConfig ，应用配置。 具体属性的解释，参见 《Dubbo 用户指南 —— dubbo:application》 文档。 3.3 RegistryConfigcom.alibaba.dubbo.config.RegistryConfig ，注册中心配置。 具体属性的解释，参见 《Dubbo 用户指南 —— dubbo:registry》 文档。 3.4 ModuleConfigcom.alibaba.dubbo.config.ModuleConfig ，模块信息配置。 具体属性的解释，参见 《Dubbo 用户指南 —— dubbo:module》 文档。 3.5 MonitorConfigcom.alibaba.dubbo.config.MonitorConfig ，监控中心配置。 具体属性的解释，参见 《Dubbo 用户指南 —— dubbo:monitor》 文档。 3.6 ArgumentConfigcom.alibaba.dubbo.config.ArgumentConfig ，方法参数配置。 具体属性的解释，参见 《Dubbo 用户指南 —— dubbo:argument》 文档。 该配置类设置到 MethodConfig 对象中，在 《API 配置（二）之服务提供者》 我们会看到。 在 《Dubbo 用户指南 —— 参数回调》 特性中使用。 4. URLcom.alibaba.dubbo.common.URL ，Dubbo URL 。代码如下： 123456789101112131415161718192021222324252627282930313233343536public final class URL implements Serializable &#123; /** * 协议名 */ private final String protocol; /** * 用户名 */ private final String username; /** * 密码 */ private final String password; /** * by default, host to registry * 地址 */ private final String host; /** * by default, port to registry * 端口 */ private final int port; /** * 路径（服务名） */ private final String path; /** * 参数集合 */ private final Map&lt;String, String&gt; parameters; // ... 省略其他代码&#125; 上文我们提到所有配置最终都将转换为 Dubbo URL 表示，并由服务提供方生成，经注册中心传递给消费方，各属性对应 URL 的参数，参见配置项一览表中的 “对应URL参数” 列。那么一个 Service 注册到注册中心的格式如下： 1dubbo://192.168.3.17:20880/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider&amp;default.delay=-1&amp;default.retries=0&amp;default.service.filter=demoFilter&amp;delay=-1&amp;dubbo=2.0.0&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello&amp;pid=19031&amp;side=provider&amp;timestamp=1519651641799 格式为 protocol://username:password@host:port/path?key=value&amp;key=value ，通过 URL#buildString(...) 方法生成。 parameters 属性，参数集合。从上面的 Service URL 例子我们可以看到，里面的 key=value ，实际上就是 Service 对应的配置项。该属性，通过 AbstractConfig#appendParameters(parameters, config, prefix) 方法生成。 🙂 在后续的文章中，我们会发现 URL 作为一个通用模型，贯穿整个 RPC 流程。 5. @Parametercom.alibaba.dubbo.config.support.@Parameter ，Parameter 参数注解，用于 Dubbo URL 的 parameters 拼接。 在配置对象的 getting 方法上，我们可以看到该注解的使用，例如下图： @Parameter 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD&#125;)public @interface Parameter &#123; /** * 键（别名） */ String key() default ""; /** * 是否必填 */ boolean required() default false; /** * 是否忽略 */ boolean excluded() default false; /** * 是否转义 */ boolean escaped() default false; /** * 是否为属性 * * 目前用于《事件通知》http://dubbo.apache.org/zh-cn/docs/user/demos/events-notify.html */ boolean attribute() default false; /** * 是否拼接默认属性，参见 &#123;@link com.alibaba.dubbo.config.AbstractConfig#appendParameters(Map, Object, String)&#125; 方法。 * * 我们来看看 `#append() = true` 的属性，有如下四个： * + &#123;@link AbstractInterfaceConfig#getFilter()&#125; * + &#123;@link AbstractInterfaceConfig#getListener()&#125; * + &#123;@link AbstractReferenceConfig#getFilter()&#125; * + &#123;@link AbstractReferenceConfig#getListener()&#125; * + &#123;@link AbstractServiceConfig#getFilter()&#125; * + &#123;@link AbstractServiceConfig#getListener()&#125; * 那么，以 AbstractServiceConfig 举例子。 * * 我们知道 ProviderConfig 和 ServiceConfig 继承 AbstractServiceConfig 类，那么 `filter` , `listener` 对应的相同的键。 * 下面我们以 `filter` 举例子。 * * 在 ServiceConfig 中，默认会&lt;b&gt;继承&lt;/b&gt; ProviderConfig 配置的 `filter` 和 `listener` 。 * 所以这个属性，就是用于，像 ServiceConfig 的这种情况，从 ProviderConfig 读取父属性。 * * 举个例子，如果 `ProviderConfig.filter=aaaFilter` ，`ServiceConfig.filter=bbbFilter` ，最终暴露到 Dubbo URL 时，参数为 `service.filter=aaaFilter,bbbFilter` 。 */ boolean append() default false; 胖友可以简单看下代码中的注释，结合具体使用的方法，在细细理解。]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精尽 Dubbo 源码分析 —— 项目结构一览]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%B2%BE%E5%B0%BD-Dubbo-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E2%80%94%E2%80%94-%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E4%B8%80%E8%A7%88%2F</url>
    <content type="text"><![CDATA[1. 概述本文主要分享 Dubbo 的项目结构。希望通过本文能让胖友对 Dubbo 的整体项目有个简单的了解。 另外，笔者会相对大量引用 《Dubbo 用户指南》 和 《Dubbo 开发指南》 ，写的真的挺好的。🙂ps：限于排版，部分地方引用会存在未标明的情况。 在拉取 Dubbo 项目后，我们会发现拆分了好多 Maven 项目。是不是内心一紧，产生了恐惧感？不要方，我们就是继续怼。 2. 代码统计这里先分享一个小技巧。笔者在开始源码学习时，会首先了解项目的代码量。 第一种方式，使用 IDEA Statistic 插件，统计整体代码量。 我们可以粗略的看到，总的代码量在 98210 行。这其中还包括单元测试，示例等等代码。所以，不慌。 第二种方式，使用 Shell 脚本命令逐个 Maven 模块统计 。 一般情况下，笔者使用 find . -name &quot;*.java&quot;|xargs cat|grep -v -e ^$ -e ^\s*\/\/.*$|wc -l 。这个命令只过滤了部分注释，所以相比 IDEA Statistic 会偏多。 当然，考虑到准确性，胖友需要手动 cd 到每个 Maven 项目的 src/main/java 目录下，以达到排除单元测试的代码量。 3. 项目一览如果胖友看过 《Dubbo 框架设计》 ，就会发现有下面这张图。 通过这图，我们可以很清晰的知道几个 Maven 模块的依赖关系。 3.1 dubbo-common dubbo-common 公共逻辑模块：提供工具类和通用模型。 工具类比较好理解，通用模型是什么？举个例子，com.alibaba.dubbo.common.URL ： FROM 《Dubbo 开发指南 —— 公共契约》 所有扩展点参数都包含 URL 参数，URL 作为上下文信息贯穿整个扩展点设计体系。 URL 采用标准格式：protocol://username:password@host:port/path?key=value&amp;key=value 。 那么 URL 有什么用呢？😈 请见后续文章。 3.2 dubbo-remoting dubbo-remoting 远程通信模块：提供通用的客户端和服务端的通讯功能。 dubbo-remoting-zookeeper ，相当于 Zookeeper Client ，和 Zookeeper Server 通信。 dubbo-remoting-api ， 定义了 Dubbo Client 和 Dubbo Server 的接口。 实现 1dubbo-remoting-api dubbo-remoting-grizzly ，基于 Grizzly 实现。 dubbo-remoting-http ，基于 Jetty 或 Tomcat 实现。 dubbo-remoting-mina ，基于 Mina 实现。 dubbo-remoting-netty ，基于 Netty 3 实现。 dubbo-remoting-netty4 ，基于 Netty 4 实现。 dubbo-remoting-p2p ，P2P 服务器。注册中心 dubbo-registry-multicast 项目的使用该项目。 从最小化的角度来看，我们只需要看： dubbo-remoting-api + dubbo-remoting-netty4 dubbo-remoting-zookeeper 3.3 dubbo-rpc dubbo-rpc 远程调用模块：抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。 集群相关的管理，由 dubbo-cluster 提供特性。 在回过头看上面的图，我们会发现，dubbo-rpc 是整个 Dubbo 的中心。 dubbo-rpc-api ，抽象各种协议以及动态代理，实现了一对一的调用。 其他模块，实现 dubbo-rpc-api ，提供对应的协议实现。在 《用户指南 —— 协议参考手册》 中，可以看到每种协议的介绍。 另外，dubbo-rpc-default 对应 dubbo:// 协议。 拓展参见 《Dubbo 开发指南 —— 协议扩展》 文档。 进一步的拆解，见 《精尽 Dubbo 源码分析 —— 核心流程一览》 文章。 3.4 dubbo-cluster dubbo-cluster 集群模块：将多个服务提供方伪装为一个提供方，包括：负载均衡, 集群容错，路由，分组聚合等。集群的地址列表可以是静态配置的，也可以是由注册中心下发。 注册中心下发，由 dubbo-registry 提供特性。 容错 com.alibaba.dubbo.rpc.cluster.Cluster 接口 + com.alibaba.dubbo.rpc.cluster.support 包。 Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。 拓展参见 《Dubbo 用户指南 —— 集群容错》 和 《Dubbo 开发指南 —— 集群扩展》 文档。 目录 com.alibaba.dubbo.rpc.cluster.Directory 接口 + com.alibaba.dubbo.rpc.cluster.directory 包。 Directory 代表了多个 Invoker ，可以把它看成 List ，但与 List 不同的是，它的值可能是动态变化的，比如注册中心推送变更。 路由 com.alibaba.dubbo.rpc.cluster.Router 接口 + com.alibaba.dubbo.rpc.cluster.router 包。 负责从多个 Invoker 中按路由规则选出子集，比如读写分离，应用隔离等。 拓展参见 《Dubbo 用户指南 —— 路由规则》 和 《Dubbo 开发指南 —— 路由拓展》 文档。 配置 com.alibaba.dubbo.rpc.cluster.Configurator 接口 + com.alibaba.dubbo.rpc.cluster.configurator 包。 拓展参见 《Dubbo 用户指南 —— 配置规则》 文档。 负载均衡 com.alibaba.dubbo.rpc.cluster.LoadBalance 接口 + com.alibaba.dubbo.rpc.cluster.loadbalance 包。 LoadBalance 负责从多个 Invoker 中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后，需要重选。 拓展参见 《Dubbo 用户指南 —— 负载均衡》 和 《Dubbo 开发指南 —— 负载均衡拓展》 文档。 合并结果 com.alibaba.dubbo.rpc.cluster.Merger 接口 + com.alibaba.dubbo.rpc.cluster.merger 包。 合并返回结果，用于分组聚合。 拓展参见 《Dubbo 用户指南 —— 分组聚合》 和 《Dubbo 开发指南 —— 合并结果扩展》 文档。 整体流程如下： 3.5 dubbo-registry dubbo-registry 注册中心模块：基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。 dubbo-registry-api ，抽象注册中心的注册与发现接口。 其他模块，实现 dubbo-registry-api ，提供对应的注册中心实现。在 《用户指南 —— 注册中心参考手册》 中，可以看到每种注册中心的介绍。 另外，dubbo-registry-default 对应 Simple 注册中心。 拓展参见 《Dubbo 开发指南 —— 注册中心扩展》 文档。 3.6 dubbo-monitor dubbo-monitor 监控模块：统计服务调用次数，调用时间的，调用链跟踪的服务。 拓展参见 《Dubbo 开发指南 —— 监控中心扩展》 。 目前社区里，有对 Dubbo 监控中心进行重构的项目，例如 ： https://github.com/handuyishe/dubbo-monitor https://github.com/zhongxig/dubbo-d-monitor 3.7 dubbo-config dubbo-config 配置模块：是 Dubbo 对外的 API，用户通过 Config 使用Dubbo，隐藏 Dubbo 所有细节。 dubbo-config-api ，实现了 API 配置 和 属性配置 功能。 dubbo-config-spring ，实现了 XML 配置 和 注解配置 功能。 推荐阅读 《Dubbo 开发指南 —— 配置设计》 。 3.8 dubbo-container dubbo-container 容器模块：是一个 Standlone 的容器，以简单的 Main 加载 Spring 启动，因为服务通常不需要 Tomcat/JBoss 等 Web 容器的特性，没必要用 Web 容器去加载服务。 dubbo-container-api ：定义了 com.alibaba.dubbo.container.Container 接口，并提供 加载所有容器启动的 Main 类。 实现 1dubbo-container-api dubbo-container-spring ，提供了 com.alibaba.dubbo.container.spring.SpringContainer 。 dubbo-container-log4j ，提供了 com.alibaba.dubbo.container.log4j.Log4jContainer 。 dubbo-container-logback ，提供了 com.alibaba.dubbo.container.logback.LogbackContainer 。 拓展参考 《Dubbo 用户指南 —— 服务容器》 和 《Dubbo 开发指南 —— 容器扩展》 文档。 3.9 dubbo-filterdubbo-filter 过滤器模块：提供了内置的过滤器。 1dubbo-filter-cache ，缓存过滤器。 拓展参考 《Dubbo 用户指南 —— 结果缓存》 和 《Dubbo 开发指南 —— 缓存拓展》 文档。 1dubbo-filter-validation ，参数验证过滤器。 拓展参考 《Dubbo 用户指南 —— 参数验证》 和 《Dubbo 开发指南 —— 验证扩展》 文档。 3.10 dubbo-plugindubbo-plugin 插件模块：提供了内置的插件。 1dubbo-qos ，提供在线运维命令。 拓展参考 《Dubbo 用户指南 —— 新版本 telnet 命令使用说明》 和 《Dubbo 开发指南 —— Telnet 命令扩展》 文档。 3.11 hessian-litehessian-lite ：Dubbo 对 Hessian 2 的 序列化 部分的精简、改进、BugFix 。 提交历史如下： 3.12 dubbo-demodubbo-demo 快速启动示例。 参见 《Dubbo 用户指南 —— 快速启动》 文档。 3.13 dubbo-testdubbo-test 测试模块。 1dubbo-test-benchmark ，性能测试。 参考 《Dubbo 用户指南 —— 性能测试报告》 文档。 1dubbo-test-compatibility ，兼容性测试。 dubbo-test-spring3 ，测试对 Spring 3 的兼容性。 dubbo-test-example ，使用示例。 3.14 Maven POM3.14.1 dubbo-dependencies-bomdubbo-dependencies-bom/pom.xml ，Maven BOM(Bill Of Materials) ，统一定义了 Dubbo 依赖的三方库的版本号： dubbo-parent 会引入该 BOM ： 更多 Maven BOM 的知识，可以看下 《Maven 与Spring BOM(Bill Of Materials)简化Spring版本控制》 文档： 通俗解说：为了防止用 Maven 管理 Spring 项目时，不同的项目依赖了不同版本的 Spring ，可以使用 Maven BOM 来解决者一问题。 3.14.2 dubbo-bomdubbo-bom/pom.xml ，Maven BOM(Bill Of Materials) ，统一定义了 Dubbo 的版本号： dubbo-demo 和 dubbo-test 会引入该 BOM 。以 dubbo-demo 举例子： 3.14.3 dubbo-parentdubbo/pom.xml ，Dubbo Parent Pom 。 Dubbo 的 Maven 模块，都会引入该 pom 文件。以 dubbo-cluster 举例子： 我们整理下上面的 pom 文件： 3.14.4 dubbo-alldubbo/all/pom.xml ，Dubbo All Pom ，定义了 Dubbo 的打包脚本。 我们在使用 Dubbo 库时，引入该 pom 文件。]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精尽 Dubbo 面试题]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%B2%BE%E5%B0%BD-Dubbo-%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[以下面试题，基于网络整理，和自己编辑。具体参考的文章，会在文末给出所有的链接。 如果胖友有自己的疑问，欢迎在星球提问，我们一起整理吊吊的 Dubbo 面试题的大保健。 而题目的难度，艿艿尽量按照从容易到困难的顺序，逐步下去。 Dubbo 有几种配置方式？正如在 《Dubbo 用户指南 —— 配置》 中所见，一共有四种配置方式： XML 配置 注解配置 属性配置 Java API 配置 实际上，还有第五种方式，外部化配置。参见 《Dubbo 新编程模型之外部化配置》 。 目前，主要使用的是 XML 配置和注解配置。具体使用哪一种，就看大家各自的喜好。目前，艿艿偏好 XML 配置，更加清晰好管理。 Dubbo 如何和 Spring Boot 进行集成？官方提供提供了集成库 dubbo-spring-boot ，对应仓库为 https://github.com/apache/incubator-dubbo-spring-boot-project 。 Dubbo 框架的分层设计在 《精尽 Dubbo 源码分析 —— 核心流程一览》 一文中，对 Dubbo 框架的分层已经有过介绍，这里再来一次。 相对比较复杂，一共分成 10 层，当然理解后是非常清晰的。如下图所示： 图例说明 最顶上九个图标，代表本图中的对象与流程。 图中左边 淡蓝背景( Consumer ) 的为服务消费方使用的接口，右边 淡绿色背景( Provider ) 的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。 图中从下至上分为十层，各层均为单向依赖，右边的 黑色箭头( Depend ) 代表层之间的依赖关系，每一层都可以剥离上层被复用。其中，Service 和 Config 层为 API，其它各层均为 SPI 。 注意，Dubbo 并未使用 JDK SPI 机制，而是自己实现了一套 Dubbo SPI 机制。 图中 绿色小块( Interface ) 的为扩展接口，蓝色小块( Class ) 为实现类，图中只显示用于关联各层的实现类。 图中 蓝色虚线( Init ) 为初始化过程，即启动时组装链。红色实线( Call )为方法调用过程，即运行时调时链。紫色三角箭头( Inherit )为继承，可以把子类看作父类的同一个节点，线上的文字为调用的方法。 各层说明 虽然，有 10 层这么多，但是总体是分层 Business、RPC、Remoting 三大层。如下： ==================== Business ==================== Service 业务层：业务代码的接口与实现。我们实际使用 Dubbo 的业务层级。 接口层，给服务提供者和消费者来实现的。 ==================== RPC ==================== config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 Spring 解析配置生成配置类。 配置层，主要是对 Dubbo 进行各种配置的。 proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 扩展接口为 ProxyFactory 。 服务代理层，无论是 consumer 还是 provider，Dubbo 都会给你生成代理，代理之间进行网络通信。 如果胖友了解 Spring Cloud 体系，可以类比成 Feign 对于 consumer ，Spring MVC 对于 provider 。 registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService 。 服务注册层，负责服务的注册与发现。 如果胖友了解 Spring Cloud 体系，可以类比成 Eureka Client 。 cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance 。 集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务。 如果胖友了解 Spring Cloud 体系，可以类比城 Ribbon 。 monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService 。 监控层，对 rpc 接口的调用次数和调用时间进行监控。 如果胖友了解 SkyWalking 链路追踪，你会发现，SkyWalking 基于 MonitorFilter 实现增强，从而透明化埋点监控。 ==================== Remoting ==================== protocol 远程调用层：封将 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter 。 远程调用层，封装 rpc 调用。 exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer 。 信息交换层，封装请求响应模式，同步转异步。 transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec 。 网络传输层，抽象 mina 和 netty 为统一接口。 serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool 。 数据序列化层。 Dubbo 调用流程 Provider 第 0 步，start 启动服务。 第 1 步，register 注册服务到注册中心。 Consumer 第 2 步，subscribe 向注册中心订阅服务。 注意，只订阅使用到的服务。 再注意，首次会拉取订阅的服务列表，缓存在本地。 【异步】第 3 步，notify 当服务发生变化时，获取最新的服务列表，更新本地缓存。 invoke 调用 Consumer 直接发起对 Provider 的调用，无需经过注册中心。而对多个 Provider 的负载均衡，Consumer 通过 cluster 组件实现。 count 监控 【异步】Consumer 和 Provider 都异步通知监控中心。 这里艿艿在引用一张在网上看到的图，更立体的展示 Dubbo 的调用流程： 注意，图中的【代理】指的是 proxy 代理服务层，和 Consumer 或 Provider 在同一进城中。 注意，图中的【负载均衡】指的是 cluster 路由层，和 Consumer 或 Provider 在同一进程中。 Dubbo 调用是同步的吗？默认情况下，调用是同步的方式。 可以参考 《Dubbo 用户指南 —— 异步调用》 文档，配置异步调用的方式。当然，使用上，感觉蛮不优雅的。所以，在 Dubbo 2.7 版本后，又提供了新的两种方式，具体先参见 《Dubbo下一站：Apache顶级项目》 文章。估计，后续才会更新官方文档。 谈谈对 Dubbo 的异常处理机制？Dubbo 异常处理机制涉及的内容比较多，核心在于 Provider 的 异常过滤器 ExceptionFilter 对调用结果的各种情况的处理。所以建议胖友看如下三篇文章： 墙裂推荐 《Dubbo(四) 异常处理》 《浅谈 Dubbo 的 ExceptionFilter 异常处理》 《精尽 Dubbo 源码分析 —— 过滤器（七）之 ExceptionFilter》 Dubbo 如何做参数校验？在 《Dubbo 用户指南 —— 参数验证》 中，介绍如下： 参数验证功能是基于 JSR303 实现的，用户只需标识 JSR303 标准的验证 annotation，并通过声明 filter 来实现验证。 参数校验功能，通过参数校验过滤器 ValidationFilter 来实现。 ValidationFilter 在 Dubbo Provider 和 Consumer 都可生效。 如果我们将校验注解写在 Service 接口的方法上，那么 Consumer 在本地就会校验。如果校验不通过，直接抛出校验失败的异常，不会发起 Dubbo 调用。 如果我们将校验注解写在 Service 实现的方法上，那么 Consumer 在本地不会校验，而是由 Provider 校验。 Dubbo 可以对调用结果进行缓存吗?Dubbo 通过 CacheFilter 过滤器，提供结果缓存的功能，且既可以适用于 Consumer 也可以适用于 Provider 。 通过结果缓存，用于加速热门数据的访问速度，Dubbo 提供声明式缓存，以减少用户加缓存的工作量。 Dubbo 目前提供三种实现： lru ：基于最近最少使用原则删除多余缓存，保持最热的数据被缓存。 threadlocal ：当前线程缓存，比如一个页面渲染，用到很多 portal，每个 portal 都要去查用户信息，通过线程缓存，可以减少这种多余访问。 jcache ：与 JSR107 集成，可以桥接各种缓存实现。 详细的源码解析，可见 《精尽 Dubbo 源码分析 —— 过滤器（十）之 CacheFilter》 。 注册中心挂了还可以通信吗？可以。对于正在运行的 Consumer 调用 Provider 是不需要经过注册中心，所以不受影响。并且，Consumer 进程中，内存已经缓存了 Provider 列表。 那么，此时 Provider 如果下线呢？如果 Provider 是正常关闭，它会主动且直接对和其处于连接中的 Consumer 们，发送一条“我要关闭”了的消息。那么，Consumer 们就不会调用该 Provider ，而调用其它的 Provider 。 另外，因为 Consumer 也会持久化 Provider 列表到本地文件。所以，此处如果 Consumer 重启，依然能够通过本地缓存的文件，获得到 Provider 列表。 再另外，一般情况下，注册中心是一个集群，如果一个节点挂了，Dubbo Consumer 和 Provider 将自动切换到集群的另外一个节点上。 Dubbo 在 Zookeeper 存储了哪些信息？下面，我们先来看下 《Dubbo 用户指南 —— zookeeper 注册中心》 文档，内容如下： 流程说明： 服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址 监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。 在图中，我们可以看到 Zookeeper 的节点层级，自上而下是： Root 层：根目录，可通过 &lt;dubbo:registry group=&quot;dubbo&quot; /&gt; 的 &quot;group&quot; 设置 Zookeeper 的根节点，缺省使用 &quot;dubbo&quot; 。 Service 层：服务接口全名。 Type 层：分类。目前除了我们在图中看到的 &quot;providers&quot;( 服务提供者列表 ) &quot;consumers&quot;( 服务消费者列表 ) 外，还有 &quot;routes&quot;( 路由规则列表 ) 和 &quot;configurations&quot;( 配置规则列表 )。 URL 层：URL ，根据不同 Type 目录，下面可以是服务提供者 URL 、服务消费者 URL 、路由规则 URL 、配置规则 URL 。 实际上 URL 上带有 &quot;category&quot; 参数，已经能判断每个 URL 的分类，但是 Zookeeper 是基于节点目录订阅的，所以增加了 Type层。 实际上，服务消费者启动后，不仅仅订阅了 &quot;providers&quot; 分类，也订阅了 &quot;routes&quot; &quot;configurations&quot; 分类。 Dubbo Provider 如何实现优雅停机？在 《Dubbo 用户指南 —— 优雅停机》 中，已经对这块进行了详细的说明。 优雅停机 Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果用户使用 kill -9 PID 等强制关闭指令，是不会执行优雅停机的，只有通过 kill PID 时，才会执行。 因为大多数情况下，Dubbo 的声明周期是交给 Spring 进行管理，所以在最新的 Dubbo 版本中，增加了对 Spring 关闭事件的监听，从而关闭 Dubbo 服务。对应可见 https://github.com/apache/incubator-dubbo/issues/2865 。 服务提供方的优雅停机过程 首先，从注册中心中取消注册自己，从而使消费者不要再拉取到它。 然后，sleep 10 秒( 可配 )，等到服务消费，接收到注册中心通知到该服务提供者已经下线，加大了在不重试情况下优雅停机的成功率。😈 此处是个概率学，嘻嘻。 之后，广播 READONLY 事件给所有 Consumer 们，告诉它们不要在调用我了！！！【很有趣的一个步骤】并且，如果此处注册中心挂掉的情况，依然能达到告诉 Consumer ，我要下线了的功能。 再之后，sleep 10 毫秒，保证 Consumer 们，尽可能接收到该消息。 再再之后，先标记为不接收新请求，新请求过来时直接报错，让客户端重试其它机器。 再再再之后，关闭心跳线程。 最后，检测线程池中的线程是否正在运行，如果有，等待所有线程执行完成，除非超时，则强制关闭。 最最后，关闭服务器。 整个过程比较复杂，感兴趣的胖友，可以详细来看看 《精尽 Dubbo 源码解析 —— 优雅停机》 。 服务消费方的优雅停机过程 停止时，不再发起新的调用请求，所有新的调用在客户端即报错。 然后，检测有没有请求的响应还没有返回，等待响应返回，除非超时，则强制关闭。 Dubbo Provider 异步关闭时，如何从注册中心下线？① Zookeeper 注册中心的情况下 服务提供者，注册到 Zookeeper 上时，创建的是 EPHEMERAL 临时节点。所以在服务提供者异常关闭时，等待 Zookeeper 会话超时，那么该临时节点就会自动删除。 ② Redis 注册中心的情况下 使用 Redis 作为注册中心，是有点小众的选择，我们就不在本文详细说了。感兴趣的胖友，可以看看 《精尽 Dubbo 源码分析 —— 注册中心（三）之 Redis》 一文。总的来说，实现上，还是蛮有趣的。因为，需要通知到消费者，服务列表发生变化，所以就无法使用 Redis Key 自动过期。所以… 还是看文章吧。哈哈哈哈。 Dubbo Consumer 只能调用从注册中心获取的 Provider 么？不是，Consumer 可以强制直连 Provider 。 在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，点对点直连方式，将以服务接口为单位，忽略注册中心的提供者列表，A 接口配置点对点，不影响 B 接口从注册中心获取列表。 相关文档，可见 《Dubbo 用户指南 —— 直连提供者》 。 另外，直连 Dubbo Provider 时，如果要 Debug 调试 Dubbo Provider ，可以通过配置，禁用该 Provider 注册到注册中心。否则，会被其它 Consumer 调用到。具体的配置方式，参见 《Dubbo 用户指南 —— 只订阅》 。 Dubbo 支持哪些通信协议？ 对应【protocol 远程调用层】。 Dubbo 目前支持如下 9 种通信协议： 【重要】dubbo:// ，默认协议。参见 《Dubbo 用户指南 —— dubbo://》 。 【重要】rest:// ，贡献自 Dubbox ，目前最合适的 HTTP Restful API 协议。参见 《Dubbo 用户指南 —— rest://》 。 rmi:// ，参见 《Dubbo 用户指南 —— rmi://》 。 webservice:// ，参见 《Dubbo 用户指南 —— webservice://》 。 hessian:// ，参见 《Dubbo 用户指南 —— hessian://》 。 thrift:// ，参见 《Dubbo 用户指南 —— thrift://》 。 memcached:// ，参见 《Dubbo 用户指南 —— memcached://》 。 redis:// ，参见 《Dubbo 用户指南 —— redis://》 。 http:// ，参见 《Dubbo 用户指南 —— http://》 。注意，这个和我们理解的 HTTP 协议有差异，而是 Spring 的 HttpInvoker 实现。 实际上，社区里还有其他通信协议正处于孵化： jsonrpc:// ，对应 Github 仓库为 https://github.com/apache/incubator-dubbo-rpc-jsonrpc ，来自千米网的贡献。 😈 每一种通信协议的实现，在 《精尽 Dubbo 源码解析》 中，都有详细解析。 另外，在 《Dubbo 用户指南 —— 性能测试报告》 中，官方提供了上述协议的性能测试对比。 什么是本地暴露和远程暴露，他们的区别？远程暴露，比较好理解。在 「Dubbo 支持哪些通信协议？」 问题汇总，我们看到的，都是远程暴露。每次 Consumer 调用 Provider 都是跨进程，需要进行网络通信。 本地暴露，在 《Dubbo 用户指南 —— 本地调用》 一文中，定义如下： 本地调用使用了 injvm:// 协议，是一个伪协议，它不开启端口，不发起远程调用，只在 JVM 内直接关联，但执行 Dubbo 的 Filter 链。 怎么理解呢？本地的 Dubbo Service Proxy 对象，每次调用时，会走 Dubbo Filter 链。 举个例子，Spring Boot Controller 调用 Service 逻辑，就变成了调用 Dubbo Service Proxy 对象。这样，如果未来有一天，本地 Dubbo Service 迁移成远程的 Dubbo Service ，只需要进行配置的修改，而对 Controller 是透明的。 Dubbo 使用什么通信框架？ 对应【transport 网络传输层】。 在通信框架的选择上，强大的技术社区有非常多的选择，如下列表： Netty3 Netty4 Mina Grizzly 那么 Dubbo 是如何做技术选型和实现的呢？Dubbo 在通信层拆分成了 API 层、实现层。项目结构如下： API 层： dubbo-remoting-api 实现层： dubbo-remoting-netty3 dubbo-remoting-netty4 dubbo-remoting-mina dubbo-remoting-grizzly 再配合上 Dubbo SPI 的机制，使用者可以自定义使用哪一种具体的实现。美滋滋。 在 Dubbo 的最新版本，默认使用 Netty4 的版本。😈 这就是结论。嘻嘻。 Dubbo 支持哪些序列化方式？ 对应【serialize 数据序列化层】。 Dubbo 目前支付如下 7 种序列化方式： 【重要】Hessian2 ：基于 Hessian 实现的序列化拓展。 1dubbo:// 协议的默认序列化方案。 Hessian 除了是 Web 服务，也提供了其序列化实现，因此 Dubbo 基于它实现了序列化拓展。 另外，Dubbo 维护了自己的 hessian-lite ，对 Hessian 2 的 序列化 部分的精简、改进、BugFix 。 Dubbo ：Dubbo 自己实现的序列化拓展。 具体可参见 《精尽 Dubbo 源码分析 —— 序列化（二）之 Dubbo 实现》 。 Kryo ：基于 Kryo 实现的序列化拓展。 具体可参见 《Dubbo 用户指南 —— Kryo 序列化》 FST ：基于 FST 实现的序列化拓展。 具体可参见 《Dubbo 用户指南 —— FST 序列化》 JSON ：基于 Fastjson 实现的序列化拓展。 NativeJava ：基于 Java 原生的序列化拓展。 CompactedJava ：在 NativeJava 的基础上，实现了对 ClassDescriptor 的处理。 可能胖友会一脸懵逼，有这么多？其实还好，上述基本是市面上主流的集中序列化工具，Dubbo 基于它们之上提供序列化拓展。 然后，胖友可能会说，Protobuf 也是非常优秀的序列化方案，为什么 Dubbo 没有基于它的序列化拓展？从 Dubbo 后续的开发计划上，应该会增加该序列化的支持。另外，微博的 Motan 有实现对 Protobuf 序列化的支持，感兴趣的胖友，可以看看 《深入理解RPC之序列化篇 —— 总结篇》 的 「Protostuff实现」 小节。 Dubbo 有哪些负载均衡策略？ 对应【cluster 路由层】的 LoadBalance 组件。 在 《Dubbo 用户指南 —— 负载均衡》 中，我们可以看到 Dubbo 内置 4 种负载均衡策略。其中，默认使用 random 随机调用策略。 Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮询，按公约后的权重设置轮询比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 举个栗子。 跟运维同学申请机器，有的时候，我们运气好，正好公司资源比较充足，刚刚有一批热气腾腾、刚刚做好的一批虚拟机新鲜出炉，配置都比较高。8核+16g，机器，2 台。过了一段时间，我感觉 2 台机器有点不太够，我去找运维同学，哥儿们，你能不能再给我 1 台机器，4核+8G的机器。我还是得要。 这个时候，可以给两台 8核16g 的机器设置权重 4，给剩余 1 台 4核8G 的机器设置权重 2。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 这个就是自动感知一下，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给不活跃的性能差的机器更少的请求。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 Dubbo 有哪些集群容错策略？ 对应【cluster 路由层】的 Cluster 组件。 在 《Dubbo 用户指南 —— 集群容错》 中，我们可以看到 Dubbo 内置 6 种负载均衡策略。其中，默认使用 failover 失败自动重试其他服务的策略。 Failover Cluster 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。 Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 Dubbo 有哪些动态代理策略？ 对应【proxy 服务代理层】。 可能有胖友对动态代理不是很了解。因为，Consumer 仅仅引用服务 ***-api.jar 包，那么可以获得到需要服务的 XXXService 接口。那么，通过动态创建对应调用 Dubbo 服务的实现类。简化代码如下： 123456789101112// ProxyFactory.java/** * create proxy. * * 创建 Proxy ，在引用服务调用。 * * @param invoker Invoker 对象 * @return proxy */@Adaptive(&#123;Constants.PROXY_KEY&#125;)&lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException; 方法参数 invoker ，实现了调用 Dubbo 服务的逻辑。 返回的 &lt;T&gt; 结果，就是 XXXService 的实现类，而这个实现类，就是通过动态代理的工具类进行生成。 通过动态代理的方式，实现了对于我们开发使用 Dubbo 时，透明的效果。当然，因为实际场景下，我们是结合 Spring 场景在使用，所以不会直接使用该 API 。 目前实现动态代理的工具类还是蛮多的，如下： Javassist JDK 原生自带 CGLIB ASM 其中，Dubbo 动态代理使用了 Javassist 和 JDK 两种方式。 默认情况下，使用 Javassist 。 可通过 SPI 机制，切换使用 JDK 的方式。 为什么默认使用 Javassist？ 在 Dubbo 开发者【梁飞】的博客 《动态代理方案性能对比》 中，我们可以看到这几种方式的性能差异，而 Javassit 排在第一。也就是说，因为性能的原因。 有一点需要注意，Javassit 提供字节码 bytecode 生成方式和动态代理接口两种方式。后者的性能比 JDK 自带的还慢，所以 Dubbo 使用的是前者字节码 bytecode 生成方式。 那么是不是 JDK 代理就没意义？ 实际上，JDK 代理在 JDK 1.8 版本下，性能已经有很大的提升，并且无需引入三方工具的依赖，也是非常棒的选择。所以，Spring 和 Motan 在动态代理生成上，优先选择 JDK 代理。 注意，Spring 同时也选择了 CGLIB 作为生成动态代理的工具之一。 更多的内容，非常推荐阅读徐妈的 《深入理解 RPC 之动态代理篇》 。很棒！ Dubbo SPI 的设计思想是什么？首先的首先，我们得来理解 Java SPI 是什么？因为徐妈在这块已经写了非常非常非常不错的文章，我们直接认真，一定要认真看 《JAVA 拾遗 —— 关于 SPI 机制》 。 那么既然 Java SPI 机制已经这么牛逼，为什么 Dubbo 还要自己实现 Dubbo SPI 机制呢？良心的 Dubbo 在 《Dubbo 开发指南 —— 扩展点加载》 中，给出了答案： 1、JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 2、如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK 标准的 ScriptEngine，通过 getName() 获取脚本类型的名称，但如果 RubyScriptEngine 因为所依赖的 jruby.jar 不存在，导致 RubyScriptEngine 类加载失败，这个失败原因被吃掉了，和 ruby 对应不起来，当用户执行 ruby 脚本时，会报不支持 ruby，而不是真正失败的原因。 3、增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。 什么意思呢？ 第一点问题，Dubbo 有很多的拓展点，例如 Protocol、Filter 等等。并且每个拓展点有多种的实现，例如 Protocol 有 DubboProtocol、InjvmProtocol、RestProtocol 等等。那么使用 JDK SPI 机制，会初始化无用的拓展点及其实现，造成不必要的耗时与资源浪费。 第二点问题，因为没用过 ScriptEngine ，所以看不懂，哈哈哈哈。 第三点问题，严格来说，这不算问题，而是增加了功能特性，更多的提现是，Dubbo SPI 提供类似 Spring IoC 和 AOP 的功能。 如果如果如果想要深入理解 Dubbo SPI 体系，胖友可以阅读 《精尽 Dubbo 源码分析 —— 拓展机制 SPI》 。艿话说的好，读懂 Dubbo SPI 的源码，你就读懂了一半 Dubbo 的源码。 如果说，胖友想要自定义一个 Dubbo SPI 某个拓展点的实现，可以阅读 《Dubbo 开发指南 —— 扩展点加载》 。当然，如果你是首次写，可能会有一丢丢复杂。实际场景下，我们写的最多的是 Filter 调用拦截扩展 。所以，撸起袖子，来一发！ 当然，虽然 Dubbo 实现了 Dubbo SPI ，这并意味着 Java SPI 不好用。实际上，Java SPI 被大量中间件所采用，例如 Tomcat、SkyWalking、JDBC 等等。 再引申下，有些刁钻的面试官，可能会让你先讲讲 Spring IoC 是如何实现的，Dubbo SPI 是怎么提供 IoC 功能的，那么你可以看看如下两篇文章来准备： Spring IoC ，《面试问烂的 Spring IoC 过程》 。 Dubbo SPI IoC ，《Dubbo SPI 机制和 IoC》 的 「IOC 注入」。 再再引申下，有些刁钻的面试官，可能会让你先讲讲 Spring AOP 是如何实现的，Dubbo SPI 是怎么提供 AOP 功能的，那么你可以看看如下两篇文章来准备： Spring AOP ，《面试问烂的 Spring AOP 原理》 。 Dubbo SPI AOP ，详细见 《精尽 Dubbo 源码分析 —— 拓展机制 SPI》 文章。核心源码是： 123456789101112131415161718192021222324252627282930313233private static final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; EXTENSION_INSTANCES = new ConcurrentHashMap&lt;Class&lt;?&gt;, Object&gt;(); 1: 7: @SuppressWarnings("unchecked") 8: private T createExtension(String name) &#123; 9: // 获得拓展名对应的拓展实现类 10: Class&lt;?&gt; clazz = getExtensionClasses().get(name); 11: if (clazz == null) &#123; 12: throw findException(name); // 抛出异常 13: &#125; 14: try &#123; 15: // 从缓存中，获得拓展对象。 16: T instance = (T) EXTENSION_INSTANCES.get(clazz); 17: if (instance == null) &#123; 18: // 当缓存不存在时，创建拓展对象，并添加到缓存中。 19: EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); 20: instance = (T) EXTENSION_INSTANCES.get(clazz); 21: &#125; 22: // 注入依赖的属性 23: injectExtension(instance); 24: // 创建 Wrapper 拓展对象 25: Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; 26: if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) &#123; 27: for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; 28: instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); 29: &#125; 30: &#125; 31: return instance; 32: &#125; catch (Throwable t) &#123; 33: throw new IllegalStateException("Extension instance(name: " + name + ", class: " + 34: type + ") could not be instantiated: " + t.getMessage(), t); 35: &#125; 36: &#125; 第 24 至 30 行：创建 Wrapper 拓展对象，将 instance 包装在其中。在 《Dubbo 开发指南 —— 扩展点加载》 文章中，如此介绍 Wrapper 类： Wrapper 类同样实现了扩展点接口，但是 Wrapper 不是扩展点的真正实现。它的用途主要是用于从 ExtensionLoader 返回扩展点时，包装在真正的扩展点实现外。即从 ExtensionLoader 中返回的实际上是 Wrapper 类的实例，Wrapper 持有了实际的扩展点实现类。 扩展点的 Wrapper 类可以有多个，也可以根据需要新增。 通过 Wrapper 类可以把所有扩展点公共逻辑移至 Wrapper 中。新加的 Wrapper 在所有的扩展点上添加了逻辑，有些类似 AOP，即 Wrapper 代理了扩展点。 例如：ListenerExporterWrapper、ProtocolFilterWrapper 。 Dubbo 服务如何监控和管理？一旦使用 Dubbo 做了服务化后，必须必须必须要做的服务治理，也就是说，要做服务的管理与监控。当然，还有服务的降级和限流。这块，放在下面的面试题，在详细解析。 Dubbo 管理平台 + 监控平台 dubbo-monitor 监控平台，基于 Dubbo 的【monitor 监控层】，实现相应的监控数据的收集到监控平台。 dubbo-admin 管理平台，基于注册中心，可以获取到服务相关的信息。 关于这块的选择，胖友直接看看 《Dubbo监控和管理（dubbokeeper）》 。 另外，目前 Dubbo 正在重做 dubbo-admin 管理平台，感兴趣的胖友，可以跟进 https://github.com/apache/incubator-dubbo-ops 。 链路追踪 关链路追踪的概念，就不重复介绍了，😈 如果不懂，请自行 Google 下。 目前能够实现链路追踪的组件还是比较多的，如下： Apache SkyWalking 【推荐】 Zipkin Cat PinPoint 具体集成的方式，Dubbo 官方推荐了两篇博文： 《使用 Apache SkyWalking (Incubator) 做分布式跟踪》 《在 Dubbo 中使用 Zipkin》 Dubbo 服务如何做降级？比如说服务 A 调用服务 B，结果服务 B 挂掉了。服务 A 再重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。 在 Dubbo 中，实现服务降级的功能，一共有两大种方式。 ① Dubbo 原生自带的服务降级功能 具体可以看看 《Dubbo 用户指南 —— 服务降级》 。 当然，这个功能，并不能实现现代微服务的熔断器的功能。所以一般情况下，不太推荐这种方式，而是采用第二种方式。 ② 引入支持服务降级的组件 目前开源社区常用的有两种组件支持服务降级的功能，分别是： Alibaba Sentinel Netflix Hystrix 因为目前 Hystrix 已经停止维护，并且和 Dubbo 的集成度不是特别高，需要做二次开发，所以推荐使用 Sentinel 。具体的介绍，胖友可以看看 《Sentinel 介绍》 。 关于 Dubbo 如何集成 Sentinel ，胖友可以阅读 《Sentinel 为 Dubbo 服务保驾护航》 一文。 关于 Sentinel 和 Hystrix 对比，胖友可以阅读 《Sentinel 与 Hystrix 的对比》 一文。 Dubbo 如何做限流？在做服务稳定性时，有一句非常经典的话： 怀疑第三方 防备使用方 做好自己 那么，上面看到的服务降级，就属于怀疑第三方。而本小节的限流目的，就是防备使用方。 此处，艿艿要再推荐一篇文章：《你应该如何正确健壮后端服务？》 。 目前，在 Dubbo 中，实现服务降级的功能，一共有两大种方式。 ① Dubbo 原生自带的限流功能 通过 TpsLimitFilter 实现，仅适用于服务提供者。具体的使用方式，源码实现，看看 《精尽 Dubbo 源码分析 —— 过滤器（九）之 TpsLimitFilter》 。 😈 参照 TpsLimitFilter 的思路，可以实现自定义限流的 Filter ，并且使用 Guava RateLimiter 工具类，达到 令牌桶算法限流的功能。 ② 引入支持限流的组件 关于这个功能，还是推荐集成 Sentinel 组件。 Dubbo 的失败重试是什么？所谓失败重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。 实际场景下，我们一般会禁用掉重试。因为，因为超时后重试会有问题，超时你不知道是成功还是失败。例如，可能会导致两次扣款的问题。 所以，我们一般使用 failfast 集群容错策略，而不是 failover 策略。配置如下： 1&lt;dubbo:service cluster="failfast" timeout="2000" /&gt; 另外，一定一定一定要配置适合自己业务的超时时间。 当然，可以将操作分成读和写两种，前者支持重试，后者不支持重试。因为，读操作天然具有幂等性。 Dubbo 支持哪些注册中心？Dubbo 支持多种主流注册中心，如下： 【默认】Zookeeper ，参见 《用户指南 —— Zookeeper 注册中心》 。 Redis ，参见 《用户指南 —— Redis 注册中心》 。 Multicast 注册中心，参见 《用户指南 —— Multicast 注册中心》 。 Simple 注册中心，参见 《用户指南 —— Simple 注册中心》 。 目前 Alibaba 正在开源新的注册中心 Nacos ，也是未来的选择之一。 当然，Netflix Eureka 也是注册中心的一个选择，不过 Dubbo 暂未集成实现。 另外，此处会引申一个经典的问题，见 《为什么不应该使用 ZooKeeper 做服务发现》 文章。 ## Dubbo 接口如何实现幂等性？ 所谓幂等，简单地说，就是对接口的多次调用所产生的结果和调用一次是一致的。扩展一下，这里的接口，可以理解为对外发布的 HTTP 接口或者 Thrift 接口，也可以是接收消息的内部接口，甚至是一个内部方法或操作。 那么我们为什么需要接口具有幂等性呢？设想一下以下情形： 在 App 中下订单的时候，点击确认之后，没反应，就又点击了几次。在这种情况下，如果无法保证该接口的幂等性，那么将会出现重复下单问题。 在接收消息的时候，消息推送重复。如果处理消息的接口无法保证幂等，那么重复消费消息产生的影响可能会非常大。 所以，从这段描述中，幂等性不仅仅是 Dubbo 接口的问题，包括 HTTP 接口、Thrift 接口都存在这样的问题，甚至说 MQ 消息、定时任务，都会碰到这样的场景。那么应该怎么办呢？ 这个不是技术问题，这个没有通用的一个方法，这个应该结合业务来保证幂等性。 所谓幂等性，就是说一个接口，多次发起同一个请求，你这个接口得保证结果是准确的，比如不能多扣款、不能多插入一条数据、不能将统计值多加了 1。这就是幂等性。 其实保证幂等性主要是三点： 对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。 每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的，比如支付之前记录一条这个订单的支付流水。 每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。 实际运作过程中，你要结合自己的业务来，比如说利用 redis，用 orderId 作为唯一键。只有成功插入这个支付流水，才可以执行实际的支付扣款。 要求是支付一个订单，必须插入一条支付流水，order_id 建一个唯一键 unique key。你在支付一个订单之前，先插入一条支付流水，order_id 就已经进去了。你就可以写一个标识到 redis 里面去，set order_id payed，下一次重复请求过来了，先查 redis 的 order_id 对应的 value，如果是 payed 就说明已经支付过了，你就别重复支付了。 Dubbo 如何升级接口？参考 《Dubbo 用户指南 —— 多版本》 。 当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。 可以按照以下的步骤进行版本迁移： 在低压力时间段，先升级一半提供者为新版本。 再将所有消费者升级为新版本。 然后将剩下的一半提供者升级为新版本。 利用多版本的特性，我们也能实现灰度的功能。对于第 2 步，不要升级所有消费者为新版本，而是一半。 Dubbo 在安全机制方面是如何解决的？通过令牌验证在注册中心控制权限，以决定要不要下发令牌给消费者，可以防止消费者绕过注册中心访问提供者。 另外通过注册中心可灵活改变授权方式，而不需修改或升级提供者。 相关文档，可以参见 《Dubbo 用户指南 —— 令牌验证》 。 源码解析，可以参见 《精尽 Dubbo 源码分析 —— 过滤器（八）之 TokenFilter》 。 Dubbo 需要 Web 容器吗？这个问题，仔细回答，需要思考 Web 容器的定义。然而实际上，真正想问的是，Dubbo 服务启动是否需要启动类似 Tomcat、Jetty 等服务器。 这个答案可以是，也可以是不是。为什么呢？根据协议的不同，Provider 会启动不同的服务器。 在使用 dubbo:// 协议时，答案是否，因为 Provider 启动 Netty、Mina 等 NIO Server 。 在使用 rest:// 协议时，答案是是，Provider 启动 Tomcat、Jetty 等 HTTP 服务器，或者也可以使用 Netty 封装的 HTTP 服务器。 在使用 hessian:// 协议时，答案是是，Provider 启动 Jetty、Tomcat 等 HTTP 服务器。 为什么要将系统进行拆分？这个问题，不是仅仅适用于 Dubbo 的场景，而是 SOA、微服务。 网上查查，答案极度零散和复杂，很琐碎，原因一大坨。但是我这里给大家直观的感受： 要是不拆分，一个大系统几十万行代码，20 个人维护一份代码，简直是悲剧啊。代码经常改着改着就冲突了，各种代码冲突和合并要处理，非常耗费时间；经常我改动了我的代码，你调用了我的，导致你的代码也得重新测试，麻烦的要死；然后每次发布都是几十万行代码的系统一起发布，大家得一起提心吊胆准备上线，几十万行代码的上线，可能每次上线都要做很多的检查，很多异常问题的处理，简直是又麻烦又痛苦；而且如果我现在打算把技术升级到最新的 spring 版本，还不行，因为这可能导致你的代码报错，我不敢随意乱改技术。 假设一个系统是 20 万行代码，其中 小A 在里面改了 1000 行代码，但是此时发布的时候是这个 20 万行代码的大系统一块儿发布。就意味着 20 万上代码在线上就可能出现各种变化，20 个人，每个人都要紧张地等在电脑面前，上线之后，检查日志，看自己负责的那一块儿有没有什么问题。 小A 就检查了自己负责的 1 万行代码对应的功能，确保ok就闪人了；结果不巧的是，小A 上线的时候不小心修改了线上机器的某个配置，导致另外 小B 和 小C 负责的 2 万行代码对应的一些功能，出错了。 几十个人负责维护一个几十万行代码的单块应用，每次上线，准备几个礼拜，上线 -&gt; 部署 -&gt; 检查自己负责的功能。 拆分了以后，整个世界清爽了，几十万行代码的系统，拆分成 20 个服务，平均每个服务就 1~2 万行代码，每个服务部署到单独的机器上。20 个工程，20 个 git 代码仓库里，20 个码农，每个人维护自己的那个服务就可以了，是自己独立的代码，跟别人没关系。再也没有代码冲突了，爽。每次就测试我自己的代码就可以了，爽。每次就发布我自己的一个小服务就可以了，爽。技术上想怎么升级就怎么升级，保持接口不变就可以了，爽。 所以简单来说，一句话总结，如果是那种代码量多达几十万行的中大型项目，团队里有几十个人，那么如果不拆分系统，开发效率极其低下，问题很多。但是拆分系统之后，每个人就负责自己的一小部分就好了，可以随便玩儿随便弄。分布式系统拆分之后，可以大幅度提升复杂系统大型团队的开发效率。 但是同时，也要提醒的一点是，系统拆分成分布式系统之后，大量的分布式系统面临的问题也是接踵而来，所以后面的问题都是在围绕分布式系统带来的复杂技术挑战在说。 艿艿曾经维护过一个几十万行的单体项目，并且基本是一天发布 2-3 次，期间的痛苦，简直了。 Dubbo 如何集成配置中心？对于使用了 Dubbo 的系统，配置分成两类： ① Dubbo 自身配置。 例如：Dubbo 请求超时，Dubbo 重试次数等等。 ② 非 Dubbo 自身配置 基建配置，例如：数据库、Redis 等配置。 业务配置，例如：订单超时时间，下单频率等等配置。 对于 ① ，如果我们在 Provider 配置 Dubbo 请求超时时间，当 Consumer 未配置请求超时时间，会继承该配置，使用该请求超时时间。 实现原理： Provider 启动时，会注册到注册中心中，包括我们在 `` 中的配置。 Consumer 启动时，从注册中心获取到 Provider 列表后，会合并它们在 &lt;dubbo:service /&gt; 的配置来使用。当然，如果 Consumer 自己配置了该配置项，则使用自身的。例如说，Provider 配置了请求超时时间是 10s ，而 Consumer 配置了请求超时超时是 5s ，那么最终 Consumer 请求超时的时间是 5s 。 绝大数配置可以被继承，合并的核心逻辑，见 ClusterUtils#mergeUrl(URL remoteUrl, Map localMap)方法。 实现代码，见 《精尽 Dubbo 源码解析 —— 集群容错（六）之 Configurator 实现》 。 对于 ② ，市面上有非常多的配置中心可供选择： Apollo Nacos Disconf 这个问题不大。对于配置中心的选择，我们考虑的不是它和 Dubbo 的集成，而是它和 Spring 的集成。因为，大多数情况下，我们都是使用 Spring 作为框架的整合基础。目前，Apollo 和 Nacos 对 Spring 的支持是比较不错的。 Dubbo 如何实现分布式事务？首先，关于分布式事务的功能，不是 Dubbo 作为服务治理框架需要去实现的，所以 Dubbo 本身并没有实现。所以在 《Dubbo 用户指南 —— 分布式事务》 也提到，目前并未实现。 说起分布式，理论的文章很多，落地的实践很少。笔者翻阅了各种分布式事务组件的选型，大体如下： TCC 模型：TCC-Transaction、Hmily XA 模型：Sharding Sphere、MyCAT 2PC 模型：raincat、lcn MQ 模型：RocketMQ BED 模型：Sharding Sphere Saga 模型：ServiceComb Saga 那怎么选择呢？目前社区对于分布式事务的选择，暂时没有定论，至少笔者没有看到。笔者的想法如下： 从覆盖场景来说，TCC 无疑是最优秀的，但是大家觉得相对复杂。实际上，复杂场景下，使用 TCC 来实现，反倒会容易很多。另外，TCC 模型，一直没有大厂开源，也是一大痛点。 从使用建议来说，MQ 可能是相对合适的( 不说 XA 的原因还是性能问题 )，并且基本轮询了一圈朋友，发现大多都是使用 MQ 实现最终一致性居多。 2PC 模型的实现，笔者觉得非常新奇，奈何隔离性是一个硬伤。 Saga 模型，可以认为是 TCC 模型的简化版，所以在理解和编写的难度上，简单非常多。 所以结论是什么呢？ TCC 模型：TCC-Transaction、Hmily 。 已经提供了和 Dubbo 集成的方案，胖友可以自己去试试。 XA 模型：Sharding Sphere、MyCAT 。 无需和 Dubbo 进行集成。 2PC 模型：raincat、lcn 。 已经提供了和 Dubbo 集成的方案，胖友可以自己去试试。 MQ 模型：RocketMQ 。 无需和 Dubbo 进行集成。 BED 模型：Sharding Sphere 。 无需和 Dubbo 进行集成。 Saga 模型：ServiceComb Saga 。 好像已经提供了和 Dubbo 集成的方案，参见 《Saga-dubbo-demo》 文档。 😈 暂时没去深入研究。 另外，胖友在理解分布式事务时，一定要记住，分布式事务需要由多个本地事务组成。无论是上述的那种事务组件模型，它们都是扮演一个协调者，使多个本地事务达到最终一致性。而协调的过程中，就非常依赖每个方法操作可以被重复执行不会产生副作用，那么就需要： 幂等性！因为可能会被重复调用。如果调用两次退款，结果退了两次钱，那就麻烦大了。 本地事务！因为执行过程中可能会出错，需要回滚。 Dubbo 如何集成网关服务？Dubbo 如何集成到网关服务，需要思考两个问题： 网关如何调用 Dubbo 服务。 网关如何发现 Dubbo 服务。 我们先来看看，市面上有哪些网关服务： Zuul Spring Cloud Gateway Kong 如上三个解决方案，都是基于 HTTP 调用后端的服务。那么，这样的情况下，Dubbo 只能通过暴露 rest:// 协议的服务，才能被它们调用。 那么 Dubbo 的 rest:// 协议的服务，怎么能够被如上三个解决方案注册发现呢？ 因为 Dubbo 可用的注册中心有 Zookeeper ，如果要被 Zuul 或 Spring Cloud Gateway 注册发现，可以使用 spring-cloud-starter-zookeeper-discovery 库。具体可参见 《Service Discovery with Zookeeper》 文章。 Dubbo 与 Kong 的集成，相对比较麻烦，需要通过 Kong 的 API 添加相应的路由规则。具体可参见 《选择 Kong 作为你的 API 网关》 文章。 可能会有胖友问，有没支持 dubbo:// 协议的网关服务呢？目前有新的网关开源 Soul ，基于 Dubbo 泛化调用的特性，实现对 dubbo:// 协议的 Dubbo 服务的调用。 感兴趣的胖友，可以去研究下。 关于 Dubbo 泛化调用的特性，胖友可以看看 《Dubbo 用户指南 —— 使用泛化调用》 。 实际场景下，我们真的需要 Dubbo 集成到网关吗？具艿艿了解到，很多公司，并未使用网关，而是使用 Spring Boot 搭建一个 Web 项目，引入 *-api.jar 包，然后进行调用，从而对外暴露 HTTP API 。 如何进行系统拆分？这个问题，不是仅仅适用于 Dubbo 的场景，而是 SOA、微服务。接上面 「为什么要将系统进行拆分？」 。 这个问题说大可以很大，可以扯到领域驱动模型设计上去，说小了也很小，我不太想给大家太过于学术的说法，因为你也不可能背这个答案，过去了直接说吧。还是说的简单一点，大家自己到时候知道怎么回答就行了。 系统拆分为分布式系统，拆成多个服务，拆成微服务的架构，是需要拆很多轮的。并不是说上来一个架构师一次就给拆好了，而以后都不用拆。 第一轮；团队继续扩大，拆好的某个服务，刚开始是 1 个人维护 1 万行代码，后来业务系统越来越复杂，这个服务是 10 万行代码，5 个人；第二轮，1个服务 -&gt; 5个服务，每个服务 2 万行代码，每人负责一个服务。 如果是多人维护一个服务，最理想的情况下，几十个人，1 个人负责 1 个或 2~3 个服务；某个服务工作量变大了，代码量越来越多，某个同学，负责一个服务，代码量变成了 10 万行了，他自己不堪重负，他现在一个人拆开，5 个服务，1 个人顶着，负责 5 个人，接着招人，2 个人，给那个同学带着，3 个人负责 5 个服务，其中 2 个人每个人负责 2 个服务，1 个人负责 1 个服务。 个人建议，一个服务的代码不要太多，1万行左右，两三万撑死了吧。 大部分的系统，是要进行多轮拆分的，第一次拆分，可能就是将以前的多个模块该拆分开来了，比如说将电商系统拆分成订单系统、商品系统、采购系统、仓储系统、用户系统，等等吧。 但是后面可能每个系统又变得越来越复杂了，比如说采购系统里面又分成了供应商管理系统、采购单管理系统，订单系统又拆分成了购物车系统、价格系统、订单管理系统。 扯深了实在很深，所以这里先给大家举个例子，你自己感受一下，核心意思就是根据情况，先拆分一轮，后面如果系统更复杂了，可以继续分拆。你根据自己负责系统的例子，来考虑一下就好了。 拆分后不用 Dubbo 可以吗？当然是可以，方式还有很多： 第一种，使用 Spring Cloud 技术体系，这个也是目前可能最主流的之一。 第二种，Dubbo 换成 gRPC 或者 Thrift 。当然，此时要自己实现注册发现、负载均衡、集群容错等等功能。 第三种，Dubbo 换成同等定位的服务化框架，例如微博的 Motan 、蚂蚁金服的 SofaRPC 。 第四种，Spring MVC + Nginx 。 第五种，每个服务拆成一个 Maven 项目，打成 Jar 包，给其它服务使用。😈 当然，这个不是一个比较特别的方案。 当然可以了，大不了最次，就是各个系统之间，直接基于 spring mvc，就纯 http 接口互相通信呗，还能咋样。但是这个肯定是有问题的，因为 http 接口通信维护起来成本很高，你要考虑超时重试、负载均衡等等各种乱七八糟的问题，比如说你的订单系统调用商品系统，商品系统部署了 5 台机器，你怎么把请求均匀地甩给那 5 台机器？这不就是负载均衡？你要是都自己搞那是可以的，但是确实很痛苦。 所以 dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡了、服务实例上下线自动感知了、超时重试了，等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。 Spring Cloud 与 Dubbo 怎么选择？首先，我们来看看这两个技术栈在国内的流行程度，据艿艿了解到： 对于国外，Spring Cloud 基本已经统一国外的微服务体系。 对于国内，老的系统使用 Dubbo 较多，新的系统使用 Spring Cloud 较多。 这样说起来，仿佛 Spring Cloud 和 Dubbo 是冲突的关系？！ 实际上，并不然。我们现在所使用的 Spring Cloud 技术体系，实际上是 Spring Cloud Netflix 为主，例如说： Netflix Eureka 注册中心 Netflix Hystrix 熔断组件 Netflix Ribbon 负载均衡 Netflix Zuul 网关服务 但是，开源的世界，总是这么有趣。目前 Alibaba 基于 Spring Cloud 的接口，对的是接口，实现了一套 Spring Cloud Alibaba 技术体系，并且已经获得 Spring Cloud 的认可，处于孵化状态。组件如下： Nacos 注册中心，对标 Eureka 。 Nacos 配置中心，集成到 Spring Cloud Config 。 Sentinel 服务保障，对标 Hystrix 。 Dubbo 服务调用( 包括负载均衡 )，对标 Ribbon + Feign 。 缺失 网关服务。 RocketMQ 队列服务，集成到 Spring Cloud Stream 。 更多的讨论，胖友可以尾随知乎上的 《请问哪位大神比较过 spring cloud 和 dubbo ，各自的优缺点是什么?》 。 艿艿的个人态度上，还是非常看好 Spring Cloud Alibaba 技术体系的。为什么呢？因为 Alibaba 背后有阿里云的存在，提供开源项目和商业服务的统一。😈 这个，是 Netflix 所无法比拟的。例如说： 开源项目 阿里云服务 Tengine LBS Dubbo EDAS RocketMQ ONS 这里在抛出一个话题。目前传说 Dubbo 在国外的接受度比较低，那么在 Spring Cloud Alibaba 成功孵化完后，是否能够杀入国外的市场呢？让我们拭目以待。 在聊一丢丢有意思的事情。 事实上，Netflix 已经基本不再维护 Eureka、Hystrix ，更有趣的是，因为网关的事情，Zuul 和 Spring Cloud 团队有点闹掰了，因而后来有了 Spring Cloud Gateway 。因而，Zuul2 后续在 Spring Cloud 体系中的情况，会非常有趣~ 另外，Spring Cloud 貌似也实现了一个 LoadBalance 负载均衡组件哟。 如何自己设计一个类似 Dubbo 的 RPC 框架？面试官心理分析 说实话，就这问题，其实就跟问你如何自己设计一个 MQ 一样的道理，就考两个： 你有没有对某个 rpc 框架原理有非常深入的理解。 你能不能从整体上来思考一下，如何设计一个 rpc 框架，考考你的系统设计能力。 面试题剖析 其实问到你这问题，你起码不能认怂，因为是知识的扫盲，那我不可能给你深入讲解什么 kafka 源码剖析，dubbo 源码剖析，何况我就算讲了，你要真的消化理解和吸收，起码个把月以后了。 所以我给大家一个建议，遇到这类问题，起码从你了解的类似框架的原理入手，自己说说参照 dubbo 的原理，你来设计一下，举个例子，dubbo 不是有那么多分层么？而且每个分层是干啥的，你大概是不是知道？那就按照这个思路大致说一下吧，起码你不能懵逼，要比那些上来就懵，啥也说不出来的人要好一些。 举个栗子，我给大家说个最简单的回答思路： 上来你的服务就得去注册中心注册吧，你是不是得有个注册中心，保留各个服务的信心，可以用 zookeeper 来做，对吧。 然后你的消费者需要去注册中心拿对应的服务信息吧，对吧，而且每个服务可能会存在于多台机器上。 接着你就该发起一次请求了，咋发起？当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址。 然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是。 接着找到一台机器，就可以跟它发送请求了，第一个问题咋发送？你可以说用 netty 了，nio 方式；第二个问题发送啥格式数据？你可以说用 hessian 序列化协议了，或者是别的，对吧。然后请求过去了。 服务器那边一样的，需要针对你自己的服务生成一个动态代理，监听某个网络端口了，然后代理你本地的服务代码。接收到请求的时候，就调用对应的服务代码，对吧。 这就是一个最最基本的 rpc 框架的思路，先不说你有多牛逼的技术功底，哪怕这个最简单的思路你先给出来行不行？ 如果上述描述，胖友看的比较闷逼，可以阅读下徐妈写的 《简单了解 RPC 实现原理》 ，自己动手撸一个最最最基础的 RPC 通信的过程。 因为 Dubbo 实现了大量的抽象，并且提供了多种代码实现，以及大量的 RPC 特性，所以代码量会相对较多。 如果胖友是自己实现一个最小化的 PRC 框架，可能代码量会比想象中的少很多，可能几千行代码就够了。强烈推荐，胖友自己撸起袖子，动起手来。从此之后，你会对 RPC 框架，有更深入的理解。 其他问题当然，Dubbo 还有很多非常细节，甚至牵扯到源码的问题，艿艿并未全部列列举。如下的问题，需要胖友自己去耐心看源码，思考答案。 Dubbo 服务发布过程中，做了哪些事？ 《精尽 Dubbo 源码分析 —— 服务暴露（一）之本地暴露（Injvm）》 《精尽 Dubbo 源码分析 —— 服务暴露（二）之远程暴露（Dubbo）》 Dubbo 服务引用过程中，做了哪些事？ 《精尽 Dubbo 源码分析 —— 服务引用（一）之本地引用（Injvm）》 《精尽 Dubbo 源码分析 —— 服务引用（二）之远程引用（Dubbo）》 Dubbo 管理平台能够动态改变接口的一些配置，其原理是怎样的? 路由规则 《精尽 Dubbo 源码解析 —— 集群容错（七）之 Router 实现》 《Dubbo 用户指南 —— 路由规则》 配置规则 《精尽 Dubbo 源码解析 —— 集群容错（六）之 Configurator 实现》 《Dubbo 用户指南 —— 配置规则》 在 Dubbo 中，什么时候更新本地的 Zookeeper 信息缓存文件？订阅Zookeeper 信息的整体过程是怎么样的? 《精尽 Dubbo 源码分析 —— 注册中心（一）之抽象 API》 《精尽 Dubbo 源码分析 —— 注册中心（二）之 Zookeeper》 最小活跃数算法中是如何统计这个活跃数的？ 《精尽 Dubbo 源码分析 —— 过滤器（四）之 ActiveLimitFilter &amp;&amp; ExecuteLimitFilter》 ，主要 「2. 2. RpcStatus」 和 「3. ActiveLimitFilter」 部分。 《精尽 Dubbo 源码解析 —— 集群容错（四）之 LoadBalance 实现》 ，主要 「6. LeastActiveLoadBalance」 部分。 简单谈谈你对一致性哈希算法的认识？ 《精尽 Dubbo 源码解析 —— 集群容错（四）之 LoadBalance 实现》 ，主要 「7. ConsistentHashSelector」 部分。 关于一致性哈希算法在缓存中的使用，我们会单独在缓存相关的面试题中分享。 666. 彩蛋在看到此处，胖友有没发现，在实际面试的 Dubbo 问题中，Dubbo 官方文档已经给了我们很多答案。这说明什么呢？一定一定一定要认真研读官方提供的知识，毕竟，这是最系统，且第一手的资料。 如果胖友想对 RPC 有一个整体的理解，推荐看看徐妈的这套文章《深入理解 RPC 系列》： 《简单了解 RPC 实现原理》 《深入理解 RPC 之序列化篇 – Kryo》 《深入理解 RPC 之序列化篇 – 总结篇》 《深入理解 RPC 之动态代理篇》 《深入理解 RPC 之传输篇》 《Motan 中使用异步 RPC 接口》 《深入理解 RPC 之协议篇》 《深入理解RPC之服务注册与发现篇》 《深入理解 RPC 之集群篇》 《【千米网】从跨语言调用到 dubbo2.js》 《天池中间件大赛 Dubbo Mesh 优化总结（QPS 从 1000 到 6850）》 参考与推荐如下文章： 《Dubbo 用户指南》 必选。 《Dubbo 开发指南》 进阶。 《Dubbo 运维管理》 可选。 《分布式系统互斥性与幂等性问题的分析与解决》 黑马程序员 《【上海校区】整理的 Dubbo 面试题》 美团 《说一下 Dubbo 的工作原理？注册中心挂了可以继续通信吗？》 lijiaccy 《Java 面试之 Dubbo》 Java 知音 Dubbo 面试题 《Dubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？》 《Dubbo 的 SPI 思想是什么？》 《如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？》 《分布式服务接口的幂等性如何设计（比如不能重复扣款）？》 《为什么要进行系统拆分？如何进行系统拆分？拆分后不用 Dubbo 可以吗？》 《如何自己设计一个类似 Dubbo 的 rpc 框架？》]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精尽 Dubbo 学习指南]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%B2%BE%E5%B0%BD-Dubbo-%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[视频 尚硅谷 《尚硅谷 Java 视频教程_Dubbo》 一共有 30P 。 动力节点 《Java 视频教程之 Dubbo 视频教程》 书籍暂无书籍 TODO 芋艿，等待超哥的书出版 文章非常重要，一定一定一定认真看官方文档 《Dubbo 用户指南》 必选。 《Dubbo 开发指南》 进阶。 《Dubbo 运维管理》 可选。 在整理一些，dubbo 实战的文章 使用 SkyWalking 作为 Dubbo 的链路追踪，是非常推荐的，具体可以参考： 张鑫 《使用 Apache Skywalking (Incubator) 做分布式跟踪》 如果你想参与到 Dubbo 的开发之中，如下两篇文章给了我们很不错的指引： 徐妈 《以 Dubbo 为例，聊聊如何向开源项目做贡献》 jerrick 《如何参与贡献 Dubbo 社区》 如果你对 Dubbo 是怎么做一次版本的发布 Release ，可以参见： Jun Liu 《如何准备 Apache Release》]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【死磕 Spring】—— IoC 之 Spring 统一资源加载策略]]></title>
    <url>%2F2019%2F02%2F11%2F%E3%80%90%E6%AD%BB%E7%A3%95-Spring%E3%80%91%E2%80%94%E2%80%94-IoC-%E4%B9%8B-Spring-%E7%BB%9F%E4%B8%80%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本文主要基于 Spring 5.0.6.RELEASE 摘要: 原创出处 http://cmsblogs.com/?p=2656 「小明哥」，谢谢！ 作为「小明哥」的忠实读者，「老艿艿」略作修改，记录在理解过程中，参考的资料。 在学 Java SE 的时候，我们学习了一个标准类 java.net.URL，该类在 Java SE 中的定位为统一资源定位器（Uniform Resource Locator），但是我们知道它的实现基本只限于网络形式发布的资源的查找和定位。然而，实际上资源的定义比较广泛，除了网络形式的资源，还有以二进制形式存在的、以文件形式存在的、以字节流形式存在的等等。而且它可以存在于任何场所，比如网络、文件系统、应用程序中。所以 java.net.URL 的局限性迫使 Spring 必须实现自己的资源加载策略，该资源加载策略需要满足如下要求： 职能划分清楚。资源的定义和资源的加载应该要有一个清晰的界限； 统一的抽象。统一的资源定义和资源加载策略。资源加载后要返回统一的抽象给客户端，客户端要对资源进行怎样的处理，应该由抽象资源接口来界定。 1. 统一资源：Resourceorg.springframework.core.io.Resource 为 Spring 框架所有资源的抽象和访问接口，它继承 org.springframework.core.io.InputStreamSource接口。作为所有资源的统一抽象，Resource 定义了一些通用的方法，由子类 AbstractResource 提供统一的默认实现。定义如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public interface Resource extends InputStreamSource &#123; /** * 资源是否存在 */ boolean exists(); /** * 资源是否可读 */ default boolean isReadable() &#123; return true; &#125; /** * 资源所代表的句柄是否被一个 stream 打开了 */ default boolean isOpen() &#123; return false; &#125; /** * 是否为 File */ default boolean isFile() &#123; return false; &#125; /** * 返回资源的 URL 的句柄 */ URL getURL() throws IOException; /** * 返回资源的 URI 的句柄 */ URI getURI() throws IOException; /** * 返回资源的 File 的句柄 */ File getFile() throws IOException; /** * 返回 ReadableByteChannel */ default ReadableByteChannel readableChannel() throws IOException &#123; return java.nio.channels.Channels.newChannel(getInputStream()); &#125; /** * 资源内容的长度 */ long contentLength() throws IOException; /** * 资源最后的修改时间 */ long lastModified() throws IOException; /** * 根据资源的相对路径创建新资源 */ Resource createRelative(String relativePath) throws IOException; /** * 资源的文件名 */ @Nullable String getFilename(); /** * 资源的描述 */ String getDescription();&#125; 1.1 子类结构类结构图如下： 从上图可以看到，Resource 根据资源的不同类型提供不同的具体实现，如下： FileSystemResource ：对 java.io.File 类型资源的封装，只要是跟 File 打交道的，基本上与 FileSystemResource 也可以打交道。支持文件和 URL 的形式，实现 WritableResource 接口，且从 Spring Framework 5.0 开始，FileSystemResource 使用 NIO2 API进行读/写交互。 ByteArrayResource ：对字节数组提供的数据的封装。如果通过 InputStream 形式访问该类型的资源，该实现会根据字节数组的数据构造一个相应的 ByteArrayInputStream。 UrlResource ：对 java.net.URL类型资源的封装。内部委派 URL 进行具体的资源操作。 ClassPathResource ：class path 类型资源的实现。使用给定的 ClassLoader 或者给定的 Class 来加载资源。 InputStreamResource ：将给定的 InputStream 作为一种资源的 Resource 的实现类。 1.2 AbstractResourceorg.springframework.core.io.AbstractResource ，为 Resource 接口的默认抽象实现。它实现了 Resource 接口的大部分的公共实现，作为 Resource 接口中的重中之重，其定义如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164public abstract class AbstractResource implements Resource &#123; /** * 判断文件是否存在，若判断过程产生异常（因为会调用SecurityManager来判断），就关闭对应的流 */ @Override public boolean exists() &#123; try &#123; // 基于 File 进行判断 return getFile().exists(); &#125; catch (IOException ex) &#123; // Fall back to stream existence: can we open the stream? // 基于 InputStream 进行判断 try &#123; InputStream is = getInputStream(); is.close(); return true; &#125; catch (Throwable isEx) &#123; return false; &#125; &#125; &#125; /** * 直接返回true，表示可读 */ @Override public boolean isReadable() &#123; return true; &#125; /** * 直接返回 false，表示未被打开 */ @Override public boolean isOpen() &#123; return false; &#125; /** * 直接返回false，表示不为 File */ @Override public boolean isFile() &#123; return false; &#125; /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public URL getURL() throws IOException &#123; throw new FileNotFoundException(getDescription() + " cannot be resolved to URL"); &#125; /** * 基于 getURL() 返回的 URL 构建 URI */ @Override public URI getURI() throws IOException &#123; URL url = getURL(); try &#123; return ResourceUtils.toURI(url); &#125; catch (URISyntaxException ex) &#123; throw new NestedIOException("Invalid URI [" + url + "]", ex); &#125; &#125; /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public File getFile() throws IOException &#123; throw new FileNotFoundException(getDescription() + " cannot be resolved to absolute file path"); &#125; /** * 根据 getInputStream() 的返回结果构建 ReadableByteChannel */ @Override public ReadableByteChannel readableChannel() throws IOException &#123; return Channels.newChannel(getInputStream()); &#125; /** * 获取资源的长度 * * 这个资源内容长度实际就是资源的字节长度，通过全部读取一遍来判断 */ @Override public long contentLength() throws IOException &#123; InputStream is = getInputStream(); try &#123; long size = 0; byte[] buf = new byte[255]; // 每次最多读取 255 字节 int read; while ((read = is.read(buf)) != -1) &#123; size += read; &#125; return size; &#125; finally &#123; try &#123; is.close(); &#125; catch (IOException ex) &#123; &#125; &#125; &#125; /** * 返回资源最后的修改时间 */ @Override public long lastModified() throws IOException &#123; long lastModified = getFileForLastModifiedCheck().lastModified(); if (lastModified == 0L) &#123; throw new FileNotFoundException(getDescription() + " cannot be resolved in the file system for resolving its last-modified timestamp"); &#125; return lastModified; &#125; protected File getFileForLastModifiedCheck() throws IOException &#123; return getFile(); &#125; /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public Resource createRelative(String relativePath) throws IOException &#123; throw new FileNotFoundException("Cannot create a relative resource for " + getDescription()); &#125; /** * 获取资源名称，默认返回 null ，交给子类实现 */ @Override @Nullable public String getFilename() &#123; return null; &#125; /** * 返回资源的描述 */ @Override public String toString() &#123; return getDescription(); &#125; @Override public boolean equals(Object obj) &#123; return (obj == this || (obj instanceof Resource &amp;&amp; ((Resource) obj).getDescription().equals(getDescription()))); &#125; @Override public int hashCode() &#123; return getDescription().hashCode(); &#125;&#125; 如果我们想要实现自定义的 Resource ，记住不要实现 Resource 接口，而应该继承 AbstractResource 抽象类，然后根据当前的具体资源特性覆盖相应的方法即可。 1.3 其他子类 来自艿艿 Resource 的子类，例如 FileSystemResource、ByteArrayResource 等等的代码非常简单。感兴趣的胖友，自己去研究。 2. 统一资源定位：ResourceLoader一开始就说了 Spring 将资源的定义和资源的加载区分开了，Resource 定义了统一的资源，那资源的加载则由 ResourceLoader 来统一定义。 org.springframework.core.io.ResourceLoader 为 Spring 资源加载的统一抽象，具体的资源加载则由相应的实现类来完成，所以我们可以将 ResourceLoader 称作为统一资源定位器。其定义如下： FROM 《Spring 源码深度解析》P16 页 ResourceLoader，定义资源加载器，主要应用于根据给定的资源文件地址，返回对应的 Resource 。 123456789public interface ResourceLoader &#123; String CLASSPATH_URL_PREFIX = ResourceUtils.CLASSPATH_URL_PREFIX; // CLASSPATH URL 前缀。默认为："classpath:" Resource getResource(String location); ClassLoader getClassLoader();&#125; 1#getResource(String location) 方法，根据所提供资源的路径 location 返回 Resource 实例，但是它不确保该 Resource 一定存在，需要调用 1Resource#exist() 方法来判断。 该方法支持以下模式的资源加载： URL位置资源，如 &quot;file:C:/test.dat&quot; 。 ClassPath位置资源，如 &quot;classpath:test.dat 。 相对路径资源，如 &quot;WEB-INF/test.dat&quot; ，此时返回的Resource 实例，根据实现不同而不同。 该方法的主要实现是在其子类 DefaultResourceLoader 中实现，具体过程我们在分析 DefaultResourceLoader 时做详细说明。 #getClassLoader() 方法，返回 ClassLoader 实例，对于想要获取 ResourceLoader 使用的 ClassLoader 用户来说，可以直接调用该方法来获取。在分析 Resource 时，提到了一个类 ClassPathResource ，这个类是可以根据指定的 ClassLoader 来加载资源的。 2.1 子类结构作为 Spring 统一的资源加载器，它提供了统一的抽象，具体的实现则由相应的子类来负责实现，其类的类结构图如下： 2.1 DefaultResourceLoader与 DefaultResource 相似，org.springframework.core.io.DefaultResourceLoader 是 ResourceLoader 的默认实现。 2.1.1 构造函数它接收 ClassLoader 作为构造函数的参数，或者使用不带参数的构造函数。 在使用不带参数的构造函数时，使用的 ClassLoader 为默认的 ClassLoader（一般 Thread.currentThread()#getContextClassLoader() ）。 在使用带参数的构造函数时，可以通过 ClassUtils#getDefaultClassLoader()获取。 代码如下： 1234567891011121314151617181920@Nullableprivate ClassLoader classLoader;public DefaultResourceLoader() &#123; // 无参构造函数 this.classLoader = ClassUtils.getDefaultClassLoader();&#125;public DefaultResourceLoader(@Nullable ClassLoader classLoader) &#123; // 带 ClassLoader 参数的构造函数 this.classLoader = classLoader;&#125;public void setClassLoader(@Nullable ClassLoader classLoader) &#123; this.classLoader = classLoader;&#125;@Override@Nullablepublic ClassLoader getClassLoader() &#123; return (this.classLoader != null ? this.classLoader : ClassUtils.getDefaultClassLoader());&#125; 另外，也可以调用 #setClassLoader() 方法进行后续设置。 2.1.2 getResource 方法ResourceLoader 中最核心的方法为 #getResource(String location) ，它根据提供的 location 返回相应的 Resource 。而 DefaultResourceLoader 对该方法提供了核心实现（因为，它的两个子类都没有提供覆盖该方法，所以可以断定 ResourceLoader 的资源加载策略就封装在 DefaultResourceLoader 中)，代码如下： 1234567891011121314151617181920212223242526272829303132// DefaultResourceLoader.java@Overridepublic Resource getResource(String location) &#123; Assert.notNull(location, "Location must not be null"); // 首先，通过 ProtocolResolver 来加载资源 for (ProtocolResolver protocolResolver : this.protocolResolvers) &#123; Resource resource = protocolResolver.resolve(location, this); if (resource != null) &#123; return resource; &#125; &#125; // 其次，以 / 开头，返回 ClassPathContextResource 类型的资源 if (location.startsWith("/")) &#123; return getResourceByPath(location); // 再次，以 classpath: 开头，返回 ClassPathResource 类型的资源 &#125; else if (location.startsWith(CLASSPATH_URL_PREFIX)) &#123; return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader()); // 然后，根据是否为文件 URL ，是则返回 FileUrlResource 类型的资源，否则返回 UrlResource 类型的资源 &#125; else &#123; try &#123; // Try to parse the location as a URL... URL url = new URL(location); return (ResourceUtils.isFileURL(url) ? new FileUrlResource(url) : new UrlResource(url)); &#125; catch (MalformedURLException ex) &#123; // 最后，返回 ClassPathContextResource 类型的资源 // No URL -&gt; resolve as resource path. return getResourceByPath(location); &#125; &#125;&#125; 首先，通过 ProtocolResolver 来加载资源，成功返回 Resource 。 其次，若 location 以 &quot;/&quot; 开头，则调用 #getResourceByPath() 方法，构造 ClassPathContextResource 类型资源并返回。代码如下： 123protected Resource getResourceByPath(String path) &#123; return new ClassPathContextResource(path, getClassLoader());&#125; 再次，若 location 以 &quot;classpath:&quot; 开头，则构造 ClassPathResource 类型资源并返回。在构造该资源时，通过 #getClassLoader() 获取当前的 ClassLoader。 然后，构造 URL ，尝试通过它进行资源定位，若没有抛出 MalformedURLException 异常，则判断是否为 FileURL , 如果是则构造 FileUrlResource 类型的资源，否则构造 UrlResource 类型的资源。 最后，若在加载过程中抛出 MalformedURLException 异常，则委派 #getResourceByPath() 方法，实现资源定位加载。😈 实际上，和【其次】相同落。 2.1.3 ProtocolResolverorg.springframework.core.io.ProtocolResolver ，用户自定义协议资源解决策略，作为 DefaultResourceLoader 的 SPI：它允许用户自定义资源加载协议，而不需要继承 ResourceLoader 的子类。在介绍 Resource 时，提到如果要实现自定义 Resource，我们只需要继承 DefaultResource 即可，但是有了 ProtocolResolver 后，我们不需要直接继承 DefaultResourceLoader，改为实现 ProtocolResolver 接口也可以实现自定义的 ResourceLoader。 ProtocolResolver 接口，仅有一个方法 Resource resolve(String location, ResourceLoader resourceLoader) 。代码如下： 12345678910111213/** * 使用指定的 ResourceLoader ，解析指定的 location 。 * 若成功，则返回对应的 Resource 。 * * Resolve the given location against the given resource loader * if this implementation's protocol matches. * @param location the user-specified resource location 资源路径 * @param resourceLoader the associated resource loader 指定的加载器 ResourceLoader * @return a corresponding &#123;@code Resource&#125; handle if the given location * matches this resolver's protocol, or &#123;@code null&#125; otherwise 返回为相应的 Resource */@NullableResource resolve(String location, ResourceLoader resourceLoader); 在 Spring 中你会发现该接口并没有实现类，它需要用户自定义，自定义的 Resolver 如何加入 Spring 体系呢？调用 DefaultResourceLoader#addProtocolResolver(ProtocolResolver) 方法即可。代码如下： 123456789/** * ProtocolResolver 集合 */private final Set&lt;ProtocolResolver&gt; protocolResolvers = new LinkedHashSet&lt;&gt;(4);public void addProtocolResolver(ProtocolResolver resolver) &#123; Assert.notNull(resolver, "ProtocolResolver must not be null"); this.protocolResolvers.add(resolver);&#125; 2.1.4 示例下面示例是演示 DefaultResourceLoader 加载资源的具体策略，代码如下（该示例参考《Spring 揭秘》 P89）： 12345678910111213ResourceLoader resourceLoader = new DefaultResourceLoader();Resource fileResource1 = resourceLoader.getResource("D:/Users/chenming673/Documents/spark.txt");System.out.println("fileResource1 is FileSystemResource:" + (fileResource1 instanceof FileSystemResource));Resource fileResource2 = resourceLoader.getResource("/Users/chenming673/Documents/spark.txt");System.out.println("fileResource2 is ClassPathResource:" + (fileResource2 instanceof ClassPathResource));Resource urlResource1 = resourceLoader.getResource("file:/Users/chenming673/Documents/spark.txt");System.out.println("urlResource1 is UrlResource:" + (urlResource1 instanceof UrlResource));Resource urlResource2 = resourceLoader.getResource("http://www.baidu.com");System.out.println("urlResource1 is urlResource:" + (urlResource2 instanceof UrlResource)); 运行结果： 1234fileResource1 is FileSystemResource:falsefileResource2 is ClassPathResource:trueurlResource1 is UrlResource:trueurlResource1 is urlResource:true 其实对于 fileResource1 ，我们更加希望是 FileSystemResource 资源类型。但是，事与愿违，它是 ClassPathResource 类型。为什么呢？在 DefaultResourceLoader#getResource() 方法的资源加载策略中，我们知道 &quot;D:/Users/chenming673/Documents/spark.txt&quot; 地址，其实在该方法中没有相应的资源类型，那么它就会在抛出 MalformedURLException 异常时，通过 DefaultResourceLoader#getResourceByPath(...) 方法，构造一个 ClassPathResource 类型的资源。 而 urlResource1 和 urlResource2 ，指定有协议前缀的资源路径，则通过 URL 就可以定义，所以返回的都是 UrlResource 类型。 2.2 FileSystemResourceLoader从上面的示例，我们看到，其实 DefaultResourceLoader 对#getResourceByPath(String) 方法处理其实不是很恰当，这个时候我们可以使用 org.springframework.core.io.FileSystemResourceLoader 。它继承 DefaultResourceLoader ，且覆写了 #getResourceByPath(String) 方法，使之从文件系统加载资源并以 FileSystemResource 类型返回，这样我们就可以得到想要的资源类型。代码如下： 123456789@Overrideprotected Resource getResourceByPath(String path) &#123; // 截取首 / if (path.startsWith("/")) &#123; path = path.substring(1); &#125; // 创建 FileSystemContextResource 类型的资源 return new FileSystemContextResource(path);&#125; 2.2.1 FileSystemContextResourceFileSystemContextResource ，为 FileSystemResourceLoader 的内部类，它继承 FileSystemResource 类，实现 ContextResource 接口。代码如下： 123456789101112131415/** * FileSystemResource that explicitly expresses a context-relative path * through implementing the ContextResource interface. */private static class FileSystemContextResource extends FileSystemResource implements ContextResource &#123; public FileSystemContextResource(String path) &#123; super(path); &#125; @Override public String getPathWithinContext() &#123; return getPath(); &#125;&#125; 在构造器中，也是调用 FileSystemResource 的构造函数来构造 FileSystemResource 的。 为什么要有 FileSystemContextResource 类的原因是，实现 ContextResource 接口，并实现对应的 #getPathWithinContext() 接口方法。 2.2.2 示例😈 在回过头看 「2.1.4 示例」 ，如果将 DefaultResourceLoader 改为 FileSystemContextResource ，则 fileResource1则为 FileSystemResource 类型的资源。 2.3 ClassRelativeResourceLoaderorg.springframework.core.io.ClassRelativeResourceLoader ，是 DefaultResourceLoader 的另一个子类的实现。和 FileSystemResourceLoader 类似，在实现代码的结构上类似，也是覆写 #getResourceByPath(String path) 方法，并返回其对应的 ClassRelativeContextResource 的资源类型。 感兴趣的胖友，可以看看 《Spring5：就这一次，搞定资源加载器之ClassRelativeResourceLoader》 文章。 ClassRelativeResourceLoader 扩展的功能是，可以根据给定的class 所在包或者所在包的子包下加载资源。 2.4 ResourcePatternResolverResourceLoader 的 Resource getResource(String location) 方法，每次只能根据 location 返回一个 Resource 。当需要加载多个资源时，我们除了多次调用 #getResource(String location) 方法外，别无他法。org.springframework.core.io.support.ResourcePatternResolver 是 ResourceLoader 的扩展，它支持根据指定的资源路径匹配模式每次返回多个 Resource 实例，其定义如下： 1234567public interface ResourcePatternResolver extends ResourceLoader &#123; String CLASSPATH_ALL_URL_PREFIX = "classpath*:"; Resource[] getResources(String locationPattern) throws IOException;&#125; ResourcePatternResolver 在 ResourceLoader 的基础上增加了 #getResources(String locationPattern) 方法，以支持根据路径匹配模式返回多个 Resource 实例。 同时，也新增了一种新的协议前缀 &quot;classpath*:&quot;，该协议前缀由其子类负责实现。 2.5 PathMatchingResourcePatternResolverorg.springframework.core.io.support.PathMatchingResourcePatternResolver ，为 ResourcePatternResolver 最常用的子类，它除了支持 ResourceLoader 和 ResourcePatternResolver 新增的 &quot;classpath*:&quot; 前缀外，还支持 Ant 风格的路径匹配模式（类似于 &quot;**/*.xml&quot;）。 2.5.1 构造函数PathMatchingResourcePatternResolver 提供了三个构造函数，如下： 123456789101112131415161718192021/** * 内置的 ResourceLoader 资源定位器 */private final ResourceLoader resourceLoader;/** * Ant 路径匹配器 */private PathMatcher pathMatcher = new AntPathMatcher();public PathMatchingResourcePatternResolver() &#123; this.resourceLoader = new DefaultResourceLoader();&#125;public PathMatchingResourcePatternResolver(ResourceLoader resourceLoader) &#123; Assert.notNull(resourceLoader, "ResourceLoader must not be null"); this.resourceLoader = resourceLoader;&#125;public PathMatchingResourcePatternResolver(@Nullable ClassLoader classLoader) &#123; this.resourceLoader = new DefaultResourceLoader(classLoader);&#125; PathMatchingResourcePatternResolver 在实例化的时候，可以指定一个 ResourceLoader，如果不指定的话，它会在内部构造一个 DefaultResourceLoader 。 pathMatcher 属性，默认为 AntPathMatcher 对象，用于支持 Ant 类型的路径匹配。 2.5.2 getResource12345678@Overridepublic Resource getResource(String location) &#123; return getResourceLoader().getResource(location);&#125;public ResourceLoader getResourceLoader() &#123; return this.resourceLoader;&#125; 该方法，直接委托给相应的 ResourceLoader 来实现。所以，如果我们在实例化的 PathMatchingResourcePatternResolver 的时候，如果未指定 ResourceLoader 参数的情况下，那么在加载资源时，其实就是 DefaultResourceLoader 的过程。 其实在下面介绍的 Resource[] getResources(String locationPattern) 方法也相同，只不过返回的资源是多个而已。 2.5.3 getResources1234567891011121314151617181920212223242526272829303132@Overridepublic Resource[] getResources(String locationPattern) throws IOException &#123; Assert.notNull(locationPattern, "Location pattern must not be null"); // 以 "classpath*:" 开头 if (locationPattern.startsWith(CLASSPATH_ALL_URL_PREFIX)) &#123; // 路径包含通配符 // a class path resource (multiple resources for same name possible) if (getPathMatcher().isPattern(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()))) &#123; // a class path resource pattern return findPathMatchingResources(locationPattern); // 路径不包含通配符 &#125; else &#123; // all class path resources with the given name return findAllClassPathResources(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length())); &#125; // 不以 "classpath*:" 开头 &#125; else &#123; // Generally only look for a pattern after a prefix here, // 通常只在这里的前缀后面查找模式 // and on Tomcat only after the "*/" separator for its "war:" protocol. 而在 Tomcat 上只有在 “*/ ”分隔符之后才为其 “war:” 协议 int prefixEnd = (locationPattern.startsWith("war:") ? locationPattern.indexOf("*/") + 1 : locationPattern.indexOf(':') + 1); // 路径包含通配符 if (getPathMatcher().isPattern(locationPattern.substring(prefixEnd))) &#123; // a file pattern return findPathMatchingResources(locationPattern); // 路径不包含通配符 &#125; else &#123; // a single resource with the given name return new Resource[] &#123;getResourceLoader().getResource(locationPattern)&#125;; &#125; &#125;&#125; 处理逻辑如下图： 非 &quot;classpath*:&quot; 开头，且路径不包含通配符，直接委托给相应的 ResourceLoader 来实现。 其他情况，调用 #findAllClassPathResources(...)、或 #findPathMatchingResources(...) 方法，返回多个 Resource 。下面，我们来详细分析。 2.5.4 findAllClassPathResources当 locationPattern 以 &quot;classpath*:&quot; 开头但是不包含通配符，则调用 #findAllClassPathResources(...) 方法加载资源。该方法返回 classes 路径下和所有 jar 包中的所有相匹配的资源。 1234567891011121314protected Resource[] findAllClassPathResources(String location) throws IOException &#123; String path = location; // 去除首个 / if (path.startsWith("/")) &#123; path = path.substring(1); &#125; // 真正执行加载所有 classpath 资源 Set&lt;Resource&gt; result = doFindAllClassPathResources(path); if (logger.isTraceEnabled()) &#123; logger.trace("Resolved classpath location [" + location + "] to resources " + result); &#125; // 转换成 Resource 数组返回 return result.toArray(new Resource[0]);&#125; 真正执行加载的是在 #doFindAllClassPathResources(...) 方法，代码如下： 12345678910111213141516171819protected Set&lt;Resource&gt; doFindAllClassPathResources(String path) throws IOException &#123; Set&lt;Resource&gt; result = new LinkedHashSet&lt;&gt;(16); ClassLoader cl = getClassLoader(); // &lt;1&gt; 根据 ClassLoader 加载路径下的所有资源 Enumeration&lt;URL&gt; resourceUrls = (cl != null ? cl.getResources(path) : ClassLoader.getSystemResources(path)); // &lt;2&gt; while (resourceUrls.hasMoreElements()) &#123; URL url = resourceUrls.nextElement(); // 将 URL 转换成 UrlResource result.add(convertClassLoaderURL(url)); &#125; // &lt;3&gt; 加载路径下得所有 jar 包 if ("".equals(path)) &#123; // The above result is likely to be incomplete, i.e. only containing file system references. // We need to have pointers to each of the jar files on the classpath as well... addAllClassLoaderJarRoots(cl, result); &#125; return result;&#125; &lt;1&gt; 处，根据 ClassLoader 加载路径下的所有资源。在加载资源过程时，如果在构造 PathMatchingResourcePatternResolver 实例的时候如果传入了 ClassLoader，则调用该 ClassLoader 的 #getResources() 方法，否则调用 ClassLoader#getSystemResources(path)方法。另外，ClassLoader#getResources() 方法，代码如下: 12345678910111213// java.lang.ClassLoader.javapublic Enumeration&lt;URL&gt; getResources(String name) throws IOException &#123; @SuppressWarnings("unchecked") Enumeration&lt;URL&gt;[] tmp = (Enumeration&lt;URL&gt;[]) new Enumeration&lt;?&gt;[2]; if (parent != null) &#123; tmp[0] = parent.getResources(name); &#125; else &#123; tmp[0] = getBootstrapResources(name); &#125; tmp[1] = findResources(name); return new CompoundEnumeration&lt;&gt;(tmp);&#125; 看到这里是不是就已经一目了然了？如果当前父类加载器不为 null ，则通过父类向上迭代获取资源，否则调用 #getBootstrapResources() 。这里是不是特别熟悉，(^▽^)。 &lt;2&gt; 处，遍历 URL 集合，调用 #convertClassLoaderURL(URL url) 方法，将 URL 转换成 UrlResource 对象。代码如下： 123protected Resource convertClassLoaderURL(URL url) &#123; return new UrlResource(url);&#125; &lt;3&gt; 处，若 path 为空（“”）时，则调用 #addAllClassLoaderJarRoots(...)方法。该方法主要是加载路径下得所有 jar 包，方法较长也没有什么实际意义就不贴出来了。感兴趣的胖友，自己可以去看看。😈 当然，可能代码也比较长哈。 通过上面的分析，我们知道 #findAllClassPathResources(...) 方法，其实就是利用 ClassLoader 来加载指定路径下的资源，不论它是在 class 路径下还是在 jar 包中。如果我们传入的路径为空或者 /，则会调用 #addAllClassLoaderJarRoots(...) 方法，加载所有的 jar 包。 2.5.5 findPathMatchingResources当 locationPattern 中包含了通配符，则调用该方法进行资源加载。代码如下： 123456789101112131415161718192021222324252627282930313233343536protected Resource[] findPathMatchingResources(String locationPattern) throws IOException &#123; // 确定根路径、子路径 String rootDirPath = determineRootDir(locationPattern); String subPattern = locationPattern.substring(rootDirPath.length()); // 获取根据路径下的资源 Resource[] rootDirResources = getResources(rootDirPath); // 遍历，迭代 Set&lt;Resource&gt; result = new LinkedHashSet&lt;&gt;(16); for (Resource rootDirResource : rootDirResources) &#123; rootDirResource = resolveRootDirResource(rootDirResource); URL rootDirUrl = rootDirResource.getURL(); // bundle 资源类型 if (equinoxResolveMethod != null &amp;&amp; rootDirUrl.getProtocol().startsWith("bundle")) &#123; URL resolvedUrl = (URL) ReflectionUtils.invokeMethod(equinoxResolveMethod, null, rootDirUrl); if (resolvedUrl != null) &#123; rootDirUrl = resolvedUrl; &#125; rootDirResource = new UrlResource(rootDirUrl); &#125; // vfs 资源类型 if (rootDirUrl.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) &#123; result.addAll(VfsResourceMatchingDelegate.findMatchingResources(rootDirUrl, subPattern, getPathMatcher())); // jar 资源类型 &#125; else if (ResourceUtils.isJarURL(rootDirUrl) || isJarResource(rootDirResource)) &#123; result.addAll(doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPattern)); // 其它资源类型 &#125; else &#123; result.addAll(doFindPathMatchingFileResources(rootDirResource, subPattern)); &#125; &#125; if (logger.isTraceEnabled()) &#123; logger.trace("Resolved location pattern [" + locationPattern + "] to resources " + result); &#125; // 转换成 Resource 数组返回 return result.toArray(new Resource[0]);&#125; 方法有点儿长，但是思路还是很清晰的，主要分两步： 确定目录，获取该目录下得所有资源。 在所获得的所有资源后，进行迭代匹配获取我们想要的资源。 在这个方法里面，我们要关注两个方法，一个是 #determineRootDir(String location) 方法，一个是 #doFindPathMatchingXXXResources(...) 等方法。 2.5.5.1 determineRootDirdetermineRootDir(String location) 方法，主要是用于确定根路径。代码如下： 1234567891011121314151617181920212223242526272829/** * Determine the root directory for the given location. * &lt;p&gt;Used for determining the starting point for file matching, * resolving the root directory location to a &#123;@code java.io.File&#125; * and passing it into &#123;@code retrieveMatchingFiles&#125;, with the * remainder of the location as pattern. * &lt;p&gt;Will return "/WEB-INF/" for the pattern "/WEB-INF/*.xml", * for example. * @param location the location to check * @return the part of the location that denotes the root directory * @see #retrieveMatchingFiles */protected String determineRootDir(String location) &#123; // 找到冒号的后一位 int prefixEnd = location.indexOf(':') + 1; // 根目录结束位置 int rootDirEnd = location.length(); // 在从冒号开始到最后的字符串中，循环判断是否包含通配符，如果包含，则截断最后一个由”/”分割的部分。 // 例如：在我们路径中，就是最后的ap?-context.xml这一段。再循环判断剩下的部分，直到剩下的路径中都不包含通配符。 while (rootDirEnd &gt; prefixEnd &amp;&amp; getPathMatcher().isPattern(location.substring(prefixEnd, rootDirEnd))) &#123; rootDirEnd = location.lastIndexOf('/', rootDirEnd - 2) + 1; &#125; // 如果查找完成后，rootDirEnd = 0 了，则将之前赋值的 prefixEnd 的值赋给 rootDirEnd ，也就是冒号的后一位 if (rootDirEnd == 0) &#123; rootDirEnd = prefixEnd; &#125; // 截取根目录 return location.substring(0, rootDirEnd);&#125; 方法比较绕，效果如下示例： 原路径 确定根路径 classpath*:test/cc*/spring-*.xml classpath*:test/ classpath*:test/aa/spring-*.xml classpath*:test/aa/ 2.5.5.2 doFindPathMatchingXXXResources 来自艿艿 #doFindPathMatchingXXXResources(...) 方法，是个泛指，一共对应三个方法： #doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPatter) 方法 #doFindPathMatchingFileResources(rootDirResource, subPattern) 方法 VfsResourceMatchingDelegate#findMatchingResources(rootDirUrl, subPattern, pathMatcher) 方法 因为本文重在分析 Spring 统一资源加载策略的整体流程。相对来说，上面几个方法的代码量会比较多。所以本文不再追溯，感兴趣的胖友，推荐阅读如下文章： 《Spring源码情操陶冶-PathMatchingResourcePatternResolver路径资源匹配溶解器》 ，主要针对 #doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPatter) 方法。 《深入 Spring IoC 源码之 ResourceLoader》 ，主要针对 #doFindPathMatchingFileResources(rootDirResource, subPattern) 方法。 《Spring 源码学习 —— 含有通配符路径解析（上）》 😈 貌似没有下 3. 小结至此 Spring 整个资源记载过程已经分析完毕。下面简要总结下： Spring 提供了 Resource 和 ResourceLoader 来统一抽象整个资源及其定位。使得资源与资源的定位有了一个更加清晰的界限，并且提供了合适的 Default 类，使得自定义实现更加方便和清晰。 DefaultResource 为 Resource 的默认实现，它对 Resource 接口做了一个统一的实现，子类继承该类后只需要覆盖相应的方法即可，同时对于自定义的 Resource 我们也是继承该类。 DefaultResourceLoader 同样也是 ResourceLoader 的默认实现，在自定 ResourceLoader 的时候我们除了可以继承该类外还可以实现 ProtocolResolver 接口来实现自定资源加载协议。 DefaultResourceLoader 每次只能返回单一的资源，所以 Spring 针对这个提供了另外一个接口 ResourcePatternResolver ，该接口提供了根据指定的 locationPattern 返回多个资源的策略。其子类 PathMatchingResourcePatternResolver 是一个集大成者的 ResourceLoader ，因为它即实现了 Resource getResource(String location) 方法，也实现了 Resource[] getResources(String locationPattern)方法。 另外，如果胖友认真的看了本文的包结构，我们可以发现，Resource 和 ResourceLoader 核心是在，spring-core 项目中。 如果想要调试本小节的相关内容，可以直接使用 Resource 和 ResourceLoader 相关的 API ，进行操作调试。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RxJava]]></title>
    <url>%2F2019%2F02%2F09%2FRxJava%2F</url>
    <content type="text"><![CDATA[RxJava是什么a library for composing asynchronous and event-based programs using observable sequences for the Java VM（一个对于构成使用的Java虚拟机观察序列异步和基于事件的程序库）。github：https://github.com/ReactiveX/RxJava 观察者模式RxJava的世界里，我们有四种角色：Observable(被观察者)、Observer(观察者)Subscriber(订阅者)、SubjectObservable和Subject是两个“生产”实体，Observer和Subscriber是两个“消费”实体。Observable 和 Observer 通过 subscribe() 方法实现订阅关系，从而 Observable 可以在需要的时候发出事件来通知 Observer。 回调方法Subscribe方法用于将观察者连接到Observable，你的观察者需要实现以下方法： onNext(T item)Observable调用这个方法发射数据，方法的参数就是Observable发射的数据，这个方法可能会被调用多次，取决于你的实现。 onError(Exception ex)当Observable遇到错误或者无法返回期望的数据时会调用这个方法，这个调用会终止Observable，后续不会再调用onNext和onCompleted，onError方法的参数是抛出的异常。 onComplete正常终止，如果没有遇到错误，Observable在最后一次调用onNext之后调用此方法。 添加依赖12compile 'io.reactivex:rxandroid:1.1.0'compile 'io.reactivex:rxjava:1.1.0' 创建操作create123456789101112131415161718192021222324Observable.create(new Observable.OnSubscribe&lt;String&gt;() &#123; @Override public void call(Subscriber&lt;? super String&gt; subscriber) &#123; subscriber.onNext("Hello"); subscriber.onNext("RxJava"); subscriber.onCompleted(); &#125; &#125;) .subscribe(new Observer&lt;String&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(String s) &#123; Log.i("wxl", "onNext=" + s); &#125; &#125;); 除了 Observer 接口之外，RxJava 还内置了一个实现了 Observer 的抽象类：Subscriber。 Subscriber 对 Observer 接口进行了一些扩展，但他们的基本使用方式是完全一样的： 12345678910111213141516.subscribe(new Subscriber() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(Object o) &#123; Log.i("wxl", "onNext=" + o); &#125; &#125;); from接受数组，返回一个按参数列表顺序发射这些数据的Observable。 123456789101112131415161718String[] froms=&#123;"Hello","RxJava"&#125;;Observable.from(froms).subscribe(new Observer&lt;String&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(String s) &#123; Log.i("wxl", "onNext=" + s); &#125;&#125;); justjust函数，它接受一至九个参数，返回一个按参数列表顺序发射这些数据的Observable。 1234567891011121314151617Observable.just("Hello","RxJava") .subscribe(new Observer&lt;String&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(String s) &#123; Log.i("wxl", "onNext=" + s); &#125; &#125;); 以上打印结果都是： 123com.wuxiaolong.apksample I/wxl: onNext=Hellocom.wuxiaolong.apksample I/wxl: onNext=RxJavacom.wuxiaolong.apksample I/wxl: onCompleted 变换操作Map操作符对原始Observable发射的每一项数据应用一个你选择的函数，然后返回一个发射这些结果。如下，将原始Observable数据转化成大写，再发射： 1234567891011121314151617181920212223Observable.just("Hello", "RxJava") .map(new Func1&lt;String, String&gt;() &#123; @Override public String call(String s) &#123; return s.toUpperCase(); &#125; &#125;) .subscribe(new Observer&lt;String&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(String s) &#123; Log.i("wxl", "onNext=" + s); &#125; &#125;); 打印结果： 123com.wuxiaolong.apksample I/wxl: onNext=HELLOcom.wuxiaolong.apksample I/wxl: onNext=RXJAVAcom.wuxiaolong.apksample I/wxl: onCompleted flatMapflatMap()接收一个Observable的输出作为输入，然后作为一个新的Observable再发射。理解flatMap的关键点在于，flatMap输出的新的Observable正是我们在Subscriber想要接收的，比如这里输出单个的字符串。 1234567891011121314151617181920212223242526List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add("Hello"); list.add("RxJava");Observable.from(list) .flatMap(new Func1&lt;String, Observable&lt;String&gt;&gt;() &#123; @Override public Observable&lt;String&gt; call(String s) &#123; return Observable.just(s.toUpperCase()); &#125; &#125;) .subscribe(new Observer&lt;String&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(String s) &#123; Log.i("wxl", "onNext=" + s); &#125; &#125;); 打印结果： 123com.wuxiaolong.apksample I/wxl: onNext=HELLOcom.wuxiaolong.apksample I/wxl: onNext=RXJAVAcom.wuxiaolong.apksample I/wxl: onCompleted Scan一个累加器函数，操作符对原始Observable发射的第一项数据应用一个函数，然后将那个函数的结果作为自己的第一项数据发射。 1234567891011121314151617181920Observable.just(1, 2, 3, 4, 5) .scan(new Func2&lt;Integer, Integer, Integer&gt;() &#123; @Override public Integer call(Integer integer, Integer integer2) &#123; return integer + integer2; &#125; &#125;) .subscribe(new Observer&lt;Integer&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(Integer integer) &#123; Log.i("wxl", "onNext=" + integer); &#125; &#125;); 第一次发射得到1，作为结果与2相加；发射得到3，作为结果与3相加，以此类推，打印结果： 123456I/wxl: onNext=1I/wxl: onNext=3I/wxl: onNext=6I/wxl: onNext=10I/wxl: onNext=15I/wxl: onCompleted GroupBy按照指定的规则来分组元素。 过滤操作Filter观测序列中只有通过的数据才会被发射。 1234567891011121314151617181920Observable.just(4, 2, 1, 7, 5) .filter(new Func1&lt;Integer, Boolean&gt;() &#123; @Override public Boolean call(Integer integer) &#123; return integer &gt; 3; &#125; &#125;) .subscribe(new Observer&lt;Integer&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(Integer integer) &#123; Log.i("wxl", "onNext=" + integer); &#125; &#125;); 过滤小于3的，打印结果： 1234I/wxl: onNext=4I/wxl: onNext=7I/wxl: onNext=5I/wxl: onCompleted take()、takeLast()1.take(3) 只发射前N个元素 1.takeLast(3) 只发射最后N个元素 First、last只发射第一个元素或者最后一个元素 Skip、SkipLast1.skip(2) 来创建一个不发射前两个元素而是发射它后面的那些数据的序列 distinct仅处理一次，可以处理去除重复的数据 ElementAt仅从一个序列中发射第n个元素然后就完成了，这里是从0开始计的。 123Observable.just(1, 2, 3, 4, 5, 6) .elementAt(3) .subscribe(……); 打印结果：4 Sample定期发射Observable最近发射的数据项 1.sample(1000, TimeUnit.MILLISECONDS) 合并操作Merge合并多个Observables的发射物，多输入，单输出 12345678910111213141516Observable&lt;Integer&gt; observable1 = Observable.just(1, 3, 5);Observable&lt;Integer&gt; observable2 = Observable.just(2, 4, 6);Observable.merge(observable1,observable2) .subscribe(new Observer&lt;Integer&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(Integer integer) &#123; Log.i("wxl", "onNext=" + integer); &#125; &#125;); 打印结果： 1234567I/wxl: onNext=1I/wxl: onNext=3I/wxl: onNext=5I/wxl: onNext=2I/wxl: onNext=4I/wxl: onNext=6I/wxl: onCompleted zip合并两个或者多个Observables发射出的数据项，根据指定的函数Func2变换它们，并发射一个新值。 123456789101112131415161718192021Observable&lt;Integer&gt; observable1 = Observable.just(1, 3, 5);Observable&lt;Integer&gt; observable2 = Observable.just(2, 4, 6, 9);Observable.zip(observable1, observable2, new Func2&lt;Integer, Integer, Integer&gt; @Override public Integer call(Integer integer, Integer integer2) &#123; return integer + integer2; &#125;&#125;) .subscribe(new Observer&lt;Integer&gt;() &#123; @Override public void onCompleted() &#123; Log.i("wxl", "onCompleted"); &#125; @Override public void onError(Throwable e) &#123; &#125; @Override public void onNext(Integer integer) &#123; Log.i("wxl", "onNext=" + integer); &#125; &#125;); 打印结果： 1234I/wxl: onNext=3I/wxl: onNext=7I/wxl: onNext=11I/wxl: onCompleted joinstartWith1.startWith(1) 在数据序列的开头插入一条指定的项1 Schedulers调度器，解决Android主线程问题，有5种： Schedulers.io()这个调度器时用于I/O操作（读写文件、读写数据库、网络信息交互等） Schedulers.computation()这个是计算工作默认的调度器，它与I/O操作无关。它也是许多RxJava方法的默认调度器：buffer()，debounce()，delay()，interval()，sample()，skip() Schedulers.immediate()这个调度器允许你立即在当前线程执行你指定的工作。它是timeout()，timeInterval()，以及timestamp()方法默认的调度器。 Schedulers.newThread()它为指定任务启动一个新的线程。 Schedulers.trampoline()当我们想在当前线程执行一个任务时，并不是立即，我们可以用.trampoline()将它入队。这个调度器将会处理它的队列并且按序运行队列中每一个任务。它是repeat()和retry()方法默认的调度器。 SubscribeOn、ObserveOnsubscribeOn()：事件产生的线程observeOn()：事件消费的线程，AndroidSchedulers.mainThread()，它指定的操作将在 Android 主线程运行。 1.subscribeOn(Schedulers.io()) // 指定 subscribe() 发生在 IO 线程]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>RxJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat性能优化]]></title>
    <url>%2F2019%2F01%2F28%2FTomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[配置优化减少配置优化 场景一：假设当前 REST 应用（微服务） 分析：它不需要静态资源，Tomcat 容器静态和动态 静态处理：DefaultServlet 优化方案：通过移除conf/web.xml 中 org.apache.catalina.servlets.DefaultServlet。 动态：JspServlet 优化方案：通过移除conf/web.xml 中 org.apache.jasper.servlet.JspServlet。 DispatcherServlet：Spring Web MVC 应用 Servlet JspServlet：编译并且执行 Jsp 页面 DefaultServlet：Tomcat 处理静态资源的 Servlet 移除 welcome-file-list 12345&lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;&lt;/welcome-file-list&gt; 如果程序是REST JSON Content-Type 或者 MIME Type： application/json 移除 Session 设置 对于微服务/REST 应用，不需要 Session，因为不需要状态。 Spring Security OAuth 2.0、JWT Session 通过 jsessionId 进行用户跟踪，HTTP 无状态，需要一个ID 与当前用户会话联系。Spring Session HttpSession jessionId 作为 Redis，实现多个机器登录，用户会话不丢失。 存储方法：Cookie、URL 重写、 SSL 移除 Valve Valve 类似于 Filter 移除 AccessLogValve，可以通过 Nginx 的 Access Log 替代，Valve 实现都需要消耗 Java 应用的计算时间。 场景二：需要 JSP 的情况 分析：了解 JspServlet 处理原理 Servlet 周期： 实例化：Servlet 和 Filter 实现类必须包含默认构造器。反射的方式进行实例化。 初始化：Servlet 容器调用 Servlet 或 Filter init() 方法 销毁：Servlet 容器关闭时，Servlet 或者 Filter destroy() 方法被调用 ​ Servlet 或者 Filter 在一个容器中，是一般情况在一个 Web App 中是一个单例，不排除应用定义多个。 JspServlet 相关的优化 ServletConfig 参数: 需要编译 compiler modificationTestInterval 不需要编译 development 设置 false development = false ，那么，这些 JSP 要如何编译。优化方法： Ant Task 执行 JSP 编译 Maven 插件：org.codehaus.mojo:jspc-maven-plugin 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.sling&lt;/groupId&gt; &lt;artifactId&gt;jspc-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; JSP -&gt; 翻译.jsp 或者.jspx 文件成 .java -&gt; 编译 .class 总结，conf/web.xml 作为 Servlet 应用的默认web.xml,实际上，应用程序存在两份web.xml，其中包括Tomcat conf/web.xml 和 应用的web.xml，最终将两者合并。 JspServlet 如果 development 参数为 true，它会自定检查文件是否修改，如果修改重新翻译，再编译（加载和执行）。言外之意，JspServlet 开发模式可能会导致内存溢出。卸载 Class不及时会导致 Perm 区域不够。 ParentClassLoader -&gt; 1.class 2.class 3.class ChildClassLoader -&gt; 4.class , 5.class ChildClassLoader load 1 - 5 .class 1.class 需要卸载，需要将 ParentClassLoader 设置为 null，当 ClassLoader 被 GC 后，1-3 class 全部会被卸载。 1.class 它是文件，文件被 JVM 加载，二进制-&gt; Verify -&gt; 解析 配置调整关闭自动重载context.xml 12&lt;Context docBase="E:/Downloads/tomcat/target/tomcat-1.0-SNAPSHOT" reloadable="false" &gt;&lt;/Context&gt; 修改连接线程池数量通过 server.xml1234567&lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="99" minSpareThreads="9"/&gt;&lt;Connector executor="tomcatThreadPool" port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; 通过程序来理解，&lt;Executor&gt; 实际的Tomcat 接口： org.apache.catalina.Executor 扩展： J.U.C 标准接口 java.util.concurrent.Executor 实现：org.apache.catalina.core.StandardThreadExecutor 线程数量 1234567891011121314151617181920212223 /** * max number of threads */ protected int maxThreads = 200; /** * min number of threads */ protected int minSpareThreads = 25;public void setMinSpareThreads(int minSpareThreads) &#123; this.minSpareThreads = minSpareThreads; if (executor != null) &#123; executor.setCorePoolSize(minSpareThreads); &#125; &#125; public void setMaxThreads(int maxThreads) &#123; this.maxThreads = maxThreads; if (executor != null) &#123; executor.setMaximumPoolSize(maxThreads); &#125; &#125; 线程池：org.apache.tomcat.util.threads.ThreadPoolExecutor(java.util.concurrent.ThreadPoolExecutor) 总结：Tomcat IO 连接器使用的线程池实际标准的 Java 线程池的扩展，最大线程数量和最小线程数量实际上分别是 MaximumPoolSize 和 CorePoolSize。 通过 JMX jconsole命令，或者jvisualvm ，进入JMX，选择进程 调整tomat线程池大小 123## 线程池大小server.tomcat.maxThreads=99server.tomcat.minSpareThreads=9 JMX查看线程 jmeter.sh启动，定义100个线程，发起api请求 jconsole 或者 jvisualvm 查看线程数变化 观察StandardThreadExecutor是否存在调整线程池数量的 API 评估一些参考： 正确率 Load（CPU -&gt; JVM GC） TPS / QPS (越大越好) CPU 密集型（加密/解密、算法） I/O 密集型，网络、文件读写等 问题：到底设置多少的线程数量才是最优？ 首先，评估整体的情况量，假设 100W QPS，有机器数量 100 台，每台支撑 1w QPS。 第二，进行压力测试，需要一些测试样本，JMeter 来实现，假设一次请求需要RT 10ms，1秒可以同时完成 100个请求。10000 / 100 = 100 线程。 JMeter的线程数。 确保，Load 不要太高。减少 Full GC，GC 取决于 JVM 堆的大小。 执行一次操作需要 5 MB 内存， 50 GB。 20 GB 内存，必然执行 GC。要不调优程序，最好对象存储外化，比如 Redis，同时又需要评估 Redis 网络开销。又要评估网卡的接受能力。 第三，常规性压测，由于业务变更，会导致底层性能变化。 JVM 优化调整 GC 算法如果 Java 版本小于 9，默认PS MarkSweep，可选设置 CMS、G1。 如果 Java 9 的话，默认 G1 默认算法1java -jar -server -XX:-PrintGCDetails -Xloggc:./1g/gc.log -XX:+HeapDumpOnOutOfMemoryError -Xms1g -Xmx1g -XX:MaxGCPauseMillis=250 -Djava.awt.headless=true stress-test-demo-0.0.1-SNAPSHOT.jar G1 算法1java -jar -server -XX:-PrintGCDetails -Xloggc:./1g/g1-gc.log -XX:+HeapDumpOnOutOfMemoryError -Xms1g -Xmx1g -XX:+UseG1GC -XX:+UseNUMA -XX:MaxGCPauseMillis=250 -Djava.awt.headless=true stress-test-demo-0.0.1-SNAPSHOT.jar -server 主要提高吞吐量，在有限的资源，实现最大化利用。-client 主要提高响应时间，主要是提高用户体验。 Spring Boot 配置调整Maven 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&lt;/dependency&gt; application.properties 1234567891011# &lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;# maxThreads=&quot;9&quot; minSpareThreads=&quot;9&quot;/&gt;## 线程池大小server.tomcat.maxThreads = 99server.tomcat.minSpareThreads = 9## 取消 Tomcat AccessLogValveserver.tomcat.accesslog.enabled = false## 取消 JspServletserver.jspServlet.registered=false tomcat.getServer().await()和Object.wait()有什么区别 Tomcat tomcat.getServer().await() 利用 Thread.sleep(long) 实现： 123456789101112131415if( port==-1 ) &#123; try &#123; awaitThread = Thread.currentThread(); while(!stopAwait) &#123; try &#123; Thread.sleep( 10000 ); &#125; catch( InterruptedException ex ) &#123; // continue and check the flag &#125; &#125; &#125; finally &#123; awaitThread = null; &#125; return; &#125; Object#wait() 方法也是 Native 方法。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[嵌入式 Tomcat]]></title>
    <url>%2F2019%2F01%2F26%2F%E5%B5%8C%E5%85%A5%E5%BC%8FTomcat%2F</url>
    <content type="text"><![CDATA[Tomcat 架构 Web 技术栈Servlet 技术栈Web Flux（Netty）BIO NIO Web 自动装配API 角度分析Servlet 3.0 + API 实现 ServletContainerInitializer 容器角度分析传统的 Web 应用，将 webapp 部署到 Servlet 容器中。 嵌入式 Web 应用，灵活部署，任意指定位置（或者通过复杂的条件判断） Tomcat 7 是 Servlet 3.0 的实现，ServletContainerInitializer Tomcat 8 是 Servlet 3.1 的实现，NIO HttpServletRequest、HttpServletResponse NIO 并非一定能够提高性能，比如请求数据量较大，NIO 性能比 BIO 还要差 NIO 多工，读、写，同步的 jar 启动java -jar 或者 jar 读取 .jar META-INF/MANIFEST.MF ，其中属性 Main-Class 就是引导类所在。 参考 JDK API ： java.util.jar.Manifest Tomcat Maven 插件Tomcat 7 Maven 插件123&lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;&lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;&lt;version&gt;2.1&lt;/version&gt; 12Manifest-Version: 1.0Main-Class: org.apache.tomcat.maven.runner.Tomcat7RunnerCli 得出 Tomcat 7 可执行 jar 引导类是org.apache.tomcat.maven.runner.Tomcat7RunnerCli Tomcat 7 API 编程代码参考： https://github.com/Frankenjoy123/embeded-tomcat 确定 Classpath 目录classes 绝对路径：E:\Downloads\tomcat\target\classes 12String classesPath = System.getProperty("user.dir") + File.separator + "target" + File.separator + "classes"; 创建 Tomcat 实例org.apache.catalina.startup.Tomcat Maven 坐标：org.apache.tomcat.embed:tomcat-embed-core:7.0.37 设置 Host对象1234// 设置 HostHost host = tomcat.getHost();host.setName("localhost");host.setAppBase("webapps"); 设置 ClasspathClasspath 读取资源：配置、类文件 conf/web.xml 作为配置文件，并且放置 Classpath 目录下（绝对路径） 设置 DemoServlet 123 // 添加 DemoServlet 到 Tomcat 容器Wrapper wrapper = tomcat.addServlet(contextPath, "DemoServlet", new DemoServlet());wrapper.addMapping("/demo"); Spring Boot 嵌入式 Tomcat 编程实现 EmbeddedServletContainerCustomer123456789101112131415161718192021222324252627282930@Configurationpublic class TomcatConfiguration implements EmbeddedServletContainerCustomizer &#123; @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; System.err.println(container.getClass()); if (container instanceof TomcatEmbeddedServletContainerFactory) &#123; TomcatEmbeddedServletContainerFactory factory = (TomcatEmbeddedServletContainerFactory) container; // 相当于 new TomcatContextCustomizer()&#123;&#125; factory.addContextCustomizers((context) -&gt; &#123; // Lambda if (context instanceof StandardContext) &#123; StandardContext standardContext = (StandardContext) context; // standardContext.setDefaultWebXml(); // 设置 standardContext.setReloadable(true); &#125; &#125;); // 相当于 new TomcatConnectorCustomizer() &#123;&#125; factory.addConnectorCustomizers(connector -&gt; &#123; connector.setPort(12345); &#125;); &#125; &#125;&#125; 自定义 Context实现TomcatContextCustomizer 1234567// 相当于 new TomcatContextCustomizer()&#123;&#125;factory.addContextCustomizers((context) -&gt; &#123; // Lambda if (context instanceof StandardContext) &#123; StandardContext standardContext = (StandardContext) context; // standardContext.setDefaultWebXml(); // 设置 &#125;&#125;); 自定义 Connector实现 TomcatConnectorCustomizer 1234// 相当于 new TomcatConnectorCustomizer() &#123;&#125;factory.addConnectorCustomizers(connector -&gt; &#123; connector.setPort(12345);&#125;); 问答 内嵌tomcat是不是比单独的tomcat不是在某方面具有一些优势？ 嵌入式 Tomcat 或者嵌入式 Web 容器可以不依赖文件目录，比如在 Docker 场景使用方便。 内置的tomcat 和 外部的tomcat 性能有多大差别?生产线上建议用哪个? 嵌入式 Tomcat 和 传统 Tomcat 性能可以说一样，现在非常多的生产环境 Spring Boot 嵌入式 - 嵌入式 Tomcat Spring中pre实例化和pre初始化区别(刚刚有提到) 在 Spring 早起版本中，先有初始化生命周期 - org.springframework.beans.factory.config.BeanPostProcessor 后来 Spring 1.2 ，提供新的扩展接口（BeanPostProcessor）： org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessor ​ Tomcat API 主要是讲tomcat运行原理吗？生产环境用哪种比较多？ 传统 Tomcat 和 嵌入式 Tomcat 都有在生产环境使用。 ​ Tomcat 热部署原理能给讲下吗？ org.apache.catalina.Lifecycle ​ 监控资源变化，Class 变化、配置变化了。 Tomcat 决定重启 Context ​ org.apache.catalina.Context ​ Tomcat 自动加载 1public void setReloadable(boolean reloadable)]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式与Spring结合使用]]></title>
    <url>%2F2019%2F01%2F17%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E4%B8%8ESpring%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[IOC是Spring的核心之一，利用Spring使用设计模式中的策略模式，可以把具体策略的创建交给Spring容器来管理。 策略模式接口的定义 需求：设计一个统计报表接口，暂定有两种统计方式：统计订单总数,统计新增用户数。 首先定义统计接口。 12345678/**- 策略模式的使用:选择统计算法,分离实现- 统计策略接口:定义统一的调用方法*/public interface StatStrategy &#123; void getStatData();&#125; 具体的统计算法： 1234567@Componentpublic class OrderStrategyImpl implements StatStrategy &#123; @Override public void getStatData() &#123; System.out.println("统计订单总数"); &#125;&#125; 1234567@Componentpublic class UserStrategyImpl implements StatStrategy &#123; @Override public void getStatData() &#123; System.out.println("统计新增用户数"); &#125;&#125; 利用@Component 注解将算法的实现交由Spring容器管理。 123456789101112131415161718192021222324/** * 统计策略的上下文 */public class StatContext &#123; //装载策略对象的集合,其中key:Statistics类型为自定义的枚举类型 private Map&lt;Statistics, StatStrategy&gt; statStrategy = new HashMap&lt;&gt;(); //提供给客户端使用的方法 public void loadDetailData(Integer strategyId) &#123; for (Map.Entry&lt;Statistics,StatStrategy&gt; entry : statStrategy.entrySet()) &#123; if (entry.getKey().getId()==strategyId.intValue()) &#123; statStrategy.get(entry.getKey()).getStatData(); &#125; &#125; &#125; public Map&lt;Statistics, StatStrategy&gt; getStatStrategy() &#123; return statStrategy; &#125; public void setStatStrategy(Map&lt;Statistics, StatStrategy&gt; statStrategy) &#123; this.statStrategy = statStrategy; &#125;&#125; 自定义的枚举类型Statistics ： 123456789101112131415161718192021public enum Statistics &#123; 订单_总数统计(101, "【订单】总数统计"), 用户_新增用户数统计(201, "【用户】新增用户数统计"); private int id; private String name; public int getId() &#123; return id; &#125; public String getName() &#123; return name; &#125; Statistics(int id, String name) &#123; this.id = id; this.name = name; &#125;&#125; 策略模式结合Spring来使用接下来，就是把交由Spring管理的具体算法注入到StatContext 中，用xml文件的形式来实现，Bean的定义写在applicationContext.xml中： 策略放到map中 1234567891011121314151617&lt;bean id="statContext" class="StatContext"&gt; &lt;property name="statStrategy"&gt; &lt;map&gt; &lt;entry key-ref="statOrder" value-ref="orderStrategyImpl "&gt;&lt;/entry&gt; &lt;entry key-ref="statUser" value-ref="userStrategyImpl "&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!--枚举类型要想注入到类中，一定要先使用org.springframework.beans.factory.config.FieldRetrievingFactoryBean类将枚举类型进行转换--&gt;&lt;bean id="statOrder" class="org.springframework.beans.factory.config.FieldRetrievingFactoryBean"&gt; &lt;property name="staticField" value="Statistics.订单_总数统计" /&gt;&lt;/bean&gt;&lt;bean id="statUser" class="org.springframework.beans.factory.config.FieldRetrievingFactoryBean"&gt; &lt;property name="staticField" value="Statistics.用户_新增用户数统计" /&gt;&lt;/bean&gt; 策略模式的相关定义已经写好，接下来使用就很简单了，按照MVC的架构，我们是在Service层来调用相关的策略算法，首先定义Service接口。 123public interface StatService &#123; void loadDetailData(Integer strategyId);&#125; 接口实现。 1234567891011@Servicepublic class StatServiceImpl implements StatService &#123; @Autowired private StatContext statContext; @Override public void loadDetailData(Integer strategyId) &#123; //策略模式结合Spring使用,使代码结构更清晰,避免多重if-else判断 statContext.loadDetailData(strategyId); &#125;&#125; 策略模式结合Spring使用就是这么简单，具体细节再结合项目的使用来修改，完毕。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat架构解析及部署方式]]></title>
    <url>%2F2019%2F01%2F17%2Ftomcat%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[目录结构conf 目录catalina.policy : Tomcat 安全策略文件，控制 JVM 相关权限，具体可以参考java.security.Permission catalina.properties : Tomcat Catalina 行为控制配置文件，比如 Common ClassLoader logging.properties : Tomcat 日志配置文件，JDK Logging server.xml : Tomcat Server 配置文件 GlobalNamingResources : 全局 JNDI 资源 context.xml : 全局 Context 配置文件 tomcat-users.xml : Tomcat 角色配置文件，（Realm 文件实现方式）、 web.xml : Servlet 标准的 web.xml 部署文件，Tomcat 默认实现部分配置入内： org.apache.catalina.servlets.DefaultServlet org.apache.jasper.servlet.JspServlet lib 目录Tomcat 存放公用类库 ecj-*.jar : Eclipse Java 编译器 jasper.jar : JSP 编译器 logs 目录localhost.${date}.log : 当 Tomcat 应用起不来的时候，多看该文件，比如：类冲突 NoClassDefFoundError ClassNotFoundException catalina.${date}.log : 控制台输出，System.out 外置 webapps 目录简化 web 应用部署的方式 部署 Web 应用方法一：放置在 webapps目录demo 代码 ： https://github.com/Frankenjoy123/tomcat-deploy-example mvn clean package cp target xx.war tomcat/webapps/helloworld unzip xx.war bin/startup.sh 访问 http://localhost:8080/helloworld/hello?message=abc 即可成功 方法二： 修改 confi/server.xml 在Host节点下配置Context元素 docBase配置为项目的解压后的目标地址 12345&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="" docBase="/Users/zhouxiaowu/install/tomcat/demo-tomcat-8080/webapps/helloworld" debug="0" reloadable="true" crossContext="true"/&gt;&lt;/Host&gt; 访问 http://localhost:8080/hello?message=abc 即可成功 Engine节点的名称也可以修改，在conf目录下，生产和Catatlina一样的文件目录名gupao 添加Context 元素： 12&lt;Context docBase="$&#123;webAppAbsolutePath&#125;" path="/" reloadable="true" /&gt;&lt;Context docBase="$&#123;webAppAbsolutePath&#125;" path="/tomcat" reloadable="true" /&gt; 熟悉配置元素可以参考org.apache.catalina.core.StandardContext setter 方法 Container Context 该方式不支持动态部署，建议考虑在生产环境使用。 方法三：独立 conf/Catalina/localhost 配置文件 /Users/zhouxiaowu/install/tomcat/demo-tomcat-8080/conf/Catalina/localhost新建ROOT.xml 123&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;Context crossContext="true" docBase="/Users/zhouxiaowu/IdeaProject-tongdun/Example/target/Example-1.0-SNAPSHOT" path="/" reloadable="true"&gt;&lt;/Context&gt; 主目录文件名必须是ROOT.XML(root大写)，而虚拟目录的文件名称和虚拟目录的名称一致并且为小写 conf/Catalina/localhost新建helloworld.xml conf/Catalina/localhost下建立一个xml文件，用于主目录或者虚拟目录，而不需要去修改server.xml就可以达到配置主目录和虚拟目录的目的 123&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;Context crossContext="true" docBase="/Users/zhouxiaowu/IdeaProject-tongdun/Example/target/Example-1.0-SNAPSHOT" path="helloworld" reloadable="true"&gt;&lt;/Context&gt; 注意：该方式可以实现热部署，因此建议在开发环境使用。 方法四： 多实例tomcat部署 配置CATALINA_BASE 环境变量 1export CATALINA_BASE=$APP_DEPLOY_HOME/tomcat conf目录配置，参考 https://github.com/Frankenjoy123/tomcat-deploy-example 线上示例1/home/admin/asdemo/deploy/tomcat/conf/Catalina/localhost/ROOT.xml 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Context path="" docBase="/home/admin/asdemo/deploy/target/asdemo.war" workDir="/home/admin/asdemo/deploy" debug="0" reloadable="true"&gt;&lt;/Context&gt; I/O 连接器参考文件：https://tomcat.apache.org/tomcat-7.0-doc/config/http.html 实现类：org.apache.catalina.connector.Connector 注意实现： 12345678910111213141516171819202122232425262728public void setProtocol(String protocol) &#123; if (AprLifecycleListener.isAprAvailable()) &#123; if ("HTTP/1.1".equals(protocol)) &#123; setProtocolHandlerClassName ("org.apache.coyote.http11.Http11AprProtocol"); &#125; else if ("AJP/1.3".equals(protocol)) &#123; setProtocolHandlerClassName ("org.apache.coyote.ajp.AjpAprProtocol"); &#125; else if (protocol != null) &#123; setProtocolHandlerClassName(protocol); &#125; else &#123; setProtocolHandlerClassName ("org.apache.coyote.http11.Http11AprProtocol"); &#125; &#125; else &#123; if ("HTTP/1.1".equals(protocol)) &#123; setProtocolHandlerClassName ("org.apache.coyote.http11.Http11Protocol"); &#125; else if ("AJP/1.3".equals(protocol)) &#123; setProtocolHandlerClassName ("org.apache.coyote.ajp.AjpProtocol"); &#125; else if (protocol != null) &#123; setProtocolHandlerClassName(protocol); &#125; &#125;&#125; 问答互动问题一：如果配置path的话 是以文件名为主 还是 以配置的为主独立 context XML 配置文件时，设置 path 属性是无效的。 问题二：根独立 context XML 配置文件路径${TOMCAT_HOME}/conf/${Engine.name}/${HOST.name}/ROOT.xml 问题三：如果实现热部署调整 &lt;context&gt; 元素中的属性reloadable=&quot;true&quot; 问题四：连接器里面的线程池 是用的哪个线程池注意conf/server.xml 文件中的一段注释： 1234&lt;Connector executor="tomcatThreadPool" port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; org.apache.catalina.Executor: 123456789101112131415161718public interface Executor extends java.util.concurrent.Executor, Lifecycle &#123; public String getName(); /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the &lt;tt&gt;Executor&lt;/tt&gt; implementation. * If no threads are available, it will be added to the work queue. * If the work queue is full, the system will wait for the specified * time until it throws a RejectedExecutionException * * @param command the runnable task * @throws java.util.concurrent.RejectedExecutionException if this task * cannot be accepted for execution - the queue is full * @throws NullPointerException if command or unit is null */ void execute(Runnable command, long timeout, TimeUnit unit);&#125; 标准实现：org.apache.catalina.core.StandardThreadExecutor 将连接处理交付给 Java 标准线程池： org.apache.tomcat.util.threads.ThreadPoolExecutor。 问题五：JNDI 能不能稍微说下 之前只是在数据源的时候用过，但是不是太理解1234567&lt;Context ...&gt; ... &lt;Resource name="mail/Session" auth="Container" type="javax.mail.Session" mail.smtp.host="localhost"/&gt; ...&lt;/Context&gt; 123456789101112Context initCtx = new InitialContext();Context envCtx = (Context) initCtx.lookup("java:comp/env");Session session = (Session) envCtx.lookup("mail/Session");Message message = new MimeMessage(session);message.setFrom(new InternetAddress(request.getParameter("from")));InternetAddress to[] = new InternetAddress[1];to[0] = new InternetAddress(request.getParameter("to"));message.setRecipients(Message.RecipientType.TO, to);message.setSubject(request.getParameter("subject"));message.setContent(request.getParameter("content"), "text/plain");Transport.send(message);]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Expires、Last-Modified、Etag缓存控制]]></title>
    <url>%2F2019%2F01%2F08%2FExpires%E3%80%81Last-Modified%E3%80%81Etag%E7%BC%93%E5%AD%98%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[当请求一个页面时，如果浏览器使用本地缓存，因此我们经常会看到一个HTTP请求为304状态。或者显示200状态，在chrome下标注是from cache，在火狐下会标注BFCache； 我们希望在服务器端更新了静态文件（如css、js、图片），能够在客户端得到及时的更新，但又不想让浏览器每次请求都从服务器端获取静态资源。那么就需要了解一些下面的知识： Last-Modified / If-Modified-Since当浏览器第一次请求一个url时，服务器端的返回状态码为200，同时HTTP响应头会有一个Last-Modified标记着文件在服务器端最后被修改的时间。 浏览器第二次请求上次请求过的url时，浏览器会在HTTP请求头添加一个If-Modified-Since的标记，用来询问服务器该时间之后文件是否被修改过。 如果服务器端的资源没有变化，则自动返回304状态，使用浏览器缓存，从而保证了浏览器不会重复从服务器端获取资源，也保证了服务器有变化是，客户端能够及时得到最新的资源。 Etag / If-None-Match当浏览器第一次请求一个url时，服务器端的返回状态码为200，同时HTTP响应头会有一个Etag，存放着服务器端生成的一个序列值。 浏览器第二次请求上次请求过的url时，浏览器会在HTTP请求头添加一个If-None-Match的标记，用来询问服务器该文件有没有被修改。 Etag 主要为了解决 Last-Modified 无法解决的一些问题: 1、一些文件也许会周期性的更改，但是他的内容并不改变(仅仅改变的修改时间)，这个时候我们并不希望客户端认为这个文件被修改了，而重新GET; 2、某些文件修改非常频繁，比如在秒以下的时间内进行修改，(比方说1s内修改了N次)，If-Modified-Since能检查到的粒度是s级的，这种修改无法判断(或者说UNIX记录MTIME只能精确到秒) 3、某些服务器不能精确的得到文件的最后修改时间； Expires1&lt;meta http-equiv="expires" content="Fri, 22 Aug 2014 00:52:49 GMT" /&gt; HTTP 1.0，设置缓存的截止时间，在此之前，浏览器对缓存的数据不重新发请求。它与Last-Modified/Etag结合使用，用来控制请求文件的有效时间，当请求数据在有效期内，浏览器从缓存获得数据。Last-Modifed/Etag能够节省一点宽带，但是还会发一个HTTP请求。 Catch-Control12&lt;!--Cache-Control: max-age=秒 --&gt;&lt;meta http-equiv="Cache-Control" content="max-age=120"/&gt; HTTP 1.1，设置资源在本地缓存多长时间。 如果Cache-Control与expires同时存在，Cache-Control生效。expires 的一个缺点就是，返回的到期时间是服务器端的时间，这样存在一个问题，如果客户端的时间与服务器的时间相差很大，那么误差就很大，所以在HTTP 1.1版开始，使用Cache-Control: max-age=秒替代。 用户操作与缓存 禁止缓存12345&lt;!--禁止浏览器本地缓存 --&gt;&lt;meta http-equiv="Cache-Control" content="no-cache"/&gt;&lt;!-- 或者 --&gt;&lt;meta http-equiv="Cache-Control" content="max-age=0"/&gt; 还有POST请求不使用缓存，HTTP响应头不包含Last-Modified/Etag，也不包含Cache-Control/Expires不会使用缓存。 除非有特殊需求，最好还是不要禁用缓存，毕竟是用缓存能节省宽带，节省服务器资源，节省money… 浏览器第一次请求过程 浏览器第二次请求过程 我们希望服务器端更新了文件，客户端可以及时的更新文件，根具上面流程，我们需要针对静态文件的响应头添加expires，设置为永久过期，浏览器每次请求静态文件，就会询问服务器文件有没有做过更改，如果更改了就从服务器端获取资源，否则直接使用缓存。 apache的配置：;) 1234567891011121314#开启mod_expires模块LoadModule expires_module modules/mod_expires.soExpiresActive OnExpiresDefault "access plus 0 seconds" #默认缓存0s&lt;Directory "根目录"&gt; #Options FollowSymLinks #AllowOverride all Order deny,allow Allow from all #ExpiresByType application/* "access plus 0 seconds" #ExpiresByType image/* "access plus 0 seconds" #ExpiresByType text/css "access plus 0 seconds"&lt;/Directory&gt; ;) 这样的做法有个弊端，就是每次请求都会询问服务器端资源是否过期，当然还有更好的办法。 参考链接Expires、Last-Modified、Etag缓存控制 浏览器缓存之Expires Etag Last-Modified max-age详解]]></content>
      <categories>
        <category>前端</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[序列化之serialVersionUID]]></title>
    <url>%2F2018%2F12%2F25%2F%E5%BA%8F%E5%88%97%E5%8C%96%E4%B9%8BserialVersionUID%2F</url>
    <content type="text"><![CDATA[serialVersionUIDserialVersionUID是用来验证版本一致性的。所以在做兼容性升级的时候，不要改变类中serialVersionUID的值。 强调一下：serialVersionUID 既然是验证版本一致性的，在做版本升级的时候（非兼容性升级），记得要修改这个字段的值哦，这样可以避免序列化混乱。 如果一个类实现了Serializable接口，一定要记得定义serialVersionUID，否则会发生异常。可以在IDE中通过设置，让他帮忙提示，并且可以一键快速生成一个 serialVersionUID。 之所以会发生异常，是因为反序列化过程中做了校验，并且如果没有明确定义的话，会根据类名及属性等自动生成一个。 ExternalizableJava中还提供了Externalizable接口，也可以实现它来提供序列化能力。 Externalizable继承自Serializable，该接口中定义了两个抽象方法： writeExternal()与readExternal()。 当使用Externalizable接口来进行序列化与反序列化的时候需要开发人员重写 writeExternal()与readExternal()方法。否则所有变量的值都会变成默认值。 transienttransient 关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以阻止该变量被序列化到文件中，在被反序列化后， transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。 参考为什么阿里巴巴要求程序员谨慎修改serialVersionUID Java对象的序列化与反序列化 你真的以为你了解Java的序列化了吗？]]></content>
      <tags>
        <tag>java</tag>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL性能优化常用方法]]></title>
    <url>%2F2018%2F12%2F17%2FMySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[问题定位1234show process_list;-- 查看执行计划show sql -&gt; explain; 查看锁状态1234-- 表级锁的争用状态变量show status like 'table%';-- 行级锁争用状态变量show status like 'innodb_row_lock%'; 锁表 read锁，即共享锁 1234lock table user use read;-- 解锁unlock tables; write锁，排他锁 1234lock table user use write;-- 解锁unlock tables; Innodb 支持表锁和行锁 * Myisam 只支持表锁 行锁缺点: 行级锁容易造成死锁 表锁缺点： 锁的粒度太大，并发度不高 Profiling12345set profiling=1;select nick_name ,count(*) from user group by nick_name;show profiles;-- 查看执行计划的各个环节耗时show profile cpu,block io for query 75; join_buffer_size存在2张表以上的时候，存在一个join_buffer区 1show variables like 'join_%'; sort_buffer根据sort_buffer size大小，buffer可以选择放select的全部字段，空间换时间，查询更快。另外一种，只存order by的字段和指针。 1show variables like '%sort%'; 参考美团索引优化 https://blog.csdn.net/zhanghongzheng3213/article/details/51722506 MySQL官方explain文档https://dev.mysql.com/doc/refman/5.5/en/explain-output.html gupao-性能优化Mysql篇.pdf]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域资源共享CORS详解]]></title>
    <url>%2F2018%2F11%2F30%2F%E8%B7%A8%E5%9F%9F%E8%B5%84%E6%BA%90%E5%85%B1%E4%BA%ABCORS%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。 它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。 本文详细介绍CORS的内部机制。 一、简介CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。 整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。 因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。 二、两种请求浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。 只要同时满足以下两大条件，就属于简单请求。 （1) 请求方法是以下三种方法之一： HEAD GET POST （2）HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 凡是不同时满足上面两个条件，就属于非简单请求。 浏览器对这两种请求的处理，是不一样的。 三、简单请求3.1 基本流程对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。 下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个Origin字段。 1234567&gt; GET /cors HTTP/1.1&gt; Origin: http://api.bob.com&gt; Host: api.alice.com&gt; Accept-Language: en-US&gt; Connection: keep-alive&gt; User-Agent: Mozilla/5.0...&gt; 上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。 如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。 如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 12345&gt; Access-Control-Allow-Origin: http://api.bob.com&gt; Access-Control-Allow-Credentials: true&gt; Access-Control-Expose-Headers: FooBar&gt; Content-Type: text/html; charset=utf-8&gt; 上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。 （1）Access-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 （2）Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 （3）Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(&#39;FooBar&#39;)可以返回FooBar字段的值。 3.2 withCredentials 属性上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 12&gt; Access-Control-Allow-Credentials: true&gt; 另一方面，开发者必须在AJAX请求中打开withCredentials属性。 123&gt; var xhr = new XMLHttpRequest();&gt; xhr.withCredentials = true;&gt; 否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。 但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials。 12&gt; xhr.withCredentials = false;&gt; 需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 四、非简单请求4.1 预检请求非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 下面是一段浏览器的JavaScript脚本。 123456&gt; var url = 'http://api.alice.com/cors';&gt; var xhr = new XMLHttpRequest();&gt; xhr.open('PUT', url, true);&gt; xhr.setRequestHeader('X-Custom-Header', 'value');&gt; xhr.send();&gt; 上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。 浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。 123456789&gt; OPTIONS /cors HTTP/1.1&gt; Origin: http://api.bob.com&gt; Access-Control-Request-Method: PUT&gt; Access-Control-Request-Headers: X-Custom-Header&gt; Host: api.alice.com&gt; Accept-Language: en-US&gt; Connection: keep-alive&gt; User-Agent: Mozilla/5.0...&gt; “预检”请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。 除了Origin字段，”预检”请求的头信息包括两个特殊字段。 （1）Access-Control-Request-Method 该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。 （2）Access-Control-Request-Headers 该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。 4.2 预检请求的回应服务器收到”预检”请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。 12345678910111213&gt; HTTP/1.1 200 OK&gt; Date: Mon, 01 Dec 2008 01:15:39 GMT&gt; Server: Apache/2.0.61 (Unix)&gt; Access-Control-Allow-Origin: http://api.bob.com&gt; Access-Control-Allow-Methods: GET, POST, PUT&gt; Access-Control-Allow-Headers: X-Custom-Header&gt; Content-Type: text/html; charset=utf-8&gt; Content-Encoding: gzip&gt; Content-Length: 0&gt; Keep-Alive: timeout=2, max=100&gt; Connection: Keep-Alive&gt; Content-Type: text/plain&gt; 上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 12&gt; Access-Control-Allow-Origin: *&gt; 如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 123&gt; XMLHttpRequest cannot load http://api.alice.com.&gt; Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin.&gt; 服务器回应的其他CORS相关字段如下。 12345&gt; Access-Control-Allow-Methods: GET, POST, PUT&gt; Access-Control-Allow-Headers: X-Custom-Header&gt; Access-Control-Allow-Credentials: true&gt; Access-Control-Max-Age: 1728000&gt; （1）Access-Control-Allow-Methods 该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次”预检”请求。 （2）Access-Control-Allow-Headers 如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。 （3）Access-Control-Allow-Credentials 该字段与简单请求时的含义相同。 （4）Access-Control-Max-Age 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 4.3 浏览器的正常请求和回应一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。 下面是”预检”请求之后，浏览器的正常CORS请求。 12345678&gt; PUT /cors HTTP/1.1&gt; Origin: http://api.bob.com&gt; Host: api.alice.com&gt; X-Custom-Header: value&gt; Accept-Language: en-US&gt; Connection: keep-alive&gt; User-Agent: Mozilla/5.0...&gt; 上面头信息的Origin字段是浏览器自动添加的。 下面是服务器正常的回应。 123&gt; Access-Control-Allow-Origin: http://api.bob.com&gt; Content-Type: text/html; charset=utf-8&gt; 上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。 五、与JSONP的比较CORS与JSONP的使用目的相同，但是比JSONP更强大。 JSONP只支持GET请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot AbstractMessageConverterMethodProcessor]]></title>
    <url>%2F2018%2F11%2F16%2FSpring-Boot-AbstractMessageConverterMethodProcessor%2F</url>
    <content type="text"><![CDATA[writeWithMessageConvertersorg.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor#writeWithMessageConverters(T, org.springframework.core.MethodParameter, org.springframework.http.server.ServletServerHttpRequest, org.springframework.http.server.ServletServerHttpResponse) getAcceptableMediaTypes获取的是 请求头Accept中的MediaType getProducibleMediaTypes获取的是controller中@Producer注解的MediaType，如果两者不一致，报415错误 12List&lt;MediaType&gt; requestedMediaTypes = getAcceptableMediaTypes(request);List&lt;MediaType&gt; producibleMediaTypes = getProducibleMediaTypes(request, valueType, declaredType); 123456RequestResponseBodyMethodProcessor extends AbstractMessageConverterMethodProcessorAbstractMessageConverterMethodProcessor extends AbstractMessageConverterMethodArgumentResolver implements HandlerMethodReturnValueHandlerAbstractMessageConverterMethodArgumentResolver implements HandlerMethodArgumentResolver]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL查看和修改字符集的方法]]></title>
    <url>%2F2018%2F11%2F15%2FMySQL%E6%9F%A5%E7%9C%8B%E5%92%8C%E4%BF%AE%E6%94%B9%E5%AD%97%E7%AC%A6%E9%9B%86%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一、查看字符集1.查看MYSQL数据库服务器和数据库字符集12方法一：show variables like '%character%';方法二：show variables like 'collation%'; 123456789mysql&gt; show variables like 'collation%';+----------------------+-----------------+| Variable_name | Value |+----------------------+-----------------+| collation_connection | utf8_general_ci || collation_database | utf8_general_ci || collation_server | utf8_general_ci |+----------------------+-----------------+rows in set (0.00 sec) 123456789mysql&gt; show variables like 'collation%';+----------------------+-----------------+| Variable_name | Value |+----------------------+-----------------+| collation_connection | utf8_general_ci || collation_database | utf8_general_ci || collation_server | utf8_general_ci |+----------------------+-----------------+3 rows in set (0.00 sec) 2.查看MYSQL所支持的字符集1show charset; 123456789101112131415161718192021222324252627282930313233343536373839404142434445mysql&gt; show charset;+----------+-----------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+-----------------------------+---------------------+--------+| big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 || dec8 | DEC West European | dec8_swedish_ci | 1 || cp850 | DOS West European | cp850_general_ci | 1 || hp8 | HP West European | hp8_english_ci | 1 || koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 || latin1 | cp1252 West European | latin1_swedish_ci | 1 || latin2 | ISO 8859-2 Central European | latin2_general_ci | 1 || swe7 | 7bit Swedish | swe7_swedish_ci | 1 || ascii | US ASCII | ascii_general_ci | 1 || ujis | EUC-JP Japanese | ujis_japanese_ci | 3 || sjis | Shift-JIS Japanese | sjis_japanese_ci | 2 || hebrew | ISO 8859-8 Hebrew | hebrew_general_ci | 1 || tis620 | TIS620 Thai | tis620_thai_ci | 1 || euckr | EUC-KR Korean | euckr_korean_ci | 2 || koi8u | KOI8-U Ukrainian | koi8u_general_ci | 1 || gb2312 | GB2312 Simplified Chinese | gb2312_chinese_ci | 2 || greek | ISO 8859-7 Greek | greek_general_ci | 1 || cp1250 | Windows Central European | cp1250_general_ci | 1 || gbk | GBK Simplified Chinese | gbk_chinese_ci | 2 || latin5 | ISO 8859-9 Turkish | latin5_turkish_ci | 1 || armscii8 | ARMSCII-8 Armenian | armscii8_general_ci | 1 || utf8 | UTF-8 Unicode | utf8_general_ci | 3 || ucs2 | UCS-2 Unicode | ucs2_general_ci | 2 || cp866 | DOS Russian | cp866_general_ci | 1 || keybcs2 | DOS Kamenicky Czech-Slovak | keybcs2_general_ci | 1 || macce | Mac Central European | macce_general_ci | 1 || macroman | Mac West European | macroman_general_ci | 1 || cp852 | DOS Central European | cp852_general_ci | 1 || latin7 | ISO 8859-13 Baltic | latin7_general_ci | 1 || utf8mb4 | UTF-8 Unicode | utf8mb4_general_ci | 4 || cp1251 | Windows Cyrillic | cp1251_general_ci | 1 || utf16 | UTF-16 Unicode | utf16_general_ci | 4 || cp1256 | Windows Arabic | cp1256_general_ci | 1 || cp1257 | Windows Baltic | cp1257_general_ci | 1 || utf32 | UTF-32 Unicode | utf32_general_ci | 4 || binary | Binary pseudo charset | binary | 1 || geostd8 | GEOSTD8 Georgian | geostd8_general_ci | 1 || cp932 | SJIS for Windows Japanese | cp932_japanese_ci | 2 || eucjpms | UJIS for Windows Japanese | eucjpms_japanese_ci | 3 |+----------+-----------------------------+---------------------+--------+39 rows in set (0.00 sec) 3.查看库的字符集语法：show database status from 库名 like 表名; 12345mysql&gt; show create database shiyan\G*************************** 1. row *************************** Database: shiyanCreate Database: CREATE DATABASE `shiyan` /*!40100 DEFAULT CHARACTER SET gbk */1 row in set (0.00 sec) 4.查看表的字符集语法：show table status from 库名 like 表名; 1mysql&gt; show table status from class_7 like 'test_info'; 1234567mysql&gt; show table status from class_7 like 'test_info';+-----------+--------+---------+------------+------+----------------+-------------------------+-------------+------------+-----------------+----------+-| Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_leate_time | Update_time | Check_time | Collation | Checksum |+-----------+--------+---------+------------+------+----------------+-------------------------+-------------+------------+-----------------+----------+-| test_info | InnoDB | 10 | Compact | 10 | 1638 | 17-12-05 19:01:55 | NULL | NULL | utf8_general_ci | NULL |+-----------+--------+---------+------------+------+----------------+-------------------------+-------------+------------+-----------------+----------+-1 row in set (0.00 sec) 5.查看表中所有列的字符集语法：show full columns from 表名; 1mysql&gt; show full columns from test_info; 1234567891011mysql&gt; show full columns from test_info;+-------+----------+-----------------+------+-----+---------+-------+---------------------------------+---------+| Field | Type | Collation | Null | Key | Default | Extra | Privileges | Comment |+-------+----------+-----------------+------+-----+---------+-------+---------------------------------+---------+| id | int(3) | NULL | NO | PRI | NULL | | select,insert,update,references | || name | char(12) | utf8_general_ci | YES | | NULL | | select,insert,update,references | || dorm | char(10) | utf8_general_ci | YES | | NULL | | select,insert,update,references | || addr | char(12) | utf8_general_ci | YES | | 未知 | | select,insert,update,references | || score | int(3) | NULL | YES | | NULL | | select,insert,update,references | |+-------+----------+-----------------+------+-----+---------+-------+---------------------------------+---------+5 rows in set (0.00 sec) 二、设置字符集设置字符集一般有两种方法，一种是在创建表的时候设置字符集，另一种是表建成之后修改字符集。 1.创建时指定字符集创建库的时候指定字符集： 语法：create database 库名 default character set=字符集； 1create database db2 default character set=utf8 创建表的时候指定字符集： 语法：create table 表名（属性）default character set = 字符集； 12mysql&gt; create table test1(id int(6),name char(10)) default character set = 'gbk';Query OK, 0 rows affected (0.39 sec) 2.修改字符集修改全局字符集123456789101112131415161718/*建立连接使用的编码*/set character_set_connection=utf8;/*数据库的编码*/set character_set_database=utf8;/*结果集的编码*/set character_set_results=utf8;/*数据库服务器的编码*/set character_set_server=utf8;set character_set_system=utf8;set collation_connection=utf8;set collation_database=utf8;set collation_server=utf8;修改全局字符集 修改库的字符集语法：alter database 库名 default character set 字符集; 1alter database shiyan default character set gbk; 修改表的字符集语法：alter table 表名 convert to character set 字符集; 1alter table test1 convert to character set utf8; 修改字段的字符集语法：alter table 表名 modify 字段名 字段属性 character set gbk； 1alter table test1 modify name char(10) character set gbk; 123456789101112131415161718192021mysql&gt; show full columns from test1;+-------+----------+-----------------+------+-----+---------+-------+---------------------------------+---------+| Field | Type | Collation | Null | Key | Default | Extra | Privileges | Comment |+-------+----------+-----------------+------+-----+---------+-------+---------------------------------+---------+| id | int(6) | NULL | YES | | NULL | | select,insert,update,references | || name | char(10) | utf8_general_ci | YES | | NULL | | select,insert,update,references | |+-------+----------+-----------------+------+-----+---------+-------+---------------------------------+---------+2 rows in set (0.01 sec)mysql&gt; alter table test1 modify name char(10) character set gbk;Query OK, 0 rows affected (0.58 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show full columns from test1;+-------+----------+----------------+------+-----+---------+-------+---------------------------------+---------+| Field | Type | Collation | Null | Key | Default | Extra | Privileges | Comment |+-------+----------+----------------+------+-----+---------+-------+---------------------------------+---------+| id | int(6) | NULL | YES | | NULL | | select,insert,update,references | || name | char(10) | gbk_chinese_ci | YES | | NULL | | select,insert,update,references | |+-------+----------+----------------+------+-----+---------+-------+---------------------------------+---------+2 rows in set (0.01 sec) character set即字符集 我们常看到的UTF-8、GB2312、GB18030都是相互独立的character set。即对Unicode的一套编码。 collation即比对方法 用于指定数据集如何排序，以及字符串的比对规则。 collation名字的规则可以归纳为这两类： _bin 例如： utf8_danish_ci ci是case insensitive的缩写，cs是case sensitive的缩写。即，指定大小写是否敏感。 utf8_bin是将字符串中的每一个字符用二进制数据存储，区分大小写。 奇怪的是utf8字符集对应的collation居然没有一个是cs的。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[浅谈springMVC中的设计模式——组合模式]]></title>
    <url>%2F2018%2F11%2F09%2F%E6%B5%85%E8%B0%88springMVC%E4%B8%AD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[定义惯例我们先来看一看组合模式的定义：组合模式，将对象组合成树形结构以表示“部分-整体”的层次结构，组合模式使得用户对单个对象和组合对象的使用具有一致性。通俗的来说，就是讲一系列的对象组合在一个整体的对象中，用户在对这个组合对象操作使用时就能跟操作一个对象一样。 WebMvcConfigurerComposite1. component -&gt; WebMvcConfigurer抽象接口12345678public interface WebMvcConfigurer &#123;... default void addInterceptors(InterceptorRegistry registry) &#123; &#125;...&#125; 2. leaf 具体实现 -&gt; 自定义实现1234567891011121314151617@Beanpublic WebMvcConfigurer webMvcConfigurer()&#123; WebMvcConfigurer configurer = new WebMvcConfigurer() &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new HandlerInterceptor() &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("handler执行前"); return true; &#125; &#125;); &#125; &#125;; return configurer;&#125; 3. composite容器 -&gt; WebMvcConfigurerComposite@EnableWebMvc ​ @Import(DelegatingWebMvcConfiguration.class) ​ WebMvcConfigurerComposite 本身也实现component WebMvcConfigurer接口，并存在List&lt;WebMvcConfigurer&gt; delegates，对所有的leaf进行统一配置 1234567891011121314151617181920class WebMvcConfigurerComposite implements WebMvcConfigurer &#123; private final List&lt;WebMvcConfigurer&gt; delegates = new ArrayList&lt;&gt;(); public void addWebMvcConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.delegates.addAll(configurers); &#125; &#125; @Override public void configurePathMatch(PathMatchConfigurer configurer) &#123; for (WebMvcConfigurer delegate : this.delegates) &#123; delegate.configurePathMatch(configurer); &#125; &#125; ...&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何保证微服务接口的幂等性]]></title>
    <url>%2F2018%2F10%2F16%2F%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7%2F</url>
    <content type="text"><![CDATA[在微服务架构下，我们在完成一个订单流程时经常遇到下面的场景： 一个订单创建接口，第一次调用超时了，然后调用方重试了一次 在订单创建时，我们需要去扣减库存，这时接口发生了超时，调用方重试了一次 当这笔订单开始支付，在支付请求发出之后，在服务端发生了扣钱操作，接口响应超时了，调用方重试了一次 一个订单状态更新接口，调用方连续发送了两个消息，一个是已创建，一个是已付款。但是你先接收到已付款，然后又接收到了已创建 在支付完成订单之后，需要发送一条短信，当一台机器接收到短信发送的消息之后，处理较慢。消息中间件又把消息投递给另外一台机器处理 以上问题，就是在单体架构转成微服务架构之后，带来的问题。当然不是说单体架构下没有这些问题，在单体架构下同样要避免重复请求。但是出现的问题要比这少得多。 为了解决以上问题，就需要保证接口的幂等性，接口的幂等性实际上就是接口可重复调用，在调用方多次调用的情况下，接口最终得到的结果是一致的。有些接口可以天然的实现幂等性，比如查询接口，对于查询来说，你查询一次和两次，对于系统来说，没有任何影响，查出的结果也是一样。 除了查询功能具有天然的幂等性之外，增加、更新、删除都要保证幂等性。那么如何来保证幂等性呢？ 全局唯一ID如果使用全局唯一ID，就是根据业务的操作和内容生成一个全局ID，在执行操作前先根据这个全局唯一ID是否存在，来判断这个操作是否已经执行。如果不存在则把全局ID，存储到存储系统中，比如数据库、redis等。如果存在则表示该方法已经执行。 从工程的角度来说，使用全局ID做幂等可以作为一个业务的基础的微服务存在，在很多的微服务中都会用到这样的服务，在每个微服务中都完成这样的功能，会存在工作量重复。另外打造一个高可靠的幂等服务还需要考虑很多问题，比如一台机器虽然把全局ID先写入了存储，但是在写入之后挂了，这就需要引入全局ID的超时机制。 使用全局唯一ID是一个通用方案，可以支持插入、更新、删除业务操作。但是这个方案看起来很美但是实现起来比较麻烦，下面的方案适用于特定的场景，但是实现起来比较简单。 去重表这种方法适用于在业务中有唯一标的插入场景中，比如在以上的支付场景中，如果一个订单只会支付一次，所以订单ID可以作为唯一标识。这时，我们就可以建一张去重表，并且把唯一标识作为唯一索引，在我们实现时，把创建支付单据和写入去去重表，放在一个事务中，如果重复创建，数据库会抛出唯一约束异常，操作就会回滚。 插入或更新这种方法插入并且有唯一索引的情况，比如我们要关联商品品类，其中商品的ID和品类的ID可以构成唯一索引，并且在数据表中也增加了唯一索引。这时就可以使用InsertOrUpdate操作。在mysql数据库中如下： 1234insert into goods_category (goods_id,category_id,create_time,update_time) values(#&#123;goodsId&#125;,#&#123;categoryId&#125;,now(),now()) on DUPLICATE KEY UPDATE update_time=now() 多版本控制这种方法适合在更新的场景中，比如我们要更新商品的名字，这时我们就可以在更新的接口中增加一个版本号，来做幂等 1boolean updateGoodsName(int id,String newName,int version); 在实现时可以如下 1update goods set name=#&#123;newName&#125;,version=#&#123;version&#125; where id=#&#123;id&#125; and version&lt;$&#123;version&#125; 状态机控制这种方法适合在有状态机流转的情况下，比如就会订单的创建和付款，订单的付款肯定是在之前，这时我们可以通过在设计状态字段时，使用int类型，并且通过值类型的大小来做幂等，比如订单的创建为0，付款成功为100。付款失败为99 在做状态机更新时，我们就这可以这样控制 1update order set status=#&#123;status&#125; where id=#&#123;id&#125; and status&lt;#&#123;status&#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2PC到3PC到Paxos到Raft到ISR]]></title>
    <url>%2F2018%2F10%2F15%2F2PC%E5%88%B03PC%E5%88%B0Paxos%E5%88%B0Raft%E5%88%B0ISR%2F</url>
    <content type="text"><![CDATA[分布式理论系列 从ACID到CAP到BASE 2PC到3PC到Paxos到Raft到ISR 复制、分片和路由 副本更新策略 负载均衡算法及手段 RWN及Quorum与强一致性 序本文主要讲述2PC及3PC，以及Paxos以及Raft协议。 两类一致性(操作原子性与副本一致性) 2PC协议用于保证属于多个数据分片上的操作的原子性。这些数据分片可能分布在不同的服务器上，2PC协议保证多台服务器上的操作要么全部成功，要么全部失败。 Paxos协议用于保证同一个数据分片的多个副本之间的数据一致性。当这些副本分布到不同的数据中心时，这个需求尤其强烈。 一、2PC（阻塞、数据不一致问题、单点问题）1Two-Phase Commit，两阶段提交 1、阶段一：提交事务请求（投票阶段）（1）事务询问 1协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应 （2）执行事务 1各参与者节点执行事务操作，并将Undo和Redo信息计入事务日志中 （3）各参与者向协调者反馈事务询问的响应 1如果参与者成功执行了事务操作，那么就反馈给协调者Yes响应，表示事务可以执行；如果参与者没有成功执行事务，那么就反馈给协调者No响应，表示事务不可以执行。 2、阶段二：执行事务提交（执行阶段）（1）执行事务提交 1如果所有参与者的反馈都是Yes响应，那么 A、发送提交请求 1协调者向所有参与者节点发出Commit请求 B、事务提交 1参与者接收到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源 C、反馈事务提交结果 1参与者在完成事务提交之后，向协调者发送ACK信息 D、完成事务 1协调者接收到所有参与者反馈的ACK消息后，完成事务 （2）中断事务 1任何一个参与者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。 A、发送回滚请求 1协调者向所有参与者节点发出Rollback请求 B、事务回滚 1参与者接收到rollback请求后，会利用其在阶段一中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放整个事务执行期间占用的资源 C、反馈事务回滚结果 1参与者在完成事务回滚之后，向协调者发送ACK信息 D、中断事务 1协调者接收到所有参与者反馈的ACK信息后，完成事务中断 优缺点优点：原理简单、实现方便缺点：同步阻塞、单点问题、数据不一致、太过保守 （1）同步阻塞同步阻塞会极大地限制分布式系统的性能。在二阶段提交的执行过程中，所有参与该事务操作的逻辑都处于阻塞状态，各个参与者在等待其他参与者响应的过程中，将无法进行其他任何操作。 （2）单点问题一旦协调者出现问题，那么整个二阶段提交流程将无法运转，更为严重的是，如果是在阶段二中出现问题，那么其他参与者将会一直处于锁定事务资源的状态中，无法继续完成事务操作。 （3）数据不一致在阶段二，当协调者向所有参与者发送commit请求之后，发生了局部网络异常或协调者在尚未发完commit请求之前自身发生了崩溃，导致最终只有部分参与者接收到了commit请求，于是这部分参与者执行事务提交，而没收到commit请求的参与者则无法进行事务提交，于是整个分布式系统出现了数据不一致性现象。 （4）太过保守如果参与者在与协调者通信期间出现故障，协调者只能靠超时机制来判断是否需要中断事务，这个策略比较保守，需要更为完善的容错机制，任意一个节点的失败都会导致整个事务的失败。 二、3PC（解决2PC的阻塞，但还是可能造成数据不一致）Three-Phase Commit，三阶段提交，分为CanCommit、PreCommit、do Commit三个阶段。 为了避免在通知所有参与者提交事务时，其中一个参与者crash不一致时，就出现了三阶段提交的方式。三阶段提交在两阶段提交的基础上增加了一个preCommit的过程，当所有参与者收到preCommit后，并不执行动作，直到收到commit或超过一定时间后才完成操作。 1、阶段一CanCommit （1）事务询问协调者向各参与者发送CanCommit的请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应 （2）参与者向协调者反馈询问的响应参与者收到CanCommit请求后，正常情况下，如果自身认为可以顺利执行事务，那么会反馈Yes响应，并进入预备状态，否则反馈No。 2、阶段二PreCommit（1）执行事务预提交1如果协调者接收到各参与者反馈都是Yes，那么执行事务预提交 A、发送预提交请求协调者向各参与者发送preCommit请求，并进入prepared阶段 B、事务预提交参与者接收到preCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日记中 C、各参与者向协调者反馈事务执行的响应如果各参与者都成功执行了事务操作，那么反馈给协调者Ack响应，同时等待最终指令，提交commit或者终止abort （2）中断事务如果任何一个参与者向协调者反馈了No响应，或者在等待超时后，协调者无法接收到所有参与者的反馈，那么就会中断事务。 A、发送中断请求 1协调者向所有参与者发送abort请求 B、中断事务 1无论是收到来自协调者的abort请求，还是等待超时，参与者都中断事务 3、阶段三doCommit（1）执行提交 A、发送提交请求假设协调者正常工作，接收到了所有参与者的ack响应，那么它将从预提交阶段进入提交状态，并向所有参与者发送doCommit请求 B、事务提交参与者收到doCommit请求后，正式提交事务，并在完成事务提交后释放占用的资源 C、反馈事务提交结果参与者完成事务提交后，向协调者发送ACK信息 D、完成事务协调者接收到所有参与者ack信息，完成事务 （2）中断事务假设协调者正常工作，并且有任一参与者反馈No，或者在等待超时后无法接收所有参与者的反馈，都会中断事务 A、发送中断请求协调者向所有参与者节点发送abort请求 B、事务回滚参与者接收到abort请求后，利用undo日志执行事务回滚，并在完成事务回滚后释放占用的资源 C、反馈事务回滚结果参与者在完成事务回滚之后，向协调者发送ack信息 D、中断事务协调者接收到所有参与者反馈的ack信息后，中断事务。 阶段三可能出现的问题：协调者出现问题、协调者与参与者之间网络出现故障。不论出现哪种情况，最终都会导致参与者无法及时接收到来自协调者的doCommit或是abort请求，针对这种情况，参与者都会在等待超时后，继续进行事务提交（timeout后中断事务）。 优点：降低参与者阻塞范围，并能够在出现单点故障后继续达成一致缺点：引入preCommit阶段，在这个阶段如果出现网络分区，协调者无法与参与者正常通信，参与者依然会进行事务提交，造成数据不一致。 三、Paxos（解决单点问题）基于消息传递且具有高度容错性的一致性算法。Paxos算法要解决的问题就是如何在可能发生几起宕机或网络异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。 拜占庭问题：消息不完整或者被篡改。Paxos在维持领导者选举或者变量修改一致性上，采取一种类似议会投票的过半同意机制，比如设定一个领导者，需要将此看做一个议案，征求过半同意，每个节点通过一个议案会有编号记录，再次收到此领导者的不同人选，发现已经有编号记录便驳回，最后以多数通过的结果为准。 我们举个简单的例子，来阐述一下Paxos的基本思想：假设我们有5台计算机A、B、C、D、E，每台计算机保存着公司CEO的信息，现在CEO任期到了，需要进行新一界选举了。 A计算机发起一个选举议案，提议CEO为“张三”，如果没有其他候选人议案，也没有网络问题，只要其中半数以上计算机收到并通过议案，那么最终“张三”当选CEO。由于是分布式环境，并发请求、机器故障、网络故障等问题是常态，如果A和E同时提交选举议案，A提名“张三”，E提名“李四”，那么肯定会涉及多计算机的一致性问题了：假设A、B、C先收到A的议案，D、E先收到E的议案，那么A继续提交给D时，D告诉它已经先收到E的议案了，因此驳回了A的请求。同样E继续提交给A、B、C时也碰到相同的问题。 我们可以通过“在每台计算机同时接受议案提交时设置一个编号，编号先的通过，编号后的驳回”的方式来实现。议案提交上去后，发现A、B、C投票“张三”为CEO，D、E投票“李四”为CEO，少数服从多数，因此最后结果为“张三”当选CEO。 如果是C计算机发生了网络问题或者故障，双方投票相同，那么选举无法完成。 如果C计算机发生了网络问题或者故障，A、B、D投票“张三”，E投票“李四”，那么结果为“张三”当选，而C对于这些情况一无所知，但是当C计算机恢复正常时，他会发起一个“询问谁是CEO”的议案获取最新信息。简言之，Paxos对每个节点的并发修改采取编号记录的方式保持一致性，对多个节点的并发修改采取少数服从多数的方式保持一致性。Paxos有点类似分布式二阶段提交方式，但是又不同，二阶段提交不能是多数节点同意，必须是全部同意。为了遵守过半节点同意的约束，Paxos算法往往要求节点总数为奇数。 Paxos 算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个「一致性算法」以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。从20世纪80年代起对于一致性算法的研究就没有停止过。 简单说来，Paxos的目的是让整个集群的结点对某个值的变更达成一致。Paxos算法基本上来说是个民主选举的算法——大多数的决定会成个整个集群的统一决定。任何一个点都可以提出要修改某个数据的提案，是否通过这个提案取决于这个集群中是否有超过半数的结点同意（所以Paxos算法需要集群中的结点是单数）。 这个算法有两个阶段（假设这个有三个结点：A，B，C）： 第一阶段：Prepare阶段A把申请修改的请求Prepare Request发给所有的结点A，B，C。注意，Paxos算法会有一个Sequence Number（你可以认为是一个提案号，这个数不断递增，而且是唯一的，也就是说A和B不可能有相同的提案号），这个提案号会和修改请求一同发出，任何结点在“Prepare阶段”时都会拒绝其值小于当前提案号的请求。所以，结点A在向所有结点申请修改请求的时候，需要带一个提案号，越新的提案，这个提案号就越是是最大的。 如果接收结点收到的提案号n大于其它结点发过来的提案号，这个结点会回应Yes（本结点上最新的被批准提案号），并保证不接收其它&lt;n的提案。这样一来，结点上在Prepare阶段里总是会对最新的提案做承诺。 优化：在上述 prepare 过程中，如果任何一个结点发现存在一个更高编号的提案，则需要通知 提案人，提醒其中断这次提案。 第二阶段：Accept阶段如果提案者A收到了超过半数的结点返回的Yes，然后他就会向所有的结点发布Accept Request（同样，需要带上提案号n），如果没有超过半数的话，那就返回失败。 当结点们收到了Accept Request后，如果对于接收的结点来说，n是最大的了，那么，它就会通过request（修改这个值），如果发现自己有一个更大的提案号，那么，结点就会拒绝request（拒绝修改）。 我们可以看以，这似乎就是一个“两段提交”的优化。其实，2PC/3PC都是分布式一致性算法的残次版本，Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。 我们还可以看到：对于同一个值的在不同结点的修改提案就算是在接收方被乱序收到也是没有问题的。 四、Raft协议(解决paxos的实现难度)Paxos 相比 Raft 比较复杂和难以理解。角色扮演和流程比 Raft 都要啰嗦。比如 Agreement 这个流程，在 Paxos 里边：Client 发起请求举荐 Proposer 成为 Leader，Proposer 然后向全局 Acceptors 寻求确认，Acceptors 全部同意 Proposer 后，Proposer 的 Leader 地位得已承认，Acceptors 还得再向Learners 进行全局广播来同步。而在 Raft 里边，只有 Follower/Candidate/Leader 三种角色，角色本身代表状态，角色之间进行状态转移是一件非常自由民主的事情。Raft虽然有角色之分但是是全民参与进行选举的模式；但是在Paxos里边，感觉更像议员参政模式。 三个角色follower、candidate、leader。最开始大家都是follower，当follower监听不到leader，就可以自己成为candidate，发起投票 leader选举：timeout限制选举的timeoutfollower成为candidate的超时时间，每个follower都在150ms and 300ms之间随机，之后看谁先timeout，谁就先成为candidate，然后它会先投自己一票，再向其他节点发起投票邀请。如果其他节点在这轮选举还没有投过票，那么就给candidate投票，然后重置自己的选举timeout。如果得到大多数的投票就成为leader，之后定期开始向follower发送心跳。 如果两个follower同时成为candidate的话，如果最后得到的票数相同，则等待其他follower的选择timeout之后成为candidate，继续开始新一轮的选举。 log复制leader把变动的log借助心跳同步给follower，过半回复之后才成功提交，之后再下一次心跳之后，follower也commit变动，在自己的node上生效。 分裂之后，另一个分区的follower接受不到leader的timeout，然后会有一个先timeout，成为candidate，最后成为leader。于是两个分区就有了两个leader。 当客户端有变动时，其中的leader由于无法收到过半的提交，则保持未提交状态。有的leader的修改，可以得到过半的提交，则可以修改生效。 当分裂恢复之后，leader开始对比选举的term，发现有更高的term存在时，他们会撤销未提交的修改，然后以最新的为准。 五、ISR的机制(解决f容错的2f+1成本问题)Kafka并没有使用Zab或Paxos协议的多数投票机制来保证主备数据的一致性，而是提出了ISR的机制（In-Sync Replicas）的机制来保证数据一致性。 ISR认为对于2f+1个副本来说，多数投票机制要求最多只能允许f个副本发生故障，如果要支持2个副本的容错，则需要至少维持5个副本，对于消息系统的场景来说，效率太低。 ISR的运行机制如下：将所有次级副本数据分到两个集合，其中一个被称为ISR集合，这个集合备份数据的特点是即时和主副本数据保持一致，而另外一个集合的备份数据允许其消息队列落后于主副本的数据。在做主备切换时，只允许从ISR集合中选择主副本，只有ISR集合内所有备份都写成功才能认为这次写入操作成功。在具体实现时，kafka利用zookeeper来保持每个ISR集合的信息，当ISR集合内成员变化时，相关构件也便于通知。通过这种方式，如果设定ISR集合大小为f+1，那么可以最多允许f个副本故障，而对于多数投票机制来说，则需要2f+1个副本才能达到相同的容错性。 参考 分布式系统的Raft算法 英文动画演示Raft(推荐) paxos-by-example 为啥CoreOS没用Paxos，重新搞了Raft？]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[微服务架构下分布式事务解决方式-GTS]]></title>
    <url>%2F2018%2F10%2F10%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B8%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F-GTS%2F</url>
    <content type="text"><![CDATA[1 微服务的发展微服务倡导将复杂的单体应用拆分为若干个功能简单、松耦合的服务，这样可以降低开发难度、增强扩展性、便于敏捷开发。当前被越来越多的开发者推崇，很多互联网行业巨头、开源社区等都开始了微服务的讨论和实践。Hailo有160个不同服务构成，NetFlix有大约600个服务。国内方面，阿里巴巴、腾讯、360、京东、58同城等很多互联网公司都进行了微服务化实践。当前微服务的开发框架也非常多，比较著名的有Dubbo、SpringCloud、thrift 、grpc等。 2 微服务落地存在的问题虽然微服务现在如火如荼，但对其实践其实仍处于探索阶段。很多中小型互联网公司，鉴于经验、技术实力等问题，微服务落地比较困难。如著名架构师Chris Richardson所言，目前存在的主要困难有如下几方面： 1）单体应用拆分为分布式系统后，进程间的通讯机制和故障处理措施变的更加复杂。 2）系统微服务化后，一个看似简单的功能，内部可能需要调用多个服务并操作多个数据库实现，服务调用的分布式事务问题变的非常突出。 3）微服务数量众多，其测试、部署、监控等都变的更加困难。 随着RPC框架的成熟，第一个问题已经逐渐得到解决。例如dubbo可以支持多种通讯协议，springcloud可以非常好的支持restful调用。对于第三个问题，随着docker、devops技术的发展以及各公有云paas平台自动化运维工具的推出，微服务的测试、部署与运维会变得越来越容易。 而对于第二个问题，现在还没有通用方案很好的解决微服务产生的事务问题。分布式事务已经成为微服务落地最大的阻碍，也是最具挑战性的一个技术难题。 为此，本文将深入和大家探讨微服务架构下，分布式事务的各种解决方案，并重点为大家解读阿里巴巴提出的分布式事务解决方案—-GTS。该方案中提到的GTS是全新一代解决微服务问题的分布式事务互联网中间件。 3 SOA分布式事务解决方案3.1 基于XA协议的两阶段提交方案交易中间件与数据库通过 XA 接口规范，使用两阶段提交来完成一个全局事务， XA 规范的基础是两阶段提交协议。第一阶段是表决阶段，所有参与者都将本事务能否成功的信息反馈发给协调者；第二阶段是执行阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地在所有分支上提交或者回滚。 两阶段提交方案应用非常广泛，几乎所有商业OLTP数据库都支持XA协议。但是两阶段提交方案锁定资源时间长，对性能影响很大，基本不适合解决微服务事务问题。 3.2 TCC方案TCC方案在电商、金融领域落地较多。TCC方案其实是两阶段提交的一种改进。其将整个业务逻辑的每个分支显式的分成了Try、Confirm、Cancel三个操作。Try部分完成业务的准备工作，confirm部分完成业务的提交，cancel部分完成事务的回滚。基本原理如下图所示。 事务开始时，业务应用会向事务协调器注册启动事务。之后业务应用会调用所有服务的try接口，完成一阶段准备。之后事务协调器会根据try接口返回情况，决定调用confirm接口或者cancel接口。如果接口调用失败，会进行重试。 TCC方案让应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能。 当然TCC方案也有不足之处，集中表现在以下两个方面： 对应用的侵入性强。业务逻辑的每个分支都需要实现try、confirm、cancel三个操作，应用侵入性较强，改造成本高。 实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口必须实现幂等。 上述原因导致TCC方案大多被研发实力较强、有迫切需求的大公司所采用。微服务倡导服务的轻量化、易部署，而TCC方案中很多事务的处理逻辑需要应用自己编码实现，复杂且开发量大。 3.3 基于消息的最终一致性方案消息一致性方案是通过消息中间件保证上、下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么两者都成功或者都失败。下游应用向消息系统订阅该消息，收到消息后执行相应操作。 消息方案从本质上讲是将分布式事务转换为两个本地事务，然后依靠下游业务的重试机制达到最终一致性。基于消息的最终一致性方案对应用侵入性也很高，应用需要进行大量业务改造，成本较高。 4 GTS–分布式事务解决方案GTS是一款分布式事务中间件，由阿里巴巴中间件部门研发，可以为微服务架构中的分布式事务提供一站式解决方案。 更多GTS资料请访问创始人微博。 4.1 GTS的核心优势 性能超强 GTS通过大量创新，解决了事务ACID特性与高性能、高可用、低侵入不可兼得的问题。单事务分支的平均响应时间在2ms左右，3台服务器组成的集群可以支撑3万TPS以上的分布式事务请求。 应用侵入性极低 GTS对业务低侵入，业务代码最少只需要添加一行注解（@TxcTransaction）声明事务即可。业务与事务分离，将微服务从事务中解放出来，微服务关注于业务本身，不再需要考虑反向接口、幂等、回滚策略等复杂问题，极大降低了微服务开发的难度与工作量。 完整解决方案 GTS支持多种主流的服务框架，包括EDAS，Dubbo，Spring Cloud等。有些情况下，应用需要调用第三方系统的接口，而第三方系统没有接入GTS。此时需要用到GTS的MT模式。GTS的MT模式可以等价于TCC模式，用户可以根据自身业务需求自定义每个事务阶段的具体行为。MT模式提供了更多的灵活性，可能性，以达到特殊场景下的自定义优化及特殊功能的实现。 容错能力强 GTS解决了XA事务协调器单点问题，实现真正的高可用，可以保证各种异常情况下的严格数据一致。 4.2 GTS的应用场景GTS可应用在涉及服务调用的多个领域，包括但不限于金融支付、电信、电子商务、快递物流、广告营销、社交、即时通信、手游、视频、物联网、车联网等，详细介绍可以阅读 《GTS–阿里巴巴分布式事务全新解决方案》一文。 4.3 GTS与微服务的集成GTS包括客户端（GTS Client）、资源管理器（GTS RM）和事务协调器（GTS Server）三个部分。GTS Client主要用来界定事务边界，完成事务的发起与结束。GTS RM完成事务分支的创建、提交、回滚等操作。GTS Server主要负责分布式事务的整体推进，事务生命周期的管理。GTS和微服务集成的结构图如下所示，GTS Client需要和业务应用集成部署，RM与微服务集成部署。 4.4 GTS的输出形式GTS目前有三种输出形式：公有云输出、公网输出、专有云输出。 4.4.1 公有云输出这种输出形式面向阿里云用户。如果用户的业务系统已经部署到阿里云上，可以申请开通公有云GTS。开通后业务应用即可通过GTS保证服务调用的一致性。这种使用场景下，业务系统和GTS间的网络环境比较理想，达到很好性能。 4.4.2 公网输出这种输出形式面向于非阿里云的用户，使用更加方便、灵活，业务系统只要能连接互联网即可享受GTS提供的云服务（与公有云输出的差别在于客户端部署于用户本地，而不在云上）。 在正常网络环境下，以包含两个本地事务的全局事务为例，事务完成时间在20ms左右，50个并发就可以轻松实现1000TPS以上分布式事务，对绝大多数业务来说性能是足够的。在公网环境，网络闪断很难完全避免，这种情况下GTS仍能保证服务调用的数据一致性。 具体使用样例使用参见4.7节GTS的工程样例。 4.4.3 专有云输出这种形式主要面向于已建设了自己专有云平台的大用户，GTS可以直接部署到用户的专有云上，为专有云提供分布式事务服务。目前已经有10多个特大型企业的专有云使用GTS解决分布式事务难题，性能与稳定性经过了用户的严格检测。 4.5 GTS的使用方式GTS对应用的侵入性非常低，使用也很简单。下面以订单存储应用为例说明。订单业务应用通过调用订单服务和库存服务完成订单业务，服务开发框架为Dubbo。 4.5.1 订单业务应用在业务函数外围使用@TxcTransaction注解即可开启分布式事务。Dubbo应用通过隐藏参数将GTS的事务xid传播到服务端。 1234567891011121314151617 @TxcTransaction(timeout = 1000 * 10)public void Bussiness(OrderService orderService, StockService stockService, String userId) &#123; //获取事务上下文 String xid = TxcContext.getCurrentXid(); //通过RpcContext将xid传到一个服务端 RpcContext.getContext().setAttachment("xid", xid); //执行自己的业务逻辑 int productId = new Random().nextInt(100); int productNum = new Random().nextInt(100); OrderDO orderDO = new OrderDO(userId, productId, productNum, new Timestamp(new Date().getTime())); orderService.createOrder(orderDO); //通过RpcContext将xid传到另一个服务端 RpcContext.getContext().setAttachment("xid",xid); stockService.updateStock(orderDO);&#125; 4.5.2 服务提供者更新库存方法 1234567891011121314151617public int updateStock(OrderDO orderDO) &#123;//获取全局事务ID，并绑定到上下文String xid = RpcContext.getContext().getAttachment("xid");TxcContext.bind(xid,null);//执行自己的业务逻辑int ret = jdbcTemplate.update("update stock set amount = amount - ? where product_id = ?",new Object[]&#123;orderDO.getNumber(), orderDO.getProductId()&#125;);TxcContext.unbind();return ret;&#125; 4.6 GTS的应用情况GTS目前已经在淘宝、天猫、阿里影业、淘票票、阿里妈妈、1688等阿里各业务系统广泛使用，经受了16年和17年两年双十一海量请求的考验。某线上业务系统最高流量已达十万TPS（每秒钟10万笔事务）。 GTS在公有云和专有云输出后，已经有了100多个线上用户，很多用户通过GTS解决SpringCloud、Dubbo、Edas等服务框架的分布式事务问题。业务领域涉及电力、物流、ETC、烟草、金融、零售、电商、共享出行等十几个行业，得到用户的一致认可。 上图是GTS与SpringCloud集成，应用于某共享出行系统。业务共享出行场景下，通过GTS支撑物联网系统、订单系统、支付系统、运维系统、分析系统等系各统应用的数据一致性，保证海量订单和数千万流水的交易。 4.7 GTS的工程样例GTS的公有云样例可参考阿里云网站。在公网环境下提供sample-txc-simple和sample-txc-dubbo两个样例工程。 4.7.1 sample-txc-simple样例4.7.1.1 样例业务逻辑该样例是GTS的入门sample，案例的业务逻辑是从A账户转账给B账户，其中A和B分别位于两个MySQL数据库中，使用GTS事务保证A和B账户钱的总数始终不变。 4.7.1.2 样例搭建方法1) 准备数据库环境 安装MySQL，创建两个数据库db1和db2。在db1和db2中分别创建txc_undo_log表（SQL脚本见4.7.3）。在db1库中创建user_money_a表，在db2库中创建user_money_b表。 2) 下载样例 将sample-txc-simple文件下载到本地，样例中已经包含了GTS的SDK。 3) 修改配置 打开sample-txc-simple/src/main/resources目录下的txc-client-context.xml，将数据源的url、username、password修改为实际值。 4) 运行样例 在sample-txc-simple目录下执行build.sh编译本工程。编译完成后执行run.sh。 4.7.2 sample-txc-dubbo 样例4.7.2.1 样例业务逻辑本案例模拟了用户下订单、减库存的业务逻辑。客户端（Client）通过调用订单服务（OrderService）创建订单，之后通过调用库存服务（StockService）扣库存。其中订单服务读写订单数据库，库存服务读写库存数据库。由 GTS 保证跨服务事务的一致性。 4.7.2.2 样例搭建方法1) 准备数据库环境 安装MySQL，创建两个数据库db1和db2。在db1和db2中分别创建txc_undo_log表。在db1库中创建orders表，在db2库中创建stock表。 2) 下载样例 将样例文件sample-txc-dubbo下载到本地机器，样例中已经包含了GTS的SDK。 3) 修改配置 打开sample-txc-dubbo/src/main/resources目录，将dubbo-order-service.xml、dubbo-stock-service.xml两个文件中数据源的url、username、password修改为实际值。 4) 运行样例 a. 编译程序 在工程根目录执行 build.sh 命令，编译工程。编译后会在 sample-txc-dubbo/client/bin 目录下生成 order_run.sh、stock_run.sh、client_run.sh 三个运行脚本对应订单服务、库存服务以及客户端。 b. 运行程序 在根目录执行run.sh，该脚本会依次启动order_run.sh(订单服务)、stock_run.sh(库存服务)和client_run.sh(客户端程序)。 4.7.2.3 其他说明样例使用Multicast注册中心的声明方式。如果本机使用无线网络，dubbo服务在绑定地址时有可能获取ipv6地址，可以通过jvm启动参数禁用。方法是配置jvm启动参数 -Djava.net.preferIPv4Stack=true。 4.7.3 SQL4.7.3.1 建表 txc_undo_logCREATE TABLE txc_undo_log ( id bigint(20) NOT NULL AUTO_INCREMENT COMMENT ‘主键’, gmt_create datetime NOT NULL COMMENT ‘创建时间’, gmt_modified datetime NOT NULL COMMENT ‘修改时间’, xid varchar(100) NOT NULL COMMENT ‘全局事务ID’, branch_id bigint(20) NOT NULL COMMENT ‘分支事务ID’, rollback_info longblob NOT NULL COMMENT ‘LOG’, status int(11) NOT NULL COMMENT ‘状态’, server varchar(32) NOT NULL COMMENT ‘分支所在DB IP’, PRIMARY KEY (id), KEY unionkey (xid,branch_id) ) ENGINE=InnoDB AUTO_INCREMENT=211225994 DEFAULT CHARSET=utf8 COMMENT=’事务日志表’; 4.7.3.2 建表 user_money_aCREATE TABLE user_money_a ( id int(11) NOT NULL AUTO_INCREMENT, money int(11) DEFAULT NULL, PRIMARY KEY (id) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; 4.7.3.3 建表 user_money_bCREATE TABLE user_money_b ( id int(11) NOT NULL AUTO_INCREMENT, money int(11) DEFAULT NULL, PRIMARY KEY (id) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; 4.7.3.4 建表 ordersCREATE TABLE orders ( id bigint(20) NOT NULL AUTO_INCREMENT, user_id varchar(255) NOT NULL, product_id int(11) NOT NULL, number int(11) NOT NULL, gmt_create timestamp NOT NULL, PRIMARY KEY (id) ) ENGINE=MyISAM AUTO_INCREMENT=351 DEFAULT CHARSET=utf8 4.7.3.5 建表 stockCREATE TABLE stock ( product_id int(11) NOT NULL, price float NOT NULL, amount int(11) NOT NULL, PRIMARY KEY (product_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 https://www.cnblogs.com/jiangyu666/p/8522547.html]]></content>
      <categories>
        <category>微服务</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring AutowireCapableBeanFactory 整合 quartz]]></title>
    <url>%2F2018%2F09%2F27%2FSpring-AutowireCapableBeanFactory-%E6%95%B4%E5%90%88-quartz%2F</url>
    <content type="text"><![CDATA[背景最近做spring与quartz整合。业务实现时，需要在job里引入spring的bean，但是job的初始化时quartz在执行时new出来的。不受spring的管理，无法注入相关的依赖bean。多方查阅资料后，发现AutowireCapableBeanFactory可以实现类似功能。下面就通过走读代码的方式来学习下这个类的用法。 进入正题首先来看下AutowireCapableBeanFactory的定义： 1234567891011121314151617181920public interface AutowireCapableBeanFactory extends BeanFactory &#123; &lt;T&gt; T createBean(Class&lt;T&gt; beanClass) throws BeansException; void autowireBean(Object existingBean) throws BeansException; Object configureBean(Object existingBean, String beanName) throws BeansException; Object createBean(Class&lt;?&gt; beanClass, int autowireMode, boolean dependencyCheck) throws BeansException; Object autowire(Class&lt;?&gt; beanClass, int autowireMode, boolean dependencyCheck) throws BeansException; void autowireBeanProperties(Object existingBean, int autowireMode, boolean dependencyCheck) throws BeansException; void applyBeanPropertyValues(Object existingBean, String beanName) throws BeansException; Object initializeBean(Object existingBean, String beanName) throws BeansException; Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException; Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException; void destroyBean(Object existingBean); &lt;T&gt; NamedBeanHolder&lt;T&gt; resolveNamedBean(Class&lt;T&gt; requiredType) throws BeansException; Object resolveDependency(DependencyDescriptor descriptor, String requestingBeanName) throws BeansException; Object resolveDependency(DependencyDescriptor descriptor, String requestingBeanName, Set&lt;String&gt; autowiredBeanNames, TypeConverter typeConverter) throws BeansException;&#125; 该类的注释中有这么一句话Integration code for other frameworks can leverage this interface to wire and populate existing bean instances that Spring does not control the lifecycle of，意思是说该类可以填充那些不受spring容器控制的bean。 spring和quartz在集成的时候用了autowireBean方法。下面走读这个方法的代码来看处理逻辑。 autowireBean的实现在类AbstractAutowireCapableBeanFactory中。 代码如下 123456789public void autowireBean(Object existingBean) &#123; // Use non-singleton bean definition, to avoid registering bean as dependent bean. RootBeanDefinition bd = new RootBeanDefinition(ClassUtils.getUserClass(existingBean)); bd.setScope(BeanDefinition.SCOPE_PROTOTYPE); bd.allowCaching = ClassUtils.isCacheSafe(bd.getBeanClass(), getBeanClassLoader()); BeanWrapper bw = new BeanWrapperImpl(existingBean); initBeanWrapper(bw); populateBean(bd.getBeanClass().getName(), bd, bw); &#125; 该方法的逻辑主要在populateBean中。这个方法是spring里很重要的一个方法，用于装配bean。这里逻辑很复杂，主要是通过反射获取我们new出来的对象的属性及注解。若注解是Autowired,Value,Inject时，进行bean的组装。此方法执行完成之后。我们new出来的对象里通过注解注入的bean就可以使用了。 关键代码展示： 1234567891011121314151617181920212223242526272829303132333435363738394041protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) &#123; ...... if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; //依赖的bean注入在这里实现 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); //end if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; applyPropertyValues(beanName, mbd, bw, pvs); &#125;public PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeanCreationException &#123; //获取注入的属性 InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs); try &#123; //注入 metadata.inject(bean, beanName, pvs); &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, "Injection of autowired dependencies failed", ex); &#125; return pvs; &#125; 例子quartz 的job里注入bean： job 工厂： 123456789101112131415public class JobFactory extends AdaptableJobFactory &#123; @Autowired private AutowireCapableBeanFactory capableBeanFactory; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; //调用父类的方法 Object jobInstance = super.createJobInstance(bundle); //进行注入 capableBeanFactory.autowireBean(jobInstance); return jobInstance; &#125;&#125; job的具体处理逻辑 12345678public final class InternalJob implements Job &#123; private static final Logger logger = LoggerFactory.getLogger(InternalJob .class); @Autowired private CuratorFramework client; @Autowired private JobAlarmEventService jobAlarmEventService; job的spring配置： 123456&lt;bean id="jobFactory" class="com.test.scheduler.JobFactory"&gt;&lt;/bean&gt; &lt;bean id="schedulerFactoryBean" class="org.springframework.scheduling.quartz.SchedulerFactoryBean"&gt; &lt;property name="jobFactory" ref="jobFactory"&gt;&lt;/property&gt; &lt;property name="schedulerName" value="scheduler"&gt;&lt;/property&gt; &lt;property name="configLocation" value="classpath:META-INF/spring/quartz.properties"&gt;&lt;/property&gt; &lt;/bean&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vmware 网络设置]]></title>
    <url>%2F2018%2F09%2F25%2Fvmware-%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[NAT设置 删除原有的NAT 新建一个新的NAT链接，生成MAC网卡地址 检查LAN网段 桥接设置 删除原有的桥接 新建一个新的桥接，生成MAC网卡地址 ， 路由admin绑定静态IP 检查LAN网段 ip addr 查看IP和网卡 路由设置 DHCP服务器 -&gt; 静态地址保留 ， 生效所有 IP与MAC绑定 -&gt; 静态ARP绑定设置 ，生效所有 关闭虚拟机，重启路由器]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql多表连接删除]]></title>
    <url>%2F2018%2F09%2F21%2FMysql%E5%A4%9A%E8%A1%A8%E8%BF%9E%E6%8E%A5%E5%88%A0%E9%99%A4%2F</url>
    <content type="text"><![CDATA[联表删除：1、从数据表t1 中把那些id值在数据表t2 里有匹配的记录全删除掉 12345DELETE t1 FROM t1,t2 WHERE t1.id=t2.id或DELETE FROM t1 USING t1,t2 WHERE t1.id=t2.id 2、从数据表t1里在数据表t2里没有匹配的记录查找出来并删除掉 12345DELETE t1 FROM t1 LEFT JOIN T2 ON t1.id=t2.id WHERE t2.id IS NULL或DELETE FROM t1,USING t1 LEFT JOIN T2 ON t1.id=t2.id WHERE t2.id IS NULL 3、从两个表中找出相同记录的数据并把两个表中的数据都删除掉 1DELETE t1,t2 from t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t1.id=25 注意此处的delete t1,t2 from 中的t1,t2不能是别名 如：1delete t1,t2 from table_name as t1 left join table2_name as t2 on t1.id=t2.id where table_name.id=25 要求：MYSQL 版本不小于5.0]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis原理详解]]></title>
    <url>%2F2018%2F09%2F15%2FRedis%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[expire https://redis.io/commands/expire 消极方式，访问Key，已过期删除 积极方式，1秒10次。1. 选取20个随机的key 2.删除过期key 3.超过20%过期，执行1步骤。 How Redis expires keysRedis keys are expired in two ways: a passive way, and an active way. A key is passively expired simply when some client tries to access it, and the key is found to be timed out. Of course this is not enough as there are expired keys that will never be accessed again. These keys should be expired anyway, so periodically Redis tests a few keys at random among keys with an expire set. All the keys that are already expired are deleted from the keyspace. Specifically this is what Redis does 10 times per second: Test 20 random keys from the set of keys with an associated expire. Delete all the keys found expired. If more than 25% of keys were expired, start again from step 1. This is a trivial probabilistic algorithm, basically the assumption is that our sample is representative of the whole key space, and we continue to expire until the percentage of keys that are likely to be expired is under 25% This means that at any given moment the maximum amount of keys already expired that are using memory is at max equal to max amount of write operations per second divided by 4. 数据持久化rdb （默认） 条件满足一个执行，每条规则之间是“或”的关系 In the example below the behaviour will be to save: after 900 sec (15 min) if at least 1 key changed after 300 sec (5 min) if at least 10 keys changed after 60 sec if at least 10000 keys changed 123save 900 1save 300 10save 60 10000 aof 默认的rdb能够满足持久化的需求，但是存在缺陷就是两次快照之间，可能会丢失数据。 By default Redis asynchronously dumps the dataset on disk. This mode isgood enough in many applications, but an issue with the Redis process ora power outage may result into a few minutes of writes lost (depending onthe configured save points). 12appendonly yesappendfilename "appendonly.aof" lua脚本保证原子性 redis-cli –eval example.lua 比较暴力 限流demo 10秒内限流10次demo script load 导入脚本，生成sha evalsha “{sha}” lua执行死环境脚本，会有阻塞问题 redis-cli –eval example.lua 单线程如何保证高性能同步阻塞同步非阻塞异步阻塞(redis实现，多路复用)异步不一定是多线程 异步非阻塞分布式配置12# 无磁盘复制repl-diskless-sync 命令12345678#查看集群信息info replication#告诉master节点 slave的端口replconf listening-port 6379#抓取master的同步信息sync 主从复制全量复制 增量复制 链接到集群 12redis-cli -c -p 7000会有redirect to slot提示 连接到某台机器 12redis-cli -p 7001提示MOVED error cluster slots 查看集群信息 槽信息 13主6从 cluster nodes 查看节点信息 哨兵模式 1连接哨兵节点，然后查询master的节点 客户端jedis sentinel cluster cluster jedis.watch 标志释放锁不会失败 redission single sentinel 12redissionClinet.getBucket("") 获取字符串其他类型相同 cluster 分布式锁 setNX redission lock unlock 源码解读]]></content>
      <categories>
        <category>缓存</category>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[springboot stater自定义开发]]></title>
    <url>%2F2018%2F09%2F14%2Fspringboot-stater%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[一 springboot-starter生成1. pom引入12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.joey.segmentment&lt;/groupId&gt; &lt;artifactId&gt;lessson-20-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;lessson-20-starter&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--用于生成编辑提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2. autoconfigure123456789101112@Configuration@ConditionalOnProperty(prefix = "person",name = "enable", havingValue = "true",matchIfMissing = true)public class PersonAutoConfigure &#123; @Bean @ConfigurationProperties(prefix = "person") public Person person()&#123; return new Person(); &#125;&#125; 1234567public class Person &#123; private Long id; private String name; private Integer age;... getter setter&#125; @Configuration,被该注解注释的类会提供一个或则多个@bean修饰的方法并且会被spring容器处理来生成bean definitions。 @bean注解是必须修饰函数的，该函数可以提供一个bean。而且该函数的函数名必须和bean的名称一致，除了首字母不需要大写。 @ConditionalOnClass注解是条件判断的注解，表示对应的类在classpath目录下存在时，才会去解析对应的配置文件。 ConditionalOnProperty注解是条件判断的注解，表示如果配置文件中的响应配置项数值为true,才会对该bean进行初始化。 更多注解参考 https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-developing-auto-configuration.html 3. META-INF/spring.factories在文件中添加 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ com.joey.segmentment.starter.autoconfigure.PersonAutoConfigure 4. mvn clean install二 project引入starterjar包1. 引入jar包12345&lt;dependency&gt; &lt;groupId&gt;com.joey.segmentment&lt;/groupId&gt; &lt;artifactId&gt;lessson-20-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 2. application.properties填写配置12345person.enable=trueperson.id=1person.name=joeyperson.age=18 3. 代码使用123456789101112@RestControllerpublic class TestController &#123; @Autowired private Person person; @GetMapping(value = "/person") public Person get()&#123; return person; &#125;&#125; 文献参考 https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-developing-auto-configuration.html]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka原理详解]]></title>
    <url>%2F2018%2F09%2F06%2Fkafka%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[kafka提供的基本脚本启动broker server1bin/kafka-server-start.sh config/server.properties 创建topic1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 3 -- topic testReplicaTopic 当broker节点本身只有1个，少于副本数2时，报错 12[2018-09-06 23:13:38,288] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 2 larger than available brokers: 1. (kafka.admin.TopicCommand$) 查看某个topic的信息1bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic xiaowu-topic 生产者发送消息1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic xiaowu-topic 消费者消费消息1bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic xiaowu-topic --from-beginning 查看消息日志文件1bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files /Users/zhouxiaowu/install/kafka/kafka-data/xiaowu-topic-0/00000000000000000000.log --print-data-log 查看索引文件内容1bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files /Users/zhouxiaowu/install/kafka/kafka-data/xiaowu-topic-0/00000000000000000000.index --print-data-log zookeeper状态查看某个topic的某个分区的状态12[zk: localhost:2181(CONNECTED) 16] get /brokers/topics/xiaowu-topic/partitions/0/state&#123;"controller_epoch":4,"leader":0,"version":1,"leader_epoch":0,"isr":[0]&#125;]]></content>
      <categories>
        <category>消息中间件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot Web篇]]></title>
    <url>%2F2018%2F08%2F13%2FSpring-Boot-Web%E7%AF%87%2F</url>
    <content type="text"><![CDATA[标准优化技术 资源变化 响应头：Last-Modified 请求头：If-Modified-Since 资源缓存 响应头：ETag 请求头：If-None-Match Spring Boot Actuator引用包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; /beans 查看bean的情况 ManagementServerProperties类查看配置内容 如： management.security.enabled = false关闭安全检查 localhost:8080/autoconfig 查看匹配方式，negtive匹配不成功 Spring Framwork Transaction @EnableTransactionManagement注解启用事务管理 proxyTargetClass = true选择使用cglib动态代理，这样service类可以不用实现接口。 1@EnableTransactionManagement(proxyTargetClass = true)]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL事务隔离级别测试]]></title>
    <url>%2F2018%2F08%2F10%2FMySQL%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[一、事务的基本要素（ACID） 1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。 2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。 3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。 4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。 二、事务的并发问题1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。 3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表 三、MySQL事务隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否 clientA1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586set session transaction isolation level read COMMITTED ;SELECT @@tx_isolation;CREATE TABLE person_test( id INT UNSIGNED AUTO_INCREMENT COMMENT 'id' PRIMARY KEY , age INT DEFAULT 0 COMMENT '组织编号（部门编号）', name VARCHAR(20) DEFAULT '' COMMENT '组织名称', gmt_create timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', gmt_modify timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间')ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT 'person test';BEGIN ;INSERT INTO person_test(age, name) VALUE (18,'xiaoming');SELECT * FROM person_test;COMMIT ;BEGIN ;INSERT INTO person_test(age,name) VALUE (18,'jim');SELECT * FROM person_test;ROLLBACK ;SELECT * FROM person_test WHERE id=10;-- 隔离级别（read COMMITTED） set session transaction isolation level read COMMITTED ;SELECT @@tx_isolation;BEGIN ;SELECT * FROM person_test;SELECT * FROM person_test;COMMIT ;-- 隔离级别（REPEATABLE READ）set session transaction isolation level REPEATABLE READ ;SELECT @@tx_isolation;BEGIN ;SELECT * FROM person_test;SELECT * FROM person_test;COMMIT ;SELECT * FROM person_test;BEGIN ;SELECT * FROM person_test WHERE age=18;-- 这里测试并没有出现幻读情况SELECT * FROM person_test WHERE age=18;COMMIT ;-- 隔离级别（SERIALIZABLE）set session transaction isolation level SERIALIZABLE ;SELECT @@tx_isolation;BEGIN ;SELECT * FROM person_test;SELECT * FROM person_test;-- 这里插入会dead lock-- INSERT INTO person_test (age, name) VALUE (18,'he');COMMIT ;SELECT * FROM person_test; clientB12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485set session transaction isolation level read COMMITTED ;SELECT @@tx_isolation;CREATE TABLE person_test( id INT UNSIGNED AUTO_INCREMENT COMMENT 'id' PRIMARY KEY , age INT DEFAULT 0 COMMENT '组织编号（部门编号）', name VARCHAR(20) DEFAULT '' COMMENT '组织名称', gmt_create timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', gmt_modify timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间')ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT 'person test';BEGIN ;INSERT INTO person_test(age, name) VALUE (18,'lily');SELECT * FROM person_test;COMMIT ;BEGIN ;INSERT INTO person_test(age,name) VALUE (18,'jim');SELECT * FROM person_test;ROLLBACK ;BEGIN ;UPDATE person_test SET name= 'zhangsan' WHERE id=10;SELECT * FROM person_test;ROLLBACK ;-- 隔离级别（read COMMITTED） set session transaction isolation level read COMMITTED ;SELECT @@tx_isolation;BEGIN ;UPDATE person_test SET name = 'zhangsan' WHERE id=10;SELECT * FROM person_test;DELETE FROM person_test WHERE id=2;SELECT * FROM person_test;COMMIT ;-- 隔离级别（REPEATABLE READ）set session transaction isolation level REPEATABLE READ ;SELECT @@tx_isolation;BEGIN ;SELECT * FROM person_test;UPDATE person_test SET name = 'zhangsanfeng' WHERE id=10;SELECT * FROM person_test;COMMIT ;BEGIN ;SELECT * FROM person_test WHERE age=18;INSERT INTO person_test (age,name) VALUE (18,'qiang');SELECT * FROM person_test WHERE age=18;COMMIT ;-- 隔离级别（SERIALIZABLE）set session transaction isolation level SERIALIZABLE ;SELECT @@tx_isolation;BEGIN ;SELECT * FROM person_test;-- SERIALIZABLE情况，不能增加，等待A客户端commit后 会帮助这边commitINSERT INTO person_test (age,name) VALUE (18,'fen');INSERT INTO person_test (age , name) VALUE (18,'fang');SELECT * FROM person_test;COMMIT ;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring cloud 负载均衡]]></title>
    <url>%2F2018%2F08%2F05%2FSpring-cloud-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[123&gt; JSR 305 meta-annotations&gt; 注解做编译约束&gt; 主要内容RestTemplate 原理与扩展Spring 核心 HTTP 消息转换器 HttpMessageConverter REST 自描述消息：媒体类型（MediaType）， text/html;text/xml;application/json HTTP 协议特点：纯文本协议，自我描述 REST 服务端 REST 客户端 反序列化：文本（通讯） -&gt; 对象（程序使用） 序列化：对象 -&gt; 文本 HttpMessageConverter 分析判断是否可读可写1234567public interface HttpMessageConverter&lt;T&gt; &#123; boolean canRead(Class&lt;?&gt; clazz, @Nullable MediaType mediaType); boolean canWrite(Class&lt;?&gt; clazz, @Nullable MediaType mediaType);&#125; clazz = Person.class 当前支持的媒体类型123public interface HttpMessageConverter&lt;T&gt; &#123; List&lt;MediaType&gt; getSupportedMediaTypes();&#125; MappingJackson2HttpMessageConverter 反序列化1234public interface HttpMessageConverter&lt;T&gt; &#123; T read(Class&lt;? extends T&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException;&#125; 特别提醒：Spring Web MVC 依赖 Servlet，Spring 在早期设计时，它就考虑到了去 Servlet 化。 HttpInputMessage 类似于 HttpServletRequest 12345678public interface HttpInputMessage extends HttpMessage &#123; InputStream getBody() throws IOException; // 来自于 HttpMessage HttpHeaders getHeaders();&#125; 类比 HttpServletRequest 123456789public interface HttpServletRequest &#123; // 来自于 ServletRequest public ServletInputStream getInputStream() throws IOException; public Enumeration&lt;String&gt; getHeaders(String name); public Enumeration&lt;String&gt; getHeaderNames();&#125; RestTemplate利用 HttpMessageConverter 对一定媒体类型序列化和反序列化 JSON XML TEXT 它不依赖于 Servlet API，它自定义实现 对于服务端而言，将 Servlet API 适配成 HttpInputMessage 以及 HttpOutputMessage RestTemplate 对应多个 HttpMessageConverter，那么如何决策正确媒体类型。 RestTemplate 在 HttpMessageConverter 设计123456789101112131415161718192021222324252627282930313233343536373839404142public class RestTemplate extends InterceptingHttpAccessor implements RestOperations &#123; ... // List 形式 private final List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters = new ArrayList&lt;&gt;(); ... public RestTemplate() &#123; this.messageConverters.add(new ByteArrayHttpMessageConverter()); this.messageConverters.add(new StringHttpMessageConverter()); this.messageConverters.add(new ResourceHttpMessageConverter(false)); this.messageConverters.add(new SourceHttpMessageConverter&lt;&gt;()); this.messageConverters.add(new AllEncompassingFormHttpMessageConverter()); if (romePresent) &#123; this.messageConverters.add(new AtomFeedHttpMessageConverter()); this.messageConverters.add(new RssChannelHttpMessageConverter()); &#125; if (jackson2XmlPresent) &#123; this.messageConverters.add(new MappingJackson2XmlHttpMessageConverter()); &#125; else if (jaxb2Present) &#123; this.messageConverters.add(new Jaxb2RootElementHttpMessageConverter()); &#125; if (jackson2Present) &#123; this.messageConverters.add(new MappingJackson2HttpMessageConverter()); &#125; else if (gsonPresent) &#123; this.messageConverters.add(new GsonHttpMessageConverter()); &#125; else if (jsonbPresent) &#123; this.messageConverters.add(new JsonbHttpMessageConverter()); &#125; if (jackson2SmilePresent) &#123; this.messageConverters.add(new MappingJackson2SmileHttpMessageConverter()); &#125; if (jackson2CborPresent) &#123; this.messageConverters.add(new MappingJackson2CborHttpMessageConverter()); &#125; &#125;&#125; 添加内建 HttpMessageConvertor 实现 有条件地添加第三方库HttpMessageConvertor 整合实现 问题场景一： http://localhost:8080/person -&gt; XML 而不是 Jackson Postman 、curl 场景最为明显 没有传递请求头，无从选择媒体类型 假设 Person 既能被 XML 读取，有能被 JSON 读取 Content-Type: text/html; charset=utf-8 RestTemplate 扩展扩展 HTTP 客户端 ClientHttpRequestFactory Spring 实现 SimpleClientHttpRequestFactory HttpClient HttpComponentsClientHttpRequestFactory OkHttp OkHttp3ClientHttpRequestFactory OkHttpClientHttpRequestFactory 微服务要使用轻量级的协议，比如 REST Spring Cloud RestTemplate 核心的调用器 RestTemplate 整合 ZookeeperNetflix Ribbon@LoadBalanced 利用注解来过滤，注入方和声明方同时使用 负载均衡客户端ServiceInstanceChooser LoadBalancerClient 负载均衡上下文LoadBalancerContext 负载均衡规则ILoadBalancer @Qualifier “父”注解，@Qualifier , @LoadBalanced]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring cloud服务发现]]></title>
    <url>%2F2018%2F08%2F05%2FSpring-cloud%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[简单对比 Eureka 比较点 Eureka Zookeeper Consul 运维熟悉度 相对陌生 熟悉 更陌生 一致性（CAP） AP（最终一致性） CP（一致性强） AP（最终一致性） 一致性协议 HTTP 定时轮训 ZAB RAFT 通讯方式 HTTP REST 自定义协议 HTTP REST 更新机制 Peer 2 Peer（服务器之间） + Scheduler（服务器和客户端） ZK Watch Agent 监听的方式 适用规模 20 K ~ 30 K 实例（节点） 10K ~ 20K 实例（节点） &lt; 3K 实例（节点） 性能问题 简单的更新机制、复杂设计、规模较大时 GC 频繁 扩容麻烦、规模较大时 GC 频繁 3K 节点以上，更新列表缓慢 为什么推荐使用 ZK 作为 Spring Cloud 的基础设施一致性模型维护相对熟悉配置中心和服务注册中心单一化传统的问题Spring Cloud 默认配置 Eureka 做注册中心 Git/JDBC 做配置中心 主要内容Spring Cloud Discovery 客户端Spring Cloud Discovery ZK 服务器Spring Cloud 增加 ZK 依赖 错误配置（高 ZK Client 版本 3.5，低服务器版本 3.4） 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 正确配置 123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-all&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.12&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 注册发现 配置管理 启动 ZK（3.4.11）编写引导类12345678@SpringBootApplication@EnableDiscoveryClient // 尽可能使用 @EnableDiscoveryClientpublic class ZkDSClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZkDSClientApplication.class, args); &#125;&#125; 实例一：端口 56517 ZK ID : fff20552-b4a0-43d8-a9ce-c82096f2005e 实例二：端口 56577 ZK ID : 9f4e2c91-4765-4f39-9d4b-2036e8e6c4d4 ZK 节点路径（/services/spring-cloud-service-discovery-client） ZK 服务发现节点规则（/services/{spring.application.name}/{serviceId_UUID}/) 注册增加 service Id 计算 获取应该去重 Eureka 2.0 不开源，Eureka 1.x 还可以用的 代码demohttps://github.com/Frankenjoy123/microservices-joey-project 找到spring-cloud-service-discovery入口启动]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring cloud 配置管理]]></title>
    <url>%2F2018%2F08%2F01%2FSpring-cloud-%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spring cloud配置管理客户端第三方配置commons包commons-configuration Configuration : 提供大多数常见类型的 Value 转换 PropertiesConfiguration: 将 Properties 作为 Configuration 配置 MapConfiguration EnvironmentConfiguration ： OS 环境变量 SystemConfiguration : Java 系统属性 CompositeConfiguration ApplicationContext 与 Environment关系1ConfigurableEnvironment extends Environment ApplicationContext 与Environment 一一对应，但是会merge Parent的Environment。 ConfigurableEnvironment —&gt; MutablePropertySources，一个Environment对应一个PropertySources MutablePropertySources -&gt; List PropertySource : 包含多个 123Environment -&gt; ConfigurableEnvironment: 父子层次ConfigurableEnvironment -&gt; MutablePropertySources: 获取可变多个配置源MutablePropertySources -&gt; List PropertySource : 包含多个 PropertySource PropertySource : 配置源 MapPropertySource PropertiesPropertySource CompositePropertySource : 组合 SystemEnvironmentPropertySource 环境变量 Spring Cloud 客户端配置定位扩展 : PropertySourceLocator org.springframework.core.env包 PropertySource SystemEnvironmentPropertySource 12http://localhost:9095/config/devhttp://localhost:9095/config/default 服务端基于 Git 实现 版本化配置 /应用名/profile/${label} /应用名/profile/ = /应用名/profile/master /应用名/ = /应用名.properties ${label} : 分支 Spring Cloud Config 实现一套完整的配置管理 API 设计 Git 实现缺陷： 复杂的版本更新机制（ Git 仓库） 版本 分支 提交 配置 憋足的内容更新（实时性不高） 客户端第一次启动拉取 需要整合 BUS 做更新通知 设计原理分析@EnableConfigServer123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;ConfigServerConfiguration.class&#125;)public @interface EnableConfigServer &#123;&#125; org.springframework.cloud.config.server.config.ConfigServerAutoConfiguration 1234567JdbcRepositoryConfiguration.class,VaultRepositoryConfiguration.class,SvnRepositoryConfiguration.class,NativeRepositoryConfiguration.class,GitRepositoryConfiguration.class, git的实现DefaultRepositoryConfiguration.class从代码中看，才是最真实的。 12345678@Configuration@ConditionalOnBean(ConfigServerConfiguration.Marker.class)@EnableConfigurationProperties(ConfigServerProperties.class)@Import(&#123; EnvironmentRepositoryConfiguration.class, CompositeConfiguration.class, ResourceRepositoryConfiguration.class, ConfigServerEncryptionConfiguration.class, ConfigServerMvcConfiguration.class &#125;)public class ConfigServerAutoConfiguration &#123;&#125; 当应用配置类标注了 @EnableConfigSever 导入 ConfigServerConfiguration 注册 Marker Bean 作为 ConfigServerAutoConfiguration 条件之一 jdbc实现 核心接口 EnvironmentRepository 1Environment findOne(String application, String profile, String label) 12jdbc.query(this.sql, new Object[] &#123; app, env, label &#125; JdbcTemplate Bean 来源 JdbcTemplateAutoConfiguration SQL 来源 JdbcEnvironmentProperties spring.cloud.config.server.jdbc.sql 不配置，默认：DEFAULT_SQL 1SELECT KEY, VALUE from PROPERTIES where APPLICATION=? and PROFILE=? and LABEL=? KEY VALUE APPLICATION PROFILE LABEL name mercyblitz config default master name xiaomage config test master 本质说明： JDBC 连接技术 DB 存储介质 EnvironmentRepository 核心接口 ConfigServerAutoConfiguration EnvironmentRepositoryConfiguration 默认是 Git 作为配置仓库的原因 找到了为什么默认是 Git 作为配置仓库的原因： 123@Configuration@ConditionalOnMissingBean(value = EnvironmentRepository.class, search = SearchStrategy.CURRENT)class DefaultRepositoryConfiguration git 是默认实现，条件是在EnvironmentRepository的bean没有加载。 所以自己实现自定义的配置，只需要加载一个EnvironmentRepository的bean即可。 HTTP 请求模式/${application}/$${profile}/$${label} @Controller 或者 @RestController @RequestMapping(“/{application}/{profile}/{label}”) /config/test/master config : application test : profile master : label 客户端实现Spring Cloud Config Client通过spring.cloud.config.uri搜索，找到spring-configuration-metadata.json 找到classConfigClientProperties，发现private String[] uri = { &quot;http://localhost:8888&quot; }，发现url默认端口8888。 代码demohttps://github.com/Frankenjoy123/microservices-joey-project 启动spring-cloud-config-server中的main入口，访问如下地址： http://localhost:9095/config/dev Jconsole@RefreshScopeactuator/loggersactuator/envEnvironmentRepository 接口Properties 实现HashTable hashmap]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring应用上下文及事件监听源码分析]]></title>
    <url>%2F2018%2F08%2F01%2FSpring%E5%BA%94%E7%94%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8F%8A%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[##关闭spring-cloud bootstrap应用上下文 应用启动参数添加 1--spring.cloud.bootstrap.enabled=false http://localhost:9091/actuator/beans 123456&#123;"contexts": &#123;"Joey": &#123;&#125;,"first-boot-app": &#123;&#125;&#125;&#125; 12BootstrapApplicationListeneronApplicationEvent 环境变量http://localhost:9091/actuator/env 123456789101112131415161718192021222324252627282930313233&#123;"activeProfiles": [],"propertySources": [&#123;"name": "server.ports","properties": &#123;&#125;&#125;,&#123;"name": "commandLineArgs","properties": &#123;&#125;&#125;,&#123;"name": "servletContextInitParams","properties": &#123;&#125;&#125;,&#123;"name": "systemProperties","properties": &#123;&#125;&#125;,&#123;"name": "systemEnvironment","properties": &#123;&#125;&#125;,&#123;"name": "springCloudClientHostInfo","properties": &#123;&#125;&#125;,&#123;"name": "applicationConfig: [classpath:/application.properties]","properties": &#123;&#125;&#125;]&#125; 透过现象找源码 commandLineArgs -&gt; findInPath -&gt; scope : project and library CommandLinePropertySource.COMMAND_LINE_PROPERTY_SOURCE_NAME find usage spring boot的引用-&gt; org.springframework.boot.SpringApplication#configurePropertySources 这样就可以继续分析源码 sources.addFirst(new SimpleCommandLinePropertySource(args)) 12345678910111213141516171819202122protected void configurePropertySources(ConfigurableEnvironment environment, String[] args) &#123; MutablePropertySources sources = environment.getPropertySources(); if (this.defaultProperties != null &amp;&amp; !this.defaultProperties.isEmpty()) &#123; sources.addLast( new MapPropertySource("defaultProperties", this.defaultProperties)); &#125; if (this.addCommandLineProperties &amp;&amp; args.length &gt; 0) &#123; String name = CommandLinePropertySource.COMMAND_LINE_PROPERTY_SOURCE_NAME; if (sources.contains(name)) &#123; PropertySource&lt;?&gt; source = sources.get(name); CompositePropertySource composite = new CompositePropertySource(name); composite.addPropertySource(new SimpleCommandLinePropertySource( "springApplicationCommandLineArgs", args)); composite.addPropertySource(source); sources.replace(name, composite); &#125; else &#123; sources.addFirst(new SimpleCommandLinePropertySource(args)); &#125; &#125;&#125; 从这段代码，可以看出，defaultProperties优先级最低，放在最后。commandLine优先级很高，放在最前面，addFirst。 代码demohttps://github.com/Frankenjoy123/microservices-joey-project 找到spring-cloud-native-application项目入口启动]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring-framework 5.0.2源码导入idea步骤及demo开发]]></title>
    <url>%2F2018%2F07%2F21%2FSpring-framework-5-0-2%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5idea%E6%AD%A5%E9%AA%A4%E5%8F%8Ademo%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[1.源码的下载Spring的源码可以从GitHub上下载：https://github.com/spring-projects/spring-framework 选择tag5.0.2，下载zip文件 2. 源码编译可以参考import-into-idea.md文档 执行./gradlew :spring-oxm:compileTestJava 先对 Spring-oxm 模块进行预编译。 在IDEA中 File -&gt; New -&gt; Project from Existing Sources -&gt; Navigate to directory选择build.grale文件打开 在spring-aspects中右键模块load/upload modules，uploadspring-aspects的三个子目录 Spring-framework跳过单测，可以执行./gradlew build -x test 3.demo搭建1.demo配置maven quick start快速搭建这里可以创建一个简单的Demo，该Demo依赖于Spring的源码，这样，就可以从外部，运行Demo，跟踪到Spring的内部源码了。为不失一般性，这里的Demo采用MVN进行构建，只不过，相关的Spring的源码依赖需要在IDEA中设置成本地源码 ①使用IDEA 在Spring的源码的Project目录下，创建一个Demo，可以直接使用MVN的骨架 设置依赖A、设置一下pom.xml 中的 junit 依赖版本，修改为 4.12 否则Spring的单元测试，编译不通过 B、在IDEA设置Spring的项目依赖（设置Spring-core、Spring-beans、Spring-context、Spring-expression这几个module就可以了）： C、pom.xml中需要引入commons-logging的依赖,否则编译报找不到LogginFactory的错误.配置静态资源路径(否则读取xml的时候,找不到路径) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.joey.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-start&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo-start&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_jar_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.20.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; D、设置Spring的配置和编写简单的Spring代码 创建一个简单的 登录接口 ILogin： 123public interface ILogin &#123; String loginCheck(String userName,String password);&#125; 它有个实现类： 12345678910111213141516public class LoginServiceImpl implements ILogin &#123; String id = ""; @Autowired(required = false) public void setId(String id) &#123; this.id = id; &#125; @Override public String loginCheck(String userName, String password) &#123; System.out.println("boy登录..."); return "success"; &#125;&#125; 然后，把该bean 注册到配置中(路径spring-debug/src/spring-config.xml)： 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="loginService" class="com.joey.demo.service.impl.LoginServiceImpl"/&gt;&lt;/beans&gt; 最后，编写调用的代码： 1234567891011121314151617public class App&#123; public static void main( String[] args ) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext("classpath:applicationContext.xml");// String XMLPath = "//Users/sky/Java/spring-framework/spring-debug/src/spring-config.xml";// ApplicationContext applicationContext = new FileSystemXmlApplicationContext(XMLPath); ILogin login = (ILogin) applicationContext.getBean("loginService"); login.loginCheck("boy", "123"); &#125;&#125; 然后就可以 进行Debug了，并且可以Debug到Spring源码内部。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[XMind快捷键指南]]></title>
    <url>%2F2018%2F07%2F20%2FXMind%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[快捷鍵（Windows） 快捷鍵（Mac） 描述 Ctrl+N Command+N 建立新工作簿 Ctrl+O Command+O 开启工作簿 Ctrl+S Command+S 储存目前工作簿 Ctrl+Shift+S Command+Shift+S 储存全部工作簿 Ctrl+W Command+W 关闭目前工作簿 Ctrl+Shift+W Command+Shift+W 关闭全部工作簿 Ctrl+P Command+P 列印 Ctrl+Z Command+Z 复原 Ctrl+Y Command+Y 重做 Ctrl+X Command+X 剪切 Ctrl+C Command+C 复制 Ctrl+V Command+V 贴上 Delete Delete 删除 Ctrl+Home Command+Home 返回中心主題 Ctrl+A Command+A 选择全部主題 Ctrl+Shift+A Command+Shift+A 选择同層級主題 Ctrl+Alt+A Command+Alt+A 选择子主題 Ctrl+F Command+F 寻找/取代 Ctrl++ Command++ 放大 Ctrl+- Command+- 缩小 Ctrl+= Command+= 正常大小 Ctrl+] Command+] 插入摘要 Alt+Enter Alt+Enter 属性内容內容 Enter Enter 插入主题 Tab Tab 插入子主题 Shift+Enter Shift+Enter 在目前主题前插入主题 Ctrl+Enter Command+Enter 插入目前主题父主题 Ctrl+Shift+L Command+Shift+L 快捷鍵助手 Ctrl+I Ctrl+I 插入图片 Ctrl+Shift+H Command+Shift+H 插入超链接 Ctrl+B Command+B 添加外框 Ctrl+L Command+L 添加关联 F2 F2 编辑主题 F3 F3 添加/编辑标签 F4 F4 添加/编辑备注 F5 F5 简报演示 F6 F6 下钻 Shift+F6 Shift+F6 上钻 F7 F7 智慧截取图面 + + 展开目前分支 - - 收缩目前分支 * * 展开所有分支 / / 收缩所有分支 Alt+Up Alt+Up 向前移动 Alt+Down Alt+Down 向后移动 Ctrl+T Command+T 建立新心智图 Ctrl+1,2,3,4,5,6 Command+1,2,3,4,5,6 快速添加优先等级图标 Esc Esc 关闭跳出的备注对话框 / 取消截图 Ctrl+滑鼠滚轮 Command+滑鼠滚轮 放大缩小目前的画面]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[理解spring中的BeanFactory与FactoryBean区别]]></title>
    <url>%2F2018%2F07%2F19%2F%E7%90%86%E8%A7%A3spring%E4%B8%AD%E7%9A%84BeanFactory%E4%B8%8EFactoryBean%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[实现 BeanFactory 接口的类表明此类事一个工厂，作用就是配置、新建、管理 各种Bean。DefaultListBeanFacory等都实现这个接口，IOC容器，管理bean。 而 实现 FactoryBean 的类表明此类也是一个Bean，类型为工厂Bean（Spring中共有两种bean，一种为普通bean，另一种则为工厂bean）。顾名思义，它也是用来管理Bean的，而它本身由spring管理。 一个Bean想要实现 FactoryBean ，必须实现以下三个接口： 123451. Object getObject():返回由FactoryBean创建的Bean的实例2. boolean isSingleton():确定由FactoryBean创建的Bean的作用域是singleton还是prototype；3. getObjectType():返回FactoryBean创建的Bean的类型。12345 有一点需要注意，如果将一个实现了FactoryBean的类成功配置到了spring上下文中，那么通过该类对象的名称（比如appleFactoryBean）从spring的applicationContext或者beanFactory获取bean时，获取到的是appleFactoryBean创建的apple实例，而不是appleFactoryBean自己，如果想通过spring拿到appleFactoryBean，需要在名称前加 &amp; 符号 ： 1out.println(applicationContext.getBean("&amp;appleFactoryBean"))1 这个prefix在BeanFactory接口源码中有提到： 1234567/*** Used to dereference a &#123;@link FactoryBean&#125; instance and distinguish it from* beans &lt;i&gt;created&lt;/i&gt; by the FactoryBean. For example, if the bean named* &#123;@code myJndiObject&#125; is a FactoryBean, getting &#123;@code &amp;myJndiObject&#125;* will return the factory, not the instance returned by the factory.*/ String FACTORY_BEAN_PREFIX = "&amp;";1234567 还有一点需要注意，FactoryBean管理的bean实际上也是由spring进行配置、实例化、管理，因此由FactoryBean管理的bean不能再次配置到spring配置文件中（xml、java类配置、注解均不可以），否则会报如下异常： 1234567891011121314Exception in thread "main" org.springframework.beans.factory.BeanIsNotAFactoryException: Bean named 'appleFactoryBean' is expected to be of type 'org.springframework.beans.factory.FactoryBean' but was actually of type 'java.lang.Object' at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1612) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:742) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542) at org.springframework.context.annotation.AnnotationConfigApplicationContext.&lt;init&gt;(AnnotationConfigApplicationContext.java:84) at com.joen.testspringcontainer.Start.main(Start.java:11) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)1234567891011121314 附上一个例子： spring配置类： 1234@Configuration@ComponentScanpublic class Configurations &#123;&#125;1234 AppleBean : 1234//@Component 这里不可以加注解 ！！！！！！public class AppleBean&#123;&#125;1234 AppleFactoryBean : 123456789101112131415@Componentpublic class AppleFactoryBean implements FactoryBean&#123; public Object getObject() throws Exception &#123; return new AppleBean(); &#125; public Class&lt;?&gt; getObjectType() &#123; return AppleBean.class; &#125; public boolean isSingleton() &#123; return false; &#125;&#125;123456789101112131415 启动类 : 1234567public class Start &#123; public static void main(String[] args)&#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(Configurations.class); out.println(applicationContext.getBean("appleFactoryBean"));//得到的是apple out.println(applicationContext.getBean("&amp;appleFactoryBean"));//得到的是apple工厂 &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[cookie中的path与domain属性详解]]></title>
    <url>%2F2018%2F07%2F13%2Fcookie%E4%B8%AD%E7%9A%84path%E4%B8%8Edomain%E5%B1%9E%E6%80%A7%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[#字段解释 Domain – 域domain表示的是cookie所在的域，默认为请求的地址，如网址为www.jb51.net/test/test.aspx，那么domain默认为www.jb51.net。而跨域访问，如域A为t1.test.com，域B为t2.test.com，那么在域A生产一个令域A和域B都能访问的cookie就要将该cookie的domain设置为.test.com；如果要在域A生产一个令域A不能访问而域B能访问的cookie就要将该cookie的domain设置为t2.test.com。 值是域名，比如www.china.com。这是对path路径属性的一个延伸。如果我们想让 www.china.com能够访问bbs.china.com设置的cookies，该怎么办? 我们可以把domain属性设置成“.china.com”，并把path属性设置成“/”。 路径能解决在同一个域下访问 cookie 的问题，咱们接着说 cookie 实现同域之间访问的问题。语法如下： document.cookie = “name=value;path=path;domain=domain“ 红色的domain就是设置的 cookie 域的值。例如 “www.qq.com” 与 “sports.qq.com” 公用一个关联的域名”qq.com”，我们如果想让”sports.qq.com” 下的cookie被 “www.qq.com” 访问，我们就需要用到cookie 的domain属性，并且需要把path属性设置为 “/“。例： document.cookie = “username=Darren;path=/;domain=qq.com“ 注：一定的是同域之间的访问，不能把domain的值设置成非主域的域名。 Path – 路径path表示cookie所在的目录，asp.net默认为/，就是根目录。在同一个服务器上有目录如下：/test/,/test/cd/,/test/dd/，现设一个cookie1的path为/test/，cookie2的path为/test/cd/，那么test下的所有页面都可以访问到cookie1，而/test/和/test/dd/的子页面不能访问cookie2。这是因为cookie能让其path路径下的页面访问。 值可以是一个目录，或者是一个路径。如果http://www.china.com/test/index.html 建立了一个cookie，那么在http://www.china.com/test/目录里的所有页面，以及该目录下面任何子目录里的页面都可以访问这个cookie。这就是说，在http://www.china.com/test/test2/test3 里的任何页面都可以访问http://www.china.com/test/index.html建立的cookie。但是，如果http://www.china.com/test/ 需要访问http://www.china.com/test/index.html设置的cookes，该怎么办？这时，我们要把cookies的path属性设置成“/”。在指定路径的时候，凡是来自同一服务器，URL里有相同路径的所有WEB页面都可以共享cookies。 Expires – 过期时间指cookie的生命期，确切地说是过期日期。如果想让cookie的存在期限超过当前浏览器的会话时间，就必须使用这个属性。当过了到期日期时，浏览器会自动删除cookie文件。 expires/Max-Age 字段为此cookie超时时间。若设置其值为一个时间，那么当到达此时间后，此cookie失效。不设置的话默认值是Session，意思是cookie会和session一起失效。当浏览器关闭(不是浏览器标签页，而是整个浏览器) 后，此cookie失效。 3.浏览器会将domain和path都相同的cookie保存在一个文件里，cookie间用*隔开。 ##Secure – 安全 设置是否只能通过https来传递cookie ##http字段 cookie的httponly属性。若此属性为true，则只有在http请求头中会带有此cookie的信息，而不能通过document.cookie来访问此cookie。 Size字段此cookie大小。 测试今天研究一天发现cookie无法设置除当前域名或者其父域名之外的其他domain. 这个是浏览器出于对cookie的保护造成的，也就是cookie无法跨域设置。 对于子域名也有如下规则，当前域名只能设置当前域名以及他的父域名，不能设置子域名 如在www.wo.cao.baidu.com 域名下只能设置 cao.baidu.com baidu.com 不能设置 da.jia.wo.cao.baidu.com的cookie。 当我们给网站设置cookie时，大家有没有发现在网站的其他域名下也接收到了这些cookie。这些没用的cookie看似不占多少流量，但如果对一个日PV千万的站点来说，那浪费的资源就不是一点点了。因此在设置cookie时，对它的作用域一定要设置准确了。 我们都知道在PHP中用setcookie 来设置网站的cookie，该函数的用法如下： bool setcookie ( string $name [, string $value [, int$expire = 0 [, string$path [, string $domain [, bool$secure = false [, bool$httponly = false ]]]]]] ) 今天我们就来探讨一下它的第五个参数$domain，因为它决定了cookie的作用域。 现在有如下3个域名，一个顶级域名、一个二级域名和一个三级域名： ① zydya.com②blog.zyday.com③one.blog.zyday.com 首先在①zyday.com域名下设置cookie，做四次测试，分别设置domain参数为空、’zyday.com’、’blog.zyday.com’与’one.blog.zyday.com’。√表示该域名下能取到cookie，×表示不能取到cookie domain参数 zydya.com blog.zyday.com one.blog.zyday.com setcookie(‘name’,1,time()+1) √ √ √ setcookie(‘name’,1,time()+1,’/‘,’zyday.com’) √ √ √ setcookie(‘name’,1,time() +1,’/‘,’blog.zyday.com’) × × × setcookie(‘name’,1,time() +1,’/‘,’one.blog.zyday.com’) × × × 当domain设置为空时，domain默认为当前域名，并且该域名下的子域名都可以接收到cookie。但是domain参数设置其子域名时，所有域名就接收不到了，包括那个子域名。 只能设置当前域名或者父域名的cookie， 然后在②blog.zyday.com域名下设置cookie，测试条件同上 domain参数 zydya.com *blog.zyday.com* one.blog.zyday.com setcookie(‘name’,1,time() +1) × √ √ setcookie(‘name’,1,time()+1,’/‘,’zyday.com’) √ √ √ setcookie(‘name’,1,time()+1,’/‘,’blog.zyday.com’) × √ √ setcookie(‘name’,1,time()+1,’/‘,one.blog.zyday.com’) × × × 看第二行，domain参数是zyday.com，是blog.zyday.com的父域名，那么zyday.com下所有子域名(包括zyday.com、blog.zyday.com、one.blog.zyday.com)都能接收到cookie。当domain为自身域名时，那么其父域名受影响，其本身与其子域名可以接收到cookie。而设置其子域名或其他域名时，所有域名都接收不到cookie了。 最后在③one.blog.zyday.com域名下设置cookie domain参数 zydya.com blog.zyday.com *one.blog.zyday.com* setcookie(‘name’,1,time() +1) × × √ setcookie(‘name’,1,time()+1,’/‘,’zyday.com’) √ √ √ setcookie(‘name’,1,time()+1,’/‘,’blog.zyday.com’) × √ √ setcookie(‘name’,1,time()+1,’/‘,one.blog.zyday.com’) × × √ 第三个测试得出的结论在上面已经总结了。再看一遍，这里就不多解释了。 domain的设置，有两点要注意： 1.在setcookie中省略domain参数，那么domain默认为当前域名。 2.domain参数可以设置父域名以及自身，但不能设置其它域名，包括子域名，否则cookie不起作用。 那么cookie的作用域： cookie的作用域是domain本身以及domain下的所有子域名。 设置COOKIE顶级域名顶级域名只能设置domain为顶级域名，不能设置为二级域名或者三级域名等等，否则cookie无法生成。 如yangbai.com能设置domain为yangbai.com或者www.yangbai.com，但不能设置domain为login.yangbai.com，这样cookie不会生成。 以下面的代码为例： 1234setcookie("name1", "yangbai", time() + 1000);//yangbai.com自己可以看到setcookie("name2", "yangbai", time() + 1000, "/", "www.yangbai.com");//*.www.yangbai.com都可以看到setcookie("name3", "yangbai", time() + 1000, "/", "yangbai.com");//*.yangbai.com都可以看到setcookie("name4", "yangbai", time() + 1000, "/", "login.youzan.com");//设置无效 设置domain的时候，.yangbai.com和yangbai.com是一样的。未指定domain时，默认的domain为用哪个域名访问就是哪个。 执行后，www.yangbai.com在浏览器的cookie情况如下图： 二级域名login.yangbai.com和game.yangbai.com浏览器的cookie情况如下图： 总的来说，顶级域名设置的cookie可以共享【需要指定domain主域名的host】给二级域名，也可以自己私有【不指定domain】。 二级域名拿game.yangbai.com为例，代码如下： 123setcookie("game", "yangbai");//只有自己可以看到setcookie("game1", "yangbai", time() + 1000, "/", "yangbai.com");//*.yangbai.com都可以看到setcookie("game2", "yangbai", time() + 1000, "/", "chip.game.yangbai.com");//设置无效 执行后，game.yangbai.com在浏览器的cookie情况如下图： 总的来说，设置cookie的话只能在本域名下或者domain级别高于自身的域名下才会生效！ 读取COOKIE有了上面的例子和实践，大概的规则如下： 二级域名能读取设置了domain为顶级域名或者自身的cookie，不能读取其他二级域名domain的cookie。例如：要想cookie在多个二级域名中共享，需要设置domain为顶级域名，这样就可以在所有二级域名里面或者到这个cookie的值了。 顶级域名只能获取到domain设置为顶级域名的cookie，domain设置为其他子级域名的无法获取。 修改COOKIE顶级域名顶级域名的cookie在顶级域名或者非顶级域名【需要设置domain为顶级域名才可以】都可以修改。代码如下： 12345#为所有二级域名设置一个cookiesetcookie("name", "yangbai", time() + 1000, "/", "yangbai.com");#在game.yangbai.com下面修改这个cookie值setcookie("name", "yangbai11", time() + 1000, "/", "yangbai.com"); 二级域名修改二级域名自身生成的cookie不需要设置domain，直接设置即可。代码如下： 12#修改game.yangbai.com下面自身的cookie值setcookie("game", "chip", time() + 10000); 删除COOKIE删除cookie理解为是修改cookie的一种特殊场景，只需将expire设置为过期、值设置为null即可，代码如下： 12345#删除yangbai.com下面的cookie值setcookie("name", null, time() - 1000, "/", "yangbai.com");#删除game.yangbai.com下面自身的cookie值setcookie("game", null, time() - 1000);]]></content>
      <categories>
        <category>前端</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mysql for mac 安装及环境配置]]></title>
    <url>%2F2018%2F07%2F07%2FMysql-for-mac-%E5%AE%89%E8%A3%85%E5%8F%8A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一.下载及安装首先去官网下载mac对应版本的Mysql,尾缀为.dmg的程序包 下载地址：https://dev.mysql.com/downloads/mysql/ 下载完毕后，一步步傻瓜式安装即可，安装完后mysql会弹出一个框框，告诉你安装成功以及root用户的初始密码，注意Mysql for Mac 的初始密码是随机生成的，最好记住 二.更改初始密码A.打开终端 1.进入mysql的bin目录下（默认安装的目录为 /usr/local/mysql/bin） cd /usr/local/mysql/bin/ 2.输入指令，会提示输入密码（输入mac账户的root密码） sudo ./mysqld_safe –skip-grant-tables 3.输入密码后，会发现有一些提示，且Mysql会自动重启 B.另开一个终端 1、输入指令1：（进入到mysql的bin目录下）输入：cd /usr/local/mysql/bin/2、输入指令2：输入：./mysql3、进入到mysql命令状态下：（mysql&gt;是mysql命令状态提示）输入：mysql&gt; FLUSH PRIVILEGES;4、设置密码root输入：mysql&gt; SET PASSWORD FOR &#39;root&#39;@&#39;localhost&#39; = PASSWORD(&#39;root&#39;); 至此，初始密码设置完毕 三.配置环境变量若不设置环境变量，输入命令太繁琐，每次登陆Mysql的命令为：/usr/local/mysql/bin/ mysql -u root -p windows系统直接在环境变量中添加mysql的路径就好，mac系统则需要在home目录下的.bash_profile文件中新建path路径指向mysql的路径 查看home目录： 输入命令 echo $HOME mac默认的home目录为当前用户根目录 /Users/silverlaw 配置环境变量： 1.打开终端,输入： open .bash_profile 2.直接输入如下语句： export PATH=${PATH}:/usr/local/mysql/bin 保存，关闭终端和TextEdit 重新打开终端，输入：mysql -u root -p，即可成功登陆]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux把文件压缩成.tar.gz的命令]]></title>
    <url>%2F2018%2F07%2F05%2Flinux%E6%8A%8A%E6%96%87%E4%BB%B6%E5%8E%8B%E7%BC%A9%E6%88%90-tar-gz%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585901-.tar格式解包：[＊＊＊＊＊＊＊]$ tar xvf FileName.tar打包：[＊＊＊＊＊＊＊]$ tar cvf FileName.tar DirName（注：tar是打包，不是压缩！）02-.gz格式解压1：[＊＊＊＊＊＊＊]$ gunzip FileName.gz解压2：[＊＊＊＊＊＊＊]$ gzip -d FileName.gz压 缩：[＊＊＊＊＊＊＊]$ gzip FileName03-.tar.gz格式解压：[＊＊＊＊＊＊＊]$ tar zxvf FileName.tar.gz压缩：[＊＊＊＊＊＊＊]$ tar zcvf FileName.tar.gz DirName查看：[＊＊＊＊＊＊＊]$ tar ztvf FileName.tar.gz04-.bz2格式解压1：[＊＊＊＊＊＊＊]$ bzip2 -d FileName.bz2解压2：[＊＊＊＊＊＊＊]$ bunzip2 FileName.bz2压 缩： [＊＊＊＊＊＊＊]$ bzip2 -z FileName05-.tar.bz2格式解压：[＊＊＊＊＊＊＊]$ tar jxvf FileName.tar.bz2压缩：[＊＊＊＊＊＊＊]$ tar jcvf FileName.tar.bz2 DirName06-.bz格式解压1：[＊＊＊＊＊＊＊]$ bzip2 -d FileName.bz解压2：[＊＊＊＊＊＊＊]$ bunzip2 FileName.bz07-.tar.bz格式解压：[＊＊＊＊＊＊＊]$ tar jxvf FileName.tar.bz08-.Z格式解压：[＊＊＊＊＊＊＊]$ uncompress FileName.Z压缩：[＊＊＊＊＊＊＊]$ compress FileName09-.tar.Z格式解压：[＊＊＊＊＊＊＊]$ tar Zxvf FileName.tar.Z压缩：[＊＊＊＊＊＊＊]$ tar Zcvf FileName.tar.Z DirName10-.tgz格式解压：[＊＊＊＊＊＊＊]$ tar zxvf FileName.tgz11-.tar.tgz格式解压：[＊＊＊＊＊＊＊]$ tar zxvf FileName.tar.tgz压缩：[＊＊＊＊＊＊＊]$ tar zcvf FileName.tar.tgz FileName12-.zip格式解压：[＊＊＊＊＊＊＊]$ unzip FileName.zip压缩：[＊＊＊＊＊＊＊]$ zip FileName.zip DirName13-.lha格式解压：[＊＊＊＊＊＊＊]$ lha -e FileName.lha压缩：[＊＊＊＊＊＊＊]$ lha -a FileName.lha FileName14-.rar格式解压：[＊＊＊＊＊＊＊]$ rar a FileName.rar压缩：[＊＊＊＊＊＊＊]$ rar e FileName.rarrar请到：下载！解压后请将rar_static拷贝到/usr/bin目录（其他由$PATH环境变量指定的目录也行）：[＊＊＊＊＊＊＊]$ cp rar_static /usr/bin/rar]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Nginx常用配置及反向代理解决跨域问题]]></title>
    <url>%2F2018%2F06%2F28%2FNginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.定义跨域是指a页面想获取b页面资源，如果a、b页面的协议、域名、端口、子域名不同，所进行的访问行动都是跨域的，而浏览器为了安全问题一般都限制了跨域访问，也就是不允许跨域请求资源。必须是协议、域名、端口全部一致。注意：跨域限制访问，其实是浏览器的限制。理解这一点很重要！！！ 2.跨域访问示例假设有两个网站，A网站部署在：http://localhost:81 即本地ip端口81上；B网站部署在：http://localhost:82 即本地ip端口82上。 现在A网站的页面想去访问B网站的信息，A网站页面的代码如下（这里使用jquery的异步请求）： 12345678&lt;h2&gt;Index&lt;/h2&gt;&lt;div id="show"&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt; $(function () &#123; $.get("http://localhost:82/api/values", &#123;&#125;, function (result) &#123; $("#show").html(result); &#125;) &#125;) 浏览器会提示如下错误信息： Origin ... is therefore not allowed access 3.nginx反向代理解决跨域问题3.1nginx配置找到nginx的配置文件“nginx.conf”，修改一下信息 123456789101112131415161718server &#123; listen 80; #监听80端口，可以改成其他端口 server_name localhost; # 当前服务的域名 #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://localhost:81; proxy_redirect default; &#125; location /apis &#123; #添加访问目录为/apis的代理配置 rewrite ^/apis/(.*)$ /$1 break; proxy_pass http://localhost:82; &#125;#以下配置省略 配置解释： 由配置信息可知，我们让nginx监听localhost的80端口，网站A与网站B的访问都是经过localhost的80端口进行访问。 我们特殊配置了一个“/apis”目录的访问，并且对url执行了重写，最后使以“/apis”开头的地址都转到“http://localhost:82”进行处理。 rewrite ^/apis/(.*)$ /$1 break; 代表重写拦截进来的请求，并且只能对域名后边以“/apis”开头的起作用，例如www.a.com/apis/msg?x=1重写。只对/apis重写。 请求/msg?x=1转发到localhost:82 rewrite后面的参数是一个简单的正则 ^/apis/(.*)$ ,$1代表正则中的第一个(),$2代表第二个()的值,以此类推。 break代表匹配一个之后停止匹配。 3.2 访问地址修改既然配置了nginx，那么所有的访问都要走nginx，而不是走网站原本的地址（A网站localhost:81,B网站localhost:82）。所以要修改A网站中的ajax访问地址，把访问地址由 “http://localhost:82/api/values”改成》》》“/apis/api/values”。如下代码： api/values转发到localhost:82 12345678910&lt;h2&gt;Index&lt;/h2&gt;&lt;div id="show"&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt; $(function () &#123; $.get("/apis/api/values", &#123;&#125;, function (result) &#123; $("#show").html(result); &#125;) &#125;)&lt;/script&gt; 示例案例前端放在tomcat-test/webapps/test目录 hello.html如下： 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;script src="https://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"&gt;&lt;/script&gt;&lt;script&gt;$(document).ready(function()&#123; $("button").click(function()&#123; $.get("/apis/api/hello",function(data,status)&#123; alert("数据: " + data + "\n状态: " + status); &#125;); &#125;);&#125;);&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;button&gt;发送一个 HTTP GET 请求并获取返回结果&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; 启动./tomcat-test/bin/startup.sh ，端口在8080 后端启动在8011端口，访问路径localhost:8011/api/hello 12345678910@RestController@RequestMapping("/api")public class HelloController &#123; @RequestMapping(value = "/hello", method = RequestMethod.GET) public String test() &#123; return "hello,world"; &#125;&#125; nginx.conf配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 6080; server_name localhost; #后端接口转发，解决跨域 location /apis &#123; rewrite ^/apis/(.*)$ /$1 break; proxy_pass http://127.0.0.1:8011; &#125; location /html &#123; rewrite ^/html/(.*)$ /$1 break; proxy_pass http://127.0.0.1:8080; &#125; &#125; include servers/*;&#125; 访问http://localhost:6080/html/test/hello.html Nginx匹配规则 https://moonbingbing.gitbooks.io/openresty-best-practices/ngx/nginx_local_pcre.html 常用location ^~ /uri前缀匹配 location /通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default 语法规则 location [=|~|~*|^~] /uri/ { … } 模式 含义 location = /uri = 表示精确匹配，只有完全匹配上才能生效 location ^~ /uri ^~ 开头对URL路径进行前缀匹配，并且在正则之前。 location ~ pattern 开头表示区分大小写的正则匹配 location ~* pattern 开头表示不区分大小写的正则匹配 location /uri 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后 location / 通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default 前缀匹配时，Nginx 不对 url 做编码，因此请求为 /static/20%/aa，可以被规则 ^~ /static/ /aa 匹配到（注意是空格） 多个 location 配置的情况下匹配顺序为（参考资料而来，还未实际验证，试试就知道了，不必拘泥，仅供参考）: 首先精确匹配 = 其次前缀匹配 ^~ 其次是按文件中顺序的正则匹配 然后匹配不带任何修饰的前缀匹配。 最后是交给 / 通用匹配 当有匹配成功时候，停止匹配，按当前匹配规则处理请求 注意：前缀匹配，如果有包含关系时，按最大匹配原则进行匹配。比如在前缀匹配：location /dir01 与 location /dir01/dir02，如有请求 http://localhost/dir01/dir02/file 将最终匹配到 location /dir01/dir02 例子，有如下匹配规则： 123456789101112131415161718192021222324location = / &#123; echo "规则A";&#125;location = /login &#123; echo "规则B";&#125;location ^~ /static/ &#123; echo "规则C";&#125;location ^~ /static/files &#123; echo "规则X";&#125;location ~ \.(gif|jpg|png|js|css)$ &#123; echo "规则D";&#125;location ~* \.png$ &#123; echo "规则E";&#125;location /img &#123; echo "规则Y";&#125;location / &#123; echo "规则F";&#125; 那么产生的效果如下： 访问根目录 /，比如 http://localhost/ 将匹配 规则A 访问 http://localhost/login 将匹配 规则B，http://localhost/register 则匹配 规则F 访问 http://localhost/static/a.html 将匹配 规则C 访问 http://localhost/static/files/a.exe 将匹配 规则X，虽然 规则C 也能匹配到，但因为最大匹配原则，最终选中了 规则X。你可以测试下，去掉规则 X ，则当前 URL 会匹配上 规则C。 访问 http://localhost/a.gif, http://localhost/b.jpg 将匹配 规则D 和 规则 E ，但是 规则 D 顺序优先，规则 E 不起作用，而 http://localhost/static/c.png 则优先匹配到 规则 C 访问 http://localhost/a.PNG 则匹配 规则 E ，而不会匹配 规则 D ，因为 规则 E 不区分大小写。 访问 http://localhost/img/a.gif 会匹配上 规则D,虽然 规则Y 也可以匹配上，但是因为正则匹配优先，而忽略了 规则Y。 访问 http://localhost/img/a.tiff 会匹配上 规则Y。 访问 http://localhost/category/id/1111 则最终匹配到规则 F ，因为以上规则都不匹配，这个时候应该是 Nginx 转发请求给后端应用服务器，比如 FastCGI（php），tomcat（jsp），Nginx 作为反向代理服务器存在。 所以实际使用中，笔者觉得至少有三个匹配规则定义，如下： 12345678910111213141516171819202122# 直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。# 这里是直接转发给后端应用服务器了，也可以是一个静态首页# 第一个必选规则location = / &#123; proxy_pass http://tomcat:8080/index&#125;# 第二个必选规则是处理静态文件请求，这是 nginx 作为 http 服务器的强项# 有两种配置模式，目录匹配或后缀匹配，任选其一或搭配使用location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125;# 第三个规则就是通用规则，用来转发动态请求到后端应用服务器# 非静态文件请求就默认是动态请求，自己根据实际把握# 毕竟目前的一些框架的流行，带.php、.jsp后缀的情况很少了location / &#123; proxy_pass http://tomcat:8080/&#125; rewrite 语法 last – 基本上都用这个 Flag break – 中止 Rewirte，不再继续匹配 redirect – 返回临时重定向的 HTTP 状态 302 permanent – 返回永久重定向的 HTTP 状态 301 1、下面是可以用来判断的表达式： 1234-f 和 !-f 用来判断是否存在文件-d 和 !-d 用来判断是否存在目录-e 和 !-e 用来判断是否存在文件或目录-x 和 !-x 用来判断文件是否可执行 2、下面是可以用作判断的全局变量 1234567例：http://localhost:88/test1/test2/test.php?k=v$host：localhost$server_port：88$request_uri：/test1/test2/test.php?k=v$document_uri：/test1/test2/test.php$document_root：D:\nginx/html$request_filename：D:\nginx/html/test1/test2/test.php redirect 语法123456789server &#123; listen 80; server_name start.igrow.cn; index index.html index.php; root html; if ($http_host !~ "^star\.igrow\.cn$") &#123; rewrite ^(.*) http://star.igrow.cn$1 redirect; &#125;&#125; 防盗链123456location ~* \.(gif|jpg|swf)$ &#123; valid_referers none blocked start.igrow.cn sta.igrow.cn; if ($invalid_referer) &#123; rewrite ^/ http://$host/logo.png; &#125;&#125; 根据文件类型设置过期时间123456location ~* \.(js|css|jpg|jpeg|gif|png|swf)$ &#123; if (-f $request_filename) &#123; expires 1h; break; &#125;&#125; 禁止访问某个目录1234location ~* \.(txt|doc)$&#123; root /data/www/wwwroot/linuxtone/test; deny all;&#125; Mac访问80端口1 . 先对pf.conf进行备份：1sudo cp /etc/pf.conf /etc/pf.conf.normal.bak 之后在该文件中以下行： 1sudo vim /etc/pf.conf rdr-anchor &quot;com.apple/*&quot; 后面添加一行配置，转发到5555,如下： 1rdr on lo0 inet proto tcp from any to 127.0.0.1 port 80 -&gt; 127.0.0.1 port 5555 2、依次执行以下命令：123sudo pfctl -dsudo pfctl -f /etc/pf.confsudo pfctl -e 注意：如果有apache等服务器占用了80端口，则需要将其停掉方能成功！ 如果出现 123No ALTQ support in kernelALTQ related functions disabledpfctl: pf not enabled 忽略即可。 常用命令##1、查看nginx进程 1ps -ef|grep nginx 说明：nginx的进程由主进程和工作进程组成。 ##2、启动nginx 1234nginxnginx -c ~/Dropbox/commonConfig/nginx/nginx.confnginx -t -c ~/Dropbox/commonConfig/nginx/nginx.conf 启动结果显示nginx的主线程和工作线程，工作线程的数量跟nginx.conf中的配置参数worker_processes有关。 ##3、平滑启动nginx 12345kill -HUP `cat /var/run/nginx.pid`或者nginx -s reloadnginx -s reload -c ~/Dropbox/commonConfig/nginx/nginx.conf 其中进程文件路径在配置文件nginx.conf中可以找到。 平滑启动的意思是在不停止nginx的情况下，重启nginx，重新加载配置文件，启动新的工作线程，完美停止旧的工作线程。 ##4、完美停止nginx 1kill -QUIT `cat /var/run/nginx.pid` ##5、快速停止nginx 123kill -TERM `cat /var/run/nginx.pid`或者kill -INT `cat /var/run/nginx.pid` ##6、完美停止工作进程（主要用于平滑升级） 1kill -WINCH `cat /var/run/nginx.pid` ##7、强制停止nginx 1pkill -9 nginx ##8、检查对nginx.conf文件的修改是否正确 123nginx -t -c /etc/nginx/nginx.conf 或者 nginx -tnginx -t -c ~/Dropbox/commonConfig/nginx/nginx.conf ##9、停止nginx的命令 1nginx -s stop ##10、查看nginx的版本信息 1nginx -v ##11、查看完整的nginx的配置信息 1nginx -V]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Homebrew nginx常用命令]]></title>
    <url>%2F2018%2F06%2F28%2FHomebrew%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[123456789brew updatebrew search nginx //查询要安装的软件是否存在brew info nginxbrew install nginxnginx 安装工具： homebrew（还没用过的小伙伴可以点链接进行了解或者自行百度） 步骤： 1、打开终端，习惯性命令： 12brew update//结果：Already up-to-date. 2、终端继续执行命令： 1brew search nginx //查询要安装的软件是否存在 3、这里我们多执行一步“废”命令，不过有利于我们后面的配置： 1brew info nginx 运行结果： 我们可以看到，nginx在本地还未安装（Not installed），nginx的来源（From），Docroot默认为/usr/local/var/www，在/usr/local/etc/nginx/nginx.conf配置文件中默认端口被配置为8080从而使nginx运行时不需要加sudo，nginx将在/usr/local/etc/nginx/servers/目录中加载所有文件，以及我们可以通过最简单的命令 ‘nginx’ 来启动nginx。 4、正式开始安装： 1brew install nginx 5、查看nginx安装目录（是否如info所说）： 1open /usr/local/etc/nginx/ 成功打开nginx目录，也可以看到如info所说servers目录以及nginx.conf的配置文件（后面会用到这个配置文件）。但我们并没有找到nginx被安装到了哪里。 终端继续执行： 1open /usr/local/Cellar/nginx //其实这个才是nginx被安装到的目录 会看到一个以当前安装的nginx的版本号为名称的文件夹，这个就是我们安装的nginx根目录啦。进入1.12.2_1/bin 目录，会看到nginx的可执行启动文件。 同样的，我们在1.12.2_1/目录下还可以看到一个名字为html的快捷方式文件夹（暂且就这么叫吧），进入该目录我们会发现其实它指向的就是/usr/local/var/www目录，这个在上面我们查看的info信息中有提到（Dcroot） 6、启动nginx，终端输入如下命令： 1nginx 没有报错即为启动成功。 7、访问验证： 打开浏览器访问localhost:8080,这里跟网上的一些教程会有些不一样，正常情况下到这一步就会能看到nginx的欢迎界面啦，然而博主却遇到了坑爹的情况（如果你能正常看到nginx欢迎界面，可以直接跳过这一步了） 想必这个错误大家都很熟悉了，我就不再多做解释，接下来直接说原因（该原因仅为猜测，因为无从验证）：安装的nginx会默认在html（也就是/usr/local/var/www）目录下生成一个欢迎页面文件，而出现上面这种情况就是欢迎页面文件没有生成（至于为什么没有生成就不得而知了，一切都是猜测）。 那在解决这个问题之前，我们先来了解一下nginx的配置文件吧（nginx.conf）: 1cat /usr/local/etc/nginx/nginx.conf 显示配置文件的代码为： ;) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; #侦听8080端口 listen 8080; #定义使用 localhost访问 server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; #定义服务器的默认网站根目录位置 root html; #定义首页索引文件的名称 index index.html index.htm; &#125; ... ... ... (注释代码太多，就不全部贴出来了) include servers/*;&#125; ;) 通过配置文件我们可以看到其默认的网站根目录为html（即/usr/local/var/www），而默认的索引文件为index.html 和 index.htm，这下就找到原因了，原来我们的根目录少了首页索引文件，那就来手动创建一个吧： 123cd /usr/local/var/www/ //进入到www目录下touch index.html //创建一个新的index.html文件vim index.html //编辑该文件 将如下代码写入index.html文件中： ;) 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;h1&gt;我的nginx欢迎页面&lt;/h1&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; ;) 按esc键，输入:wq推出编辑并保存（这个相信大家都会，但还是强迫症的写上了）。 回到浏览器（localhost:8080）刷新： OK，大功告成啦！]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Dubbo源码分析之服务消费过程]]></title>
    <url>%2F2018%2F06%2F28%2FDubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[消费端发送消息流程 消费端的调用过程 invoker调用链如下： 12345678910111213141516171819202122232425262728293031323334353637InvokerInvocationHandler.invoke()MockClusterInvoker.invoke()AbstractClusterInvoker.invoke() 得到invokerList 和 loadbalanceFailoverClusterInvoker.doInvoke() 然后select选出的Invoker为: RegistryDirectory.InvokerDelegate(ProtocolFilterWrapper(ListenerInvoker(DubboInvoker)))备注：private static class InvokerDelegete&lt;T&gt; extends InvokerWrapperProtocolFilterWrapper 调用buildInvokerChain调用构建一个Filter链条 , new Filter()然后执行Filter.invoker(Invoker invoker , Invocation invocation)方法MonitorFilter其他Filter====再执行真正的DubboInvoker extends AbstractInvokerDubboInvoker&lt;T&gt; extends AbstractInvoker&lt;T&gt;AbstractInvoker.invoke()DubboInvoker.doInvoke() DefaultFuture.get() 返回 ResultReferenceCountExchangeClient.request() 返回 DefaultFutureHeaderExchangeClient.request() 返回 DefaultFutureHeaderExchangeChannel.request() 返回 DefaultFutureAbstractPeer.send()AbstractClient.send()NettyChannel.send()NioClientSocket.write() 服务端接收消息处理过程NettyHandler. messageReceived接收消息的时候，通过NettyHandler.messageReceived作为入口。 123456789Overridepublic void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); try &#123; handler.received(channel, e.getMessage()); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 在服务发布的时候，组装了一系列的handler HeaderExchanger.bind 123public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; 接着又在Nettyserver中，wrap了多个handler 12345678public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME)));&#125;protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) &#123; return new MultiMessageHandler(new HeartbeatHandler(ExtensionLoader.getExtensionLoader(Dispatcher.class) .getAdaptiveExtension().dispatch(handler, url)));&#125; 所以服务端的handler处理链为 MultiMessageHandler(HeartbeatHandler(AllChannelHandler(DecodeHandler))) MultiMessageHandler: 复合消息处理 HeartbeatHandler：心跳消息处理，接收心跳并发送心跳响应 AllChannelHandler：业务线程转化处理器，把接收到的消息封装成ChannelEventRunnable可执行任务给线程池处理 DecodeHandler:业务解码处理器 调用链如下： 12345678910111213141516171819202122232425262728293031323334353637MultiMessageHandler.received()HeartbeatHandler.received()AllChannelHandler.received 放到线程池executor.execute(ChannelEventRunnable) run() RECEIVEDDecodeHandler.received()HeaderExchangeHandler.received()DubboProtocol.reply()ProtocolFilterWrapper里面buildInvokerChain（）中last = new Invoker&lt;T&gt;()的invoke()方法开始new Invoker().invoker(Invocation invocation) 里面实现是 filter.invoke(invoker , invocation)====EchoFilter.invoke()ClassLoaderFilter.invoke()GenericFilter.invoke()ContextFilter.invoke()TraceFilter.invoke()TimeoutFilter.invoke()MonitorFilter.invoke()再执行真正的AbstractProxyInvokerAbstractProxyInvoker.invoke()AbstractProxyInvoker的doInvoke方法JavassistProxyFactory中getInvoker（）方法 return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; 服务发布时 RegistryProtol.export（Invoker invoker）方法中 123final Invoker&lt;?&gt; invokerDelegete = new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker));Filter(Listener(InvokerDelegete(AbstractProxyInvoker (Wrapper.invokeMethod))) HeaderExchangeHandler.received交互层请求响应处理，有三种处理方式 handlerRequest，双向请求 2.handler.received 单向请求 3.handleResponse 响应消息 123456789101112131415161718192021222324252627282930313233343536public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; if (message instanceof Request) &#123; // handle request. Request request = (Request) message; if (request.isEvent()) &#123; handlerEvent(channel, request); &#125; else &#123; if (request.isTwoWay()) &#123; Response response = handleRequest(exchangeChannel, request); channel.send(response); &#125; else &#123; handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123; handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception e = new Exception("Dubbo client can not supported string message: " + message + " in channel: " + channel + ", url: " + channel.getUrl()); logger.error(e.getMessage(), e); &#125; else &#123; String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; handleRequest处理请求并返回response 1234567891011121314151617181920212223242526Response handleRequest(ExchangeChannel channel, Request req) throws RemotingException &#123; Response res = new Response(req.getId(), req.getVersion()); if (req.isBroken()) &#123; Object data = req.getData(); String msg; if (data == null) msg = null; else if (data instanceof Throwable) msg = StringUtils.toString((Throwable) data); else msg = data.toString(); res.setErrorMessage("Fail to decode request due to: " + msg); res.setStatus(Response.BAD_REQUEST); return res; &#125; // find handler by message class. Object msg = req.getData(); try &#123; // handle data. Object result = handler.reply(channel, msg); res.setStatus(Response.OK); res.setResult(result); &#125; catch (Throwable e) &#123; res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(e)); &#125; return res;&#125; ExchangeHandlerAdaptive.replay(DubboProtocol)调用DubboProtocol中定义的ExchangeHandlerAdapter. reply方法处理消息 12345private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123; public Object reply(ExchangeChannel channel, Object message) throws RemotingException &#123; invoker.invoke(inv);&#125; 那接下来invoker.invoke会调用哪个类中的方法呢？还记得在RegistryDirectory中发布本地方法的时候，对invoker做的包装吗？通过InvokerDelegete对原本的invoker做了一层包装，而原本的invoker是什么呢？是一个JavassistProxyFactory生成的动态代理吧。所以此处的invoker应该是 Filter(Listener(InvokerDelegete(AbstractProxyInvoker (Wrapper.invokeMethod))) RegistryDirectory生成invoker的代码如下 123456789101112131415private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker)&#123; String key = getCacheKey(originInvoker); ExporterChangeableWrapper&lt;T&gt; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; synchronized (bounds) &#123; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; final Invoker&lt;?&gt; invokerDelegete = new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker)); exporter = new ExporterChangeableWrapper&lt;T&gt;((Exporter&lt;T&gt;)protocol.export(invokerDelegete), originInvoker); bounds.put(key, exporter); &#125; &#125; &#125; return (ExporterChangeableWrapper&lt;T&gt;) exporter;&#125; Directory集群目录服务Directory， 代表多个Invoker, 可以看成List,它的值可能是动态变化的比如注册中心推送变更。集群选择调用服务时通过目录服务找到所有服务 StaticDirectory: 静态目录服务， 它的所有Invoker通过构造函数传入， 服务消费方引用服务的时候， 服务对多注册中心的引用，将Invokers集合直接传入 StaticDirectory构造器，再由Cluster伪装成一个Invoker；StaticDirectory的list方法直接返回所有invoker集合； RegistryDirectory: 注册目录服务， 它的Invoker集合是从注册中心获取的， 它实现了NotifyListener接口实现了回调接口notify(List) Directory目录服务的更新过程RegistryProtocol.doRefer方法，也就是消费端在初始化的时候，这里涉及到了RegistryDirectory这个类。然后执行cluster.join(directory)方法。 cluster.join其实就是将Directory中的多个Invoker伪装成一个Invoker, 对上层透明，包含集群的容错机制 1234567891011121314151617181920212223242526private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url);//对多个invoker进行组装 directory.setRegistry(registry); //ZookeeperRegistry directory.setProtocol(protocol); //protocol=Protocol$Adaptive //url=consumer://192.168.111.... URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); //会把consumer://192... 注册到注册中心 if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; //zkClient.create() registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY)); //Cluster$Adaptive return cluster.join(directory);&#125; directory.subscribe订阅节点的变化， 当zookeeper上指定节点发生变化以后，会通知到RegistryDirectory的notify方法 2.将url转化为invoker对象 调用过程中invokers的使用再调用过程中，AbstractClusterInvoker.invoke方法中， 123456789101112131415161718public Result invoke(final Invocation invocation) throws RpcException &#123; checkWhetherDestroyed(); LoadBalance loadbalance; List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; invokers.size() &gt; 0) &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl().getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance);&#125; list方法从directory中获得invokers 1234protected List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; invokers = directory.list(invocation); return invokers;&#125; 负载均衡LoadBalanceLoadBalance负载均衡， 负责从多个 Invokers中选出具体的一个Invoker用于本次调用，调用过程中包含了负载均衡的算法。 负载均衡代码访问入口在AbstractClusterInvoker.invoke中代码如下，通过名称获得指定的扩展点。RandomLoadBalance AbstractClusterInvoker.doselect调用LoadBalance.select方法，讲invokers按照指定算法进行负载 1234567891011121314151617181920212223242526272829303132333435private Invoker&lt;T&gt; doselect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (invokers == null || invokers.size() == 0) return null; if (invokers.size() == 1) return invokers.get(0); // 如果只有两个invoker，退化成轮循 if (invokers.size() == 2 &amp;&amp; selected != null &amp;&amp; selected.size() &gt; 0) &#123; return selected.get(0) == invokers.get(0) ? invokers.get(1) : invokers.get(0); &#125; Invoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation); //如果 selected中包含（优先判断） 或者 不可用&amp;&amp;availablecheck=true 则重试. if( (selected != null &amp;&amp; selected.contains(invoker)) ||(!invoker.isAvailable() &amp;&amp; getUrl()!=null &amp;&amp; availablecheck))&#123; try&#123; Invoker&lt;T&gt; rinvoker = reselect(loadbalance, invocation, invokers, selected, availablecheck); if(rinvoker != null)&#123; invoker = rinvoker; &#125;else&#123; //看下第一次选的位置，如果不是最后，选+1位置. int index = invokers.indexOf(invoker); try&#123; //最后在避免碰撞 invoker = index &lt;invokers.size()-1?invokers.get(index+1) :invoker; &#125;catch (Exception e) &#123; logger.warn(e.getMessage()+" may because invokers list dynamic change, ignore.",e); &#125; &#125; &#125;catch (Throwable t)&#123; logger.error("clustor relselect fail reason is :"+t.getMessage() +" if can not slove ,you can set cluster.availablecheck=false in url",t); &#125; &#125; return invoker;&#125; 默认情况下，LoadBalance使用的是Random算法，但是这个随机和我们理解上的随机还是不一样的,因为他还有个概念叫weight(权重) RandomLoadBalance假设有四个集群节点A,B,C,D,对应的权重分别是1,2,3,4,那么请求到A节点的概率就为1/(1+2+3+4) = 10%.B,C,D节点依次类推为20%,30%,40%. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; int length = invokers.size(); // 总个数 int totalWeight = 0; // 总权重 boolean sameWeight = true; // 权重是否都一样 for (int i = 0; i &lt; length; i++) &#123; int weight = getWeight(invokers.get(i), invocation); totalWeight += weight; // 累计总权重 if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) &#123; sameWeight = false; // 计算所有权重是否一样 &#125; &#125; if (totalWeight &gt; 0 &amp;&amp; ! sameWeight) &#123; // 如果权重不相同且权重大于0则按总权重数随机 int offset = random.nextInt(totalWeight); // 并确定随机值落在哪个片断上 for (int i = 0; i &lt; length; i++) &#123; offset -= getWeight(invokers.get(i), invocation); if (offset &lt; 0) &#123; return invokers.get(i); &#125; &#125; &#125; // 如果权重相同或权重为0则均等随机 return invokers.get(random.nextInt(length));&#125; new Invoker 包装Filter责任链模式123public interface Filter &#123; Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException;&#125; 12345678public class ClassLoaderFilter implements Filter &#123; public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; doSomething(); return invoker.invoke(invocation); &#125;&#125; 12345678public class OneFilter implements Filter&#123; public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) &#123; doOne(); return invoker.invoke(invocation); &#125;&#125; 123456789for(Filter filter : filterList)&#123; Filter next = last; last = new Invoker()&#123; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; &#125;&#125; 123456789for (int i = filters.size() - 1; i &gt;= 0; i --) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; &#125;;&#125;]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot源码分析之条件注解的底层实现]]></title>
    <url>%2F2018%2F06%2F25%2FSpringBoot%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%9D%A1%E4%BB%B6%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[SpringBoot内部提供了特有的注解：条件注解(Conditional Annotation)。比如@ConditionalOnBean、@ConditionalOnClass、@ConditionalOnExpression、@ConditionalOnMissingBean等。 条件注解存在的意义在于动态识别(也可以说是代码自动化执行)。比如@ConditionalOnClass会检查类加载器中是否存在对应的类，如果有的话被注解修饰的类就有资格被Spring容器所注册，否则会被skip。 比如FreemarkerAutoConfiguration这个自动化配置类的定义如下： 123456@Configuration@ConditionalOnClass(&#123; freemarker.template.Configuration.class, FreeMarkerConfigurationFactory.class &#125;)@AutoConfigureAfter(WebMvcAutoConfiguration.class)@EnableConfigurationProperties(FreeMarkerProperties.class)public class FreeMarkerAutoConfiguration 这个自动化配置类被@ConditionalOnClass条件注解修饰，这个条件注解存在的意义在于判断类加载器中是否存在freemarker.template.Configuration和FreeMarkerConfigurationFactory这两个类，如果都存在的话会在Spring容器中加载这个FreeMarkerAutoConfiguration配置类；否则不会加载。 条件注解内部的一些基础在分析条件注解的底层实现之前，我们先来看一下这些条件注解的定义。以@ConditionalOnClass注解为例，它的定义如下： 12345678@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(OnClassCondition.class)public @interface ConditionalOnClass &#123; Class&lt;?&gt;[] value() default &#123;&#125;; // 需要匹配的类 String[] name() default &#123;&#125;; // 需要匹配的类名&#125; 它有2个属性，分别是类数组和字符串数组(作用一样，类型不一样)，而且被@Conditional注解所修饰，这个@Conditional注解有个名为values的Class&lt;? extends Condition&gt;[]类型的属性。 这个Condition是个接口，用于匹配组件是否有资格被容器注册，定义如下： 1234public interface Condition &#123; // ConditionContext内部会存储Spring容器、应用程序环境信息、资源加载器、类加载器 boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);&#125; 也就是说@Conditional注解属性中可以持有多个Condition接口的实现类，所有的Condition接口需要全部匹配成功后这个@Conditional修饰的组件才有资格被注册。 Condition接口有个子接口ConfigurationCondition： 123456789101112public interface ConfigurationCondition extends Condition &#123; ConfigurationPhase getConfigurationPhase(); public static enum ConfigurationPhase &#123; PARSE_CONFIGURATION, REGISTER_BEAN &#125;&#125; 这个子接口是一种特殊的条件接口，多了一个getConfigurationPhase方法，也就是条件注解的生效阶段。只有在ConfigurationPhase中定义的两种阶段下才会生效。 Condition接口有个实现抽象类SpringBootCondition，SpringBoot中所有条件注解对应的条件类都继承这个抽象类。它实现了matches方法： 12345678910111213141516171819202122232425@Overridepublic final boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; String classOrMethodName = getClassOrMethodName(metadata); // 得到类名或者方法名(条件注解可以作用的类或者方法上) try &#123; ConditionOutcome outcome = getMatchOutcome(context, metadata); // 抽象方法，具体子类实现。ConditionOutcome记录了匹配结果boolean和log信息 logOutcome(classOrMethodName, outcome); // log记录一下匹配信息 recordEvaluation(context, classOrMethodName, outcome); // 报告记录一下匹配信息 return outcome.isMatch(); // 返回是否匹配 &#125; catch (NoClassDefFoundError ex) &#123; throw new IllegalStateException( "Could not evaluate condition on " + classOrMethodName + " due to " + ex.getMessage() + " not " + "found. Make sure your own configuration does not rely on " + "that class. This can also happen if you are " + "@ComponentScanning a springframework package (e.g. if you " + "put a @ComponentScan in the default package by mistake)", ex); &#125; catch (RuntimeException ex) &#123; throw new IllegalStateException( "Error processing condition on " + getName(metadata), ex); &#125;&#125; 基于Class的条件注解SpringBoot提供了两个基于Class的条件注解：@ConditionalOnClass(类加载器中存在指明的类)或者@ConditionalOnMissingClass(类加载器中不存在指明的类)。 @ConditionalOnClass或者@ConditionalOnMissingClass注解对应的条件类是OnClassCondition，定义如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Order(Ordered.HIGHEST_PRECEDENCE) // 优先级、最高级别class OnClassCondition extends SpringBootCondition &#123; @Override public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; StringBuffer matchMessage = new StringBuffer(); // 记录匹配信息 MultiValueMap&lt;String, Object&gt; onClasses = getAttributes(metadata, ConditionalOnClass.class); // 得到@ConditionalOnClass注解的属性 if (onClasses != null) &#123; // 如果属性存在 List&lt;String&gt; missing = getMatchingClasses(onClasses, MatchType.MISSING, context); // 得到在类加载器中不存在的类 if (!missing.isEmpty()) &#123; // 如果存在类加载器中不存在对应的类，返回一个匹配失败的ConditionalOutcome return ConditionOutcome .noMatch("required @ConditionalOnClass classes not found: " + StringUtils.collectionToCommaDelimitedString(missing)); &#125; // 如果类加载器中存在对应的类的话，匹配信息进行记录 matchMessage.append("@ConditionalOnClass classes found: " + StringUtils.collectionToCommaDelimitedString( getMatchingClasses(onClasses, MatchType.PRESENT, context))); &#125; // 对@ConditionalOnMissingClass注解做相同的逻辑处理(说明@ConditionalOnClass和@ConditionalOnMissingClass可以一起使用) MultiValueMap&lt;String, Object&gt; onMissingClasses = getAttributes(metadata, ConditionalOnMissingClass.class); if (onMissingClasses != null) &#123; List&lt;String&gt; present = getMatchingClasses(onMissingClasses, MatchType.PRESENT, context); if (!present.isEmpty()) &#123; return ConditionOutcome .noMatch("required @ConditionalOnMissing classes found: " + StringUtils.collectionToCommaDelimitedString(present)); &#125; matchMessage.append(matchMessage.length() == 0 ? "" : " "); matchMessage.append("@ConditionalOnMissing classes not found: " + StringUtils.collectionToCommaDelimitedString(getMatchingClasses( onMissingClasses, MatchType.MISSING, context))); &#125; // 返回全部匹配成功的ConditionalOutcome return ConditionOutcome.match(matchMessage.toString()); &#125; private enum MatchType &#123; // 枚举：匹配类型。用于查询类名在对应的类加载器中是否存在。 PRESENT &#123; // 匹配成功 @Override public boolean matches(String className, ConditionContext context) &#123; return ClassUtils.isPresent(className, context.getClassLoader()); &#125; &#125;, MISSING &#123; // 匹配不成功 @Override public boolean matches(String className, ConditionContext context) &#123; return !ClassUtils.isPresent(className, context.getClassLoader()); &#125; &#125;; public abstract boolean matches(String className, ConditionContext context); &#125;&#125; 比如FreemarkerAutoConfiguration中的@ConditionalOnClass注解中有value属性是freemarker.template.Configuration.class和FreeMarkerConfigurationFactory.class。在OnClassCondition执行过程中得到的最终ConditionalOutcome中的log message如下： 1@ConditionalOnClass classes found: freemarker.template.Configuration,org.springframework.ui.freemarker.FreeMarkerConfigurationFactory 基于Bean的条件注解@ConditionalOnBean(Spring容器中存在指明的bean)、@ConditionalOnMissingBean(Spring容器中不存在指明的bean)以及ConditionalOnSingleCandidate(Spring容器中存在且只存在一个指明的bean)都是基于Bean的条件注解，它们对应的条件类是ConditionOnBean。 @ConditionOnBean注解定义如下： 1234567891011@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(OnBeanCondition.class)public @interface ConditionalOnBean &#123; Class&lt;?&gt;[] value() default &#123;&#125;; // 匹配的bean类型 String[] type() default &#123;&#125;; // 匹配的bean类型的类名 Class&lt;? extends Annotation&gt;[] annotation() default &#123;&#125;; // 匹配的bean注解 String[] name() default &#123;&#125;; // 匹配的bean的名字 SearchStrategy search() default SearchStrategy.ALL; // 搜索策略。提供CURRENT(只在当前容器中找)、PARENTS(只在所有的父容器中找；但是不包括当前容器)和ALL(CURRENT和PARENTS的组合)&#125; OnBeanCondition条件类的匹配代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Overridepublic ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; StringBuffer matchMessage = new StringBuffer(); // 记录匹配信息 if (metadata.isAnnotated(ConditionalOnBean.class.getName())) &#123; BeanSearchSpec spec = new BeanSearchSpec(context, metadata, ConditionalOnBean.class); // 构造一个BeanSearchSpec，会从@ConditionalOnBean注解中获取属性，然后设置到BeanSearchSpec中 List&lt;String&gt; matching = getMatchingBeans(context, spec); // 从BeanFactory中根据策略找出所有匹配的bean if (matching.isEmpty()) &#123; // 如果没有匹配的bean，返回一个没有匹配成功的ConditionalOutcome return ConditionOutcome .noMatch("@ConditionalOnBean " + spec + " found no beans"); &#125; // 如果找到匹配的bean，匹配信息进行记录 matchMessage.append( "@ConditionalOnBean " + spec + " found the following " + matching); &#125; if (metadata.isAnnotated(ConditionalOnSingleCandidate.class.getName())) &#123; // 相同的逻辑，针对@ConditionalOnSingleCandidate注解 BeanSearchSpec spec = new SingleCandidateBeanSearchSpec(context, metadata, ConditionalOnSingleCandidate.class); List&lt;String&gt; matching = getMatchingBeans(context, spec); if (matching.isEmpty()) &#123; return ConditionOutcome.noMatch( "@ConditionalOnSingleCandidate " + spec + " found no beans"); &#125; else if (!hasSingleAutowireCandidate(context.getBeanFactory(), matching)) &#123; // 多了一层判断，判断是否只有一个bean return ConditionOutcome.noMatch("@ConditionalOnSingleCandidate " + spec + " found no primary candidate amongst the" + " following " + matching); &#125; matchMessage.append("@ConditionalOnSingleCandidate " + spec + " found " + "a primary candidate amongst the following " + matching); &#125; if (metadata.isAnnotated(ConditionalOnMissingBean.class.getName())) &#123; // 相同的逻辑，针对@ConditionalOnMissingBean注解 BeanSearchSpec spec = new BeanSearchSpec(context, metadata, ConditionalOnMissingBean.class); List&lt;String&gt; matching = getMatchingBeans(context, spec); if (!matching.isEmpty()) &#123; return ConditionOutcome.noMatch("@ConditionalOnMissingBean " + spec + " found the following " + matching); &#125; matchMessage.append(matchMessage.length() == 0 ? "" : " "); matchMessage.append("@ConditionalOnMissingBean " + spec + " found no beans"); &#125; return ConditionOutcome.match(matchMessage.toString()); //返回匹配成功的ConditonalOutcome&#125; SpringBoot还提供了其他比如ConditionalOnJava、ConditionalOnNotWebApplication、ConditionalOnWebApplication、ConditionalOnResource、ConditionalOnProperty、ConditionalOnExpression等条件注解，有兴趣的读者可以自行查看它们的底层处理逻辑。 各种条件注解的总结 条件注解 对应的Condition处理类 处理逻辑 @ConditionalOnBean OnBeanCondition Spring容器中是否存在对应的实例。可以通过实例的类型、类名、注解、昵称去容器中查找(可以配置从当前容器中查找或者父容器中查找或者两者一起查找)这些属性都是数组，通过”与”的关系进行查找 @ConditionalOnClass OnClassCondition 类加载器中是否存在对应的类。可以通过Class指定(value属性)或者Class的全名指定(name属性)。如果是多个类或者多个类名的话，关系是”与”关系，也就是说这些类或者类名都必须同时在类加载器中存在 @ConditionalOnExpression OnExpressionCondition 判断SpEL 表达式是否成立 @ConditionalOnJava OnJavaCondition 指定Java版本是否符合要求。内部有2个属性value和range。value表示一个枚举的Java版本，range表示比这个老或者新于等于指定的Java版本(默认是新于等于)。内部会基于某些jdk版本特有的类去类加载器中查询，比如如果是jdk9，类加载器中需要存在java.security.cert.URICertStoreParameters；如果是jdk8，类加载器中需要存在java.util.function.Function；如果是jdk7，类加载器中需要存在java.nio.file.Files；如果是jdk6，类加载器中需要存在java.util.ServiceLoader @ConditionalOnMissingBean OnBeanCondition Spring容器中是否缺少对应的实例。可以通过实例的类型、类名、注解、昵称去容器中查找(可以配置从当前容器中查找或者父容器中查找或者两者一起查找)这些属性都是数组，通过”与”的关系进行查找。还多了2个属性ignored(类名)和ignoredType(类名)，匹配的过程中会忽略这些bean @ConditionalOnMissingClass OnClassCondition 跟ConditionalOnClass的处理逻辑一样，只是条件相反，在类加载器中不存在对应的类 @ConditionalOnNotWebApplication OnWebApplicationCondition 应用程序是否是非Web程序，没有提供属性，只是一个标识。会从判断Web程序特有的类是否存在，环境是否是Servlet环境，容器是否是Web容器等 @ConditionalOnProperty OnPropertyCondition 应用环境中的屬性是否存在。提供prefix、name、havingValue以及matchIfMissing属性。prefix表示属性名的前缀，name是属性名，havingValue是具体的属性值，matchIfMissing是个boolean值，如果属性不存在，这个matchIfMissing为true的话，会继续验证下去，否则属性不存在的话直接就相当于匹配不成功 @ConditionalOnResource OnResourceCondition 是否存在指定的资源文件。只有一个属性resources，是个String数组。会从类加载器中去查询对应的资源文件是否存在 @ConditionalOnSingleCandidate OnBeanCondition Spring容器中是否存在且只存在一个对应的实例。只有3个属性value、type、search。跟ConditionalOnBean中的这3种属性值意义一样 @ConditionalOnWebApplication OnWebApplicationCondition 应用程序是否是Web程序，没有提供属性，只是一个标识。会从判断Web程序特有的类是否存在，环境是否是Servlet环境，容器是否是Web容器等 例子 例子意义 @ConditionalOnBean(javax.sql.DataSource.class) Spring容器或者所有父容器中需要存在至少一个javax.sql.DataSource类的实例 @ConditionalOnClass ({ Configuration.class, FreeMarkerConfigurationFactory.class }) 类加载器中必须存在Configuration和FreeMarkerConfigurationFactory这两个类 @ConditionalOnExpression (“‘${server.host}’==’localhost’”) server.host配置项的值需要是localhost ConditionalOnJava(JavaVersion.EIGHT) Java版本至少是8 @ConditionalOnMissingBean(value = ErrorController.class, search = SearchStrategy.CURRENT) Spring当前容器中不存在ErrorController类型的bean @ConditionalOnMissingClass (“GenericObjectPool”) 类加载器中不能存在GenericObjectPool这个类 @ConditionalOnNotWebApplication 必须在非Web应用下才会生效 @ConditionalOnProperty(prefix = “spring.aop”, name = “auto”, havingValue = “true”, matchIfMissing = true) 应用程序的环境中必须有spring.aop.auto这项配置，且它的值是true或者环境中不存在spring.aop.auto配置(matchIfMissing为true) @ConditionalOnResource (resources=”mybatis.xml”) 类加载路径中必须存在mybatis.xml文件 @ConditionalOnSingleCandidate (PlatformTransactionManager.class) Spring当前或父容器中必须存在PlatformTransactionManager这个类型的实例，且只有一个实例 @ConditionalOnWebApplication 必须在Web应用下才会生效 SpringBoot条件注解的激活机制分析完了条件注解的执行逻辑之后，接下来的问题就是SpringBoot是如何让这些条件注解生效的？ SpringBoot使用ConditionEvaluator这个内部类完成条件注解的解析和判断。 在Spring容器的refresh过程中，只有跟解析或者注册bean有关系的类都会使用ConditionEvaluator完成条件注解的判断，这个过程中一些类不满足条件的话就会被skip。这些类比如有AnnotatedBeanDefinitionReader、ConfigurationClassBeanDefinitionReader、ConfigurationClassParse、ClassPathScanningCandidateComponentProvider等。 比如ConfigurationClassParser的构造函数会初始化内部属性conditionEvaluator： 1234567891011121314public ConfigurationClassParser(MetadataReaderFactory metadataReaderFactory, ProblemReporter problemReporter, Environment environment, ResourceLoader resourceLoader, BeanNameGenerator componentScanBeanNameGenerator, BeanDefinitionRegistry registry) &#123; this.metadataReaderFactory = metadataReaderFactory; this.problemReporter = problemReporter; this.environment = environment; this.resourceLoader = resourceLoader; this.registry = registry; this.componentScanParser = new ComponentScanAnnotationParser( resourceLoader, environment, componentScanBeanNameGenerator, registry); // 构造ConditionEvaluator用于处理条件注解 this.conditionEvaluator = new ConditionEvaluator(registry, environment, resourceLoader);&#125; ConfigurationClassParser对每个配置类进行解析的时候都会使用ConditionEvaluator： 123if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123; return;&#125; ConditionEvaluator的skip方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public boolean shouldSkip(AnnotatedTypeMetadata metadata, ConfigurationPhase phase) &#123; // 如果这个类没有被@Conditional注解所修饰，不会skip if (metadata == null || !metadata.isAnnotated(Conditional.class.getName())) &#123; return false; &#125; // 如果参数中沒有设置条件注解的生效阶段 if (phase == null) &#123; // 是配置类的话直接使用PARSE_CONFIGURATION阶段 if (metadata instanceof AnnotationMetadata &amp;&amp; ConfigurationClassUtils.isConfigurationCandidate((AnnotationMetadata) metadata)) &#123; return shouldSkip(metadata, ConfigurationPhase.PARSE_CONFIGURATION); &#125; // 否则使用REGISTER_BEAN阶段 return shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN); &#125; // 要解析的配置类的条件集合 List&lt;Condition&gt; conditions = new ArrayList&lt;Condition&gt;(); // 获取配置类的条件注解得到条件数据，并添加到集合中 for (String[] conditionClasses : getConditionClasses(metadata)) &#123; for (String conditionClass : conditionClasses) &#123; Condition condition = getCondition(conditionClass, this.context.getClassLoader()); conditions.add(condition); &#125; &#125; // 对条件集合做个排序 AnnotationAwareOrderComparator.sort(conditions); // 遍历条件集合 for (Condition condition : conditions) &#123; ConfigurationPhase requiredPhase = null; if (condition instanceof ConfigurationCondition) &#123; requiredPhase = ((ConfigurationCondition) condition).getConfigurationPhase(); &#125; // 没有这个解析类不需要阶段的判断或者解析类和参数中的阶段一致才会继续进行 if (requiredPhase == null || requiredPhase == phase) &#123; // 阶段一致切不满足条件的话，返回true并跳过这个bean的解析 if (!condition.matches(this.context, metadata)) &#123; return true; &#125; &#125; &#125; return false;&#125; SpringBoot在条件注解的解析log记录在了ConditionEvaluationReport类中，可以通过BeanFactory获取(BeanFactory是有父子关系的；每个BeanFactory都存有一份ConditionEvaluationReport，互不相干)： 12345678910ConditionEvaluationReport conditionEvaluationReport = beanFactory.getBean("autoConfigurationReport", ConditionEvaluationReport.class);Map&lt;String, ConditionEvaluationReport.ConditionAndOutcomes&gt; result = conditionEvaluationReport.getConditionAndOutcomesBySource();for(String key : result.keySet()) &#123; ConditionEvaluationReport.ConditionAndOutcomes conditionAndOutcomes = result.get(key); Iterator&lt;ConditionEvaluationReport.ConditionAndOutcome&gt; iterator = conditionAndOutcomes.iterator(); while(iterator.hasNext()) &#123; ConditionEvaluationReport.ConditionAndOutcome conditionAndOutcome = iterator.next(); System.out.println(key + " -- " + conditionAndOutcome.getCondition().getClass().getSimpleName() + " -- " + conditionAndOutcome.getOutcome()); &#125;&#125; 打印出条件注解下的类加载信息： 12345678.......org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration -- OnClassCondition -- required @ConditionalOnClass classes not found: freemarker.template.Configuration,org.springframework.ui.freemarker.FreeMarkerConfigurationFactoryorg.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration -- OnClassCondition -- required @ConditionalOnClass classes not found: groovy.text.markup.MarkupTemplateEngineorg.springframework.boot.autoconfigure.gson.GsonAutoConfiguration -- OnClassCondition -- required @ConditionalOnClass classes not found: com.google.gson.Gsonorg.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration -- OnClassCondition -- required @ConditionalOnClass classes not found: org.h2.server.web.WebServletorg.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration -- OnClassCondition -- required @ConditionalOnClass classes not found: org.springframework.hateoas.Resource,org.springframework.plugin.core.Pluginorg.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration -- OnClassCondition -- required @ConditionalOnClass classes not found: com.hazelcast.core.HazelcastInstance.......]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Dubbo源码分析之服务发布过程]]></title>
    <url>%2F2018%2F06%2F24%2FDubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%8F%91%E5%B8%83%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[服务端发布流程 Spring 对外留出的扩展dubbo 是基于 spring 配置来实现服务的发布的，一定是基于 spring 的扩展来写了一套自己的标签。在 dubbo 配置文件中看到的&lt;dubbo:service&gt; ，就是属于自定义扩展标签要实现自定义扩展，有三个步骤(在 spring 中定义了两个接口，用来实现 扩展) NamespaceHandler: 注册一堆 BeanDefinitionParser，利用他们来进行解析 BeanDefinitionParser:用于解析每个element的内容 Spring 默认会加载 jar 包下的 META-INF/spring.handlers 文件寻找对应的 NamespaceHandler。 这个里面主要做了一件事，把不同的配置分别转化成 spring 容器中的 bean 对象application 对应 ApplicationConfigregistry 对应 RegistryConfigmonitor 对应 MonitorConfigprovider 对应 ProviderConfigconsumer 对应 ConsumerConfig 为了在 spring 启动的时候，也相应的启动 provider 发布服务注册服务的 过程，而同时为了让客户端在启动的时候自动订阅发现服务，加入了两个 beanServiceBean、ReferenceBean。分别继承了 ServiceConfig 和 ReferenceConfig同 时 还 分 别 实 现 了 InitializingBean 、 DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware InitializingBean 接口为 bean 提供了初始化方法的方式，它只包括 afterPropertiesSet 方法，凡是继承该接口的类，在初始化 bean 的时候会 执行该方法。DisposableBean bean 被销毁的时候，spring 容器会自动执行 destory 方 法，比如释放资源ApplicationContextAware 实现了这个接口的 bean，当 spring 容器初始 化的时候，会自动的将 ApplicationContext 注入进来ApplicationListener ApplicationEvent 事件监听，spring 容器启动后会发一个事件通知BeanNameAware 获得自身初始化时，本身的 bean 的 id 属性 那么基本的实现思路可以整理出来了 利用 spring 的解析收集 xml 中的配置信息，然后把这些配置信息存储到 serviceConfig 中 调用ServiceConfig的export方法来进行服务的发布和注册 服务的发布过程serviceBean 是服务发布的切入点，通过 afterPropertiesSet 方法，调用 export()方法进行发布。export 为父类 ServiceConfig 中的方法，所以跳转到 SeviceConfig 类中的 export 方法 delay作用 export 是 synchronized 修饰的方法。也就是说暴露的过程是原子操作，正常情况下不会出现锁竞争的问题，毕竟初始化过程大多数情况下都是 单一线程操作，这里联想到了 spring 的初始化流程，也进行了加锁操 作，这里也给我们平时设计一个不错的启示:初始化流程的性能调优优先级应该比较低，但是安全的优先级应该放的比较高! 继续看doExport()方法。同样是一堆初始化代 12345678910111213141516171819202122232425262728293031public synchronized void export() &#123; if (provider != null) &#123; if (export == null) &#123; export = provider.getExport(); &#125; if (delay == null) &#123; delay = provider.getDelay(); &#125; &#125; if (export != null &amp;&amp; ! export.booleanValue()) &#123; return; &#125; if (delay != null &amp;&amp; delay &gt; 0) &#123; Thread thread = new Thread(new Runnable() &#123; public void run() &#123; try &#123; Thread.sleep(delay); &#125; catch (Throwable e) &#123; &#125; doExport(); &#125; &#125;); thread.setDaemon(true); thread.setName("DelayExportServiceThread"); thread.start(); &#125; else &#123; doExport(); &#125;&#125; 继续看 doExport()，最终会调用到 doExportUrls()中:123456private void doExportUrls() &#123; List&lt;URL&gt; registryURLs = loadRegistries(true);//是不是获得注册中心的配置 for (ProtocolConfig protocolConfig : protocols) &#123; //是不是支持多协议发布 doExportUrlsFor1Protocol(protocolConfig, registryURLs); &#125;&#125; 这 个 protocols 长 这 个 样 子 protocols 也是根据配置装配出来的。接下 来让我们进入 doExportUrlsFor1Protocol 方法看看 dubbo 具体是怎么样 将服务暴露出去 doExportUrlsFor1Protocol1234567891011121314151617181920212223242526272829303132//如果配置不是local则暴露为远程服务.(配置为local，则表示只暴露本地服务)//注册服务if (! Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope) )&#123; if (logger.isInfoEnabled()) &#123; logger.info("Export dubbo service " + interfaceClass.getName() + " to url " + url); &#125; if (registryURLs != null &amp;&amp; registryURLs.size() &gt; 0 &amp;&amp; url.getParameter("register", true)) &#123; for (URL registryURL : registryURLs) &#123;// url = url.addParameterIfAbsent("dynamic", registryURL.getParameter("dynamic")); URL monitorUrl = loadMonitor(registryURL); if (monitorUrl != null) &#123; url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString()); &#125; if (logger.isInfoEnabled()) &#123; logger.info("Register dubbo service " + interfaceClass.getName() + " url " + url + " to registry " + registryURL); &#125; //通过proxyFactory来获取Invoker对象 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class)interfaceClass,registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); //注册服务 Exporter&lt;?&gt; exporter = protocol.export(invoker); //将exporter添加到list中 exporters.add(exporter); &#125; &#125; else &#123; Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); Exporter&lt;?&gt; exporter = protocol.export(invoker); exporters.add(exporter); &#125;&#125; doExportUrlsFor1Protocol 方 法，先创建两个 URL，分别如下 dubbo://192.168.xx.63:20888/com.gupaoedu.IGHello; registry://192.168.xx ;是不是觉得这个 URL 很眼熟，没错在注册中心看到的 services 的 providers 信息就是这个在上面这段代码中可以看到 Dubbo 的比较核心的抽象:Invoke。Invoker 是一个代理类，从 ProxyFactory 中生成。 这个地方可以做一个小结 Invoker - 执行具体的远程调用 Protocol – 服务地址的发布和订阅 Exporter – 暴露服务或取消暴露 protocol.export(invoker)protocol 这个地方，其实并不是直接调用 DubboProtocol 协议的 export, 大家跟我看看 protocol 这个属性是在哪里实例化的?以及实例化的代码 是什么?这个 Protocol 得到的应该是一个 Protocol$Adaptive一个自适应 的适配器。这个时候，通过 protocol.export(invoker),实际上调用的应该是Protocol$Adaptive 这个动态类的 export 方法。 Protocol$Adaptive前面的ExtensionLoader有讲过，默认是dubbo。 上面这段代码做两个事情 从 url 中获得 protocol 的协议地址，如果 protocol 为空，表示已 dubbo协议发布服务，否则根据配置的协议类型来发布服务。 调 用ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName);ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); 这段代码做了什么事情呢?前面这段代码我们已经理解了，通过工厂模式 获得一个 ExtensionLoader 实例，我们来分析下下 getExtension 这个方法。getExtension这个方法的主要作用是用来获取 ExtensionLoader 实例代表的扩展的指定 实现，已扩展实现的名字作为参数。 1234567891011121314151617181920212223242526272829303132 /** * 返回指定名字的扩展。如果指定名字的扩展不存在，则抛异常 &#123;@link IllegalStateException&#125;. * * @param name * @return */@SuppressWarnings("unchecked")public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException("Extension name == null"); if ("true".equals(name)) &#123; return getDefaultExtension(); &#125; ////判断是否已经缓存过该扩展点 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; Object instance = holder.get(); if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; ////createExtension ，创建扩展点 instance = createExtension(name); holder.set(instance); &#125; &#125; &#125; return (T) instance;&#125; createExtension 根据 name 获取对应的 class 根据class创建一个实例 对获取的实例进行依赖注入 对实例进行包装，分别调用带 Protocol 参数的构造函数创建实例，然后进行依赖注入。a) 在 dubbo-rpc-api 的 resources 路 径 下 ， 找 到com.alibaba.dubbo.rcp.Protocol 文件中有存在 filter/listenerb) 遍历 cachedWrapperClass 对 DubboProtocol 进行包装，会通过ProtocolFilterWrapper、ProtocolListenerWrapper 包装 12345678910111213141516171819202122232425private T createExtension(String name) &#123; Class&lt;?&gt; clazz = getExtensionClasses().get(name);//"dubbo" clazz=DubboProtocol if (clazz == null) &#123; throw findException(name); &#125; try &#123; T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; injectExtension(instance); Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; wrapperClasses.size() &gt; 0) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; //// 对实例进行包装，分别调用带 Protocol 参数的构 造函数创建实例，然后进行依赖注入。 instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException("Extension instance(name: " + name + ", class: " + type + ") could not be instantiated: " + t.getMessage(), t); &#125;&#125; getExtensionClasses这个方法之前在讲自适应扩展点的时候讲过了，其实就是加载扩展点实现 类了。然后调用 loadExtensionClasses，去对应文件下去加载指定的扩展 点123456789101112131415//加载扩展点的实现类private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; classes = loadExtensionClasses(); cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; ResigtryProtocolExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extN ame); 当 extName 为 registry 的时候，我们不需要再次去阅读这块代码 了，直接可以在扩展点中找到相应的实现扩展点[/dubbo-registry- api/src/main/resources/META- INF/dubbo/internal/com.alibaba.dubbo.rpc.Protocol] 配置如下所以，我们可以定位到 RegistryProtocol这个类中的export方法 1234567891011121314151617181920212223242526272829303132333435363738public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; //export invoker ， 本地发布服务（启动netty） final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); //registry provider final Registry registry = getRegistry(originInvoker); final URL registedProviderUrl = getRegistedProviderUrl(originInvoker); registry.register(registedProviderUrl); // 订阅override数据 // FIXME 提供者订阅时，会影响同一JVM即暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。 final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //保证每次export都返回一个新的exporter实例 return new Exporter&lt;T&gt;() &#123; public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; public void unexport() &#123; try &#123; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; registry.unregister(registedProviderUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; overrideListeners.remove(overrideSubscribeUrl); registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;;&#125; 本地先启动监听服务 123456789101112131415private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker)&#123; String key = getCacheKey(originInvoker); ExporterChangeableWrapper&lt;T&gt; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; synchronized (bounds) &#123; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; final Invoker&lt;?&gt; invokerDelegete = new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker)); exporter = new ExporterChangeableWrapper&lt;T&gt;((Exporter&lt;T&gt;)protocol.export(invokerDelegete), originInvoker); bounds.put(key, exporter); &#125; &#125; &#125; return (ExporterChangeableWrapper&lt;T&gt;) exporter;&#125; 上面代码中，protocol代码是怎么赋值的呢？我们看看代码，熟悉吗？是一个依赖注入的扩展点。不熟悉的话，我们再回想一下，在加载扩展点的时候， 有一个injectExtension方法，针对已经加载的扩展点中的扩展点属性进行依赖注入。（牛逼的代码） 12345private Protocol protocol;public void setProtocol(Protocol protocol) &#123; this.protocol = protocol;&#125; 因此我们知道protocol是一个自适应扩展点，Protocol$Adaptive，然后调用这个自适应扩展点中的export方法，这个时候传入的协议地址应该是 dubbo://127.0.0.1/xxxx… 因此在Protocol$Adaptive.export方法中，ExtensionLoader.getExtension(Protocol.class).getExtension(extName)。应该就是ProtocolFilterWrapper(ProtocolListenerWrapper(DubboProtocol)))，在ExtensionLoader中会扫描是否有wrappedClass，就是存在构造函数，参数是父类接口。 这里并不是获得一个单纯的DubboProtocol扩展点，而是会通过Wrapper对Protocol进行装饰，装饰器分别为: ProtocolFilterWrapper/ ProtocolListenerWrapper; 至于MockProtocol为什么不在装饰器里面呢？大家再回想一下我们在看ExtensionLoader.loadFile这段代码的时候，有一个判断，装饰器必须要具备一个带有Protocol的构造方法，如下 123456public ProtocolFilterWrapper(Protocol protocol)&#123; if (protocol == null) &#123; throw new IllegalArgumentException("protocol == null"); &#125; this.protocol = protocol;&#125; 分析ProtocolFilterWrapper和ProtocolListenerWrapperProtocolFilterWrapper这个类非常重要，dubbo机制里面日志记录、超时等等功能都是在这一部分实现的 这个类有3个特点， 第一它有一个参数为Protocol protocol的构造函数； 第二，它实现了Protocol接口； 第三，它使用责任链模式，对export和refer函数进行了封装。分别使用SERVICE_FILTER_KEY和REFERENCE_FILTER_KEY调用buildInvokerChain方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class ProtocolFilterWrapper implements Protocol &#123; private final Protocol protocol; public ProtocolFilterWrapper(Protocol protocol)&#123; if (protocol == null) &#123; throw new IllegalArgumentException("protocol == null"); &#125; this.protocol = protocol; &#125; public int getDefaultPort() &#123; return protocol.getDefaultPort(); &#125; public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); &#125; public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER); &#125; public void destroy() &#123; protocol.destroy(); &#125;//buildInvokerChain函数：它读取所有的filter类，利用这些类封装invoker private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (filters.size() &gt; 0) &#123; for (int i = filters.size() - 1; i &gt;= 0; i --) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; public URL getUrl() &#123; return invoker.getUrl(); &#125; public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last; &#125;&#125; 我们看如下文件： /dubbo-rpc-api/src/main/resources/META-INF/dubbo/internal/com.alibaba.dubbo.rpc.Filter 其实就是对Invoker，通过如下的Filter组装成一个责任链 1234567891011121314echo=com.alibaba.dubbo.rpc.filter.EchoFiltergeneric=com.alibaba.dubbo.rpc.filter.GenericFiltergenericimpl=com.alibaba.dubbo.rpc.filter.GenericImplFiltertoken=com.alibaba.dubbo.rpc.filter.TokenFilteraccesslog=com.alibaba.dubbo.rpc.filter.AccessLogFilteractivelimit=com.alibaba.dubbo.rpc.filter.ActiveLimitFilterclassloader=com.alibaba.dubbo.rpc.filter.ClassLoaderFiltercontext=com.alibaba.dubbo.rpc.filter.ContextFilterconsumercontext=com.alibaba.dubbo.rpc.filter.ConsumerContextFilterexception=com.alibaba.dubbo.rpc.filter.ExceptionFilterexecutelimit=com.alibaba.dubbo.rpc.filter.ExecuteLimitFilterdeprecated=com.alibaba.dubbo.rpc.filter.DeprecatedFiltercompatible=com.alibaba.dubbo.rpc.filter.CompatibleFiltertimeout=com.alibaba.dubbo.rpc.filter.TimeoutFilter 这其中涉及到很多功能，包括权限验证、异常、超时等等，当然可以预计计算调用时间等等应该也是在这其中的某个类实现的； 这里我们可以看到export和refer过程都会被filter过滤 ProtocolListenerWrapper在这里我们可以看到export和refer分别对应了不同的Wrapper；export是对应的ListenerExporterWrapper。这块暂时先不去分析，因为这个地方并没有提供实现类。 123456789101112131415161718public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; return new ListenerExporterWrapper&lt;T&gt;(protocol.export(invoker), Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY)));&#125;public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return new ListenerInvokerWrapper&lt;T&gt;(protocol.refer(type, url), Collections.unmodifiableList( ExtensionLoader.getExtensionLoader(InvokerListener.class) .getActivateExtension(url, Constants.INVOKER_LISTENER_KEY)));&#125; DubboProtocol.export通过上面的代码分析完以后，最终我们能够定位到DubboProtocol.export方法。我们看一下dubboProtocol的export方法：openServer(url） 123456789101112131415161718192021222324252627public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; URL url = invoker.getUrl(); // export service. String key = serviceKey(url); DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); exporterMap.put(key, exporter); //export an stub service for dispaching event Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice)&#123; String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0 )&#123; if (logger.isWarnEnabled())&#123; logger.warn(new IllegalStateException("consumer [" +url.getParameter(Constants.INTERFACE_KEY) + "], has set stubproxy support event ,but no stub methods founded.")); &#125; &#125; else &#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125; //暴露服务 openServer(url); return exporter;&#125; openServer开启服务 123456789101112131415private void openServer(URL url) &#123; // find server. String key = url.getAddress();//192.168.11.156：20880 //client 也可以暴露一个只有server可以调用的服务。 boolean isServer = url.getParameter(Constants.IS_SERVER_KEY,true); if (isServer) &#123; ExchangeServer server = serverMap.get(key); if (server == null) &#123;//没有的话就是创建服务 serverMap.put(key, createServer(url)); &#125; else &#123; //server支持reset,配合override功能使用 server.reset(url); &#125; &#125;&#125; createServer创建服务,开启心跳检测，默认使用netty。组装url 1234567891011121314151617181920212223242526private ExchangeServer createServer(URL url) &#123; //默认开启server关闭时发送readonly事件 url = url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()); //默认开启heartbeat url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; ! ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) throw new RpcException("Unsupported server type: " + str + ", url: " + url); url = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); ExchangeServer server; try &#123; server = Exchangers.bind(url, requestHandler); &#125; catch (RemotingException e) &#123; throw new RpcException("Fail to start server(url: " + url + ") " + e.getMessage(), e); &#125; str = url.getParameter(Constants.CLIENT_KEY); if (str != null &amp;&amp; str.length() &gt; 0) &#123; Set&lt;String&gt; supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); if (!supportedTypes.contains(str)) &#123; throw new RpcException("Unsupported client type: " + str); &#125; &#125; return server;&#125; Exchangers.bind12345678910public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; if (handler == null) &#123; throw new IllegalArgumentException("handler == null"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, "exchange"); return getExchanger(url).bind(url, handler);&#125; 通过ExtensionLoader获得指定的扩展点，type默认为header 123456789public static Exchanger getExchanger(URL url) &#123; //url中获得exchanger, 默认为header String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER); return getExchanger(type);&#125;public static Exchanger getExchanger(String type) &#123; return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type);&#125; HeaderExchanger.bind调用headerExchanger的bind方法 123public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; 通过transporter.bind来进行绑定。 123456789101112131415public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; if (handlers == null || handlers.length == 0) &#123; throw new IllegalArgumentException("handlers == null"); &#125; ChannelHandler handler; if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; handler = new ChannelHandlerDispatcher(handlers); &#125; return getTransporter().bind(url, handler);&#125; NettyTransport.bind通过NettyTranport创建基于Netty的server服务 123public Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; return new NettyServer(url, listener);&#125; new HeaderExchangeServer在调用HeaderExchanger.bind方法的时候，是先new一个HeaderExchangeServer. 这个server是干嘛呢？ 是对当前这个连接去建立心跳机制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class HeaderExchangeServer implements ExchangeServer &#123; private final ScheduledExecutorService scheduled = Executors. newScheduledThreadPool(1,new NamedThreadFactory( "dubbo-remoting-server-heartbeat", true)); // 心跳定时器 private ScheduledFuture&lt;?&gt; heatbeatTimer; // 心跳超时，毫秒。缺省0，不会执行心跳。 private int heartbeat; private int heartbeatTimeout; private final Server server; private volatile boolean closed = false; public HeaderExchangeServer(Server server) &#123; //..属性赋值 //心跳 startHeatbeatTimer(); &#125; private void startHeatbeatTimer() &#123; //关闭心跳定时 stopHeartbeatTimer(); if (heartbeat &gt; 0) &#123; //每隔heartbeat时间执行一次 heatbeatTimer = scheduled.scheduleWithFixedDelay( new HeartBeatTask( new HeartBeatTask.ChannelProvider() &#123; //获取channels public Collection&lt;Channel&gt; getChannels() &#123; return Collections.unmodifiableCollection( HeaderExchangeServer.this.getChannels() ); &#125; &#125;, heartbeat, heartbeatTimeout), heartbeat, heartbeat,TimeUnit.MILLISECONDS); &#125; &#125; //关闭心跳定时 private void stopHeartbeatTimer() &#123; try &#123; ScheduledFuture&lt;?&gt; timer = heatbeatTimer; if (timer != null &amp;&amp; ! timer.isCancelled()) &#123; timer.cancel(true); &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; finally &#123; heatbeatTimer =null; &#125; &#125; 服务注册的过程前面，我们已经知道，基于spring这个解析入口，到发布服务的过程，接着基于DubboProtocol去发布，最终调用Netty的api创建了一个NettyServer。 那么继续沿着RegistryProtocol.export这个方法，来看看注册服务的代码 RegistryProtocol.export1234567891011121314151617181920212223242526272829303132333435363738public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; //export invoker通过DubboProtocal发布本地服务 final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); //registry provider 这个方法是invoker的地址获取registry实例 final Registry registry = getRegistry(originInvoker); final URL registedProviderUrl = getRegistedProviderUrl(originInvoker); registry.register(registedProviderUrl); // 订阅override数据 // FIXME 提供者订阅时，会影响同一JVM即暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。 final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //保证每次export都返回一个新的exporter实例 return new Exporter&lt;T&gt;() &#123; public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; public void unexport() &#123; try &#123; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; registry.unregister(registedProviderUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; overrideListeners.remove(overrideSubscribeUrl); registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;;&#125; getRegistry这个方法是invoker的地址获取registry实例 registry://192.168.11.156：2181的协议地址 , registryUrl就会变成了zookeeper://192.168.11.156 12345678910111213141516/** * 根据invoker的地址获取registry实例 * @param originInvoker * @return */private Registry getRegistry(final Invoker&lt;?&gt; originInvoker)&#123; URL registryUrl = originInvoker.getUrl(); //获得registry://192.168.11.156：2181的协议地址 if (Constants.REGISTRY_PROTOCOL.equals(registryUrl.getProtocol())) &#123;//得到zookeeper的协议地址 String protocol = registryUrl.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_DIRECTORY); //registryUrl就会变成了zookeeper://192.168.11.156registryUrl = registryUrl.setProtocol(protocol).removeParameter(Constants.REGISTRY_KEY); &#125;//registryFactory是什么？ return registryFactory.getRegistry(registryUrl);&#125; registryFactory.getRegistry这段代码很明显了，通过前面这段代码的分析，其实就是把registry的协议头改成服务提供者配置的协议地址，也就是我们配置的 然后registryFactory.getRegistry的目的，就是通过协议地址匹配到对应的注册中心。那registryFactory是一个什么样的对象呢？，我们找一下这个代码的定义 12345private RegistryFactory registryFactory;public void setRegistryFactory(RegistryFactory registryFactory) &#123; this.registryFactory = registryFactory;&#125; 这个代码有点眼熟，再来看看RegistryFactory这个类的定义，我猜想一定是一个扩展点，不信，咱们看 并且，大家还要注意这里面的一个方法上，有一个@Adaptive的注解，说明什么？ 这个是一个自适应扩展点。按照我们之前看过代码，自适应扩展点加在方法 层面上，表示会动态生成一个自适应的适配器。所以这个自适应适配器应该是RegistryFactory$Adaptive 12345@SPI("dubbo")public interface RegistryFactory &#123; @Adaptive(&#123;"protocol"&#125;) Registry getRegistry(URL url);&#125; 123456789101112131415public class RegistryFactory$Adaptive implements com.alibaba.dubbo.registry.RegistryFactory &#123; public com.alibaba.dubbo.registry.Registry getRegistry(com.alibaba.dubbo.common.URL arg0) &#123; if (arg0 == null) throw new IllegalArgumentException("url == null"); com.alibaba.dubbo.common.URL url = arg0; String extName = (url.getProtocol() == null ? "dubbo" : url.getProtocol()); if (extName == null) throw new IllegalStateException("Fail to get extension(com.alibaba.dubbo.registry.RegistryFactory) " + "name from url(" + url.toString() + ") use keys([protocol])"); com.alibaba.dubbo.registry.RegistryFactory extension = (com.alibaba.dubbo.registry.RegistryFactory) ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.registry.RegistryFactory.class). getExtension(extName); return extension.getRegistry(arg0); &#125;&#125; ZookeeperRegistryFactory这个方法中并没有getRegistry方法，而是在父类AbstractRegistryFactory 从缓存REGISTRIES中，根据key获得对应的Registry 如果不存在，则创建Registry 1234567891011121314151617181920212223public Registry getRegistry(URL url) &#123; url = url.setPath(RegistryService.class.getName()) .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY); String key = url.toServiceString(); // 锁定注册中心获取过程，保证注册中心单一实例 LOCK.lock(); try &#123; Registry registry = REGISTRIES.get(key); if (registry != null) &#123; return registry; &#125; registry = createRegistry(url); if (registry == null) &#123; throw new IllegalStateException("Can not create registry " + url); &#125; REGISTRIES.put(key, registry); return registry; &#125; finally &#123; // 释放锁 LOCK.unlock(); &#125;&#125; createRegistry创建一个注册中心，这个是一个抽象方法，具体的实现在对应的子类实例中实现的，在ZookeeperRegistryFactory中 123456789101112131415161718192021222324252627public Registry createRegistry(URL url) &#123; return new ZookeeperRegistry(url, zookeeperTransporter);&#125;//通过zkClient，获得一个zookeeper的连接实例public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException("registry address == null"); &#125; String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (! group.startsWith(Constants.PATH_SEPARATOR)) &#123; group = Constants.PATH_SEPARATOR + group; &#125; this.root = group; //设置根节点 zkClient = zookeeperTransporter.connect(url);//建立连接 zkClient.addStateListener(new StateListener() &#123; public void stateChanged(int state) &#123; if (state == RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125;);&#125; 代码分析到这里，我们对于getRegistry得出了一个结论，根据当前注册中心的配置信息，获得一个匹配的注册中心，也就是ZookeeperRegistry registry.register(registedProviderUrl);ZookeeperRegistry extends FailbackRegistry 继续往下分析，会调用registry.register去将dubbo://的协议地址注册到zookeeper上 这个方法会调用FailbackRegistry类中的register. 为什么呢？因为ZookeeperRegistry这个类中并没有register这个方法，但是他的父类FailbackRegistry中存在register方法，而这个类又重写了AbstractRegistry类中的register方法。所以我们可以直接定位FailbackRegistry这个类中的register方法中 FailbackRegistry.register FailbackRegistry，从名字上来看，是一个失败重试机制 调用父类的register方法，讲当前url添加到缓存集合中 调用doRegister方法，这个方法很明显，是一个抽象方法，会由ZookeeperRegistry子类实现。 12345678910111213141516171819202122232425262728@Overridepublic void register(URL url) &#123; super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; // 向服务器端发送注册请求 doRegister(url); &#125; catch (Exception e) &#123; Throwable t = e; // 如果开启了启动时检测，则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; ! Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if(skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException("Failed to register " + url + " to registry " + getUrl().getAddress() + ", cause: " + t.getMessage(), t); &#125; else &#123; logger.error("Failed to register " + url + ", waiting for retry, cause: " + t.getMessage(), t); &#125; // 将失败的注册请求记录到失败列表，定时重试 failedRegistered.add(url); &#125;&#125; 1234567protected void doRegister(URL url) &#123; try &#123; zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; throw new RpcException("Failed to register " + url + " to zookeeper " + getUrl() + ", cause: " + e.getMessage(), e); &#125;&#125; RegistryProtocol.export 这个方法中后续的代码就不用再分析了。就是去对服务提供端去注册一个zookeeper监听，当监听发生变化的时候，服务端做相应的处理。 消费端启动初始化过程消费端的代码解析是从下面这段代码开始的 1ReferenceBean(afterPropertiesSet) -&gt;getObject() -&gt;get()-&gt;init()-&gt;createProxy 最终会获得一个代理对象。 createProxy第375行前面很多代码都是初始化的动作，需要仔细分析的代码代码从createProxy第375行开始 1234567891011121314151617181920212223242526272829303132List&lt;URL&gt; us = loadRegistries(false); //从注册中心上获得相应的协议url地址if (us != null &amp;&amp; us.size() &gt; 0) &#123; for (URL u : us) &#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &#123; map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125;&#125;if (urls == null || urls.size() == 0) &#123; throw new IllegalStateException("No such any registry to reference " + interfaceName + " on the consumer " + NetUtils.getLocalHost() + " use dubbo version " + Version.getVersion() + ", please config &lt;dubbo:registry address=\"...\" /&gt; to your spring config."); &#125;if (urls.size() == 1) &#123; invoker = refprotocol.refer(interfaceClass, urls.get(0)); //获得invoker代理对象&#125; else &#123; List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) &#123; invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; // 用了最后一个registry url &#125; &#125; if (registryURL != null) &#123; // 有 注册中心协议的URL // 对有注册中心的Cluster 只用 AvailableCluster URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); invoker = cluster.join(new StaticDirectory(u, invokers)); &#125; else &#123; // 不是 注册中心的URL invoker = cluster.join(new StaticDirectory(invokers)); &#125;&#125; refprotocol.refer​ invokers.add(refprotocol.refer(interfaceClass, url)); 调用protocol的refer方法，得到invoker， 传递进来的参数url，协议地址为registry://。 refprotocol这个对象，定义的代码如下，是一个自适应扩展点，得到的是Protocol$Adaptive ReferenceConfig中refprotocol的定义如下 1private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 所以最终调用RegistryProtocol.refer代码 RegistryProtocol.refer这个方法里面的代码，基本上都能看懂1.根据根据url获得注册中心，这个registry是zookeeperRegistry2.调用doRefer，按方法，传递了几个参数， 其中有一个culster参数，这个需要注意下 123456789101112131415161718192021222324252627282930313233public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // group="a,b" or group="*" Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || "*".equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; return doRefer(cluster, registry, type, url); &#125; clusterdoRefer方法中有一个参数是cluster,我们找到它的定义代码如下，。又是一个自动注入的扩展点。 12345private Cluster cluster;public void setCluster(Cluster cluster) &#123; this.cluster = cluster;&#125; 从下面的代码可以看出，这个不仅仅是一个扩展点，而且方法层面上，还有一个@Adaptive，表示会动态生成一个自适应适配器Cluster$Adaptive 1234567@SPI(FailoverCluster.NAME)public interface Cluster &#123; @Adaptive &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException;&#125; Cluster$Adaptive通过debug的方式，，获取到Cluster$Adaptive这个适配器，代码如下。我们知道cluster这个对象的实例以后，继续看doRefer方法；注意：这里的Cluster$Adaptive也并不单纯，大家还记得在讲扩展点的时候有一个扩展点装饰器吗？如果这个扩展点存在一个构造函数，并且构造函数就是扩展接口本身，那么这个扩展点就会这个wrapper装饰，而Cluster被装饰的是：MockClusterWrapper 123456789101112131415public class Cluster$Adaptive implements com.alibaba.dubbo.rpc.cluster.Cluster &#123; public Invoker join(Directory arg0) throws RpcException &#123; if (arg0 == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.cluster.Directory argument == null"); if (arg0.getUrl() == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() == null"); com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter("cluster", "failover"); if (extName == null) throw new IllegalStateException("Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(" + url.toString() + ") use keys([cluster])"); com.alibaba.dubbo.rpc.cluster.Cluster extension = (com.alibaba.dubbo.rpc.cluster.Cluster) ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName); return extension.join(arg0); &#125;&#125; RegistryProtocol.doRefer这段代码中，有一个RegistryDirectory,可能看不懂，我们暂时先忽略，等会单独讲.（基于注册中心动态发现服务提供者） 将consumer://协议地址注册到注册中心 registryDirectory的subscribe方法，订阅zookeeper地址的变化 调用cluster.join()方法 12345678910111213141516171819private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123;// 将consumer://协议地址注册到注册中心 registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; //通过registryDirectory的subscribe， directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY)); return cluster.join(directory);&#125; cluster.join由前面的Cluster$Adaptive这个类中的join方法的分析，得知cluster.join会调用MockClusterWrapper.join方法， 然后再调用FailoverCluster.join方法。 MockClusterWrapper.join这个意思很明显了。也就是我们上节课讲过的mock容错机制，如果出现异常情况，会调用MockClusterInvoker，否则，调用FailoverClusterInvoker. 12345678910111213public class MockClusterWrapper implements Cluster &#123; private Cluster cluster; public MockClusterWrapper(Cluster cluster) &#123; this.cluster = cluster; &#125; public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory)); &#125;&#125; 小结refprotocol.ref，这个方法，会返回一个MockClusterInvoker(FailoverClusterInvoker)。这里面一定还有疑问，我们先把主线走完，再回过头看看什么是cluster、什么是directory proxyFactory.getProxy(invoker);再回到ReferenceConfig这个类，在createProxy方法的最后一行，调用proxyFactory.getProxy(invoker). 把前面生成的invoker对象作为参数，再通过proxyFactory工厂去获得一个代理对象。接下来我们分析下这段代码做了什么。 其实前面在分析服务发布的时候，基本分析过了，所以再看这段代码，应该会很熟悉 ProxyFactory， 会生成一个动态的自适应适配器。ProxyFactory$Adaptive，然后调用这个适配器中的getProxy方法，代码如下 123ReferenceConfig// 创建服务代理 return (T) proxyFactory.getProxy(invoker); 12345678910public java.lang.Object getProxy(Invoker arg0) throws RpcException &#123; if (arg0 == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument == null"); if (arg0.getUrl() == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument getUrl() == null");com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter("proxy", "javassist"); if(extName == null) throw new IllegalStateException("Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(" + url.toString() + ") use keys([proxy])"); com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); 很显然，又是通过javassist实现的一个动态代理，我们来看看JavassistProxyFactory.getProxy JavassistProxyFactory.getProxy通过javasssist动态字节码生成动态代理类， 123public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));&#125; Proxy.getProxy(interfaces)在Proxy.getProxy这个类的如下代码中添加断点，在debug下可以看到动态字节码如下 123456public java.lang.String sayHello(java.lang.String arg0)&#123; Object[] args = new Object[1]; args[0] = ($w)$1; Object ret = handler.invoke(this, methods[0], args);return (java.lang.String)ret;&#125; 上面代码的handler，就是在JavassistProxyFactory.getProxy中。传递的new InvokerInvocationHandler(invoker) 什么时候建立和服务端的连接前面我们通过代码分析到了，消费端的初始化过程，但是似乎没有看到客户端和服务端建立NIO连接。实际上，建立连接的过程在消费端初始化的时候就建立好的，只是前面我们没有分析，代码在RegistryProtocol.doRefer方法内的directory.subscribe方法中。 1234567891011121314151617181920212223private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // consumer://192.*** URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; // consumer://192.***注册到zk注册中心 registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; //registryDirectory订阅provider、configurator、router的目录的变化 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY)); return cluster.join(directory);&#125; directory.subscribeRegistryProtocol的refer方法Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url)，传入的参数url为zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=dubbo-client-demo 而registryFactory是RegistryFactory$Adaptive，所以根据url的protocol，实际调用的是ZookeeperRegistryFactory的getRegistry方法，最终得到ZookeeperRegsitry实例。 12345678910111213141516171819202122//RegistryProtocol public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); //ZookeeperRegistyFactory得到ZookeeperRegistry Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // group="a,b" or group="*" Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || "*".equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; return doRefer(cluster, registry, type, url); &#125; 在RegistryProtocol的doRefer方法中，directory.setResgitry中参数为zookeeperRegistry。 因为ZookeeperRegistry extends FailbackRegistry，FailbackRegistry extends AbstractRegistry 所以registryDirectory的调用链为： RegistryDirectory.subscribe -&gt;FailbackRegistry. subscribe-&gt;- AbstractRegistry.subscribe&gt;zookeeperRegistry.doSubscribe 123456//RegistryDirectorypublic void subscribe(URL url) &#123; setConsumerUrl(url); registry.subscribe(url, this);&#125; FailbackRegistry. subscribe调用FailbackRegistry.subscribe 进行订阅，这里有一个特殊处理，如果订阅失败，则会添加到定时任务中进行重试 1234567@Overridepublic void subscribe(URL url, NotifyListener listener) &#123; super.subscribe(url, listener); removeFailedSubscribed(url, listener); try &#123; // 向服务器端发送订阅请求 doSubscribe(url, listener); zookeeperRegistry. doSubscribe调用zookeeperRegistry执行真正的订阅操作，这段代码太长，我就不贴出来了，这里面主要做两个操作 对providers/routers/configurator三个节点进行创建和监听 调用notify(url,listener,urls) 将已经可用的列表进行通知 AbstractRegistry.notify12345678910111213141516171819202122232425262728293031323334353637383940414243protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url == null) &#123; throw new IllegalArgumentException("notify url == null"); &#125; if (listener == null) &#123; throw new IllegalArgumentException("notify listener == null"); &#125; if ((urls == null || urls.size() == 0) &amp;&amp; ! Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; logger.warn("Ignore empty notify urls for subscribe url " + url); return; &#125; if (logger.isInfoEnabled()) &#123; logger.info("Notify urls for subscribe url " + url + ", urls: " + urls); &#125; Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); listener.notify(categoryList); &#125;&#125; 总结消费端初始化这块就完了]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Dubbo源码分析之ExtensionLoader动态扩展]]></title>
    <url>%2F2018%2F06%2F24%2FDubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BExtensionLoader%E5%8A%A8%E6%80%81%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[1. 相关注解SPI定义一个扩展点，service provider interface Adaptive自适应扩展点，在{@link ExtensionLoader}生成Extension的Adaptive Instance时，为{@link ExtensionLoader}提供信息。 Activate自动激活加载扩展点 在这个源码中可以看到有两个注 解，一个是在类级别上的@SPI(“dubbo”), 另一个是 @Adaptive@SPI 表示当前这个接口是一个扩展点，可以实现自己的 扩展实现，默认的扩展点是 DubboProtocol。@Adaptive 表示一个自适应扩展点，在方法级别上，会动态拼接字符串生成一个适配器类。在类上，则不会。 123456789101112@SPI("dubbo")public interface Protocol &#123; int getDefaultPort(); @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; void destroy();&#125; 2. getAdaptiveExtension获取自适应的扩展点流程时序图如下： getExtensionLoader不存在，new一个123456789 public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123;//异常null处理省略。。。 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) &#123; EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader; &#125; 123456private ExtensionLoader(Class&lt;?&gt; type) &#123;//Protocol.class this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class). getAdaptiveExtension());&#125; getAdaptiveExtension这个方法里面主要做几个事情: 从 cacheAdaptiveInstance 这个内存缓存中获得一个对象实例 如果实例为空，说明是第一次加载，则通过双重检查锁的方式去创建一个适配器扩展点123456789101112131415161718192021public T getAdaptiveExtension() &#123; Object instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; if(createAdaptiveInstanceError == null) &#123; synchronized (cachedAdaptiveInstance) &#123; instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; instance = createAdaptiveExtension(); cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123; createAdaptiveInstanceError = t; throw new IllegalStateException("fail to create adaptive instance: " + t.toString(), t); &#125; &#125; &#125; &#125; &#125; return (T) instance;&#125; createAdaptiveExtension这段代码里面有两个结构，一个是 injectExtension. 另一 个是 getAdaptiveExtensionClass() 12345678private T createAdaptiveExtension() &#123; try &#123; //可以实现扩展点的注入 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123; throw new IllegalStateException("Can not create adaptive extenstion " + type + ", cause: " + e.getMessage(), e); &#125;&#125; getAdaptiveExtensionClass从类名来看，是获得一个适配器扩展点的类。 在这段代码中，做了两个事情 getExtensionClasses() 加载所有路径下的扩展点 createAdaptiveExtensionClass() 动态创建一个扩展点 cachedAdaptiveClass 这里有个判断，用来判断当前 Protocol 这个扩展点是否存在一个自定义的适配器，如果 有，则直接返回自定义适配器，否则，就动态创建，这个值 是在 getExtensionClasses 中赋值的，这块代码我们稍后再看1234567private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; getExtensionClasses(); if (cachedAdaptiveClass != null) &#123; return cachedAdaptiveClass; //AdaptiveCompiler &#125; return cachedAdaptiveClass = createAdaptiveExtensionClass();&#125; createAdaptiveExtensionClass动态生成适配器代码，以及动态编译 createAdaptiveExtensionClassCode, 动态创建一个字节码文件。返回 code 这个字符串 通过 compiler.compile 进行编译(默认情况下使用的是javassist) 通过 ClassLoader 加载到 jvm 中12345678910//创建一个适配器扩展点。（创建一个动态的字节码文件）private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; //生成字节码代码 String code = createAdaptiveExtensionClassCode(); //获得类加载器 ClassLoader classLoader = findClassLoader(); com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); //动态编译字节码 return compiler.compile(code, classLoader);&#125; code的字节码内容12345678910111213141516171819202122232425262728293031public class Protocol$Adaptive implements com.alibaba.dubbo.rpc.Protocol &#123; public void destroy() &#123; throw new UnsupportedOperationException("method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!"); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException("method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!"); &#125; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws com.alibaba.dubbo.rpc.RpcException &#123; if (arg1 == null) throw new IllegalArgumentException("url == null"); com.alibaba.dubbo.common.URL url = arg1; String extName = (url.getProtocol() == null ? "dubbo" : url.getProtocol()); if (extName == null) throw new IllegalStateException("Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(" + url.toString() + ") use keys([protocol])"); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.RpcException &#123; if (arg0 == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument == null"); if (arg0.getUrl() == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument getUrl() == null"); com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? "dubbo" : url.getProtocol()); if (extName == null) throw new IllegalStateException("Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(" + url.toString() + ") use keys([protocol])"); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125;&#125; Protocol$Adaptive 的主要功能 从 url 或扩展接口获取扩展接口实现类的名称; 根 据 名 称 ， 获 取 实 现 类 ExtensionLoader.getExtensionLoader( 扩 展 接 口 类).getExtension(扩展接口实现类名称)，然后调用实现类 的方法。需要明白一点 dubbo 的内部传参基本上都是基于 Url 来实 现的，也就是说 Dubbo 是基于 URL 驱动的技术 所以，适配器类的目的是在运行期获取扩展的真正实现来调用，解耦接口和实现，这样的话不要我们自己实现适配器类，而这些都是通过 Adpative 来实现。到目前为止，我们的 AdaptiveExtension 的主线走完了，可 以简单整理一下他们的调用关系如下 getExtensionClasses这段代码主要做如下几个事情 从 cachedClasses 中获得一个结果，这个结果实际上就 是所有的扩展点类，key 对应 name，value 对应 class 通过双重检查锁进行判断 调用 loadExtensionClasses，去加载左右扩展点的实现 123456789101112131415//加载扩展点的实现类private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; classes = loadExtensionClasses(); cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; loadExtensionClasses从不同目录去加载扩展点的实现，META-INF/dubbo ; META-INF/internal ; META- INF/ser vices主要逻辑 获得当前扩展点的注解，也就是 Protocol.class 这个类的 注解，@SPI 判断这个注解不为空，则再次获得@SPI 中的 value 值 如果 value 有值，也就是@SPI(“dubbo”)，则讲这个 dubbo 的值赋给 cachedDefaultName。这就是为什么我们能够通过 ExtensionLoader.getExtensionLoader(Protocol.class).getDefaultExtension() ,能够获得 DubboProtocol 这个扩 展点的原因 最后，通过 loadFile 去加载指定路径下的所有扩展点。 也 就 是 META-INF/dubbo;META-INF/internal;META-INF/services 读取com.alibaba.dubbo.common.extension.ExtensionFactory的文件内容，按行读取，文件采用 name=value 方式123adaptive=com.alibaba.dubbo.common.extension.factory.AdaptiveExtensionFactoryspi=com.alibaba.dubbo.common.extension.factory.SpiExtensionFactoryspring=com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory 1.Adaptive注解在类上Apaptive注解在类上，比如AdaptiveExtensionFactory是ExtensionFactory的实现，则直接cachedAdaptiveClass = clazz。因为`cachedAdaptiveClass已经不为null，不会去再执行动态拼接字节码。 @Adaptive如果是加在类上， 表示当前类是一个自定义的自适应扩展点 。如果是加在方法级别上，表示需要动态创建一个自适应扩展点，也就是Protocol$Adaptive 1234567if (clazz.isAnnotationPresent(Adaptive.class)) &#123; if(cachedAdaptiveClass == null) &#123; cachedAdaptiveClass = clazz; &#125; else if (! cachedAdaptiveClass.equals(clazz)) &#123; throw new IllegalStateException("More than 1 adaptive class found: "+ cachedAdaptiveClass.getClass().getName()+ ", " + clazz.getClass().getName()); &#125;&#125; 12345678private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; getExtensionClasses(); //如果cachedAdaptiveClass已经赋值，直接返回 if (cachedAdaptiveClass != null) &#123; return cachedAdaptiveClass; &#125; return cachedAdaptiveClass = createAdaptiveExtensionClass();&#125; 2.类没有Adaptive注解如果类没有Adaptive注解，比如SpringExtensionFactory，不存在（ExtensionFactory）的构造函数，走catch的逻辑，spring=com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory，最后分别向cachedNames和extensionClasses存入key value : 字符串spring和SpringExtensionFactory的class字节码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344else &#123; try &#123; clazz.getConstructor(type); Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) &#123; cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; &#125; wrappers.add(clazz); &#125; catch (NoSuchMethodException e) &#123; //SpringExtensionFactory不存在（ExtensionFactory）的构造函数 clazz.getConstructor(); if (name == null || name.length() == 0) &#123; name = findAnnotationName(clazz); if (name == null || name.length() == 0) &#123; if (clazz.getSimpleName().length() &gt; type.getSimpleName().length() &amp;&amp; clazz.getSimpleName().endsWith(type.getSimpleName())) &#123; name = clazz.getSimpleName().substring(0, clazz.getSimpleName().length() - type.getSimpleName().length()).toLowerCase(); &#125; else &#123; throw new IllegalStateException("No such extension name for the class " + clazz.getName() + " in the config " + url); &#125; &#125; &#125; String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length &gt; 0) &#123; Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) &#123; cachedActivates.put(names[0], activate); &#125; for (String n : names) &#123; if (! cachedNames.containsKey(clazz)) &#123; cachedNames.put(clazz, n); &#125; Class&lt;?&gt; c = extensionClasses.get(n); if (c == null) &#123; extensionClasses.put(n, clazz); &#125; else if (c != clazz) &#123; throw new IllegalStateException("Duplicate extension " + type.getName() + " name " + n + " on " + c.getName() + " and " + clazz.getName()); &#125; &#125; &#125; &#125;&#125; 3.存在构造函数ProtocolListenerWrapper存在构造函数ProtocolListenerWrapper(Protocol protocol)，则向wrappers集合中添加clazz 如果没有 Adaptive 注解，则判断当前类是否带有参数是 type 类型的构造函数，如果有，则认为是wrapper 类。这个 wrapper 实际上就是对扩展类进行装 饰.可 以在 dubbo-rpc-api/internal 下找到 Protocol 文件，发现 Protocol 配置了 3 个装饰分别是,filter/listener/mock. 所以 Protocol 这个实 例来说，会增加对应的装饰器 1234567clazz.getConstructor(type); Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) &#123; cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; &#125; wrappers.add(clazz); 3. ExtensionFactory12ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension() Object object = objectFactory.getExtension(pt, property); objectFactory =&gt; AdaptiveExtensionFactory AdaptiveExtensionFactory123456789public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; for (ExtensionFactory factory : factories) &#123; T extension = factory.getExtension(type, name); if (extension != null) &#123; return extension; &#125; &#125; return null;&#125; 1registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=dubbo-client&amp;dubbo=2.5.3&amp;owner=joey&amp;pid=57644&amp;registry=zookeeper&amp;timestamp=1529844392952 1234 if (urls.size() == 1) &#123; invoker = refprotocol.refer(interfaceClass, urls.get(0)); &#125;//这里invoker为 MockClusterInvoker 12345678public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) &#123; if (arg1 == null) throw new IllegalArgumentException("url == null"); com.alibaba.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? "dubbo" : url.getProtocol() ); if(extName == null) throw new IllegalStateException("Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(" + url.toString() + ") use keys([protocol])"); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1);&#125; 12345678910111213141516171819public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); //获得注册中心 Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // group="a,b" or group="*" Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || "*".equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; return doRefer(cluster, registry, type, url); &#125; 1234567891011121314151617private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; //将消费者的地址注册到zk registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY)); return cluster.join(directory);&#125; 1234directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY)); url = zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=dubbo-client&amp;dubbo=2.5.3&amp;owner=joey&amp;pid=57644&amp;refer=application%3Ddubbo-client%26dubbo%3D2.5.3%26interface%3Dcom.joey.hello.IhelloService%26methods%3DsayHello%26owner%3Djoey%26pid%3D57644%26side%3Dconsumer%26timestamp%3D1529844387888&amp;timestamp=1529844392952 123456789mock=com.alibaba.dubbo.rpc.cluster.support.wrapper.MockClusterWrapperfailover=com.alibaba.dubbo.rpc.cluster.support.FailoverClusterfailfast=com.alibaba.dubbo.rpc.cluster.support.FailfastClusterfailsafe=com.alibaba.dubbo.rpc.cluster.support.FailsafeClusterfailback=com.alibaba.dubbo.rpc.cluster.support.FailbackClusterforking=com.alibaba.dubbo.rpc.cluster.support.ForkingClusteravailable=com.alibaba.dubbo.rpc.cluster.support.AvailableClustermergeable=com.alibaba.dubbo.rpc.cluster.support.MergeableClusterbroadcast=com.alibaba.dubbo.rpc.cluster.support.BroadcastCluster MockClusterWrapper存在MockClusterWrapper(Cluster cluster)，所以会将FailfastCluster等进行包装，是失败降级用的。 1234567891011121314public class MockClusterWrapper implements Cluster &#123; private Cluster cluster; public MockClusterWrapper(Cluster cluster) &#123; this.cluster = cluster; &#125; public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory)); &#125;&#125; ProxyFactory$Adaptive StubProxyFactoryWrapper存在构造函数，是wrapper，会把JavassistProxyFactory包装 123public StubProxyFactoryWrapper(ProxyFactory proxyFactory) &#123; this.proxyFactory = proxyFactory;&#125; 最终还是JavassistProxyFactory Proxy123456789// create Proxy class.String fcn = Proxy.class.getName() + id;ccm = ClassGenerator.newInstance(cl);ccm.setClassName(fcn);ccm.addDefaultConstructor();ccm.setSuperClass(Proxy.class);ccm.addMethod("public Object newInstance(" + InvocationHandler.class.getName() + " h)&#123; return new " + pcn + "($1); &#125;");Class&lt;?&gt; pc = ccm.toClass();proxy = (Proxy)pc.newInstance(); ccm method debug的结果 12345public java.lang.String sayHello(java.lang.String arg0)&#123;Object[] args = new Object[1]; args[0] = ($w)$1;Object ret = handler.invoke(this, methods[0], args);return (java.lang.String)ret;&#125; 1public java.lang.Object $echo(java.lang.Object arg0)&#123;Object[] args = new Object[1]; args[0] = ($w)$1; Object ret = handler.invoke(this, methods[1], args); return (java.lang.Object)ret;&#125; Proxy0 hander invoker :interface com.joey.hello.IhelloService -&gt; zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?anyhost=true&amp;application=dubbo-client&amp;check=false&amp;dubbo=2.5.3&amp;interface=com.joey.hello.IhelloService&amp;methods=sayHello&amp;owner=joey&amp;pid=57718&amp;side=consumer&amp;timestamp=1529847722831,directory: com.alibaba.dubbo.registry.integration.RegistryDirectory@3cfdd820 1234567891011121314151617181920212223List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;();for (String path : toCategoriesPath(url)) &#123; ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds)); &#125; &#125;); zkListener = listeners.get(listener); &#125; zkClient.create(path, false); List&lt;String&gt; children = zkClient.addChildListener(path, zkListener); if (children != null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125;&#125;notify(url, listener, urls); AbstractRegistry1234567for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); listener.notify(categoryList);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 根据invokerURL列表转换为invoker列表。转换规则如下： * 1.如果url已经被转换为invoker，则不在重新引用，直接从缓存中获取，注意如果url中任何一个参数变更也会重新引用 * 2.如果传入的invoker列表不为空，则表示最新的invoker列表 * 3.如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用。 * @param invokerUrls 传入的参数不能为null */private void refreshInvoker(List&lt;URL&gt; invokerUrls)&#123; if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123; this.forbidden = true; // 禁止访问 this.methodInvokerMap = null; // 置空列表 destroyAllInvokers(); // 关闭所有Invoker &#125; else &#123; this.forbidden = false; // 允许访问 Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference if (invokerUrls.size() == 0 &amp;&amp; this.cachedInvokerUrls != null)&#123; invokerUrls.addAll(this.cachedInvokerUrls); &#125; else &#123; this.cachedInvokerUrls = new HashSet&lt;URL&gt;(); this.cachedInvokerUrls.addAll(invokerUrls);//缓存invokerUrls列表，便于交叉对比 &#125; if (invokerUrls.size() ==0 )&#123; return; &#125; Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls) ;// 将URL列表转成Invoker列表 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表 // state change //如果计算错误，则不进行处理. if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0 )&#123; logger.error(new IllegalStateException("urls to invokers error .invokerUrls.size :"+invokerUrls.size() + ", invoker.size :0. urls :"+invokerUrls.toString())); return ; &#125; this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap; this.urlInvokerMap = newUrlInvokerMap; try&#123; destroyUnusedInvokers(oldUrlInvokerMap,newUrlInvokerMap); // 关闭未使用的Invoker &#125;catch (Exception e) &#123; logger.warn("destroyUnusedInvokers error. ", e); &#125; &#125;&#125; filter(listener(dubboProtocol)) DubboProtocol 123456public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; // create rpc invoker. DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker;&#125; 12Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls) ;// 将URL列表转成Invoker列表Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表 MockClusterInvoker invoke -&gt; 1MockClusterInvoker 4.dubbo SPI机制大部分的思想都是和 SPI 是一样，只是下面两个地方有差 异。 需要在 resource 目录下配置 META-INF/dubbo 或者 META-INF/dubbo/internal 或者 META-INF/services，并基 于 SPI 接口去创建一个文件 文件名称和接口名称保持一致，文件内容和 SPI 有差异， 内容是 KEY 对应 Value 如果类没有Adaptive注解，比如SpringExtensionFactory，不存在（ExtensionFactory）的构造函数，走catch的逻辑，spring=com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory，最后分别向cachedNames和extensionClasses存入key value : 字符串spring和SpringExtensionFactory的class字节码。]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP协议详解]]></title>
    <url>%2F2018%2F06%2F21%2FTCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[TCP三次握手 Client A 序号 Server B ——1——&gt; &lt;——2—— ——3——&gt; ClientA -&gt; ServerB: SYN=1, ACK=0 , 序列号seq=x 。 此时，TCP客户端ClientA进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。 ServerB -&gt; ClientA: SYN=1, ACK=1 , 序列号seq=y , 确认号ack=x+1 。此时，ServerB进入SYN-RCVD同步收到状态。SNC报文段不能携带数据，但是需要消耗一个序列号。 ClientA -&gt; ServerB: ACK=1, seq=x+1 , ack=y+1 。clinetA发送后进入ESTABLISHED（已建立连接）状态，serverB收到后=，也进入ESTABLISHED（已建立连接）状态。 TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。 ACK: TCP协议规定，只有ACK=1时有效，也规定连接建立后所有发送的报文的ACK必须为1 SYN(SYNchronization) ： 在连接建立时用来同步序号。 当SYN=1，ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应报文中使SYN=1，ACK=1。 FIN，用来释放连接。当FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放。 为什么需要三次握手，而不是两次​ clientA 第一次在步骤1中发送一个请求，由于网络原因，长时间没有收到ServerB确认回复。于是，clientA第二次发送请求，成功建立连接，处理完成后，关闭连接。但是，第一次的请求经过漫长的一段时间后，到达了ServerB，并且给了回复确认。即已失效的请求连接报文段。 ​ 如果只有两次握手，那么第一次的这个连接就建立了，实际是不应该建立的，导致不要的错误和资源浪费。 ​ 采用三次握手，就可以防止上面的问题。clientA对于的ServerB的回复确认不予理睬，ServerB收不到clinetA的第三次回复，这样就不会浪费建立新的连接。 TCP四次挥手 Client A 序号 Server B ——1——&gt; &lt;——2—— &lt;——3—— ——4——&gt; clientA -&gt; ServerB : FIN=1 , 序列号seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1） 。 此时ClientA从ESTABLISHED建立连接状态变为FIN-WAIT-1终止等待1状态。TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 ServerB -&gt; clientA : ACK=1 , seq=v , ack=u+1 。 此时， ServerB从ESTABLISHED建立连接状态变为CLOSE-WAIT关闭等待状态。clientA收到后，变为FIN-WAIT-2终止等待2状态。 即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。 ServerB -&gt; clientA : FIN=1 , ACK=1 , seq=w , ack=u+1 。 服务器ServerB就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 clientA -&gt; ServerB : ACK=1 , seq=u+1 , ack=w+1 。 clientA发出后，进入TIME_WAIT状态。 注意此时TCP连接还没有释放，必须经过2*MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 为什么客户端最后需要等待2MSL]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[sublime user setting]]></title>
    <url>%2F2018%2F06%2F19%2Fsublime-user-setting%2F</url>
    <content type="text"><![CDATA[Sublime3 Preferences -&gt; settings User配置 12345678910111213141516171819202122&#123; "atomic_save": true, "color_scheme": "Packages/Color Scheme - Default/Mariana.sublime-color-scheme", "draw_white_space": "all", "font_face": "YaHei Consolas Hybrid", "font_size": 14, "ignored_packages": [ "Vintage" ], "open_files_in_new_window": false, "save_on_focus_lost": true, "soda_classic_tabs": true, "soda_folder_icons": true, "tab_size": 4, "theme": "Soda Light 3.sublime-theme", "translate_tabs_to_spaces": true, "trim_trailing_white_space_on_save": true, "update_check": false, "fold_buttons": true, "fade_fold_buttons": false,&#125; 手动安装soda Preferences -&gt; browse packages 将Theme - Soda解压放到目录，同一级的还有Pretty JSON User 中文网 http://www.sublimetextcn.com/ 删除空行CTRL+H打开replace功能，勾选上左侧的regular expression，并填写 find what栏 : \s+$ （正则表达式）replace with栏 : （这行留空） 操作多行5种方法 1，鼠标选中多行，按下 Ctrl Shift L (Command Shift L) 即可同时编辑这些行；2，鼠标选中文本，反复按 CTRL D (Command D) 即可继续向下同时选中下一个相同的文本进行同时编辑；3，鼠标选中文本，按下 Alt F3 (Win) 或 Ctrl Command G(Mac) 即可一次性选择全部的相同文本进行同时编辑；4，Shift 鼠标右键 (Win) 或 Option 鼠标左键 (Mac) 或使用鼠标中键可以用鼠标进行竖向多行选择；5，Ctrl 鼠标左键(Win) 或 Command 鼠标左键(Mac) 可以手动选择同时要编辑。]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[telnet命令详解]]></title>
    <url>%2F2018%2F06%2F12%2Ftelnet%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[telnet命令用于登录远程主机，对远程主机进行管理。telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 语法1telnet(选项)(参数) 选项123456789101112131415161718-8：允许使用8位字符资料，包括输入与输出；-a：尝试自动登入远端系统；-b&lt;主机别名&gt;：使用别名指定远端主机名称；-c：不读取用户专属目录里的.telnetrc文件；-d：启动排错模式；-e&lt;脱离字符&gt;：设置脱离字符；-E：滤除脱离字符；-f：此参数的效果和指定"-F"参数相同；-F：使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机；-k&lt;域名&gt;：使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名；-K：不自动登入远端主机；-l&lt;用户名称&gt;：指定要登入远端主机的用户名称；-L：允许输出8位字符资料；-n&lt;记录文件&gt;：指定文件记录相关信息；-r：使用类似rlogin指令的用户界面；-S&lt;服务类型&gt;：设置telnet连线所需的ip TOS信息；-x：假设主机有支持数据加密的功能，就使用它；-X&lt;认证形态&gt;：关闭指定的认证形态。 参数 远程主机：指定要登录进行管理的远程主机； 端口：指定TELNET协议使用的端口号。 实例12345678910telnet 192.168.2.10Trying 192.168.2.10...Connected to 192.168.2.10 (192.168.2.10).Escape character is '^]'. localhost (Linux release 2.6.18-274.18.1.el5 #1 SMP Thu Feb 9 12:45:44 EST 2012) (1)login: rootPassword:Login incorrect 示例1：远程服务器无法访问 1234[root@linuxprobe ~]# telnet 192.168.120.209Trying 192.168.120.209...telnet: connect to address 192.168.120.209: No route to hosttelnet: Unable to connect to remote host: No route to host 处理这种情况方法：（1）确认IP地址是否正确（2）确认IP地址对应的装机是否已经开机（3）如果主机已经启动，确认路由设置是否设置正确（使用route命令查看）（4）如果主机已经启动，确认主机上是否开启了telnet服务（使用netstat命令查看，TCP的23端口是否有LISTEN状态行）（5）如果主机已经启动telnet服务，确认防火墙是否开放了23端口的访问（使用iptables-save查看） 示例2：域名无法解析 12[root@linuxprobe ~]# telnet www.baidu.comwww.baidu.com/telnet: Temporary failure in name resolution 处理这种情况方法：（1）确认域名是否正确（2）确认本机的域名解析有关的设置是否正确(/etc/resolv.conf中nameserver的配置是否正确，如果没有，可以使用nameserver 8.8.8.8)（3）确认防火墙是否放开了UDP53端口的访问(DNS使用UDP协议，端口53，使用iptables-save查看) 示例3：拒绝访问 1234[root@linuxprobe ~]# telnet 192.168.120.206Trying 192.168.120.206...telnet: connect to address 192.168.120.206: Connection refusedtelnet: Unable to connect to remote host: Connection refused 处理这种情况方法：（1）确认IP地址或者主机名是否正确（2）确认端口是否正确，是否默认23端口 若要检查192.168.120.206的某端口是否能否能访问，如443端口，可使用如下命令 123[root@linuxprobe ~]# telnet 192.168.120.206 443Trying 192.168.120.206...telnet: connect to address 192.168.120.206: Connection refused 说明：这表示192.168.120.206的443端口不能访问 示例4：telnet root用户的登入 12345678910[root@linuxprobe ~]# telnet 192.168.120.204Trying 192.168.120.204...Connected to 192.168.120.204 (192.168.120.204).Escape character is '^]'. localhost (Linux release 2.6.18-274.18.1.el5 #1 SMP Thu Feb 9 12:45:44 EST 2012) (1)login: rootPassword:Login incorrect 说明：一般情况下不允许root从远程登录，可以先用普通账号登录，然后再su -切到root用户。若要允许root用户登入，可用下列方法： 1234[root@linuxprobe ~]# vi /etc/pam.d/login#auth required pam_securetty.so #将这一行加上注释！或[root@linuxprobe ~]# mv /etc/securetty /etc/securetty.bak 示例5：启用telnet服务 123456789101112131415161718192021222324252627282930313233343536[root@linuxprobe ~]# cd /etc/xinetd.d/[root@linuxprobe xinetd.d]# ll总计 124-rw-r--r-- 1 root root 1157 2011-05-31 chargen-dgram-rw-r--r-- 1 root root 1159 2011-05-31 chargen-stream-rw-r--r-- 1 root root 523 2009-09-04 cvs-rw-r--r-- 1 root root 1157 2011-05-31 daytime-dgram-rw-r--r-- 1 root root 1159 2011-05-31 daytime-stream-rw-r--r-- 1 root root 1157 2011-05-31 discard-dgram-rw-r--r-- 1 root root 1159 2011-05-31 discard-stream-rw-r--r-- 1 root root 1148 2011-05-31 echo-dgram-rw-r--r-- 1 root root 1150 2011-05-31 echo-stream-rw-r--r-- 1 root root 323 2004-09-09 eklogin-rw-r--r-- 1 root root 347 2005-09-06 ekrb5-telnet-rw-r--r-- 1 root root 326 2004-09-09 gssftp-rw-r--r-- 1 root root 310 2004-09-09 klogin-rw-r--r-- 1 root root 323 2004-09-09 krb5-telnet-rw-r--r-- 1 root root 308 2004-09-09 kshell-rw-r--r-- 1 root root 317 2004-09-09 rsync-rw-r--r-- 1 root root 1212 2011-05-31 tcpmux-server-rw-r--r-- 1 root root 1149 2011-05-31 time-dgram-rw-r--r-- 1 root root 1150 2011-05-31 time-stream[root@linuxprobe xinetd.d]# cat krb5-telnet# default: off# description: The kerberized telnet server accepts normal telnet sessions, \# but can also use Kerberos 5 authentication.service telnet&#123; flags = REUSE socket_type = stream wait = no user = root server = /usr/kerberos/sbin/telnetd log_on_failure += USERID disable = yes&#125; 配置参数通常如下： 12345678910111213141516171819service telnet&#123;disable = no #启用flags = REUSE #socket可重用socket_type = stream #连接方式为TCPwait = no #为每个请求启动一个进程user = root #启动服务的用户为rootserver = /usr/sbin/in.telnetd #要激活的进程log_on_failure += USERID #登录失败时记录登录用户名&#125; 如果要配置允许登录的客户端列表，加入only_from = 192.168.0.2 #只允许192.168.0.2登录如果要配置禁止登录的客户端列表，加入no_access = 192.168.0.{2,3,4} #禁止192.168.0.2、192.168.0.3、192.168.0.4登录如果要设置开放时段，加入access_times = 9:00-12:00 13:00-17:00 # 每天只有这两个时段开放服务（我们的上班时间：P）如果你有两个IP地址，一个是私网的IP地址如192.168.0.2，一个是公网的IP地址如218.75.74.83，如果你希望用户只能从私网来登录telnet服务，那么加入bind = 192.168.0.2各配置项具体的含义和语法可参考xined配置文件属性说明（man xinetd.conf）配置端口，修改services文件：# vi /etc/services找到以下两句telnet 23/tcptelnet 23/udp如 果前面有#字符，就去掉它。telnet的默认端口是23，这个端口也是黑客端口扫描的主要对象，因此最好将这个端口修改掉，修改的方法很简单，就是将 23这个数字修改掉，改成大一点的数字，比如61123。注意，1024以下的端口号是internet保留的端口号，因此最好不要用，还应该注意不要与 其它服务的端口冲突。启动服务：service xinetd restart]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zookeeper watcher机制源码分析]]></title>
    <url>%2F2018%2F06%2F10%2Fzookeeper-watcher%E6%9C%BA%E5%88%B6%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Watcher的基本流程ZooKeeper 的 Watcher 机制，总的来说可以分为三个过程：客户端注册 Watcher、服务器处理 Watcher 和客户端回调 Watcher 客户端注册watcher有3种方式，getData、exists、getChildren；以如下代码为例来分析整个触发机制的原理 12345678910ZooKeeper zookeeper=new ZooKeeper(“192.168.11.152:2181”,4000,new Watcher()&#123; public void processor(WatchedEvent event)&#123; System.out.println(“event.type”);&#125;&#125;)；zookeeper.create(“/mic”,”0”.getByte(),ZooDefs.Ids. OPEN_ACL_UNSAFE,CreateModel. PERSISTENT); //创建节点zookeeper.exists(“/mic”,true); //注册监听zookeeper.setData(“/mic”, “1”.getByte(),-1) ; //修改节点的值触发监听 ZooKeeper API的初始化过程12345ZooKeeper zookeeper=new ZooKeeper(“192.168.11.152:2181”,4000,new Watcher()&#123; public void processor(WatchedEvent event)&#123; System.out.println(“event.type”);&#125;&#125;)； 在创建一个 ZooKeeper 客户端对象实例时，我们通过new Watcher()向构造方法中传入一个默认的 Watcher, 这个 Watcher 将作为整个 ZooKeeper会话期间的默认 Watcher，会一直被保存在客户端 ZKWatchManager 的 defaultWatcher 中;代码如下 123456789101112131415161718192021public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly, HostProvider aHostProvider, ZKClientConfig clientConfig) throws IOException &#123; LOG.info("Initiating client connection, connectString=" + connectString + " sessionTimeout=" + sessionTimeout + " watcher=" + watcher); if (clientConfig == null) &#123; clientConfig = new ZKClientConfig(); &#125; this.clientConfig = clientConfig; watchManager = defaultWatchManager(); watchManager.defaultWatcher = watcher; --在这里将watcher设置到ZKWatchManager ConnectStringParser connectStringParser = new ConnectStringParser( connectString); hostProvider = aHostProvider; --初始化了ClientCnxn，并且调用cnxn.start()方法 cnxn = new ClientCnxn(connectStringParser.getChrootPath(), hostProvider, sessionTimeout, this, watchManager, getClientCnxnSocket(), canBeReadOnly); cnxn.start(); &#125; ClientCnxn:是Zookeeper客户端和Zookeeper服务器端进行通信和事件通知处理的主要类，它内部包含两个类， SendThread ：负责客户端和服务器端的数据通信, 也包括事件信息的传输 EventThread : 主要在客户端回调注册的Watchers进行通知处理 ClientCnxn初始化123456789101112131415161718192021222324public ClientCnxn(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) &#123; this.zooKeeper = zooKeeper; this.watcher = watcher; this.sessionId = sessionId; this.sessionPasswd = sessionPasswd; this.sessionTimeout = sessionTimeout; this.hostProvider = hostProvider; this.chrootPath = chrootPath; connectTimeout = sessionTimeout / hostProvider.size(); readTimeout = sessionTimeout * 2 / 3; readOnly = canBeReadOnly; sendThread = new SendThread(clientCnxnSocket); --初始化sendThread eventThread = new EventThread(); --初始化eventThread this.clientConfig=zooKeeper.getClientConfig(); &#125; public void start() &#123; --启动两个线程 sendThread.start(); eventThread.start(); &#125; 客户端通过exists注册监听1zookeeper.exists(“/mic”,true); //注册监听 通过exists方法来注册监听，代码如下 12345678910111213141516171819202122232425262728293031323334 public Stat exists(final String path, Watcher watcher) throws KeeperException, InterruptedException &#123; final String clientPath = path; PathUtils.validatePath(clientPath); // the watch contains the un-chroot path WatchRegistration wcb = null; if (watcher != null) &#123; wcb = new ExistsWatchRegistration(watcher, clientPath); //构建ExistWatchRegistration &#125; final String serverPath = prependChroot(clientPath); // 构造RequestHeader RequestHeader h = new RequestHeader(); h.setType(ZooDefs.OpCode.exists); //设置操作类型为exists ExistsRequest request = new ExistsRequest(); // 构造ExistsRequest request.setPath(serverPath); request.setWatch(watcher != null); //是否注册监听 SetDataResponse response = new SetDataResponse(); //设置服务端响应的接收类//将封装的RequestHeader、ExistsRequest、SetDataResponse、WatchRegistration添加到发送队列 ReplyHeader r = cnxn.submitRequest(h, request, response, wcb); if (r.getErr() != 0) &#123; if (r.getErr() == KeeperException.Code.NONODE.intValue()) &#123; return null; &#125; throw KeeperException.create(KeeperException.Code.get(r.getErr()), clientPath); &#125; //返回exists得到的结果（Stat信息） return response.getStat().getCzxid() == -1 ? null : response.getStat(); &#125; cnxn.submitRequest1234567891011121314public ReplyHeader submitRequest(RequestHeader h, Record request, Record response, WatchRegistration watchRegistration, WatchDeregistration watchDeregistration) throws InterruptedException &#123; ReplyHeader r = new ReplyHeader(); //将消息添加到队列,并构造一个Packet传输对象 Packet packet = queuePacket(h, r, request, response, null, null, null, null, watchRegistration, watchDeregistration); synchronized (packet) &#123; while (!packet.finished) &#123; //在数据包没有处理完成之前，一直阻塞 packet.wait(); &#125; &#125; return r; &#125; 将RequestHeader h, ReplyHeader r, Record request, Record response，封装成package， 添加到outgoingQueue队列中，再唤醒sendThread,通知有数据包过来。outgoingQueue是一个阻塞队列，outgoingQueue是待发送的队列。 1private final LinkedBlockingDeque&lt;Packet&gt; outgoingQueue = new LinkedBlockingDeque&lt;Packet&gt;(); 1234567891011121314151617181920212223242526public Packet queuePacket(RequestHeader h, ReplyHeader r, Record request, Record response, AsyncCallback cb, String clientPath, String serverPath, Object ctx, WatchRegistration watchRegistration, WatchDeregistration watchDeregistration) &#123; //将相关传输对象转化成Packet Packet packet = null; packet = new Packet(h, r, request, response, watchRegistration); packet.cb = cb; packet.ctx = ctx; packet.clientPath = clientPath; packet.serverPath = serverPath; packet.watchDeregistration = watchDeregistration; synchronized (state) &#123; if (!state.isAlive() || closing) &#123; conLossPacket(packet); &#125; else &#123; if (h.getType() == OpCode.closeSession) &#123; closing = true; &#125; outgoingQueue.add(packet); //添加到outgoingQueue &#125; &#125; sendThread.getClientCnxnSocket().packetAdded();//此处是多路复用机制，唤醒Selector，告诉他有数据包添加过来了 return packet;&#125; 在 ZooKeeper 中，Packet 是一个最小的通信协议单元，即数据包。Pakcet 用于进行客户端与服务端之间的网络传输，任何需要传输的对象都需要包装成一个 Packet 对象。在 ClientCnxn 中 WatchRegistration 也会被封装到 Pakcet 中，然后由 SendThread 线程调用queuePacket方法把 Packet 放入发送队列中等待客户端发送，这又是一个异步过程，分布式系统采用异步通信是一个非常常见的手段。 SendThread的发送过程在初始化连接的时候，zookeeper初始化了两个线程并且启动了。接下来我们来分析SendThread的发送过程，因为是一个线程，所以启动的时候会调用SendThread.run方法。 run方法中，通过clientCnxnSocket，去拿队列的数据处理。 1clientCnxnSocket.doTransport(to, pendingQueue, ClientCnxn.this); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152public void run() &#123; clientCnxnSocket.introduce(this, sessionId, outgoingQueue); clientCnxnSocket.updateNow(); clientCnxnSocket.updateLastSendAndHeard(); int to; long lastPingRwServer = Time.currentElapsedTime(); final int MAX_SEND_PING_INTERVAL = 10000; //10 seconds while (state.isAlive()) &#123; try &#123; if (!clientCnxnSocket.isConnected()) &#123;// 如果没有连接：发起连接 // don't re-establish connection if we are closing if (closing) &#123; break; &#125; startConnect(); //发起连接 clientCnxnSocket.updateLastSendAndHeard(); &#125; if (state.isConnected()) &#123; //如果是连接状态，则处理sasl的认证授权 // determine whether we need to send an AuthFailed event. if (zooKeeperSaslClient != null) &#123; boolean sendAuthEvent = false; if (zooKeeperSaslClient.getSaslState() == ZooKeeperSaslClient.SaslState.INITIAL) &#123; try &#123; zooKeeperSaslClient.initialize(ClientCnxn.this); &#125; catch (SaslException e) &#123; LOG.error("SASL authentication with Zookeeper Quorum member failed: " + e); state = States.AUTH_FAILED; sendAuthEvent = true; &#125; &#125; KeeperState authState = zooKeeperSaslClient.getKeeperState(); if (authState != null) &#123; if (authState == KeeperState.AuthFailed) &#123; // An authentication error occurred during authentication with the Zookeeper Server. state = States.AUTH_FAILED; sendAuthEvent = true; &#125; else &#123; if (authState == KeeperState.SaslAuthenticated) &#123; sendAuthEvent = true; &#125; &#125; &#125; if (sendAuthEvent == true) &#123; eventThread.queueEvent(new WatchedEvent( Watcher.Event.EventType.None, authState,null)); &#125; &#125; to = readTimeout - clientCnxnSocket.getIdleRecv(); &#125; else &#123; to = connectTimeout - clientCnxnSocket.getIdleRecv(); &#125; //to,表示客户端距离timeout还剩多少时间，准备发起ping连接 if (to &lt;= 0) &#123;//表示已经超时了。 String warnInfo; warnInfo = "Client session timed out, have not heard from server in " + clientCnxnSocket.getIdleRecv() + "ms" + " for sessionid 0x" + Long.toHexString(sessionId); LOG.warn(warnInfo); throw new SessionTimeoutException(warnInfo); &#125; if (state.isConnected()) &#123; //计算下一次ping请求的时间 int timeToNextPing = readTimeout / 2 - clientCnxnSocket.getIdleSend() - ((clientCnxnSocket.getIdleSend() &gt; 1000) ? 1000 : 0); //send a ping request either time is due or no packet sent out within MAX_SEND_PING_INTERVAL if (timeToNextPing &lt;= 0 || clientCnxnSocket.getIdleSend() &gt; MAX_SEND_PING_INTERVAL) &#123; sendPing(); //发送ping请求 clientCnxnSocket.updateLastSend(); &#125; else &#123; if (timeToNextPing &lt; to) &#123; to = timeToNextPing; &#125; &#125; &#125; // If we are in read-only mode, seek for read/write server if (state == States.CONNECTEDREADONLY) &#123; long now = Time.currentElapsedTime(); int idlePingRwServer = (int) (now - lastPingRwServer); if (idlePingRwServer &gt;= pingRwTimeout) &#123; lastPingRwServer = now; idlePingRwServer = 0; pingRwTimeout = Math.min(2*pingRwTimeout, maxPingRwTimeout); pingRwServer(); &#125; to = Math.min(to, pingRwTimeout - idlePingRwServer); &#125; 调用clientCnxnSocket，发起传输 其中 pendingQueue是一个用来存放已经发送、等待回应的Packet队列，clientCnxnSocket默认使用ClientCnxnSocketNIO（ps：还记得在哪里初始化吗？在实例化zookeeper的时候） clientCnxnSocket.doTransport(to, pendingQueue, ClientCnxn.this); &#125; catch (Throwable e) &#123; if (closing) &#123; if (LOG.isDebugEnabled()) &#123; // closing so this is expected LOG.debug("An exception was thrown while closing send thread for session 0x" + Long.toHexString(getSessionId()) + " : " + e.getMessage()); &#125; break; &#125; else &#123; // this is ugly, you have a better way speak up if (e instanceof SessionExpiredException) &#123; LOG.info(e.getMessage() + ", closing socket connection"); &#125; else if (e instanceof SessionTimeoutException) &#123; LOG.info(e.getMessage() + RETRY_CONN_MSG); &#125; else if (e instanceof EndOfStreamException) &#123; LOG.info(e.getMessage() + RETRY_CONN_MSG); &#125; else if (e instanceof RWServerFoundException) &#123; LOG.info(e.getMessage()); &#125; else &#123; LOG.warn( "Session 0x" + Long.toHexString(getSessionId()) + " for server " + clientCnxnSocket.getRemoteSocketAddress() + ", unexpected error" + RETRY_CONN_MSG, e); &#125; // At this point, there might still be new packets appended to outgoingQueue. // they will be handled in next connection or cleared up if closed. cleanup(); if (state.isAlive()) &#123; eventThread.queueEvent(new WatchedEvent( Event.EventType.None, Event.KeeperState.Disconnected, null)); &#125; clientCnxnSocket.updateNow(); clientCnxnSocket.updateLastSendAndHeard(); &#125; &#125; &#125; synchronized (state) &#123; // When it comes to this point, it guarantees that later queued // packet to outgoingQueue will be notified of death. cleanup(); &#125; clientCnxnSocket.close(); if (state.isAlive()) &#123; eventThread.queueEvent(new WatchedEvent(Event.EventType.None, Event.KeeperState.Disconnected, null)); &#125; ZooTrace.logTraceMessage(LOG, ZooTrace.getTextTraceLevel(), "SendThread exited loop for session: 0x" + Long.toHexString(getSessionId())); &#125; client 和 server的网络交互doTransport有两种实现，一种java nio，另一种是netty 这里就是sendThread的run方法，发送数据的具体代码。pendingQueue表示处于已经发送过等待响应的packet队列。outgoingQueue为待发送的数据包队列。这里先从outgoingQueue.poll出一个package，准备发送。再调用doWrite(pendingQueue, head, cnxn)放入pendingQueue中，等待server的响应。 12345678910111213141516171819202122232425262728293031323334353637@Override void doTransport(int waitTimeOut, List&lt;Packet&gt; pendingQueue, ClientCnxn cnxn) throws IOException, InterruptedException &#123; try &#123; if (!firstConnect.await(waitTimeOut, TimeUnit.MILLISECONDS)) &#123; return; &#125; Packet head = null; if (needSasl.get()) &#123; if (!waitSasl.tryAcquire(waitTimeOut, TimeUnit.MILLISECONDS)) &#123; return; &#125; &#125; else &#123; //判断outgoingQueue是否存在待发送的数据包，不存在则直接返回 if ((head = outgoingQueue.poll(waitTimeOut, TimeUnit.MILLISECONDS)) == null) &#123; return; &#125; &#125; // check if being waken up on closing. if (!sendThread.getZkState().isAlive()) &#123; // adding back the patck to notify of failure in conLossPacket(). addBack(head); return; &#125; // channel disconnection happened if (disconnected.get()) &#123; //异常流程，channel关闭了，讲当前的packet添加到addBack中 addBack(head); throw new EndOfStreamException("channel for sessionid 0x" + Long.toHexString(sessionId) + " is lost"); &#125; if (head != null) &#123; //如果当前存在需要发送的数据包，则调用doWrite方法，pendingQueue表示处于已经发送过等待响应的packet队列 doWrite(pendingQueue, head, cnxn); &#125; &#125; finally &#123; updateNow(); &#125; &#125; DoWrite方法将当前的packet添加到pendingQueue队列中 1234567891011121314151617181920private void doWrite(List&lt;Packet&gt; pendingQueue, Packet p, ClientCnxn cnxn) &#123; updateNow(); while (true) &#123; if (p != WakeupPacket.getInstance()) &#123; if ((p.requestHeader != null) &amp;&amp; //判断请求头以及判断当前请求类型不是ping或者auth操作 (p.requestHeader.getType() != ZooDefs.OpCode.ping) &amp;&amp; (p.requestHeader.getType() != ZooDefs.OpCode.auth)) &#123; p.requestHeader.setXid(cnxn.getXid()); //设置xid，这个xid用来区分请求类型 synchronized (pendingQueue) &#123; pendingQueue.add(p); //将当前的packet添加到pendingQueue队列中 &#125; &#125; sendPkt(p); //将数据包发送出去 &#125; if (outgoingQueue.isEmpty()) &#123; break; &#125; p = outgoingQueue.remove(); &#125;&#125; sendPkt通过nio channel发送字节缓存到服务端 12345678private void sendPkt(Packet p) &#123; // Assuming the packet will be sent out successfully. Because if it fails, // the channel will close and clean up queues. p.createBB(); //序列化请求数据 updateLastSend(); //更新最后一次发送updateLastSend sentCount++; //更新发送次数 channel.write(ChannelBuffers.wrappedBuffer(p.bb)); //通过nio channel发送字节缓存到服务端 &#125; createBB1234567891011121314151617181920212223public void createBB() &#123; try &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); boa.writeInt(-1, "len"); // We'll fill this in later if (requestHeader != null) &#123; requestHeader.serialize(boa, "header"); //序列化header头(requestHeader) &#125; if (request instanceof ConnectRequest) &#123; request.serialize(boa, "connect"); // append "am-I-allowed-to-be-readonly" flag boa.writeBool(readOnly, "readOnly"); &#125; else if (request != null) &#123; request.serialize(boa, "request"); //序列化request(request) &#125; baos.close(); this.bb = ByteBuffer.wrap(baos.toByteArray()); this.bb.putInt(this.bb.capacity() - 4); this.bb.rewind(); &#125; catch (IOException e) &#123; LOG.warn("Ignoring unexpected exception", e); &#125; &#125; 从createBB方法中，我们看到在底层实际的网络传输序列化中，zookeeper只会讲requestHeader和request两个属性进行序列化，即只有这两个会被序列化到底层字节数组中去进行网络传输，不会将watchRegistration相关的信息进行网络传输。 总结用户调用exists注册监听以后，会做几个事情 讲请求数据封装为packet，添加到outgoingQueue SendThread这个线程会执行数据发送操作，主要是将outgoingQueue队列中的数据发送到服务端 通过clientCnxnSocket.doTransport(to, pendingQueue, ClientCnxn.this); 其中ClientCnxnSocket只zookeeper客户端和服务端的连接通信的封装，有两个具体的实现类ClientCnxnSocketNetty和ClientCnxnSocketNIO;具体使用哪一个类来实现发送，是在初始化过程是在实例化Zookeeper的时候设置的，代码如下 12345678910111213141516171819cnxn = new ClientCnxn(connectStringParser.getChrootPath(), hostProvider, sessionTimeout, this, watchManager, getClientCnxnSocket(), canBeReadOnly); private ClientCnxnSocket getClientCnxnSocket() throws IOException &#123; String clientCnxnSocketName = getClientConfig().getProperty( ZKClientConfig.ZOOKEEPER_CLIENT_CNXN_SOCKET); if (clientCnxnSocketName == null) &#123; clientCnxnSocketName = ClientCnxnSocketNIO.class.getName(); &#125; try &#123; Constructor&lt;?&gt; clientCxnConstructor = Class.forName(clientCnxnSocketName).getDeclaredConstructor(ZKClientConfig.class); ClientCnxnSocket clientCxnSocket = (ClientCnxnSocket) clientCxnConstructor.newInstance(getClientConfig()); return clientCxnSocket; &#125; catch (Exception e) &#123; IOException ioe = new IOException("Couldn't instantiate " + clientCnxnSocketName); ioe.initCause(e); throw ioe; &#125; &#125; 基于第3步，最终会在ClientCnxnSocketNetty方法中执行sendPkt将请求的数据包发送到服务端 服务端接收请求处理流程服务端有一个NettyServerCnxn类，用来处理客户端发送过来的请求。 通过zks.processPacket(this, bb)处理客户端传过来的数据包。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public void receiveMessage(ChannelBuffer message) &#123; try &#123; while(message.readable() &amp;&amp; !throttled) &#123; if (bb != null) &#123; //ByteBuffer不为空 if (LOG.isTraceEnabled()) &#123; LOG.trace("message readable " + message.readableBytes() + " bb len " + bb.remaining() + " " + bb); ByteBuffer dat = bb.duplicate(); dat.flip(); LOG.trace(Long.toHexString(sessionId) + " bb 0x" + ChannelBuffers.hexDump( ChannelBuffers.copiedBuffer(dat))); &#125; //bb剩余空间大于message中可读字节大小 if (bb.remaining() &gt; message.readableBytes()) &#123; int newLimit = bb.position() + message.readableBytes(); bb.limit(newLimit); &#125; // 将message写入bb中 message.readBytes(bb); bb.limit(bb.capacity()); if (LOG.isTraceEnabled()) &#123; LOG.trace("after readBytes message readable " + message.readableBytes() + " bb len " + bb.remaining() + " " + bb); ByteBuffer dat = bb.duplicate(); dat.flip(); LOG.trace("after readbytes " + Long.toHexString(sessionId) + " bb 0x" + ChannelBuffers.hexDump( ChannelBuffers.copiedBuffer(dat))); &#125; if (bb.remaining() == 0) &#123; // 已经读完message，表示内容已经全部接收 packetReceived(); // 统计接收信息 bb.flip(); ZooKeeperServer zks = this.zkServer; if (zks == null || !zks.isRunning()) &#123;//Zookeeper服务器为空 ,说明服务端挂了 throw new IOException("ZK down"); &#125; if (initialized) &#123; //处理客户端传过来的数据包 zks.processPacket(this, bb); if (zks.shouldThrottle(outstandingCount.incrementAndGet())) &#123; disableRecvNoWait(); &#125; &#125; else &#123; LOG.debug("got conn req request from " + getRemoteSocketAddress()); zks.processConnectRequest(this, bb); initialized = true; &#125; bb = null; &#125; &#125; else &#123; //bb为null的情况，大家自己去看，我就不细讲了 if (LOG.isTraceEnabled()) &#123; LOG.trace("message readable " + message.readableBytes() + " bblenrem " + bbLen.remaining()); ByteBuffer dat = bbLen.duplicate(); dat.flip(); LOG.trace(Long.toHexString(sessionId) + " bbLen 0x" + ChannelBuffers.hexDump( ChannelBuffers.copiedBuffer(dat))); &#125; if (message.readableBytes() &lt; bbLen.remaining()) &#123; bbLen.limit(bbLen.position() + message.readableBytes()); &#125; message.readBytes(bbLen); bbLen.limit(bbLen.capacity()); if (bbLen.remaining() == 0) &#123; bbLen.flip(); if (LOG.isTraceEnabled()) &#123; LOG.trace(Long.toHexString(sessionId) + " bbLen 0x" + ChannelBuffers.hexDump( ChannelBuffers.copiedBuffer(bbLen))); &#125; int len = bbLen.getInt(); if (LOG.isTraceEnabled()) &#123; LOG.trace(Long.toHexString(sessionId) + " bbLen len is " + len); &#125; bbLen.clear(); if (!initialized) &#123; if (checkFourLetterWord(channel, message, len)) &#123; return; &#125; &#125; if (len &lt; 0 || len &gt; BinaryInputArchive.maxBuffer) &#123; throw new IOException("Len error " + len); &#125; bb = ByteBuffer.allocate(len); &#125; &#125; &#125; &#125; catch(IOException e) &#123; LOG.warn("Closing connection to " + getRemoteSocketAddress(), e); close(); &#125; &#125; NettyServerCnxnZookeeperServer-zks.processPacket(this, bb);处理客户端传送过来的数据包，封装请求对象，并发送。 12Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(), h.getType(), incomingBuffer, cnxn.getAuthInfo()); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public void processPacket(ServerCnxn cnxn, ByteBuffer incomingBuffer) throws IOException &#123; // We have the request, now process and setup for next InputStream bais = new ByteBufferInputStream(incomingBuffer); BinaryInputArchive bia = BinaryInputArchive.getArchive(bais); RequestHeader h = new RequestHeader(); h.deserialize(bia, "header"); //反序列化客户端header头信息 // Through the magic of byte buffers, txn will not be // pointing // to the start of the txn incomingBuffer = incomingBuffer.slice(); if (h.getType() == OpCode.auth) &#123; //判断当前操作类型，如果是auth操作，则执行下面的代码 LOG.info("got auth packet " + cnxn.getRemoteSocketAddress()); AuthPacket authPacket = new AuthPacket(); ByteBufferInputStream.byteBuffer2Record(incomingBuffer, authPacket); String scheme = authPacket.getScheme(); ServerAuthenticationProvider ap = ProviderRegistry.getServerProvider(scheme); Code authReturn = KeeperException.Code.AUTHFAILED; if(ap != null) &#123; try &#123; authReturn = ap.handleAuthentication(new ServerAuthenticationProvider.ServerObjs(this, cnxn), authPacket.getAuth()); &#125; catch(RuntimeException e) &#123; LOG.warn("Caught runtime exception from AuthenticationProvider: " + scheme + " due to " + e); authReturn = KeeperException.Code.AUTHFAILED; &#125; &#125; if (authReturn == KeeperException.Code.OK) &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug("Authentication succeeded for scheme: " + scheme); &#125; LOG.info("auth success " + cnxn.getRemoteSocketAddress()); ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.OK.intValue()); cnxn.sendResponse(rh, null, null); &#125; else &#123; if (ap == null) &#123; LOG.warn("No authentication provider for scheme: " + scheme + " has " + ProviderRegistry.listProviders()); &#125; else &#123; LOG.warn("Authentication failed for scheme: " + scheme); &#125; // send a response... ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.AUTHFAILED.intValue()); cnxn.sendResponse(rh, null, null); // ... and close connection cnxn.sendBuffer(ServerCnxnFactory.closeConn); cnxn.disableRecv(); &#125; return; &#125; else &#123; //如果不是授权操作，再判断是否为sasl操作 if (h.getType() == OpCode.sasl) &#123; Record rsp = processSasl(incomingBuffer,cnxn); ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.OK.intValue()); cnxn.sendResponse(rh,rsp, "response"); // not sure about 3rd arg..what is it? return; &#125; else &#123;//最终进入这个代码块进行处理 //封装请求对象 Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(), h.getType(), incomingBuffer, cnxn.getAuthInfo()); si.setOwner(ServerCnxn.me); // Always treat packet from the client as a possible // local request. setLocalSessionFlag(si); submitRequest(si); //提交请求 &#125; &#125; cnxn.incrOutstandingRequests(h); &#125; submitRequest负责在服务端提交当前请求 123456789101112131415161718192021222324252627282930313233343536373839public void submitRequest(Request si) &#123; if (firstProcessor == null) &#123; //processor处理器，request过来以后会经历一系列处理器的处理过程 synchronized (this) &#123; try &#123; // Since all requests are passed to the request // processor it should wait for setting up the request // processor chain. The state will be updated to RUNNING // after the setup. while (state == State.INITIAL) &#123; wait(1000); &#125; &#125; catch (InterruptedException e) &#123; LOG.warn("Unexpected interruption", e); &#125; if (firstProcessor == null || state != State.RUNNING) &#123; throw new RuntimeException("Not started"); &#125; &#125; &#125; try &#123; touch(si.cnxn); boolean validpacket = Request.isValid(si.type); //判断是否合法 if (validpacket) &#123; firstProcessor.processRequest(si); 调用firstProcessor发起请求，而这个firstProcess是一个接口，有多个实现类，具体的调用链是怎么样的？往下看吧 if (si.cnxn != null) &#123; incInProcess(); &#125; &#125; else &#123; LOG.warn("Received packet at server of unknown type " + si.type); new UnimplementedRequestProcessor().processRequest(si); &#125; &#125; catch (MissingSessionException e) &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug("Dropping request: " + e.getMessage()); &#125; &#125; catch (RequestProcessorException e) &#123; LOG.error("Unable to process request:" + e.getMessage(), e); &#125; &#125; firstProcessor的请求链组成 firstProcessor的初始化是在ZookeeperServer的setupRequestProcessor中完成的，代码如下 1234567protected void setupRequestProcessors() &#123; RequestProcessor finalProcessor = new FinalRequestProcessor(this); RequestProcessor syncProcessor = new SyncRequestProcessor(this, finalProcessor); ((SyncRequestProcessor)syncProcessor).start(); firstProcessor = new PrepRequestProcessor(this, syncProcessor);//需要注意的是，PrepRequestProcessor中传递的是一个syncProcessor ((PrepRequestProcessor)firstProcessor).start(); &#125; 从上面我们可以看到firstProcessor的实例是一个PrepRequestProcessor，而这个构造方法中又传递了一个Processor构成了一个调用链。 RequestProcessor syncProcessor = new SyncRequestProcessor(this, finalProcessor); 而syncProcessor的构造方法传递的又是一个Processor，对应的是FinalRequestProcessor 所以整个调用链是PrepRequestProcessor -&gt; SyncRequestProcessor -&gt;FinalRequestProcessor PredRequestProcessor.processRequest(si);通过上面了解到调用链关系以后，我们继续再看firstProcessor.processRequest(si)； 会调用到PrepRequestProcessor 唉，很奇怪，processRequest只是把request添加到submittedRequests中，根据前面的经验，很自然的想到这里又是一个异步操作。而subittedRequests又是一个阻塞队列 LinkedBlockingQueue&lt;Request&gt; submittedRequests = new LinkedBlockingQueue&lt;Request&gt;(); 而PrepRequestProcessor这个类又继承了线程类，因此我们直接找到当前类中的run方法如下 1234567891011121314151617181920212223242526public void run() &#123; try &#123; while (true) &#123; Request request = submittedRequests.take(); //ok，从队列中拿到请求进行处理 long traceMask = ZooTrace.CLIENT_REQUEST_TRACE_MASK; if (request.type == OpCode.ping) &#123; traceMask = ZooTrace.CLIENT_PING_TRACE_MASK; &#125; if (LOG.isTraceEnabled()) &#123; ZooTrace.logRequest(LOG, traceMask, 'P', request, ""); &#125; if (Request.requestOfDeath == request) &#123; break; &#125; pRequest(request); //调用pRequest进行预处理 &#125; &#125; catch (RequestProcessorException e) &#123; if (e.getCause() instanceof XidRolloverException) &#123; LOG.info(e.getCause().getMessage()); &#125; handleException(this.getName(), e); &#125; catch (Exception e) &#123; handleException(this.getName(), e); &#125; LOG.info("PrepRequestProcessor exited loop!"); &#125; pRequest预处理这块的代码太长，就不好贴了。前面的N行代码都是根据当前的OP类型进行判断和做相应的处理，在这个方法中的最后一行中，我们会看到如下代码 1nextProcessor.processRequest(request); 很显然，nextProcessor对应的应该是SyncRequestProcessor SyncRequestProcessor. processRequest1234public void processRequest(Request request) &#123; // request.addRQRec("&gt;sync"); queuedRequests.add(request); &#125; 这个方法的代码也是一样，基于异步化的操作，把请求添加到queuedRequets中，那么我们继续在当前类找到run方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public void run() &#123; try &#123; int logCount = 0; // we do this in an attempt to ensure that not all of the servers // in the ensemble take a snapshot at the same time int randRoll = r.nextInt(snapCount/2); while (true) &#123; Request si = null; //从阻塞队列中获取请求 if (toFlush.isEmpty()) &#123; si = queuedRequests.take(); &#125; else &#123; si = queuedRequests.poll(); if (si == null) &#123; flush(toFlush); continue; &#125; &#125; if (si == requestOfDeath) &#123; break; &#125; if (si != null) &#123; // track the number of records written to the log //下面这块代码，粗略看来是触发快照操作，启动一个处理快照的线程 if (zks.getZKDatabase().append(si)) &#123; logCount++; if (logCount &gt; (snapCount / 2 + randRoll)) &#123; randRoll = r.nextInt(snapCount/2); // roll the log zks.getZKDatabase().rollLog(); // take a snapshot if (snapInProcess != null &amp;&amp; snapInProcess.isAlive()) &#123; LOG.warn("Too busy to snap, skipping"); &#125; else &#123; snapInProcess = new ZooKeeperThread("Snapshot Thread") &#123; public void run() &#123; try &#123; zks.takeSnapshot(); &#125; catch(Exception e) &#123; LOG.warn("Unexpected exception", e); &#125; &#125; &#125;; snapInProcess.start(); &#125; logCount = 0; &#125; &#125; else if (toFlush.isEmpty()) &#123; // optimization for read heavy workloads // iff this is a read, and there are no pending // flushes (writes), then just pass this to the next // processor if (nextProcessor != null) &#123; nextProcessor.processRequest(si); //继续调用下一个处理器来处理请求 if (nextProcessor instanceof Flushable) &#123; ((Flushable)nextProcessor).flush(); &#125; &#125; continue; &#125; toFlush.add(si); if (toFlush.size() &gt; 1000) &#123; flush(toFlush); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; handleException(this.getName(), t); &#125; finally&#123; running = false; &#125; LOG.info("SyncRequestProcessor exited!"); &#125; FinalRequestProcessor. processRequest这个方法就是我们在课堂上分析到的方法了，FinalRequestProcessor.processRequest方法并根据Request对象中的操作更新内存中Session信息或者znode数据。 这块代码有小300多行，就不全部贴出来了，我们直接定位到关键代码，根据客户端的OP类型找到如下的代码 1234567891011121314151617 case OpCode.exists: &#123; lastOp = "EXIS"; // TODO we need to figure out the security requirement for this! ExistsRequest existsRequest = new ExistsRequest(); //反序列化 (将ByteBuffer反序列化成为ExitsRequest.这个就是我们在客户端发起请求的时候传递过来的Request对象 ByteBufferInputStream.byteBuffer2Record(request.request, existsRequest); String path = existsRequest.getPath(); //得到请求的路径 if (path.indexOf('\0') != -1) &#123; throw new KeeperException.BadArgumentsException(); &#125; //终于找到一个很关键的代码，判断请求的getWatch是否存在，如果存在，则传递cnxn（servercnxn）//对于exists请求，需要监听data变化事件，添加watcher Stat stat = zks.getZKDatabase().statNode(path, existsRequest.getWatch() ? cnxn : null); rsp = new ExistsResponse(stat); //在服务端内存数据库中根据路径得到结果进行组装，设置为ExistsResponse break; &#125; statNode这个方法做了什么？123public Stat statNode(String path, ServerCnxn serverCnxn) throws KeeperException.NoNodeException &#123; return dataTree.statNode(path, serverCnxn); &#125; 一路向下，在下面这个方法中，讲ServerCnxn向上转型为Watcher了。 因为ServerCnxn实现了Watcher接口 123456789101112131415public Stat statNode(String path, Watcher watcher) throws KeeperException.NoNodeException &#123; Stat stat = new Stat(); DataNode n = nodes.get(path); //获得节点数据 if (watcher != null) &#123; //如果watcher不为空，则讲当前的watcher和path进行绑定 dataWatches.addWatch(path, watcher); &#125; if (n == null) &#123; throw new KeeperException.NoNodeException(); &#125; synchronized (n) &#123; n.copyStat(stat); return stat; &#125; &#125; WatchManager.addWatch(path, watcher);12345678910111213141516171819synchronized void addWatch(String path, Watcher watcher) &#123; HashSet&lt;Watcher&gt; list = watchTable.get(path); //判断watcherTable中是否存在当前路径对应的watcher if (list == null) &#123; //不存在则主动添加 // don't waste memory if there are few watches on a node // rehash when the 4th entry is added, doubling size thereafter // seems like a good compromise list = new HashSet&lt;Watcher&gt;(4); // 新生成watcher集合 watchTable.put(path, list); &#125; list.add(watcher); //添加到watcher表 HashSet&lt;String&gt; paths = watch2Paths.get(watcher); if (paths == null) &#123; // cnxns typically have many watches, so use default cap here paths = new HashSet&lt;String&gt;(); watch2Paths.put(watcher, paths); // 设置watcher到节点路径的映射 &#125; paths.add(path); // 将路径添加至paths集合 &#125; 其大致流程如下 ① 通过传入的path（节点路径）从watchTable获取相应的watcher集合，进入② ② 判断①中的watcher是否为空，若为空，则进入③，否则，进入④ ③ 新生成watcher集合，并将路径path和此集合添加至watchTable中，进入④ ④ 将传入的watcher添加至watcher集合，即完成了path和watcher添加至watchTable的步骤，进入⑤ ⑤ 通过传入的watcher从watch2Paths中获取相应的path集合，进入⑥ ⑥ 判断path集合是否为空，若为空，则进入⑦，否则，进入⑧ ⑦ 新生成path集合，并将watcher和paths添加至watch2Paths中，进入⑧ ⑧ 将传入的path（节点路径）添加至path集合，即完成了path和watcher添加至watch2Paths的步骤 总结调用关系链如下 NettyServerCnxn(processPackage) -&gt; ZookeeperServer(processRequest) -&gt; PredRequestProcessor(processRequest) -&gt; SyncRequestProcessor(processRequest) -&gt; FinalRequestProcessor(processRequest) -&gt; ZKDataBase (statNode)-&gt; DataTree(statNode) -&gt; WatchManager(addWatch) 客户端接收服务端处理完成的响应ClientCnxnSocketNetty.messageReceived服务端处理完成以后，会通过NettyServerCnxn.sendResponse发送返回的响应信息， 客户端会在ClientCnxnSocketNetty.messageReceived接收服务端的返回 12345678910111213141516171819202122232425262728293031323334public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; updateNow(); ChannelBuffer buf = (ChannelBuffer) e.getMessage(); while (buf.readable()) &#123; if (incomingBuffer.remaining() &gt; buf.readableBytes()) &#123; int newLimit = incomingBuffer.position() + buf.readableBytes(); incomingBuffer.limit(newLimit); &#125; buf.readBytes(incomingBuffer); incomingBuffer.limit(incomingBuffer.capacity()); if (!incomingBuffer.hasRemaining()) &#123; incomingBuffer.flip(); if (incomingBuffer == lenBuffer) &#123; recvCount++; readLength(); &#125; else if (!initialized) &#123; readConnectResult(); lenBuffer.clear(); incomingBuffer = lenBuffer; initialized = true; updateLastHeard(); &#125; else &#123; sendThread.readResponse(incomingBuffer); //收到消息以后触发SendThread.readResponse方法 lenBuffer.clear(); incomingBuffer = lenBuffer; updateLastHeard(); &#125; &#125; &#125; wakeupCnxn(); &#125; SendThread. readResponse这个方法里面主要的流程如下 首先读取header，如果其xid == -2，表明是一个ping的response，return 如果xid是 -4 ，表明是一个AuthPacket的response return 如果xid是 -1，表明是一个notification,此时要继续读取并构造一个enent，通过EventThread.queueEvent发送，return 其它情况下： 从pendingQueue拿出一个Packet，校验后更新packet信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118void readResponse(ByteBuffer incomingBuffer) throws IOException &#123; ByteBufferInputStream bbis = new ByteBufferInputStream( incomingBuffer); BinaryInputArchive bbia = BinaryInputArchive.getArchive(bbis); ReplyHeader replyHdr = new ReplyHeader(); replyHdr.deserialize(bbia, "header"); //反序列化header if (replyHdr.getXid() == -2) &#123; //? // -2 is the xid for pings if (LOG.isDebugEnabled()) &#123; LOG.debug("Got ping response for sessionid: 0x" + Long.toHexString(sessionId) + " after " + ((System.nanoTime() - lastPingSentNs) / 1000000) + "ms"); &#125; return; &#125; if (replyHdr.getXid() == -4) &#123; // -4 is the xid for AuthPacket if(replyHdr.getErr() == KeeperException.Code.AUTHFAILED.intValue()) &#123; state = States.AUTH_FAILED; eventThread.queueEvent( new WatchedEvent(Watcher.Event.EventType.None, Watcher.Event.KeeperState.AuthFailed, null) ); &#125; if (LOG.isDebugEnabled()) &#123; LOG.debug("Got auth sessionid:0x" + Long.toHexString(sessionId)); &#125; return; &#125; if (replyHdr.getXid() == -1) &#123; //表示当前的消息类型为一个notification(意味着是服务端的一个响应事件) // -1 means notification if (LOG.isDebugEnabled()) &#123; LOG.debug("Got notification sessionid:0x" + Long.toHexString(sessionId)); &#125; WatcherEvent event = new WatcherEvent();//? event.deserialize(bbia, "response"); //反序列化响应信息 // convert from a server path to a client path if (chrootPath != null) &#123; String serverPath = event.getPath(); if(serverPath.compareTo(chrootPath)==0) event.setPath("/"); else if (serverPath.length() &gt; chrootPath.length()) event.setPath(serverPath.substring(chrootPath.length())); else &#123; LOG.warn("Got server path " + event.getPath() + " which is too short for chroot path " + chrootPath); &#125; &#125; WatchedEvent we = new WatchedEvent(event); if (LOG.isDebugEnabled()) &#123; LOG.debug("Got " + we + " for sessionid 0x" + Long.toHexString(sessionId)); &#125; eventThread.queueEvent( we ); return; &#125; // If SASL authentication is currently in progress, construct and // send a response packet immediately, rather than queuing a // response as with other packets. if (tunnelAuthInProgress()) &#123; GetSASLRequest request = new GetSASLRequest(); request.deserialize(bbia,"token"); zooKeeperSaslClient.respondToServer(request.getToken(), ClientCnxn.this); return; &#125; Packet packet; synchronized (pendingQueue) &#123; if (pendingQueue.size() == 0) &#123; throw new IOException("Nothing in the queue, but got " + replyHdr.getXid()); &#125; packet = pendingQueue.remove(); //因为当前这个数据包已经收到了响应，所以讲它从pendingQueued中移除 &#125; /* * Since requests are processed in order, we better get a response * to the first request! */ try &#123;//校验数据包信息，校验成功后讲数据包信息进行更新（替换为服务端的信息） if (packet.requestHeader.getXid() != replyHdr.getXid()) &#123; packet.replyHeader.setErr( KeeperException.Code.CONNECTIONLOSS.intValue()); throw new IOException("Xid out of order. Got Xid " + replyHdr.getXid() + " with err " + + replyHdr.getErr() + " expected Xid " + packet.requestHeader.getXid() + " for a packet with details: " + packet ); &#125; packet.replyHeader.setXid(replyHdr.getXid()); packet.replyHeader.setErr(replyHdr.getErr()); packet.replyHeader.setZxid(replyHdr.getZxid()); if (replyHdr.getZxid() &gt; 0) &#123; lastZxid = replyHdr.getZxid(); &#125; if (packet.response != null &amp;&amp; replyHdr.getErr() == 0) &#123; packet.response.deserialize(bbia, "response"); //获得服务端的响应，反序列化以后设置到packet.response属性中。所以我们可以在exists方法的最后一行通过packet.response拿到改请求的返回结果 &#125; if (LOG.isDebugEnabled()) &#123; LOG.debug("Reading reply sessionid:0x" + Long.toHexString(sessionId) + ", packet:: " + packet); &#125; &#125; finally &#123; finishPacket(packet); //最后调用finishPacket方法完成处理 &#125; &#125; finishPacket方法主要功能是把从 Packet 中取出对应的 Watcher 并注册到 ZKWatchManager 中去 123456789101112131415161718192021222324252627282930313233343536373839private void finishPacket(Packet p) &#123; int err = p.replyHeader.getErr(); if (p.watchRegistration != null) &#123; p.watchRegistration.register(err); //将事件注册到zkwatchemanager中watchRegistration，熟悉吗？在组装请求的时候，我们初始化了这个对象把watchRegistration 子类里面的 Watcher 实例放到 ZKWatchManager 的 existsWatches 中存储起来。 &#125; //将所有移除的监视事件添加到事件队列, 这样客户端能收到 “data/child 事件被移除”的事件类型 if (p.watchDeregistration != null) &#123; Map&lt;EventType, Set&lt;Watcher&gt;&gt; materializedWatchers = null; try &#123; materializedWatchers = p.watchDeregistration.unregister(err); for (Entry&lt;EventType, Set&lt;Watcher&gt;&gt; entry : materializedWatchers.entrySet()) &#123; Set&lt;Watcher&gt; watchers = entry.getValue(); if (watchers.size() &gt; 0) &#123; queueEvent(p.watchDeregistration.getClientPath(), err, watchers, entry.getKey()); // ignore connectionloss when removing from local // session p.replyHeader.setErr(Code.OK.intValue()); &#125; &#125; &#125; catch (KeeperException.NoWatcherException nwe) &#123; p.replyHeader.setErr(nwe.code().intValue()); &#125; catch (KeeperException ke) &#123; p.replyHeader.setErr(ke.code().intValue()); &#125; &#125; //cb就是AsnycCallback，如果为null，表明是同步调用的接口，不需要异步回掉，因此，直接notifyAll即可。 if (p.cb == null) &#123; synchronized (p) &#123; p.finished = true; p.notifyAll(); &#125; &#125; else &#123; p.finished = true; eventThread.queuePacket(p); &#125; &#125; watchRegistration12345678910111213public void register(int rc) &#123; if (shouldAddWatch(rc)) &#123; Map&lt;String, Set&lt;Watcher&gt;&gt; watches = getWatches(rc); // //通过子类的实现取得ZKWatchManager 中的 existsWatches synchronized(watches) &#123; Set&lt;Watcher&gt; watchers = watches.get(clientPath); if (watchers == null) &#123; watchers = new HashSet&lt;Watcher&gt;(); watches.put(clientPath, watchers); &#125; watchers.add(watcher); //将 Watcher 对象放到 ZKWatchManager 中的 existsWatches里面 &#125; &#125; &#125; 下面这段代码是客户端存储watcher的几个map集合，分别对应三种注册监听事件 1234567static class ZKWatchManager implements ClientWatchManager &#123; private final Map&lt;String, Set&lt;Watcher&gt;&gt; dataWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private final Map&lt;String, Set&lt;Watcher&gt;&gt; existWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private final Map&lt;String, Set&lt;Watcher&gt;&gt; childWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); 总的来说，当使用ZooKeeper 构造方法或者使用 getData、exists 和 getChildren 三个接口来向 ZooKeeper 服务器注册 Watcher 的时候，首先将此消息传递给服务端，传递成功后，服务端会通知客户端，然后客户端将该路径和Watcher对应关系存储起来备用。 EventThread.queuePacket()finishPacket方法最终会调用eventThread.queuePacket， 讲当前的数据包添加到等待事件通知的队列中 12345678910public void queuePacket(Packet packet) &#123; if (wasKilled) &#123; synchronized (waitingEvents) &#123; if (isRunning) waitingEvents.add(packet); else processEvent(packet); &#125; &#125; else &#123; waitingEvents.add(packet); &#125; &#125; 事件触发前面这么长的说明，只是为了清洗的说明事件的注册流程，最终的触发，还得需要通过事务型操作来完成 在我们最开始的案例中，通过如下代码去完成了事件的触发 1zookeeper.setData(“/mic”, “1”.getByte(),-1) ; //修改节点的值触发监听 前面的客户端和服务端对接的流程就不再重复讲解了，交互流程是一样的，唯一的差别在于事件触发了 服务端的事件响应DataTree.setData()12345678910111213141516171819202122232425public Stat setData(String path, byte data[], int version, long zxid, long time) throws KeeperException.NoNodeException &#123; Stat s = new Stat(); DataNode n = nodes.get(path); if (n == null) &#123; throw new KeeperException.NoNodeException(); &#125; byte lastdata[] = null; synchronized (n) &#123; lastdata = n.data; n.data = data; n.stat.setMtime(time); n.stat.setMzxid(zxid); n.stat.setVersion(version); n.copyStat(s); &#125; // now update if the path is in a quota subtree. String lastPrefix = getMaxPrefixWithQuota(path); if(lastPrefix != null) &#123; this.updateBytes(lastPrefix, (data == null ? 0 : data.length) - (lastdata == null ? 0 : lastdata.length)); &#125; dataWatches.triggerWatch(path, EventType.NodeDataChanged); //触发对应节点的NodeDataChanged事件 return s; &#125; WatcherManager. triggerWatch 12345678910111213141516171819202122232425262728Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) &#123; WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); // 根据事件类型、连接状态、节点路径创建WatchedEvent HashSet&lt;Watcher&gt; watchers; synchronized (this) &#123; watchers = watchTable.remove(path); // 从watcher表中移除path，并返回其对应的watcher集合 if (watchers == null || watchers.isEmpty()) &#123; if (LOG.isTraceEnabled()) &#123; ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, "No watchers for " + path); &#125; return null; &#125; for (Watcher w : watchers) &#123; // 遍历watcher集合 HashSet&lt;String&gt; paths = watch2Paths.get(w); // 根据watcher从watcher表中取出路径集合 if (paths != null) &#123; paths.remove(path); //移除路径 &#125; &#125; &#125; for (Watcher w : watchers) &#123; // 遍历watcher集合 if (supress != null &amp;&amp; supress.contains(w)) &#123; continue; &#125; w.process(e); //OK，重点又来了，w.process是做什么呢？ &#125; return watchers; &#125; w.process(e);还记得我们在服务端绑定事件的时候，watcher绑定是是什么？是ServerCnxn， 所以w.process(e)，其实调用的应该是ServerCnxn的process方法。而servercnxn又是一个抽象方法，有两个实现类，分别是：NIOServerCnxn和NettyServerCnxn。那接下来我们扒开NettyServerCnxn这个类的process方法看看究竟 123456789101112131415161718192021public void process(WatchedEvent event) &#123; ReplyHeader h = new ReplyHeader(-1, -1L, 0); if (LOG.isTraceEnabled()) &#123; ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, "Deliver event " + event + " to 0x" + Long.toHexString(this.sessionId) + " through " + this); &#125; // Convert WatchedEvent to a type that can be sent over the wire WatcherEvent e = event.getWrapper(); try &#123; sendResponse(h, e, "notification"); //look， 这个地方发送了一个事件，事件对象为WatcherEvent。完美 &#125; catch (IOException e1) &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug("Problem sending to " + getRemoteSocketAddress(), e1); &#125; close(); &#125; &#125; 那接下里，客户端会收到这个response，触发SendThread.readResponse方法 客户端处理事件响应SendThread.readResponse这块代码上面已经贴过了，所以我们只挑选当前流程的代码进行讲解，按照前面我们将到过的，notifacation通知消息的xid为-1，意味着~直接找到-1的判断进行分析在下面代码标红处. eventThread.queueEvent SendThread 接收到服务端的通知事件后，会通过调用 EventThread 类的 queueEvent 方法将事件传给 EventThread 线程，queueEvent 方法根据该通知事件，从 ZKWatchManager 中取出所有相关的 Watcher，如果获取到相应的Watcher，就会让Watcher移除失效。 Meterialize方法通过dataWatches或者existWatches或者childWatches的remove取出对应的watch，表明客户端watch也是注册一次就移除同时需要根据keeperState、eventType和path返回应该被通知的Watcher集合 waitingEvents.add最后一步，接近真相了waitingEvents是EventThread这个线程中的阻塞队列，很明显，又是在我们第一步操作的时候实例化的一个线程。从名字可以指导，waitingEvents 是一个待处理 Watcher 的队列，EventThread 的 run() 方法会不断从队列中取数据，交由 processEvent 方法处理： ProcessEvent由于这块的代码太长，我只把核心的代码贴出来，这里就是处理事件触发的核心代]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper原生API使用]]></title>
    <url>%2F2018%2F06%2F09%2Fzookeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_05_%E5%8E%9F%E7%94%9FAPI%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1、准备工作1.1、jar包12345&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.8&lt;/version&gt;&lt;/dependency&gt; 1.2、准备工作本人使用的是VMware + CentOS7环境，即虚拟机，这里需要将zookeeper客户端访问接口对外暴露。参考：Centos防火墙设置与端口开放的方法123456// 在指定区域打开端口firewall-cmd --zone=public --add-port=80/tcpfirewall-cmd --zone=public --add-port=80/tcp --permanent // 永久生效// 重启防火墙firewall-cmd --reload 2、创建连接、创建节点、修改节点、删除节点2.1、创建连接12345// org.apache.zookeeper.ZooKeeperpublic ZooKeeper(String connectString, int sessionTimeout, Watcher watcher)public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly)public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd)public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) 参数 含义 connectString Zookeeper服务器的地址和端口号ip:port。集群环境使用逗号隔开。 sessionTimeout 超时时间，超过一定时间不在连接 watcher 监听事件 canBeReadOnly 表示当前new的对象只能执行读操作，不能执行写操作。默认：false sessionId 因Zookeeper的重连机制，即断开连接后，在一定时间内可再次连接，保持同一个会话。zookeeper.getSessionId()可以在断开连接前获取sessionId sessionPasswd 因Zookeeper的重连机制，即断开连接后，在一定时间内可再次连接，保持同一个会话。zookeeper.getSessionPasswd()sessionPasswd 参考：Zookeeper实例原生API–复用sessionId和sessionPasswd 2.2、创建节点12String create(final String path, byte[] data, List&lt;ACL&gt; acl, CreateMode createMode)void create(final String path, byte[] data, List&lt;ACL&gt; acl, CreateMode createMode, StringCallback cb, Object ctx) 参数 含义 path 被创建节点的路径 data 被创建节点的值 acl acl策略。详见zookeeper客户端的使用的1.6章节 createMode 节点类型，临时或者持久，有序节点等。详见zookeeper客户端的使用的1.2、1.3章节 cb 异步创建方法参数。注册的回调函数，需实现StringCallback接口。数据节点创建完成之后，会调用此方法进行业务逻辑处理。主要针对public void processResult(int rc, String path, Object ctx, String name)接口进行重写。参考：Zookeeper客户端API之创建节点（七） ctx 异步创建方法参数。用户传递一个对象，可以在回调方法执行时使用 临时节点下不能创建子节点 因为是原生API，故不能在没有父节点的前提下直接创建子节点 2.2.1、关于StringCallback转自：Zookeeper客户端API之创建节点（七） StringCallback接口继承了AsyncCallback接口，来实现回调时的业务处理。其中AsyncCallback接口还包8个回调接口：StatCallback、DataCallback、ACLCallback、ChildrenCallback、Children2Callback、VoidCallback、MultiCallback、StringCallback。可以在不同的异步接口中实现不同的回调接口。 StringCallback接口的public void processResult(int rc, String path, Object ctx, String name)方法。 参数 含义 rc 服务器的响应码，即Event.KeeperState，0表示调用成功，-4表示连接已断开，-110表示指定节点已存在，-112表示会话已过期。 path 调用create方法时传入的path。 ctx 调用create方法时传入的ctx。 name 创建成功的节点名称。 2.3、修改节点12Stat setData(final String path, byte data[], int version)public void setData(final String path, byte data[], int version, StatCallback cb, Object ctx) 参数 含义 path 被修改节点的路径 data 被修改节点的新值 version 代表节点的版本号，如果该值与zookeeper服务器此节点的dataVersion属性值不相同，则修改失败。 -1代表忽略版本号的作用，强制修改！ cb 异步创建方法参数。注册的回调函数，需实现StatCallback接口。数据节点创建完成之后，会调用此方法进行业务逻辑处理。 ctx 异步创建方法参数。用户传递一个对象，可以在回调方法执行时使用 返回值Stat 描述一个节点的信息，具体可以查看zookeeper客户端的使用的章节2 关于StatCallback，与StringCallback类似。 实现的方法是public void processResult(int rc, String path, Object ctx, Stat stat) 2.4、删除节点12void delete(final String path, int version)void delete(final String path, int version, VoidCallback cb, Object ctx) 与修改节点setData方法类似。 因为是原始API，不允许删除存在子节点的节点 2.5、Demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class ApiZookeeper&#123; // 集群环境用,隔开 private static final String CONNECTSTRING = "192.168.27.128:2181"; private static ZooKeeper zookeeper; public static void main(String[] args) throws Exception &#123; connect(); createNode("/xych", "xych"); // createNode("/xych1/lanboo","lanboo"); // 报错 setNode("/xych", "XYCH", -1); deleteNode("/xych", -1); &#125; /** * 删除节点 */ public static void deleteNode(String nodePath, int version) throws Exception &#123; zookeeper.delete(nodePath, version); System.out.println("删除成功"); &#125; /** * 修改节点 */ public static void setNode(String nodePath, String value, int version) throws Exception &#123; Stat stat = zookeeper.setData(nodePath, value.getBytes(), version); System.out.println("修改成功 " + stat); &#125; /** * 创建节点 */ public static void createNode(String nodePath, String value) throws Exception &#123; String result = zookeeper.create(nodePath, value.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); System.out.println("创建成功 " + result); &#125; /** * 创建连接 */ public static void connect() throws Exception &#123; // 使用CountDownLatch，使主线程等待 CountDownLatch countDownLatch = new CountDownLatch(1); zookeeper = new ZooKeeper(CONNECTSTRING, 10000, new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; if(event.getState() == Event.KeeperState.SyncConnected) &#123; System.out.println("Watcher " + zookeeper.getState()); countDownLatch.countDown(); &#125; &#125; &#125;); System.out.println("connect " + zookeeper.getState()); countDownLatch.await(); System.out.println("connect " + zookeeper.getState()); // zookeeper.close(); &#125;&#125;/* 输出结果connect CONNECTINGWatcher CONNECTEDconnect CONNECTED创建成功 /xych修改成功 46,47,1524152856857,1524152856864,1,0,0,72057600313458694,4,0,46删除成功*/ 3、exists、getData、getChildren3.1、exists 判断某节点是否存在1234Stat exists(String path, boolean watch)Stat exists(final String path, Watcher watcher)void exists(String path, boolean watch, StatCallback cb, Object ctx)void exists(final String path, Watcher watcher, StatCallback cb, Object ctx) 参数 含义 path 被判断节点的路径 watch 是否添加一个默认Watcher watcher 监听事件 cb 异步创建方法参数。注册的回调函数，需实现StatCallback接口。数据节点创建完成之后，会调用此方法进行业务逻辑处理。 ctx 异步创建方法参数。用户传递一个对象，可以在回调方法执行时使用 关于StatCallback可以参考本文2.2.1。 3.2、getData 获取节点内容，同步获取和异步获取1234byte[] getData(String path, boolean watch, Stat stat)byte[] getData(final String path, Watcher watcher, Stat stat)void getData(String path, boolean watch, DataCallback cb, Object ctx)void getData(final String path, Watcher watcher, DataCallback cb, Object ctx) 参数 含义 path 节点的路径 watch 是否注册一个默认Watcher watcher 监听事件 cb 异步创建方法参数。注册的回调函数，需实现DataCallback接口。数据节点创建完成之后，会调用此方法进行业务逻辑处理。 ctx 异步创建方法参数。用户传递一个对象，可以在回调方法执行时使用 关于DataCallback可以参考本文2.2.1。 3.3、getChildren 获取子节点列表，同步获取和异步获取12345678List&lt;String&gt; getChildren(String path, boolean watch)List&lt;String&gt; getChildren(final String path, Watcher watcher)List&lt;String&gt; getChildren(String path, boolean watch, Stat stat)List&lt;String&gt; getChildren(final String path, Watcher watcher, Stat stat)void getChildren(String path, boolean watch, ChildrenCallback cb, Object ctx)void getChildren(String path, boolean watch, Children2Callback cb, Object ctx)void getChildren(final String path, Watcher watcher, ChildrenCallback cb, Object ctx)void getChildren(final String path, Watcher watcher, Children2Callback cb, Object ctx) 参数 含义 path 节点的路径 watch 是否注册一个默认Watcher watcher 监听事件 stat 描述一个节点的信息会将path指定的节点的信息更新具体可以查看zookeeper客户端的使用的章节2 cb 异步创建方法参数。注册的回调函数，需实现ChildrenCallback、Children2Callback接口。数据节点创建完成之后，会调用此方法进行业务逻辑处理。 ctx 异步创建方法参数。用户传递一个对象，可以在回调方法执行时使用 关于ChildrenCallback、Children2Callback可以参考本文2.2.1。 4、Watcher事件监控 Watcher是一次性的，用完就会失效 转自：ZooKeeper监听机制 4.1、事件类型 事件类型 含义 EventType.None 与服务器建立连接时触发 EventType.NodeCreated 被监控的节点被创建触发 EventType.NodeDeleted 被监控的节点被删除触发 EventType.NodeDataChanged 被监控的节点被修改触发 EventType.NodeChildrenChanged 被监控的节点的子节点数量发生改变时触发 4.2、读操作绑定事件 读操作 含义 new ZooKeeper 不会指定某节点，故触发类型为EventType.None exists 判断某节点是否存在，同时对该节点添加Watcher getData 获取某节点的值，同时对该节点添加Watcher getChildren 获取某节点的子节点列表，同时对该节点添加Watcher 4.3、写操作触发事件 写操作 Event For “/path” Event For “/path/child” create(“/path”) EventType.NodeCreated - delete(“/path”) EventType.NodeDeleted - setData(“/path”) EventType.NodeDataChanged - create(“/path/child”) EventType.NodeChildrenChanged EventType.NodeCreated delete(“/path/child”) EventType.NodeChildrenChanged EventType.NodeDeleted setData(“/path/child”) - EventType.NodeDataChanged 4.4、写操作触发[读操作绑定的事件] “/path” “/path/child” 写操作所触发的绑定事件 exists getData getChildren exists getData getChildren create(“/path”) √ √ delete(“/path”) √ √ √ setData(“/path”) √ √ create(“/path/child”) √ √ √ delete(“/path/child”) √ √ √ √ setData(“/path/child”) √ √ create(&quot;/path/child&quot;)和delete(&quot;/path/child&quot;)只会触发getChildren对&quot;/path&quot;的绑定事件； 不会触发exists、getData对&quot;/path&quot;的绑定事件。 4.4、Demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184public class ApiZookeeperWatcher implements Watcher&#123; // 集群环境用,隔开 private static final String CONNECTSTRING = "192.168.27.131:2181"; private static ZooKeeper zookeeper; // 使用CountDownLatch，使主线程等待 private static CountDownLatch countDownLatch = new CountDownLatch(1); public static void main(String[] args) throws Exception &#123; connect(); createWatcher("/xych", "xych"); setDataWatcher("/xych", "XYCH"); deleteWatcher("/xych"); // 这里"/xych"已被删除，再次创建。（此时"/xych"没有任何Watcher） // 注意：临时节点下不能创建节点 if(zookeeper.exists("/xych1", false) == null) &#123; zookeeper.create("/xych1", "xych".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); &#125; createWatcher_Children("/xych1", "/lanboo", "lanboo"); setDataWatcher_Children("/xych1", "/lanboo", "LANBOO"); deleteWatcher_Children("/xych1", "/lanboo"); &#125; public static void deleteWatcher_Children(String path, String children) throws Exception &#123; countDownLatch = new CountDownLatch(1); // 利用getChildren，对父节点添加Watcher List&lt;String&gt; pathChildren = zookeeper.getChildren(path, new ApiZookeeperWatcher()); System.out.println("deleteWatcher_Children：" + path + "的子节点：" + pathChildren); // 利用exists，对子节点添加Watcher Stat childrenStat = zookeeper.exists(path + children, new ApiZookeeperWatcher()); if(pathChildren != null &amp;&amp; childrenStat != null) &#123; zookeeper.delete(path + children, -1); countDownLatch.await(); &#125; System.out.println(); &#125; public static void setDataWatcher_Children(String path, String children, String value) throws Exception &#123; countDownLatch = new CountDownLatch(1); // 利用getChildren，对父节点添加Watcher List&lt;String&gt; pathChildren = zookeeper.getChildren(path, new ApiZookeeperWatcher()); System.out.println("setDataWatcher_Children：" + path + "的子节点：" + pathChildren); // 利用exists，对子节点添加Watcher Stat childrenStat = zookeeper.exists(path + children, new ApiZookeeperWatcher()); if(pathChildren != null &amp;&amp; childrenStat != null) &#123; zookeeper.setData(path + children, value.getBytes(), -1); countDownLatch.await(); &#125; System.out.println(); &#125; /** * 对某节点添加Warcher，对该节点添加子节点 */ public static void createWatcher_Children(String path, String children, String value) throws Exception &#123; countDownLatch = new CountDownLatch(2); // 利用getChildren，对父节点添加Watcher List&lt;String&gt; pathChildren = zookeeper.getChildren(path, new ApiZookeeperWatcher()); System.out.println("createWatcher_Children：" + path + "的子节点：" + pathChildren); // 利用exists，对子节点添加Watcher Stat childrenStat = zookeeper.exists(path + children, new ApiZookeeperWatcher()); if(pathChildren != null &amp;&amp; childrenStat == null) &#123; zookeeper.create(path + children, value.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); countDownLatch.await(); &#125; System.out.println(); &#125; /** * 对setData监控 * 做法： * 1、利用exists，判断某节点是否存在，同时对该节点添加一个Watcher * 2、删除该节点 */ public static void deleteWatcher(String path) throws Exception &#123; countDownLatch = new CountDownLatch(1); // 判断"/xych"节点是否存在，并且对此节点添加一个Watcher Stat stat = zookeeper.exists(path, new ApiZookeeperWatcher()); System.out.println("deleteWatcher：" + path + "的节点属性：" + stat); if(stat != null) &#123; zookeeper.delete(path, -1); countDownLatch.await(); &#125; System.out.println(); &#125; /** * 对setData监控 * 做法： * 1、利用getData，获取某节点的value，同时对该节点添加一个Watcher * 2、创建该节点 */ public static void setDataWatcher(String path, String value) throws Exception &#123; countDownLatch = new CountDownLatch(1); Stat stat = new Stat(); byte[] bytes = zookeeper.getData(path, new ApiZookeeperWatcher(), stat); System.out.println("setDataWatcher：" + path + "的原始值 = " + new String(bytes)); System.out.println("setDataWatcher：" + path + "的节点信息 = " + stat); zookeeper.setData(path, value.getBytes(), -1); countDownLatch.await(); System.out.println(); &#125; /** * 对create监控 * 做法： * 1、利用exists，判断某节点是否存在，同时对该节点添加一个Watcher * 2、创建该节点 */ public static void createWatcher(String path, String value) throws Exception &#123; countDownLatch = new CountDownLatch(1); // 判断path节点是否存在，并且对此节点添加一个Watcher Stat stat = zookeeper.exists(path, new ApiZookeeperWatcher()); System.out.println("createWatcher：" + path + "的节点属性：" + stat); if(stat == null) &#123; zookeeper.create(path, value.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); countDownLatch.await(); &#125; System.out.println(); &#125; /** * 创建连接 */ public static void connect() throws Exception &#123; zookeeper = new ZooKeeper(CONNECTSTRING, 10000, new ApiZookeeperWatcher()); System.out.println("connect " + zookeeper.getState()); countDownLatch.await(); System.out.println("connect " + zookeeper.getState()); System.out.println(); &#125; @Override public void process(WatchedEvent watchedEvent) &#123; // 只在连接成功的情况下，进行事件监听 if(watchedEvent.getState() == Watcher.Event.KeeperState.SyncConnected) &#123; try &#123; if(Event.EventType.None == watchedEvent.getType()) &#123; System.out.println("Watcher：" + watchedEvent.getState() + "--&gt;" + watchedEvent.getType()); &#125; else if(Event.EventType.NodeCreated == watchedEvent.getType()) &#123; System.out.println("Watcher：" + watchedEvent.getPath() + "被创建"); &#125; else if(Event.EventType.NodeDeleted == watchedEvent.getType()) &#123; System.out.println("Watcher：" + watchedEvent.getPath() + "被删除"); &#125; else if(Event.EventType.NodeDataChanged == watchedEvent.getType()) &#123; System.out.println("Watcher：" + watchedEvent.getPath() + "被修改"); &#125; else if(Event.EventType.NodeChildrenChanged == watchedEvent.getType()) &#123; System.out.println("Watcher：" + watchedEvent.getPath() + "的子节点数量发生改变"); &#125; countDownLatch.countDown(); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125; System.out.println("Watcher：" + this); &#125;&#125; 输出12345678910111213141516171819202122232425262728293031323334353637connect CONNECTINGWatcher：SyncConnected--&gt;NoneWatcher：com.xych.zookeeper.api.ApiZookeeperWatcher@7b23ec81connect CONNECTEDcreateWatcher：/xych的节点属性：nullWatcher：/xych被创建Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@1a7d63bdsetDataWatcher：/xych的原始值 = xychsetDataWatcher：/xych的节点信息 = 165,165,1524221468877,1524221468877,0,0,0,72057600313458724,4,0,165Watcher：/xych被修改Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@7aa0aa6fdeleteWatcher：/xych的节点属性：165,166,1524221468877,1524221468884,1,0,0,72057600313458724,4,0,165Watcher：/xych被删除Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@bb15e0dcreateWatcher_Children：/xych1的子节点：[]Watcher：/xych1/lanboo被创建Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@2cce4a9aWatcher：/xych1的子节点数量发生改变Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@2d8e2810setDataWatcher_Children：/xych1的子节点：[lanboo]Watcher：/xych1/lanboo被修改Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@7333dbfedeleteWatcher_Children：/xych1的子节点：[lanboo]Watcher：/xych1/lanboo被删除Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@7165a6c4Watcher：/xych1的子节点数量发生改变Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@2f21b320Watcher：/xych1的子节点数量发生改变Watcher：com.xych.zookeeper.api.ApiZookeeperWatcher@31ecabd5]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大型跨境电商JVM调优经历]]></title>
    <url>%2F2018%2F05%2F29%2F%E5%A4%A7%E5%9E%8B%E8%B7%A8%E5%A2%83%E7%94%B5%E5%95%86JVM%E8%B0%83%E4%BC%98%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[示例 引用自 https://juejin.im/post/5b091ee35188253892389683?utm_source=gold_browser_extension 前提：某大型跨境电商业务发展非常快，线上机器扩容也很频繁，但是对于线上机器的运行情况，特别是jvm内存的情况，一直没有一个统一的标准来给到各个应用服务的owner。经过618大促之后，和运维的同学讨论了下，希望将线上服务器的jvm参数标准化，可以以一个统一的方式给到各个应用，提升线上服务器的稳定性，同时减少大家都去调整jvm参数的时间。参考了之前在淘宝天猫工作的公司的经历：经过大家讨论，根据jdk的版本以及线上机器配置，确定了一个推荐的默认jvm模版：最终推荐的jvm模版：jdk版本 机器配置 建议jvm参数 备注 1jdk1.7 6V8G -server -Xms4g -Xmx4g -Xmn2g -Xss768k -XX:PermSize=512m -XX:MaxPermSize=512m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSClassUnloadingEnabled -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=68 -verbose:gc -XX:+PrintGCDetails -Xloggc:&#123;CATALINA_BASE&#125;/logs/gc.log -XX:+PrintGCDateStamps -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=&#123;CATALINA_BASE&#125;/logs 前台 1jdk1.7 8V8G -server -Xms4g -Xmx4g -Xmn2g -Xss768k -XX:PermSize=512m -XX:MaxPermSize=512m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSClassUnloadingEnabled -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=68 -verbose:gc -XX:+PrintGCDetails -Xloggc:&#123;CATALINA_BASE&#125;/logs/gc.log -XX:+PrintGCDateStamps -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=&#123;CATALINA_BASE&#125;/logs 前台 1jdk1.7 4V8G -server -Xms4g -Xmx4g -Xmn2g -Xss768k -XX:PermSize=512m -XX:MaxPermSize=512m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSClassUnloadingEnabled -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=68 -verbose:gc -XX:+PrintGCDetails -Xloggc:&#123;CATALINA_BASE&#125;/logs/gc.log -XX:+PrintGCDateStamps -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=&#123;CATALINA_BASE&#125;/logs 前台 123jdk1.7 6V8G -server -Xms4g -Xmx4g -XX:MaxPermSize=512m \-verbose:gc -XX:+PrintGCDetails -Xloggc￼&#123;CATALINA_BASE&#125;/logs/gc.log -XX:+PrintGCTimeStamps \ 后台 配置说明： 堆设置 o -Xms:初始堆大小o -Xmx:最大堆大小o -XX:NewSize=n:设置年轻代大小o -XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4o -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5o -XX:MaxPermSize=n:设置持久代大小 收集器设置 o -XX:+UseSerialGC:设置串行收集器o -XX:+UseParallelGC:设置并行收集器o -XX:+UseParalledlOldGC:设置并行年老代收集器o -XX:+UseConcMarkSweepGC:设置并发收集器 垃圾回收统计信息-XX:+PrintGC-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-Xloggc:filename 并行收集器设置-XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。-XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间-XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) 并发收集器设置-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。-XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。 参数解释：-Xms3072m -Xmx3072m针对JVM堆的设置，通过-Xms -Xmx限定其最小、最大值 -Xmn1024m设置年轻代大小为1024m整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小（perm）。 -Xss768k 设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 -XX:PermSize=512m -XX:MaxPermSize=512m持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。设置非堆内存初始值，默认是物理内存的1/64；由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4 -XX:+UseConcMarkSweepGCCMS收集器也被称为短暂停顿并发收集器。它是对年老代进行垃圾收集的。CMS收集器通过多线程并发进行垃圾回收，尽量减少垃圾收集造成的停顿。CMS收集器对年轻代进行垃圾回收使用的算法和Parallel收集器一样。这个垃圾收集器适用于不能忍受长时间停顿要求快速响应的应用。 -XX:+UseParNewGC对年轻代采用多线程并行回收，这样收得快； -XX:+CMSClassUnloadingEnabled如果你启用了CMSClassUnloadingEnabled ，垃圾回收会清理持久代，移除不再使用的classes。这个参数只有在 UseConcMarkSweepGC 也启用的情况下才有用。 -XX:+DisableExplicitGC禁止System.gc()，免得程序员误调用gc方法影响性能； -XX:+UseCMSInitiatingOccupancyOnly标志来命令JVM不基于运行时收集的数据来启动CMS垃圾收集周期。而是，当该标志被开启时，JVM通过CMSInitiatingOccupancyFraction的值进行每一次CMS收集，而不仅仅是第一次。然而，请记住大多数情况下，JVM比我们自己能作出更好的垃圾收集决策。因此，只有当我们充足的理由(比如测试)并且对应用程序产生的对象的生命周期有深刻的认知时，才应该使用该标志。 -XX:CMSInitiatingOccupancyFraction=68默认CMS是在tenured generation(年老代）占满68%的时候开始进行CMS收集，如果你的年老代增长不是那么快，并且希望降低CMS次数的话，可以适当调高此值； -XX:+UseParNewGC：对年轻代采用多线程并行回收，这样收得快； -XX:HeapDumpPath-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-Xloggc:/usr/aaa/dump/heap_trace.txt上面的的参数打Heap Dump信息 “ -XX:+HeapDumpOnOutOfMemoryError此参数可以控制OutOfMemoryError时打印堆的信息 大家可能注意到了，这里推荐采用cms方式进行垃圾回收；CMS是一种以获取最短回收停顿时间为目标的收集器，可以有效减少服务器停顿的时间；CMS的GC线程对CPU的占用率会比较高，但在多核的服务器上还是展现了优越的特性，目前也被部署在国内的各大电商网站上。所以这里强烈推荐！cms的概念： CMS收集器也被称为短暂停顿并发收集器。它是对年老代进行垃圾收集的。CMS收集器通过多线程并发进行垃圾回收，尽量减少垃圾收集造成的停顿。CMS收集器对年轻代进行垃圾回收使用的算法和Parallel收集器一样。这个垃圾收集器适用于不能忍受长时间停顿要求快速响应的应用。CMS采用了多种方式尽可能降低GC的暂停时间,减少用户程序停顿。停顿时间降低的同时牺牲了CPU吞吐量 。这是在停顿时间和性能间做出的取舍，可以简单理解为”空间(性能)”换时间。 调整的节奏：由于怕影响线上应用，所以调整的步骤分三步：第一步：部分影响少量机器试点，对比未调整的机器，观察调整后的结果；第二步：调整部分应用的参数，进行压测，观察高并发压测之后的效果；第三步：调整部分核心应用的jvm参数，通过818大促来实际检验效果； 一:长期表现，第一个变化：fgc的次数减少，减少了大概一倍以上；mobile工程，调整前基本上一天1-2辆次，调整后基本上就是2-3天一次：online（另外一个工程）：可以明显看到fgc的统计频率少了很多； 第二个变化：fgc的时间减少原来一次fgc要将近500ms，现在只要100ms不到了。也证明了cms最大的好处就是减少fgc的停顿时间。]]></content>
      <categories>
        <category>调优</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql语句优化explain使用]]></title>
    <url>%2F2018%2F05%2F18%2FMysql%E8%AF%AD%E5%8F%A5%E4%BC%98%E5%8C%96explain%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[id1如果是子查询，id的序号会递增，id的值越大优先级越高，越先被执行 select_type查询的类型，主要用于区别普通查询、联合查询、子查询等的复杂查询 SIMPLE:简单的select查询，查询中不包含子查询或者UNION PRIMARY:查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY（最后加载的那一个 ） SUBQUERY:在SELECT或WHERE列表中包含了子查询 DERIVED:在FROM列表中包含的子查询被标记为DERIVED（衍生），Mysql会递归执行这些子查询，把结果放在临时表里。 UNION:若第二个SELECT出现在UNION之后，则被标记为UNION；若UNION包含在FROM字句的查询中，外层SELECT将被标记为:DERIVED UNION RESULT:从UNION表获取结果的SELECT type 显示查询使用了何种类型，从最好到最差依次是System&gt;const&gt;eq_ref&gt;range&gt;index&gt;All（全表扫描），一般来说至少达到range级别，最好达到ref All:全表扫描 System:表只有一行记录，这是const类型的特例，平时不会出现(忽略不计) const:表示通过索引一次就找到了,const用于比较primary key或者unique索引，因为只匹配一行数据，所以很快。如将主键置于where列表中，MySQL就能将该查询转换为一个常量。 const:表示通过索引一次就找到了,const用于比较primary key或者unique索引，因为只匹配一行数据，所以很快。如将主键置于where列表中，MySQL就能将该查询转换为一个常量。 eq_ref:唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。 ref：非唯一索引扫描，返回匹配某个单独值的行，本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而它可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体 range：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引，一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询。这种范围扫描索引比全表扫描要好，因为它只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引。 index:FULL INDEX SCAN,index与all区别为index类型只遍历索引树。这通常比all快，因为索引文件通常比数据文件小。 rows根据表统计信息及索引选用情况，大致估算出找到所需记录所需要读取的行数 extra包含不适合在其他列中显示但十分重要的额外信息 包含的信息： （危险!）Using filesort:说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取，MYSQL中无法利用索引完成的排序操作称为“文件排序” （特别危险!）Using temporary:使用了临时表保存中间结果，MYSQL在对查询结果排序时使用临时表。常见于排序order by 和分组查询 group by Using index:表示相应的select操作中使用了覆盖索引，避免访问了表的数据行，效率不错。如果同时出现using where，表明索引被用来执行索引键值的查找；如果没有同时出现using where，表明索引用来读取数据而非执行查找操作。 possible_keys显示可能应用在这张表中的索引，一个或多个。查询涉及到的字段上若存在索引，则该索引将被列出， 但不一定被查询实际使用 key实际使用的索引，如果为NULL，则没有使用索引。查询中若使用了覆盖索引，则该索引仅出现在key列表中，key参数可以作为使用了索引的判断标准 key_len:表示索引中使用的字节数，可通过该列计算查询中索引的长度，在不损失精确性的情况下，长度越短越好，key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。 ref对应索引的赋值，显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引上的值。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 Redis 的分布式锁]]></title>
    <url>%2F2018%2F05%2F15%2F%E5%9F%BA%E4%BA%8E-Redis-%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[前言分布式锁在分布式应用中应用广泛，想要搞懂一个新事物首先得了解它的由来，这样才能更加的理解甚至可以举一反三。 首先谈到分布式锁自然也就联想到分布式应用。 在我们将应用拆分为分布式应用之前的单机系统中，对一些并发场景读取公共资源时如扣库存，卖车票之类的需求可以简单的使用同步或者是加锁就可以实现。 但是应用分布式了之后系统由以前的单进程多线程的程序变为了多进程多线程，这时使用以上的解决方案明显就不够了。 因此业界常用的解决方案通常是借助于一个第三方组件并利用它自身的排他性来达到多进程的互斥。如： 基于 DB 的唯一索引。 基于 ZK 的临时有序节点。 基于 Redis 的 NX EX 参数。 这里主要基于 Redis 进行讨论。 实现既然是选用了 Redis，那么它就得具有排他性才行。同时它最好也有锁的一些基本特性： 高性能(加、解锁时高性能) 可以使用阻塞锁与非阻塞锁。 不能出现死锁。 可用性(不能出现节点 down 掉后加锁失败)。 这里利用 Redis set key 时的一个 NX 参数可以保证在这个 key 不存在的情况下写入成功。并且再加上 EX 参数可以让该 key 在超时之后自动删除。 所以利用以上两个特性可以保证在同一时刻只会有一个进程获得锁，并且不会出现死锁(最坏的情况就是超时自动删除 key)。 加锁实现代码如下： 123456789101112private static final String SET_IF_NOT_EXIST = "NX";private static final String SET_WITH_EXPIRE_TIME = "PX";public boolean tryLock(String key, String request) &#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; return true ; &#125;else &#123; return false ; &#125;&#125; 注意这里使用的 jedis 的 1String set(String key, String value, String nxxx, String expx, long time); api。 该命令可以保证 NX EX 的原子性。 一定不要把两个命令(NX EX)分开执行，如果在 NX 之后程序出现问题就有可能产生死锁。 阻塞锁同时也可以实现一个阻塞锁： 123456789101112131415161718192021222324252627282930//一直阻塞public void lock(String key, String request) throws InterruptedException &#123; for (;;)&#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; break ; &#125; //防止一直消耗 CPU Thread.sleep(DEFAULT_SLEEP_TIME) ; &#125;&#125; //自定义阻塞时间 public boolean lock(String key, String request,int blockTime) throws InterruptedException &#123; while (blockTime &gt;= 0)&#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; return true ; &#125; blockTime -= DEFAULT_SLEEP_TIME ; Thread.sleep(DEFAULT_SLEEP_TIME) ; &#125; return false ;&#125; 解锁解锁也很简单，其实就是把这个 key 删掉就万事大吉了，比如使用 del key 命令。 但现实往往没有那么 easy。 如果进程 A 获取了锁设置了超时时间，但是由于执行周期较长导致到了超时时间之后锁就自动释放了。这时进程 B 获取了该锁执行很快就释放锁。这样就会出现进程 B 将进程 A 的锁释放了。 所以最好的方式是在每次解锁时都需要判断锁是否是自己的。 这时就需要结合加锁机制一起实现了。 加锁时需要传递一个参数，将该参数作为这个 key 的 value，这样每次解锁时判断 value 是否相等即可。 所以解锁代码就不能是简单的 del了。 1234567891011121314151617181920public boolean unlock(String key,String request)&#123; //lua script String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Object result = null ; if (jedis instanceof Jedis)&#123; result = ((Jedis)this.jedis).eval(script, Collections.singletonList(LOCK_PREFIX + key), Collections.singletonList(request)); &#125;else if (jedis instanceof JedisCluster)&#123; result = ((JedisCluster)this.jedis).eval(script, Collections.singletonList(LOCK_PREFIX + key), Collections.singletonList(request)); &#125;else &#123; //throw new RuntimeException("instance is error") ; return false ; &#125; if (UNLOCK_MSG.equals(result))&#123; return true ; &#125;else &#123; return false ; &#125;&#125; 这里使用了一个 lua 脚本来判断 value 是否相等，相等才执行 del 命令。 使用 lua 也可以保证这里两个操作的原子性。 因此上文提到的四个基本特性也能满足了： 使用 Redis 可以保证性能。 阻塞锁与非阻塞锁见上文。 利用超时机制解决了死锁。 Redis 支持集群部署提高了可用性。 使用我自己有撸了一个完整的实现，并且已经用于了生产，有兴趣的朋友可以开箱使用: maven 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;top.crossoverjie.opensource&lt;/groupId&gt; &lt;artifactId&gt;distributed-redis-lock&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 配置 bean : 1234567891011121314@Configurationpublic class RedisLockConfig &#123; @Bean public RedisLock build()&#123; RedisLock redisLock = new RedisLock() ; HostAndPort hostAndPort = new HostAndPort("127.0.0.1",7000) ; JedisCluster jedisCluster = new JedisCluster(hostAndPort) ; // Jedis 或 JedisCluster 都可以 redisLock.setJedisCluster(jedisCluster) ; return redisLock ; &#125;&#125; 使用： 123456789101112131415161718192021@Autowiredprivate RedisLock redisLock ;public void use() &#123; String key = "key"; String request = UUID.randomUUID().toString(); try &#123; boolean locktest = redisLock.tryLock(key, request); if (!locktest) &#123; System.out.println("locked error"); return; &#125; //do something &#125; finally &#123; redisLock.unlock(key,request) ; &#125;&#125; 使用很简单。这里主要是想利用 Spring 来帮我们管理 RedisLock 这个单例的 bean，所以在释放锁的时候需要手动(因为整个上下文只有一个 RedisLock 实例)的传入 key 以及 request(api 看起来不是特别优雅)。 也可以在每次使用锁的时候 new 一个 RedisLock 传入 key 以及 request，这样倒是在解锁时很方便。但是需要自行管理 RedisLock 的实例。各有优劣吧。 项目源码在： https://github.com/crossoverJie/distributed-lock-redis 欢迎讨论。 单测在做这个项目的时候让我不得不想提一下单测。 因为这个应用是强依赖于第三方组件的(Redis)，但是在单测中我们需要排除掉这种依赖。比如其他伙伴 fork 了该项目想在本地跑一遍单测，结果运行不起来： 有可能是 Redis 的 ip、端口和单测里的不一致。 Redis 自身可能也有问题。 也有可能是该同学的环境中并没有 Redis。 所以最好是要把这些外部不稳定的因素排除掉，单测只测我们写好的代码。 于是就可以引入单测利器 Mock 了。 它的想法很简答，就是要把你所依赖的外部资源统统屏蔽掉。如：数据库、外部接口、外部文件等等。 使用方式也挺简单，可以参考该项目的单测： 12345678910111213141516@Testpublic void tryLock() throws Exception &#123; String key = "test"; String request = UUID.randomUUID().toString(); Mockito.when(jedisCluster.set(Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyLong())).thenReturn("OK"); boolean locktest = redisLock.tryLock(key, request); System.out.println("locktest=" + locktest); Assert.assertTrue(locktest); //check Mockito.verify(jedisCluster).set(Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyLong());&#125; 这里只是简单演示下，可以的话下次仔细分析分析。 它的原理其实也挺简单，debug 的话可以很直接的看出来： 这里我们所依赖的 JedisCluster 其实是一个 cglib 代理对象。所以也不难想到它是如何工作的。 比如这里我们需要用到 JedisCluster 的 set 函数并需要它的返回值。 Mock 就将该对象代理了，并在实际执行 set 方法后给你返回了一个你自定义的值。 这样我们就可以随心所欲的测试了，完全把外部依赖所屏蔽了。 总结至此一个基于 Redis 的分布式锁完成，但是依然有些问题。 如在 key 超时之后业务并没有执行完毕但却自动释放锁了，这样就会导致并发问题。 就算 Redis 是集群部署的，如果每个节点都只是 master 没有 slave，那么 master 宕机时该节点上的所有 key 在那一时刻都相当于是释放锁了，这样也会出现并发问题。就算是有 slave 节点，但如果在数据同步到 salve 之前 master 宕机也是会出现上面的问题。 感兴趣的朋友还可以参考 Redisson 的实现。]]></content>
      <categories>
        <category>缓存</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Disruptor并发框架上手demo]]></title>
    <url>%2F2018%2F05%2F15%2FDisruptor%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6%E4%B8%8A%E6%89%8Bdemo%2F</url>
    <content type="text"><![CDATA[框架简介 Martin Fowler在自己网站上写了一篇LMAX架构的文章，在文章中他介绍了LMAX是一种新型零售金融交易平台，它能够以很低的延迟产生大量交易。这个系统是建立在JVM平台上，其核心是一个业务逻辑处理器，它能够在一个线程里每秒处理6百万订单。业务逻辑处理器完全是运行在内存中，使用事件源驱动方式。业务逻辑处理器的核心是Disruptor。 Disruptor它是一个开源的并发框架，并获得2011 Duke’s 程序框架创新奖，能够在无锁的情况下实现网络的Queue并发操作。 Disruptor是一个高性能的异步处理框架，或者可以认为是最快的消息框架（轻量的JMS），也可以认为是一个观察者模式的实现，或者事件监听模式的实现。 在使用之前，首先说明disruptor主要功能加以说明，你可以理解为他是一种高效的”生产者-消费者”模型。也就性能远远高于传统的BlockingQueue容器。 上手demo 首先声明一个Event来包含需要传递的数据： 12345678910public class LongEvent &#123; private long value; public long getValue() &#123; return value; &#125; public void setValue(long value) &#123; this.value = value; &#125;&#125; 于需要让Disruptor为我们创建事件，我们同时还声明了一个EventFactory来实例化Event对象。 12345678// 需要让disruptor为我们创建事件，我们同时还声明了一个EventFactory来实例化Event对象。public class LongEventFactory implements EventFactory &#123; @Override public Object newInstance() &#123; return new LongEvent(); &#125;&#125; 我们还需要一个事件消费者，也就是一个事件处理器。这个事件处理器简单地把事件中存储的数据打印到终端： 12345678public class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123; @Override public void onEvent(LongEvent longEvent, long l, boolean b) throws Exception &#123; System.out.println(longEvent.getValue()); &#125;&#125; 事件都会有一个生成事件的源，这个例子中假设事件是由于磁盘IO或者network读取数据的时候触发的，事件源使用一个ByteBuffer来模拟它接受到的数据，也就是说，事件源会在IO读取到一部分数据的时候触发事件（触发事件不是自动的，程序员需要在读取到数据的时候自己触发事件并发布） 1234567891011121314151617181920212223242526272829public class LongEventProducer &#123; private final RingBuffer&lt;LongEvent&gt; ringBuffer; public LongEventProducer(RingBuffer&lt;LongEvent&gt; ringBuffer)&#123; this.ringBuffer = ringBuffer; &#125; /** * onData用来发布事件，每调用一次就发布一次事件 * 它的参数会用过事件传递给消费者 */ public void onData(ByteBuffer bb)&#123; //1.可以把ringBuffer看做一个事件队列，那么next就是得到下面一个事件槽 long sequence = ringBuffer.next(); try &#123; //2.用上面的索引取出一个空的事件用于填充（获取该序号对应的事件对象） LongEvent event = ringBuffer.get(sequence); //3.获取要通过事件传递的业务数据 event.setValue(bb.getLong(0)); &#125; finally &#123; //4.发布事件 //注意，最后的 ringBuffer.publish 方法必须包含在 finally 中以确保必须得到调用； // 如果某个请求的 sequence 未被提交，将会堵塞后续的发布操作或者其它的 producer。 ringBuffer.publish(sequence); &#125; &#125;&#125; main函数执行调用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class LongEventMain &#123; public static void main(String[] args) throws Exception &#123; //创建缓冲池 ExecutorService executor = Executors.newCachedThreadPool(); //创建工厂 LongEventFactory factory = new LongEventFactory(); //创建bufferSize ,也就是RingBuffer大小，必须是2的N次方 int ringBufferSize = 1024 * 1024; // /** //BlockingWaitStrategy 是最低效的策略，但其对CPU的消耗最小并且在各种不同部署环境中能提供更加一致的性能表现 WaitStrategy BLOCKING_WAIT = new BlockingWaitStrategy(); //SleepingWaitStrategy 的性能表现跟BlockingWaitStrategy差不多，对CPU的消耗也类似，但其对生产者线程的影响最小，适合用于异步日志类似的场景 WaitStrategy SLEEPING_WAIT = new SleepingWaitStrategy(); //YieldingWaitStrategy 的性能是最好的，适合用于低延迟的系统。在要求极高性能且事件处理线数小于CPU逻辑核心数的场景中，推荐使用此策略；例如，CPU开启超线程的特性 WaitStrategy YIELDING_WAIT = new YieldingWaitStrategy(); */ /** * 参数说明： */ //创建disruptor Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;LongEvent&gt;(factory, ringBufferSize, executor, ProducerType.SINGLE, new YieldingWaitStrategy()); // 连接消费事件方法 disruptor.handleEventsWith(new LongEventHandler()); // 启动 disruptor.start(); //Disruptor 的事件发布过程是一个两阶段提交的过程： //发布事件 RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); LongEventProducer producer = new LongEventProducer(ringBuffer); //LongEventProducerWithTranslator producer = new LongEventProducerWithTranslator(ringBuffer); ByteBuffer byteBuffer = ByteBuffer.allocate(8); for(long l = 0; l&lt;100; l++)&#123; byteBuffer.putLong(0, l); producer.onData(byteBuffer); //Thread.sleep(1000); &#125; disruptor.shutdown();//关闭 disruptor，方法会堵塞，直至所有的事件都得到处理； executor.shutdown();//关闭 disruptor 使用的线程池；如果需要的话，必须手动关闭， disruptor 在 shutdown 时不会自动关闭； &#125;&#125;]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java并发包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stream分组和分区]]></title>
    <url>%2F2018%2F05%2F14%2FStream%E5%88%86%E7%BB%84%E5%92%8C%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[这篇文章展示了如何使用 Streams API 中的 Collector 及 groupingBy 和 partitioningBy 来对流中的元素进行分组和分区。 思考一下 Employee 对象流，每个对象对应一个名字、城市和销售数量，如下表所示： 12345678+----------+------------+-----------------+| Name | City | Number of Sales |+----------+------------+-----------------+| Alice | London | 200 || Bob | London | 150 || Charles | New York | 160 || Dorothy | Hong Kong | 190 |+----------+------------+-----------------+ 分组首先，我们利用（lambda表达式出现之前的）命令式风格Java 程序对流中的雇员按城市进行分组： 12345678910Map&lt;String, List&lt;Employee&gt;&gt; result = new HashMap&lt;&gt;();for (Employee e : employees) &#123; String city = e.getCity(); List&lt;Employee&gt; empsInCity = result.get(city); if (empsInCity == null) &#123; empsInCity = new ArrayList&lt;&gt;(); result.put(city, empsInCity); &#125; empsInCity.add(e);&#125; 你可能很熟悉写这样的代码，你也看到了，一个如此简单的任务就需要这么多代码！ 而在 Java 8 中，你可以使用 groupingBy 收集器，一条语句就能完成相同的功能，像这样： 12Map&lt;String, List&lt;Employee&gt;&gt; employeesByCity = employees.stream().collect(groupingBy(Employee::getCity)); 结果如下面的 map 所示： 1&#123;New York=[Charles], Hong Kong=[Dorothy], London=[Alice, Bob]&#125; 还可以计算每个城市中雇员的数量，只需传递一个计数收集器给 groupingBy 收集器。第二个收集器的作用是在流分类的同一个组中对每个元素进行递归操作。 12Map&lt;String, Long&gt; numEmployeesByCity = employees.stream().collect(groupingBy(Employee::getCity, counting())); 结果如下面的 map 所示： 1&#123;New York=1, Hong Kong=1, London=2&#125; 顺便提一下，该功能与下面的 SQL 语句是等同的： 1select city, count(*) from Employee group by city 另一个例子是计算每个城市的平均年龄，这可以联合使用 averagingInt 和 groupingBy 收集器： 123Map&lt;String, Double&gt; avgSalesByCity = employees.stream().collect(groupingBy(Employee::getCity, averagingInt(Employee::getNumSales))); 结果如下 map 所示： 1&#123;New York=160.0, Hong Kong=190.0, London=175.0&#125; 分区分区是一种特殊的分组，结果 map 至少包含两个不同的分组——一个true，一个false。例如，如果想找出最优秀的员工，你可以将所有雇员分为两组，一组销售量大于 N，另一组小于 N，使用 partitioningBy 收集器： 12Map&lt;Boolean, List&lt;Employee&gt;&gt; partitioned = employees.stream().collect(partitioningBy(e -&gt; e.getNumSales() &gt; 150)); 输出如下结果： 1&#123;false=[Bob], true=[Alice, Charles, Dorothy]&#125; 你也可以将 groupingBy 收集器传递给 partitioningBy 收集器来将联合使用分区和分组。例如，你可以统计每个分区中的每个城市的雇员人数： 这样会生成一个二级 Map: 123Map&lt;Boolean, Map&lt;String, Long&gt;&gt; result = employees.stream().collect(partitioningBy(e -&gt; e.getNumSales() &gt; 150, groupingBy(Employee::getCity, counting())));]]></content>
      <categories>
        <category>java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java死锁重现与排查]]></title>
    <url>%2F2018%2F05%2F14%2Fjava%E6%AD%BB%E9%94%81%E9%87%8D%E7%8E%B0%E4%B8%8E%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[1.构造死锁通过模拟两个哲学吃饭，需要两把叉子。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * Created by xiaowu.zhou@tongdun.cn on 2018/5/14. */public class DeadLock extends Thread&#123; //哲学家吃饭需要的刀叉 static Object fork1 = new Object(); static Object fork2 = new Object(); private Object tool; public DeadLock(Object object) &#123; this.tool = object; if (tool == fork1)&#123; this.setName("哲学家1"); &#125;else if (tool == fork2)&#123; this.setName("哲学家2"); &#125; &#125; @Override public void run() &#123; if (tool == fork1)&#123; synchronized (fork1)&#123; try &#123; System.out.println("哲学家1开始准备，有了一把叉子1"); Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (fork2)&#123; System.out.println("哲学家1开始吃饭，有了两把叉子"); &#125; &#125; &#125; if(tool == fork2)&#123; synchronized (fork2)&#123; try &#123; System.out.println("哲学家2开始准备，有了一把叉子2"); Thread.sleep(1500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (fork1)&#123; System.out.println("哲学家2开始吃饭，有了两把叉子"); &#125; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; DeadLock deadLock1 = new DeadLock(fork1); DeadLock deadLock2 = new DeadLock(fork2); deadLock1.start(); deadLock2.start(); while (true)&#123; &#125; &#125;&#125; 2. 排查问题死锁的线程不占用cpu，通过jstack可以排查 1jstack 59356 &gt; dead_lock_stack.log 搜索deadlock 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071082018-05-14 09:08:13Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.144-b01 mixed mode):"Attach Listener" #12 daemon prio=9 os_prio=31 tid=0x00007fb3818c8000 nid=0x1407 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"哲学家2" #11 prio=5 os_prio=31 tid=0x00007fb38185a000 nid=0x5103 waiting for monitor entry [0x000070000d069000] java.lang.Thread.State: BLOCKED (on object monitor) at DeadLock.run(DeadLock.java:59) - waiting to lock &lt;0x0000000795782620&gt; (a java.lang.Object) - locked &lt;0x0000000795782630&gt; (a java.lang.Object)"哲学家1" #10 prio=5 os_prio=31 tid=0x00007fb382042800 nid=0x4f03 waiting for monitor entry [0x000070000cf66000] java.lang.Thread.State: BLOCKED (on object monitor) at DeadLock.run(DeadLock.java:41) - waiting to lock &lt;0x0000000795782630&gt; (a java.lang.Object) - locked &lt;0x0000000795782620&gt; (a java.lang.Object)"Service Thread" #9 daemon prio=9 os_prio=31 tid=0x00007fb38206c800 nid=0x4b03 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE"C1 CompilerThread2" #8 daemon prio=9 os_prio=31 tid=0x00007fb38185f000 nid=0x4903 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"C2 CompilerThread1" #7 daemon prio=9 os_prio=31 tid=0x00007fb382815800 nid=0x4703 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"C2 CompilerThread0" #6 daemon prio=9 os_prio=31 tid=0x00007fb381859000 nid=0x4503 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE"Monitor Ctrl-Break" #5 daemon prio=5 os_prio=31 tid=0x00007fb3830b9000 nid=0x4303 runnable [0x000070000c954000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284) at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326) at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178) - locked &lt;0x0000000795708738&gt; (a java.io.InputStreamReader) at java.io.InputStreamReader.read(InputStreamReader.java:184) at java.io.BufferedReader.fill(BufferedReader.java:161) at java.io.BufferedReader.readLine(BufferedReader.java:324) - locked &lt;0x0000000795708738&gt; (a java.io.InputStreamReader) at java.io.BufferedReader.readLine(BufferedReader.java:389) at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java:64)"Signal Dispatcher" #4 daemon prio=9 os_prio=31 tid=0x00007fb382030800 nid=0x4103 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE"Finalizer" #3 daemon prio=8 os_prio=31 tid=0x00007fb38202b000 nid=0x3103 in Object.wait() [0x000070000c74e000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795588ec8&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x0000000795588ec8&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)"Reference Handler" #2 daemon prio=10 os_prio=31 tid=0x00007fb382805000 nid=0x2f03 in Object.wait() [0x000070000c64b000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795586b68&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x0000000795586b68&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)"main" #1 prio=5 os_prio=31 tid=0x00007fb382005800 nid=0x1c03 runnable [0x000070000c039000] java.lang.Thread.State: RUNNABLE at DeadLock.main(DeadLock.java:81)"VM Thread" os_prio=31 tid=0x00007fb382802800 nid=0x2d03 runnable"GC task thread#0 (ParallelGC)" os_prio=31 tid=0x00007fb38200e800 nid=0x2503 runnable"GC task thread#1 (ParallelGC)" os_prio=31 tid=0x00007fb38200f800 nid=0x2703 runnable"GC task thread#2 (ParallelGC)" os_prio=31 tid=0x00007fb382010000 nid=0x2903 runnable"GC task thread#3 (ParallelGC)" os_prio=31 tid=0x00007fb382010800 nid=0x2b03 runnable"VM Periodic Task Thread" os_prio=31 tid=0x00007fb382085800 nid=0x4d03 waiting on conditionJNI global references: 22Found one Java-level deadlock:============================="哲学家2": waiting to lock monitor 0x00007fb38202a5f8 (object 0x0000000795782620, a java.lang.Object), which is held by "哲学家1""哲学家1": waiting to lock monitor 0x00007fb3818ca808 (object 0x0000000795782630, a java.lang.Object), which is held by "哲学家2"Java stack information for the threads listed above:==================================================="哲学家2": at DeadLock.run(DeadLock.java:59) - waiting to lock &lt;0x0000000795782620&gt; (a java.lang.Object) - locked &lt;0x0000000795782630&gt; (a java.lang.Object)"哲学家1": at DeadLock.run(DeadLock.java:41) - waiting to lock &lt;0x0000000795782630&gt; (a java.lang.Object) - locked &lt;0x0000000795782620&gt; (a java.lang.Object)Found 1 deadlock. 发现哲学家1，持有锁0x0000000795782620,等待锁0x0000000795782630 ； 而哲学家2，则相反。]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MAT使用教程]]></title>
    <url>%2F2018%2F05%2F13%2FMAT%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[MAT 全称 Eclipse Memory Analysis Tools 是一个分析 Java堆数据的专业工具，可以计算出内存中对象的实例数量、占用空间大小、引用关系等，看看是谁阻止了垃圾收集器的回收工作，从而定位内存泄漏的原因。 什么时候会用到MAT? a） OutOfMemoryError的时候，触发full gc，但空间却回收不了，引发内存泄露 b）java服务器系统异常，比如load飙高，io异常，或者线程死锁等，都可能通过分析堆中的内存对象来定位原因 如何安装： eclipse插件安装，地址：http://download.eclipse.org/mat/1.0/update-site/ 分析文件生成方式： a）自动生成，jvm启动参数里添加下面配置，当发生OutOfMemoryError时，虚拟机会自动dump内存快照 [html] view plain copy -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$LOG_DIR/java.hprof” b）手动生成，通过执行jdk自带命令 jmap -dump:format=b,file=heap.bin 接下就可以用 MAT打开转换后的 hprof文件 打开后的首页，里面是一些堆的基本概要信息，比如空间大小、类的数量、对象实例数量、类加载器等等 Atcion里面提供了多种分析维度： Histogram可以列出内存中的对象，对象的个数以及大小。 Dominator Tree可以列出那个线程，以及线程下面的那些对象占用的空间。 Top consumers通过图形列出最大的object。 Leak Suspects通过MA自动分析泄漏的原因。 Histogram 它按类名将所有的实例对象列出来，点击表头（Class Name）可以排序，第一行输入正则表达式可以过滤筛选 ； Shallow Heap ：一个对象内存的消耗大小，不包含对其他对象的引用；Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收的内存大小； 详细解释可参考文章：Shallow heap &amp; Retained heap 在某一项上右键打开菜单选择 list objects ： with incoming references 将列出哪些类引入该类； with outgoing references 列出该类引用了哪些类 从工具栏中点开 Heap Dump Overview视图，可以看到一个全局的内存占用信息 Dominator Tree 可以列出内存中存活的大对象列表，优点是有Percentage字段，可以看各种情况的百分比。 分组工具可以根据自己的需求分组查找，默认根据class分组，本文中是根据 package分组，发现存在大量的SSLSocketImpl类无法回收，这样会导致所有直接或间接引用到SSLSocketImpl的类都无法回收，图中可以看出虽然Shallow Heap大小只有1.6M，但Retained Heap大小却有378M。 快速找出某个实例没被释放的原因，可以右健 Path to GC Roots–&gt;exclude all phantom/weak/soft etc. references 它展示了对象间的引用关系，比如SSLSocketImpl @0xa124b208被PushNotificationManager 实例中的socket属性所引用。 Top consumers 多种维度（包括 类大小、类加载器、包名）展示占用内存比较多的对象的分布，从而定位内存资源主要耗费在哪些地方！ Leak Suspects MAT插件会给出一份可疑的分析报告，非常方便，我们只需结合源代码稍加分析到底哪个Problem才是引发问题真正原因所在。 参考资料： http://www.eclipse.org/mat/about/screenshots.php https://www.yourkit.com/docs/java/help/garbage_collection.jsp http://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-ma/index.html http://help.eclipse.org/luna/index.jsp?topic=/org.eclipse.mat.ui.help/welcome.html]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK内置工具]]></title>
    <url>%2F2018%2F05%2F13%2FJDK%E5%86%85%E7%BD%AE%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[1. jps -ml用于查看JVM里面所有进程的具体状态，包括进程ID，进程启动的路径等等 参数格式： -m 输出传递给main方法的参数，如果是内嵌的JVM则输出为null。 -l 输出应用程序主类的完整包名，或者是应用程序JAR文件的完整路径。（非常适用于task任务） -v 输出传给JVM的参数。 ​ 2. jstat -gcutil pid 时间间隔1）简介： Jstat是JDK自带的一个轻量级小工具。全称“Java Virtual Machine statistics monitoring tool”，它位于java的bin目录下，主要利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对Heap size和垃圾回收状况的监控。可见，Jstat是轻量级的、专门针对JVM的工具，非常适用。由于JVM内存设置较大，图中百分比变化不太明显一个极强的监视VM内存工具。可以用来监视VM内存内的各种堆和非堆的大小及其内存使用量。 jstat工具特别强大，有众多的可选项，详细查看堆内各个部分的使用量，以及加载类的数量。使用时，需加上查看进程的进程id，和所选参数。 它主要是用来显示GC及PermGen相关的信息. 2）参数： -class Option -compiler Option -gc Option -gccapacity Option -gccause Option -gcnew Option -gcnewcapacity Option -gcold Option -gcoldcapacity Option -gcpermcapacity Option -gcutil Option -printcompilation Option 注：其中最常用的就是 -gcutil 选项了，因为他能够给我们展示大致的GC信息。 Option：指的是vmid、显示间隔时间及间隔次数等 vmid —VM的进程号，即当前运行的java进程号 interval 间隔时间，单位毫秒 count — 打印次数，如果缺省则打印无数次 3）输出结果 S0 — Heap上的 Survivor space 0 区已使用空间的百分比 S0C：S0当前容量的大小 S0U：S0已经使用的大小 S1 — Heap上的 Survivor space 1 区已使用空间的百分比 S1C：S1当前容量的大小 S1U：S1已经使用的大小 E — Heap上的 Eden space 区已使用空间的百分比 EC：Eden space当前容量的大小 EU：Eden space已经使用的大小 O — Heap上的 Old space 区已使用空间的百分比 OC：Old space当前容量的大小 OU：Old space已经使用的大小 P — Perm space 区已使用空间的百分比 PC：Perm space当前容量的大小 PU：Perm space已经使用的大小 YGC — 从应用程序启动到采样时发生 Young GC 的次数 YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒) FGC — 从应用程序启动到采样时发生 Full GC 的次数 FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC 4）示例 jstat -gcutil [pid]. interval 图中同时打印了young gc和full gc的总次数、总耗时。而每次young gc消耗的时间，可以用相间隔的两行（红线标示的）YGCT相减得到。每次full gc消耗的时间，可以用相隔的两行FGCT相减得到。 常驻内存区(P)的使用率，始终停留在64.78%左右，说明常驻内存没有突变，比较正常。如果young gc和full gc能够正常发生，而且都能有效回收内存，常驻内存区变化不明显，则说明java内存释放情况正常，垃圾回收及时，java内存泄露的几率就会大大降低，但也不能说明一定没有内存泄露。 jstat -class 进程id 显示加载class的数量，及所占空间等信息。 12341. [yang@vm-cbu-qa-172-43 ~]$ jstat -class 12384 20002. Loaded Bytes Unloaded Bytes Time3. 11493 23583.9 195 291.8 12.31 3. jinfo格式：jinfo 进程id 观察运行中的java程序的运行环境参数：参数包括Java System属性和JVM命令行参数 4. jstack观察jvm中当前所有线程的运行情况和线程当前状态 详细使用可参考《java服务器load飚高排查思路》 5. jmap1）简介 输出内存中对象的工具，打印出某个java进程在内存中所有“对象”的使用情况（如：产生那些对象、数量） 1jmap -histo pid &gt; aa.log 可以将二进制输出到文本（aa.log）中，在一段时间后，使用文本比较工具，可以对比出GC回收了哪些对象。 1jmap -dump:format=b,file=heap.bin 12384 可以将12384进程的内存堆栈输出到heap.bin 文件里，再配合MAT（内存分析工具(Memory Analysis Tool），参考文章 或 jhat (Java Heap Analysis Tool)一起使用，能够以图像的形式直观的反映当前内存是否存在问题。 如果你的机子是64位，格式：jmap -J-d64 -heap pid 2）参数格式 1-dump:[live,]format=b,file=&lt;filename&gt; 使用hprof二进制形式，输出jvm的heap内容到文件中。 live子选项是可选的，假如指定live选项，那么只输出活的对象 -finalizerinfo 打印正等候回收的对象的信息. -heap 打印heap的概要信息（年轻代、年老代、持久代的概括使用情况），GC使用的算法，heap的配置及wise heap的使用情况。 -histo[:live] 输出每个对象的实例个数、占用字节数、类全名信息。 VM的内部类名字开头会加上前缀”*”。如果加上live子参数，只统计活的对象数量。（ps：默认按内存中占用的字节数大小排序，使用场景较多） -permstat 打印classloader和jvm heap的信息。 包含classloader的名字、加载的class数量、占用内存大小、父classloader、活跃性、类型。 3）实例 11. [yang@vm-cbu-qa-172-43 ~]$ jmap -histo 12384 &gt;aa.log]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教你如何成为Java的OOM Killer]]></title>
    <url>%2F2018%2F05%2F13%2F%E6%95%99%E4%BD%A0%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BAJava%E7%9A%84OOM-Killer%2F</url>
    <content type="text"><![CDATA[Become OOM Killer我们都知道JVM的内存管理是自动化的，Java语言的程序指针也不需要开发人员手工释放，JVM的GC会自动的进行回收，但是，如果编程不当，JVM仍然会发生内存泄露，导致Java程序产生了OutOfMemoryError（OOM）错误。 产生OutOfMemoryError错误的原因包括： java.lang.OutOfMemoryError: Java heap space java.lang.OutOfMemoryError: PermGen space及其解决方法 java.lang.OutOfMemoryError: unable to create new native thread java.lang.OutOfMemoryError：GC overhead limit exceeded 对于第1种异常，表示Java堆空间不够，当应用程序申请更多的内存，而Java堆内存已经无法满足应用程序对内存的需要，将抛出这种异常。 对于第2种异常，表示Java永久带（方法区）空间不够，永久带用于存放类的字节码和长常量池，类的字节码加载后存放在这个区域，这和存放对象实例的堆区是不同的，大多数JVM的实现都不会对永久带进行垃圾回收，因此，只要类加载的过多就会出现这个问题。一般的应用程序都不会产生这个错误，然而，对于Web服务器来讲，会产生有大量的JSP，JSP在运行时被动态的编译成Java Servlet类，然后加载到方法区，因此，太多的JSP的Web工程可能产生这个异常。 对于第3种异常，本质原因是创建了太多的线程，而能创建的线程数是有限制的，导致了这种异常的发生。 对于第4种异常，是在并行或者并发回收器在GC回收时间过长、超过98%的时间用来做GC并且回收了不到2%的堆内存，然后抛出这种异常进行提前预警，用来避免内存过小造成应用不能正常工作。 下面两个异常与OOM有关系，但是，又没有绝对关系。 java.lang.StackOverflowError … java.net.SocketException: Too many open files 对于第1种异常，是JVM的线程由于递归或者方法调用层次太多，占满了线程堆栈而导致的，线程堆栈默认大小为1M。 对于第2种异常，是由于系统对文件句柄的使用是有限制的，而某个应用程序使用的文件句柄超过了这个限制，就会导致这个问题。 上面介绍了OOM相关的基础知识，接下来我们开始讲述笔者经历的一次OOM问题的定位和解决的过程。 1. 产生问题的现象 在某一段时间内，我们发现不同的业务服务开始偶发的报OOM的异常，有的时候是白天发生，有的时候是晚上发生，有的时候是基础服务A发生，有的时候是上层服务B发生，有的时候是上层服务C发生，有的时候是下层服务D发生，丝毫看不到一点规律。 产生问题的异常如下： 123Caused by: java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method)at java.lang.Thread.start(Thread.java:597)at java.util.Timer.&lt;init&gt;(Timer.java:154) 2. 解决问题的思路和过程 经过细心观察发现，产生问题虽然在不同的时间发生在不同的服务池，但是，晚上0点发生的时候概率较大，也有其他时间偶发，但是都在整点。 这个规律很重要，虽然不是一个时间，但是基本都在整点左右发生，并且晚上0点居多。从这个角度思考，整点或者0点系统是否有定时，与出问题的每个业务系统技术负责人核实，0点没有定时任务，其他时间的整点有定时任务，但是与发生问题的时间不吻合，这个思路行不通。 到现在为止，从现象的规律上我们已经没法继续分析下去了，那我们回顾一下错误本身： java.lang.OutOfMemoryError: unable to create new native thread 顾名思义，错误产生的原因就是应用不能创建线程了，但是，应用还需要创建线程。为什么程序不能创建线程呢？ 有两个具体原因造成这个异常: 由于线程使用的资源过多，操作系统已经不能再提供给应用资源了。 操作系统设置了应用创建线程的最大数量，并且已经达到了最大允许数量。 上面第1条资源指的是内存，而第2条中，在Linux下线程使用轻量级进程实现的，因此线程的最大数量也是操作系统允许的进程的最大数量。 内存计算 操作系统中的最大可用内存除去操作系统本身使用的部分，剩下的都可以为某一个进程服务，在JVM进程中，内存又被分为堆、本地内存和栈等三大块，Java堆是JVM自动管理的内存，应用的对象的创建和销毁、类的装载等都发生在这里，本地内存是Java应用使用的一种特殊内存，JVM并不直接管理其生命周期，每个线程也会有一个栈，是用来存储线程工作过程中产生的方法局部变量、方法参数和返回值的，每个线程对应的栈的默认大小为1M。 Linux和JVM的内存管理示意图如下： 因此，从内存角度来看创建线程需要内存空间，如果JVM进程正当一个应用创建线程，而操作系统没有剩余的内存分配给此JVM进程，则会抛出问题中的OOM异常：unable to create new native thread。 如下公式可以用来从内存角度计算允许创建的最大线程数： 最大线程数 = （操作系统最大可用内存 - JVM内存 - 操作系统预留内存）/ 线程栈大小 根据这个公式，我们可以通过剩余内存计算可以创建线程的数量。 下面是问题出现的时候，从生产机器上执行前面小节介绍的Linux命令free的输出： 123free -m &gt;&gt; /tmp/free.log total used free shared buffers cachedMem: 7872 7163 709 0 31 3807-/+ buffers/cache: 3324 4547Swap: 4095 173 3922Tue Jul 5 00:27:51 CST 2016 从上面输出可以得出，生产机器8G内存，使用了7G，剩余700M可用，其中操作系统cache使用3.8G。操作系统cache使用的3.8G是用来缓存IO数据的，如果进程内存不够用，这些内存是可以释放出来优先分配给进程使用。然而，我们暂时并不需要考虑这块内存，剩余的700M空间完全可以继续用来创建线程数： 700M / 1M = 700个线程 因此，根据内存可用计算，当OOM异常：unable to create new native thread问题发生的时候，还有700M可用内存，可以创建700个线程。 到现在为止可以证明此次OOM异常不是因为线程吃光所有的内存而导致的。 线程数对比 上面提到，有两个具体原因造成这个异常，我们上面已经排除了第1个原因，那我们现在从第2个原因入手，评估是否操作系统设置了应用创建线程的最大数量，并且已经达到了最大允许数量。 在问题出现的生产机器上使用ulimit -a来显示当前的各种系统对用户使用资源的限制： 123456robert@robert-ubuntu1410：~$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 62819max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 65535pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 10240cpu time (seconds, -t) unlimitedmax user processes (-u) 1024virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 这里面我们看到生产机器设置的允许使用的最大用户进程数为1024： 1max user processes (-u) 1024 现在，我们必须获得问题出现的时候，用户下创建的线程情况。 在问题产生的时候，我们使用前面小结介绍的JVM监控命令jstack命令打印出了Java线程情况,jstack命令的示例输出如下： 12345678910111213141516171819202122robert@robert-ubuntu1410:~$ jstack 27432017-04-09 12:06:51Full thread dump Java HotSpot(TM) Server VM (25.20-b23 mixed mode):"Attach Listener" #23 daemon prio=9 os_prio=0 tid=0xc09adc00 nid=0xb4c waiting on condition [0x00000000] java.lang.Thread.State: RUNNABLE"http-nio-8080-Acceptor-0" #22 daemon prio=5 os_prio=0 tid=0xc3341000 nid=0xb02 runnable [0xbf1bd000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:241) - locked &lt;0xcf8938d8&gt; (a java.lang.Object) at org.apache.tomcat.util.net.NioEndpoint$Acceptor.run(NioEndpoint.java:688) at java.lang.Thread.run(Thread.java:745)"http-nio-8080-ClientPoller-1" #21 daemon prio=5 os_prio=0 tid=0xc35bc400 nid=0xb01 runnable [0xbf1fe000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0xcf99b100&gt; (a sun.nio.ch.Util$2) - locked &lt;0xcf99b0f0&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0xcf99aff8&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:1052) at java.lang.Thread.run(Thread.java:745)...... 从jstack命令的输出并统计后，我们得知，JVM一共创建了904个线程，但是，这还没有到最大的进程限制1024。 12robert@robert-ubuntu1410:~$ grep "Thread " js.log | wc -l 904 这是我们思考，除了JVM创建的应用层线程，JVM本身可能会有一些管理线程存在，而且操作系统内用户下可能也会有守护线程在运行。 我们继续从操作系统的角度来统计线程数，我们使用上面小结介绍的Linux操作系统命令pstack，并得到如下的输出： 123456789PID LWP USER %CPU %MEM CMD 1 1 root 0.0 0.0 /sbin/init 2 2 root 0.0 0.0 [kthreadd] 3 3 root 0.0 0.0 [migration/0] 4 4 root 0.0 0.0 [ksoftirqd/0] 5 5 root 0.0 0.0 [migration/0] 6 6 root 0.0 0.0 [watchdog/0] 7 7 root 0.0 0.0 [migration/1] 8 8 root 0.0 0.0 [migration/1] 9 9 root 0.0 0.0 [ksoftirqd/1] 10 10 root 0.0 0.0 [watchdog/1] 11 11 root 0.0 0.0 [migration/2] 12 12 root 0.0 0.0 [migration/2] 13 13 root 0.0 0.0 [ksoftirqd/2] 14 14 root 0.0 0.0 [watchdog/2] 15 15 root 0.0 0.0 [migration/3] 16 16 root 0.0 0.0 [migration/3] 17 17 root 0.0 0.0 [ksoftirqd/3] 18 18 root 0.0 0.0 [watchdog/3] 19 19 root 0.0 0.0 [events/0] 20 20 root 0.0 0.0 [events/1] 21 21 root 0.0 0.0 [events/2] 22 22 root 0.0 0.0 [events/3] 23 23 root 0.0 0.0 [cgroup] 24 24 root 0.0 0.0 [khelper] ...... 7257 7257 zabbix 0.0 0.0 /usr/local/zabbix/sbin/zabbix_agentd: active checks #2 [idle 1 sec] 7258 7258 zabbix 0.0 0.0 /usr/local/zabbix/sbin/zabbix_agentd: active checks #3 [idle 1 sec] 7259 7259 zabbix 0.0 0.0 /usr/local/zabbix/sbin/zabbix_agentd: active checks #4 [idle 1 sec] ...... 9040 9040 app 0.0 30.5 /apps/prod/jdk1.6.0_24/bin/java -Dnop -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Ddbconfigpath=/apps/dbconfig/ -Djava.io.tmpdir=/apps/data/java-tmpdir -server -Xms2048m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=512m -Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=192.168.10.194 -Dcom.sun.management.jmxremote.port=6969 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp -Xshare:off -Dhostname=sjsa-trade04 -Djute.maxbuffer=41943040 -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8 -Dworkdir=/apps/data/tomcat-work -Djava.endorsed.dirs=/apps/product/tomcat-trade/endorsed -classpath commonlib:/apps/product/tomcat-trade/bin/bootstrap.jar:/apps/product/tomcat-trade/bin/tomcat-juli.jar -Dcatalina.base=/apps/product/tomcat-trade -Dcatalina.home=/apps/product/tomcat-trade -Djava.io.tmpdir=/apps/data/tomcat-temp/ org.apache.catalina.startup.Bootstrap start 9040 9041 app 0.0 30.5 /apps/prod/jdk1.6.0_24/bin/java -Dnop -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Ddbconfigpath=/apps/dbconfig/ -Djava.io.tmpdir=/apps/data/java-tmpdir -server -Xms2048m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=512m -Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=192.168.10.194 -Dcom.sun.management.jmxremote.port=6969 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp -Xshare:off -Dhostname=sjsa-trade04 -Djute.maxbuffer=41943040 -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8 -Dworkdir=/apps/data/tomcat-work -Djava.endorsed.dirs=/apps/product/tomcat-trade/endorsed -classpath commonlib:/apps/product/tomcat-trade/bin/bootstrap.jar:/apps/product/tomcat-trade/bin/tomcat-juli.jar -Dcatalina.base=/apps/product/tomcat-trade -Dcatalina.home=/apps/product/tomcat-trade -Djava.io.tmpdir=/apps/data/tomcat-temp/ org.apache.catalina.startup.Bootstrap start...... 通过命令统计用户下已经创建的线程数为1021。 12$ grep app pthreads.log | wc -l 1021 现在我们确定，1021的数字已经相当的接近1021的最大进程数了，正如前面我们提到，在Linux操作系统里，线程是通过轻量级的进程实现的，因此，限制用户的最大进程数，就是限制用户的最大线程数，至于为什么没有精确达到1024这个最大值就已经报出异常，应该是系统的自我保护功能，在还剩下3个线程的前提下，就开始报错。 到此为止，我们已经通过分析来找到问题的原因，但是，我们还是不知道为什么会创建这么多的线程，从第一个输出得知，JVM已经创建的应用线程有907个，那么他们都在做什么事情呢？ 于是，在问题发生的时候，我们又使用JVM的jstack命令，查看输出得知，每个线程都阻塞在打印日志的语句上，log4j中打印日志的代码实现如下： 1234567891011public void callAppenders(LoggingEvent event) &#123; int writes = 0; for(Category c = this; c != null; c=c.parent) &#123; // Protected against simultaneous call to addAppender, removeAppender,... synchronized(c) &#123; if(c.aai != null) &#123; writes += c.aai.appendLoopOnAppenders(event); &#125; if(!c.additive) &#123; break; &#125; &#125; &#125; if(writes == 0) &#123; repository.emitNoAppenderWarning(this); &#125;&#125; 在log4j中，打印日志有一个锁，锁的作用是让打印日志可以串行，保证日志在日志文件中的正确性和顺序性。 那么，新的问题又来了，为什么只有凌晨0点会出现打印日志阻塞，其他时间会偶尔发生呢？这时，我们带着新的线索又回到问题开始的思路，凌晨12点应用没有定时任务，系统会不会有其他的IO密集型的任务，比如说归档日志、磁盘备份等？ 经过与运维部门碰头，基本确定是每天凌晨0点日志切割导致磁盘IO被占用，于是堵塞打印日志，日志是每个工作任务都必须的，日志阻塞，线程池就阻塞，线程池阻塞就导致线程池被撑大，线程池里面的线程数超过1024就会报错。 到这里，我们基本确定了问题的原因，但是还需要对日志切割导致IO增大进行分析和论证。 首先我们使用前面小结介绍的vmstat查看问题发生时IO等待数据： 123vmstat 2 1 &gt;&gt; /tmp/vm.logprocs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 3 0 177608 725636 31856 3899144 0 0 2 10 0 0 39 1 1 59 0 Tue Jul 5 00:27:51 CST 2016 可见，问题发生的时候，CPU的IO等待为59%，同时又与运维部门同事复盘，运维同事确认，脚本切割通过cat命令方法，先把日志文件cat后，通过管道打印到另外一个文件，再清空原文件，因此，一定会导致IO的上升。 其实，问题的过程中，还有一个疑惑，我们认为线程被IO阻塞，线程池被撑开，导致线程增多，于是，我们查看了一下Tomcat线程池的设置，我们发现Tomcat线程池设置了800，按理说，永远不会超过1024。 12345&lt;Connector port="8080" maxThreads="800" minSpareThreads="25" maxSpareThreads="75" enableLookups="false" redirectPort="8443" acceptCount="100" debug="0" connectionTimeout="20000" disableUploadTimeout="true" /&gt; 关键在于，笔者所在的支付平台服务化架构中，使用了两套服务化框架，一个是基于dubbo的框架，一个是点对点的RPC，用来紧急情况下dubbo服务出现问题，服务降级使用。 每个服务都配置了点对点的RPC服务，并且独享一个线程池： 12345&lt;Connector port="8090" maxThreads="800" minSpareThreads="25" maxSpareThreads="75" enableLookups="false" redirectPort="8443" acceptCount="100" debug="0" connectionTimeout="20000" disableUploadTimeout="true" /&gt; 由于我们在对dubbo服务框架进行定制化的时候，设计了自动降级原则，如果dubbo服务负载变高，会自动切换到点对点的RPC框架，这也符合微服务的失效转移原则，但是设计中没有进行全面的考虑，一旦一部分服务切换到了点对点的RPC，而一部分的服务没有切换，就导致两个现场池都被撑满，于是超过了1024的限制，就出了问题。 到这里，我们基本可以验证，问题的根源是日志切割导致IO负载增加，然后阻塞线程池，最后发生OOM：unable to create new native thread。 剩下的任务就是最小化重现的问题，通过实践来验证问题的原因。我们与性能压测部门沟通，提出压测需求： Tomcat线程池最大设置为1500. 操作系统允许的最大用户进程数1024. 在给服务加压的过程中，需要人工制造繁忙的IO操作，IO等待不得低于50%。 经过压测压测部门的一下午努力，环境搞定，结果证明完全可以重现此问题。 最后，与所有相关部门讨论和复盘，应用解决方案，解决方案包括： 全部应用改成按照小时切割，或者直接使用log4j的日志滚动功能。 Tomcat线程池的线程数设置与操作系统的线程数设置不合理，适当的减少Tomcat线程池线程数量的大小。 升级log4j日志，使用logback或者log4j2。 这次OOM问题的可以归结为“多个因、多个果、多台机器、多个服务池、不同时间”，针对这个问题，与运维部、监控部和性能压测部门的同事奋斗了几天几夜，终于通过在线上抓取信息、分析问题、在性能压测部门同事的帮助下，最小化重现问题并找到问题的根源原因，最后，针对问题产生的根源提供了有效的方案。 3. 与监控同事现场编写的脚本 本节提供一个笔者在实践过程中解决OOM问题的一个简单脚本，这个脚本是为了解决OOM（unable to create native thread)的问题而在问题机器上临时编写，并临时使用的，脚本并没有写的很专业，笔者也没有进行优化，保持原汁原味的风格，这样能让读者有种身临其境的感觉，只是为了抓取需要的信息并解决问题，但是在线上问题十分火急的情况下，这个脚本会有大用处。 12345678#!/bin/bashps -Leo pid,lwp,user,pcpu,pmem,cmd &gt;&gt; /tmp/pthreads.logecho "ps -Leo pid,lwp,user,pcpu,pmem,cmd &gt;&gt; /tmp/pthreads.log" &gt;&gt; /tmp/pthreads.logecho `date` &gt;&gt; /tmp/pthreads.logecho 1pid=`ps aux|grep tomcat|grep cwh|awk -F ' ' '&#123;print $2&#125;'`echo 2echo "pstack $pid &gt;&gt; /tmp/pstack.log" &gt;&gt; /tmp/pstack.logpstack $pid &gt;&gt; /tmp/pstack.logecho `date` &gt;&gt; /tmp/pstack.logecho 3echo "lsof &gt;&gt; /tmp/sys-o-files.log" &gt;&gt; /tmp/sys-o-files.loglsof &gt;&gt; /tmp/sys-o-files.logecho `date` &gt;&gt; /tmp/sys-o-files.logecho 4echo "lsof -p $pid &gt;&gt; /tmp/service-o-files.log" &gt;&gt; /tmp/service-o-files.loglsof -p $pid &gt;&gt; /tmp/service-o-files.logecho `date` &gt;&gt; /tmp/service-o-files.logecho 5echo "jstack -l $pid &gt;&gt; /tmp/js.log" &gt;&gt; /tmp/js.logjstack -l -F $pid &gt;&gt; /tmp/js.logecho `date` &gt;&gt; /tmp/js.logecho 6 echo "free -m &gt;&gt; /tmp/free.log" &gt;&gt; /tmp/free.logfree -m &gt;&gt; /tmp/free.logecho `date` &gt;&gt; /tmp/free.logecho 7echo "vmstat 2 1 &gt;&gt; /tmp/vm.log" &gt;&gt; /tmp/vm.logvmstat 2 1 &gt;&gt; /tmp/vm.logecho `date` &gt;&gt; /tmp/vm.logecho 8echo "jmap -dump:format=b,file=/tmp/heap.hprof 2743" &gt;&gt; /tmp/jmap.logjmap -dump:format=b,file=/tmp/heap.hprof &gt;&gt; /tmp/jmap.logecho `date` &gt;&gt; /tmp/jmap.logecho 9echo end 如果读者在线上已经遇到了OOM的问题，可以顺着这个看似简陋而又信息满满的Java服务的监控脚本的思路，利用本文提供的各种脚本和命令来深挖问题的根本原因。]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上服务内存OOM问题定位三板斧]]></title>
    <url>%2F2018%2F05%2F13%2F%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%86%85%E5%AD%98OOM%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E4%B8%89%E6%9D%BF%E6%96%A7%2F</url>
    <content type="text"><![CDATA[相信大家都有感触，线上服务内存OOM的问题，是最难定位的问题，不过归根结底，最常见的原因： 本身资源不够 申请的太多 资源耗尽 题目 某服务器上部署了Java服务一枚，出现了OutOfMemoryError，请问有可能是什么原因，问题应该如何定位？ 不妨设服务进程PID为10765 解决思路 Java服务OOM，最常见的原因为： 有可能是内存分配确实过小，而正常业务使用了大量内存 某一个对象被频繁申请，却没有释放，内存不断泄漏，导致内存耗尽 某一个资源被频繁申请，系统资源耗尽，例如：不断创建线程，不断发起网络连接 更具体的，可以使用以下的一些工具逐一排查。 一、确认是不是内存本身就分配过小方法：jmap -heap 10765 可以查看新生代，老生代堆内存的分配大小以及使用情况，看是否本身分配过小。 二、找到最耗内存的对象方法：jmap -histo:live 10765 | more 输入命令后，会以表格的形式显示存活对象的信息，并按照所占内存大小排序： 实例数 所占内存大小 类名 是不是很直观？对于实例数较多，占用内存大小较多的实例/类，相关的代码就要针对性review了。 上图中占内存最多的对象是RingBufferLogEvent，共占用内存18M，属于正常使用范围。 如果发现某类对象占用内存很大（例如几个G），很可能是类对象创建太多，且一直未释放。例如： 申请完资源后，未调用close()或dispose()释放资源 消费者消费速度慢（或停止消费了），而生产者不断往队列中投递任务，导致队列中任务累积过多 三、确认是否是资源耗尽工具： pstree netstat 查看进程创建的线程数，以及网络连接数，如果资源耗尽，也可能出现OOM。 这里介绍另一种方法，通过 /proc/${PID}/fd /proc/${PID}/task 可以分别查看句柄详情和线程数。 例如，某一台线上服务器的sshd进程PID是9339，查看 ll /proc/9339/fd ll /proc/9339/task 如上图，sshd共占用了四个句柄 0 -&gt; 标准输入 1 -&gt; 标准输出 2 -&gt; 标准错误输出 3 -&gt; socket（容易想到是监听端口） sshd只有一个主线程PID为9339，并没有多线程。 所以，只要 ll /proc/${PID}/fd | wc -l ll /proc/${PID}/task | wc -l （效果等同pstree -p | wc -l） 就能知道进程打开的句柄数和线程数。 附：MAT工具使用mac安装mat https://www.jianshu.com/p/68a657ed2286 方法一修改mat.app/Contents/Eclipse/MemoryAnalyzer.ini123456789101112-startup../Eclipse/plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar-data/Users/cdqiushengsen/Documents/mat/log--launcher.library../Eclipse/plugins/org.eclipse.equinox.launcher.cocoa.macosx.x86_64_1.1.300.v20150602-1417-vm/Library/Java/Home/jre-vmargs-Xmx1024m-Dorg.eclipse.swt.internal.carbon.smallFonts-XstartOnFirstThread 方法二mac启动 1mat.app/Contents/MacOS/MemoryAnalyzer -data ./workspace 配置获取dump文件，配置 1-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError 示例 1234567891011121314151617import java.util.ArrayList;import java.util.List;public class HeapDumpMain &#123; static class OOMHeapDumpObject&#123; String str ="1234567890"; &#125; public static void main(String[] args) &#123; List&lt;OOMHeapDumpObject&gt; ooms = new ArrayList&lt;OOMHeapDumpObject&gt;(); while (true) &#123; ooms.add(new OOMHeapDumpObject()); &#125; &#125;&#125; 打开生成Heap Dump文件 直接点击下方的 Reports-&gt;Leak Suspects 链接来生成报告，查看导致内存泄露的罪魁祸首]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java服务器load飙高排查思路]]></title>
    <url>%2F2018%2F05%2F13%2Fjava%E6%9C%8D%E5%8A%A1%E5%99%A8load%E9%A3%9A%E9%AB%98%E6%8E%92%E6%9F%A5%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[Load 是指对计算机干活多少的度量（WikiPedia：the system load is a measure of the amount of work that a computer system is doing），简单的说是进程队列的长度。Load Average 就是一段时间 (1 分钟、5分钟、15分钟) 内平均 Load 通过uptime命令可以查看当前的load，如果值很高。一般情况是java某些线程长期占用资源、死锁、死循环等导致某个进程占用的CPU资源过高。大致可以从以下几个角度来排查： 1.首先通过jps命令，查看当前进程id，如id为 28174 2.查看该进程下的线程资源使用情况 1top -p 28174 –H 1234567891011121314151632694 root 20 0 3249m 2.0g 11m S 2 6.4 3:31.12 java28175 root 20 0 3249m 2.0g 11m S 0 6.4 0:00.06 java28176 root 20 0 3249m 2.0g 11m S 0 6.4 1:40.79 java28177 root 20 0 3249m 2.0g 11m S 0 6.4 1:41.12 java28178 root 20 0 3249m 2.0g 11m S 0 6.4 1:41.11 java28179 root 20 0 3249m 2.0g 11m S 0 6.4 1:41.33 java28180 root 20 0 3249m 2.0g 11m S 0 6.4 1:41.58 java28181 root 20 0 3249m 2.0g 11m S 0 6.4 1:40.36 java28182 root 20 0 3249m 2.0g 11m S 0 6.4 1:41.02 java28183 root 20 0 3249m 2.0g 11m S 0 6.4 1:40.96 java28184 root 20 0 3249m 2.0g 11m S 0 6.4 4:38.30 java28185 root 20 0 3249m 2.0g 11m S 0 6.4 0:00.46 java28186 root 20 0 3249m 2.0g 11m S 0 6.4 0:01.83 java28187 root 20 0 3249m 2.0g 11m S 0 6.4 0:00.00 java28189 root 20 0 3249m 2.0g 11m S 0 6.4 0:00.01 java28190 root 20 0 3249m 2.0g 11m S 0 6.4 0:49.01 java 3.打印JAVA进程28174的堆栈信息 1jstack 28174 &gt;&gt; stack.log 4.将cpu消耗高的线程的pid换算为16进制 1printf 0x%x 32694 转换后的16进制为 0x7fb6 5.从刚才的栈日志中查找该线程正在运行的方法 1grep 0x7fb6 stack.log -a3 123456"MSXMLProcessorThread" prio=10 tid=0x00002b469923a800 [color=darkred]nid=0x7fb6[/color] sleeping[0x00002b46b0200000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.adventnet.management.xml.MSXmlProcessor.listen(MSXmlProcessor.java:279) at com.adventnet.management.xml.MSXmlProcessor.run(MSXmlProcessor.java:264) at java.lang.Thread.run(Thread.java:619) 6.另外也可以查找正在运行的线程，及线程处于运行状态的位置，从这些线程中来查找资源消耗过高的代码。 1grep RUNNABLE stack.log -a1 1less a.log |awk '&#123;FS="java.lang.Thread.State:";print $2&#125;'|sort |uniq -c |sort -nr]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2018%2F05%2F13%2Flinux-commands%2F</url>
    <content type="text"><![CDATA[CPU相关、进程查看cpu硬件配置1less /proc/cpuinfo 1234uname -a 查看内核/操作系统/CPU信息head -n 1 /etc/issue 查看操作系统版本less /proc/cpuinfo 查看CPU信息hostname 查看计算机名 top 命令实时显示各种系统资源使用情况及进程状态 1234567详细命令参数：h: 显示帮助c：显示详细的命令参数M：按照占用内存大小（%MEM 列）对进程排序；P：按照 CPU 使用率( %CPU 列）对进程排序；u：显示指定用户的进程。默认显示所有进程；T：根据累计运行时间排序 123456789第一行：当前时间：系统已运行时间：751天，目前4个用户，1、5、15分钟内的load分别是0.07、0.02 、0.00第二行：进程情况：总共148个，正在运行的有2个，休眠有139个，僵尸进程1个第三行：cpu的使用情况（按数字1显示所有cpu）第四行：内存情况（buffers表示用作内核缓存的内存量）第五行：虚拟内存情况（系统的物理内存不够用的时候，把硬盘空间中的一部分空间释放出来，以供当前运行的程序使用）第六行：进程id，虚拟内存，驻留内存使用，cpu，内存使用百分比，运行时间,命令参数等。VIRT表示进程可以使用的内存总大小，VIRT=SWAP+RES，包括这个进程真实使用的内存, 映射过的文件, 和别的进程共享的内存等。RES表示这个进程真实占用内存的大小，一般这个值和JVM的参数配置有关，如果%MEM使用过高则需要关注SHR表示可以和别的进程共享的内存和库大小。 某一个进程下的线程资源使用情况： 1top -p &#123;pid&#125; -H 查看系统load、cpu资源的其它命令 12345mpstat 1 （汇总的）mpstat -P ALL 1 （汇总的+每个cpu的）wuptimetop -H 和 ps -efL/ -Tel 显示 线程 统计一个进程下的线程数123456789cat /proc/$&#123;pid&#125;/status返回：...省略Threads: 74....省略其它命令：top -bH -d 3 -p &#123;pid&#125; pstree （以树状图的方式展现进程之间的派生关系）Linux命令大全 12pstree -ppstree -p &#123;pid&#125; | wc -l pstack （显示每个进程的栈跟踪），也可以查看一个进程下的线程总数 123pstack &#123;pid&#125;// 输出第一行pstack &#123;pid&#125; | head -1 查看所有进程12ps -efps -ef|grep java 5、对于Java应用从操作系统层面观察，就只有进程和线程两个指标，任何东西在操作系统层面都是以文件的形式存储的，进程也不例外。Linux上部署一个Tomcat程序产生一个进程，这个进程所有的东西都在这个目录下 ll /proc/{pid}/ 12## 可以查看所有的socket连接ll /proc/&#123;pid&#125;/fd | grep socket ulimit -a （显示当前的各种用户进程限制）linux修改max user processes limits 12345678910111213141516ulimit -acore file size (blocks, -c) 100data seg size (kbytes, -d) unlimitedfile size (blocks, -f) unlimitedpending signals (-i) 15237max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 15237virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 12345678910111213141516输出的每一行由资源名字、（单位，ulimit命令的参数）、软限制组成。详细解释：参数 描述core file size core文件的最大值为100 blocks，data seg size 进程的数据段可以任意大file size 文件可以任意大pending signals 最多有15237个待处理的信号max locked memory 一个任务锁住的物理内存的最大值为64kBmax memory size 一个任务的常驻物理内存的最大值open files 一个任务最多可以同时打开1024的文件pipe size 管道的最大空间为4096字节POSIX message queues POSIX的消息队列的最大值为819200字节stack size 进程的栈的最大值为8192字节cpu time 进程使用的CPU时间max user processes 当前用户同时打开的进程(包括线程)的最大个数为15237virtual memory 没有限制进程的最大地址空间file locks 所能锁住的文件的最大个数没有限制 内存相关vmstatVirtual Memory Statistics，统计进程、内存、io、cpu等的活动信息。对于多CPU系统，vmstat打印的是所有CPU的平均输出 12345678910111213141516171819202122procsr: 运行队列中进程数量b: 等待IO的进程数量memoryswpd: 使用虚拟内存大小free: 可用内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小swapsi: 每秒从交换区写到内存的大小so: 每秒从内存写入交换区的大小iobi: 每秒读取的块数（现在的Linux版本块的大小为1024bytes）bo: 每秒写入的块数systemin: 每秒中断数，包括时钟中断cs: 每秒上下文切换数cpu（以百分比表示）us: 用户进程执行时间(user time)sy: 系统进程执行时间(system time)id: 空闲时间(包括IO等待时间)wa: 等待IO时间 注意：排查问题时，要特别关注r的值，如果长时间超过cpu核数2倍，说明系统的负载很重，cpu已经无法及时处理堆积任务。 IO及网络网络协议OSI 七层模型 （应表会，传网数物） 应用层 APDU应用协议数据单元 应用协议数据单元 用户接口 表示层 PPDU 数据的表现形式，压缩、加密 会话层 SPDU 会话的管理、同步 上三层，给用户 传输层 TPDU TCP/UDP 可靠与不可靠的传输，确定端口 网络层 IP地址 报文，提供逻辑地址，选路由 数据链路层 成帧、用MAC地址访问媒介 物理层 物理层协议 设备之间的比特流的传输、物理接口、电气特性等 TCP/IP 四层协议常用网络命令清理dns缓存 mac 1sudo dscacheutil -flushcache curl参考 http://aiezu.com/article/linux_curl_command.html -i输出响应头和内容, -b设置cookie内容 1curl -i -b "TSESSIONID=K5PCUJM6W-NWH6793X36IPW7Y7QWSW3-868SY2XJ-YP6" https://portal.tongdun.cn/admin/acl/userManage.json?operationType=doSearch 12345curl -i -b "TSESSIONID=K5PCUJM6W-NWH6793X36IPW7Y7QWSW3-868SY2XJ-YP6" https://oceanus.tongdun.cn/PartnerAppSelect.json?operationType=doSelectMessagecurl -i http://login-dev.tongdun.cn:8081/userLogin.htm\?loginId\=asgard.pro.06@demo.com\&amp;password\=Tongdun123450curl -i https://login.tongdun.cn/userLogin.htm\?loginId\=asgard.pro.06@demo.com\&amp;password\=Tongdun123450 tsar –traffic：显示网络带宽netstat12# 查看端口，及其进程netstat -tunlp | grep 8088 1234# 所有TCP链接netstat -nat# 查询dubbo的链接，总数netstat -nat | grep ip:20880 | wc -l 统计每个状态的数量 1netstat -n | awk '/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,"\t",state[key]&#125;' 123456TIME_WAIT 5856CLOSE_WAIT 268FIN_WAIT1 3ESTABLISHED 4837SYN_RECV 14CLOSING 1 12345-t tcp-u udp-n numeric，使用数字显示，不用别名-l listening,正在监听-p programs,显示pid和名称 一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 命令参数： 123456789101112131415161718192021222324-a或–all 显示所有连线中的Socket。-A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。-c或–continuous 持续列出网络状态。-C或–cache 显示路由器配置的快取信息。-e或–extend 显示网络其他相关信息。-F或–fib 显示FIB。-g或–groups 显示多重广播功能群组组员名单。-h或–help 在线帮助。-i或–interfaces 显示网络界面信息表单。-l或–listening 显示监控中的服务器的Socket。-M或–masquerade 显示伪装的网络连线。-n或–numeric 直接使用IP地址，而不通过域名服务器。-N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。-o或–timers 显示计时器。-p或–programs 显示正在使用Socket的程序识别码和程序名称。-r或–route 显示Routing Table。-s或–statistice 显示网络工作信息统计表。-t或–tcp 显示TCP传输协议的连线状况。-u或–udp 显示UDP传输协议的连线状况。-v或–verbose 显示指令执行过程。-V或–version 显示版本信息。-w或–raw 显示RAW传输协议的连线状况。-x或–unix 此参数的效果和指定”-A unix”参数相同。–ip或–inet 此参数的效果和指定”-A inet”参数相同。 输出结果： 123456789101112131415161718一个是Active Internet connections，称为有源TCP连接，其中"Recv-Q"和"Send-Q"指的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。状态说明：LISTEN：侦听来自远方的TCP端口的连接请求SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了）SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了）ESTABLISHED：代表一个打开的连接FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认FIN-WAIT-2：从远程TCP等待连接中断请求CLOSE-WAIT：等待从本地用户发来的连接中断请求CLOSING：等待远程TCP对连接中断的确认LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击）TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认CLOSED：没有任何连接状态 找出运行在指定端口的进程 12netstat -anpt | grep ':20130'netstat -nat | grep "172.16.49.161:20130" 其它使用场景 1234567netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c 不同网络状态结果统计netstat -anop | grep 6379 应用连接Redis情况netstat -pt 输出中显示 PID 和进程名称netstat -s 查看网络统计信息netstat -nu 显示当前UDP连接状况netstat -nt 显示当前TCP连接状况netstat -i 显示网卡列表 3、 iostatiostat是I/O statistics（输入/输出统计）的缩写，主要的功能是对系统的磁盘I/O操作进行监视。它的输出主要显示磁盘读写操作的统计信息，同时也会给出CPU使用情况。同vmstat一样，iostat也不能对某个进程进行深入分析，仅对系统的整体情况进行分析。 命令参数： 12345678910-c 显示CPU使用情况-d 显示磁盘使用情况-k 以 KB 为单位显示-m 以 M 为单位显示-N 显示磁盘阵列(LVM) 信息-n 显示NFS 使用情况-p[磁盘] 显示磁盘和分区的情况-t 显示终端和CPU的信息-x 显示详细信息-V 显示版本信息 输出结果： 1234567891011121314151617181920212223242526272829cpu属性值说明：%user：CPU处在用户模式下的时间百分比。%nice：CPU处在带NICE值的用户模式下的时间百分比。%system：CPU处在系统模式下的时间百分比。%iowait：CPU等待输入输出完成时间的百分比。%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。%idle：CPU空闲时间百分比。备注：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。disk属性值说明：（iostat -x）rrqm/s: 每秒进行 merge 的读操作数目。即 rmerge/swrqm/s: 每秒进行 merge 的写操作数目。即 wmerge/sr/s: 每秒完成的读 I/O 设备次数。即 rio/sw/s: 每秒完成的写 I/O 设备次数。即 wio/srsec/s: 每秒读扇区数。即 rsect/swsec/s: 每秒写扇区数。即 wsect/srkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。wkB/s: 每秒写K字节数。是 wsect/s 的一半。avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。avgqu-sz: 平均I/O队列长度。await: 平均每次设备I/O操作的等待时间 (毫秒)。svctm: 平均每次设备I/O操作的服务时间 (毫秒)。%util: 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待。 定时显示所有信息（每隔 2秒刷新显示，且显示3次） 1iostat 2 3 以kB为单位显示所有信息 1iostat -k 3 4、traceroute1traceroute www.baidu.com 5、telnet 退出，ctrl+] 出现telnet后，再输入quit 文件lsof (一切皆文件)命令详情 查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP) 12// 查看sys.log文件被哪个进程打开lsof sys.log 12// 查看端口被哪个进程占用lsof -i：端口号 12// 查看各个进程打开的文件数量lsof -n |awk '&#123;print $2&#125; " " $3'|sort|uniq -c |sort -nr|more df123df -hldf -h 查看磁盘的使用情况磁盘的使用情况 du12du -hl当前目录下的最叶子目录的大小 12du -sch *当前目录下的各目录的大小 find文件查找 1234567891011121314151617181920212223find . -name "*蝙蝠侠*"# 找出当前目录以及其所有子目录下所有名字中包含“蝙蝠侠”三字的文件find . -inmae '*hello*' -maxdepth 1不区分大小写，在当前目录查找，不包括子目录find . -name "*.rmvb" -maxdepth 1# 找出当前目录（不包括子目录）下所有名字中后缀为".rmvb"的文件find . -name sys.log当前目录下查找sys.log文件find . -name "sy*log"查找文件支持通配符find . -size +20M查找当前目录下大小超过20M的文件find . -size +20M | xargs ls -lh查找当前目录下大小超过20M的文件，并计算文件大小find -type f -printf '%s %p\n' |sort -nr | head查找占用空间最大的10个文件 grep12345--递归查找目录下含有该字符串的所有文件grep -rn "data_chushou_pay_info" /home/hadoop/nisj/automationDemand/--查找当前目录下后缀名过滤的文件grep -rn "data_chushou_pay_info" *.py tail从指定点开始将文件标准输出 显示文件最后5行内容 1tail -n 5 test.log 实时显示文件内容 1tail -f test.log 12ping baidu.com &gt; 1.txt &amp;后台以守护进程的方式，将ping命令的返回结果写入 1.txt awk12# 每行按空格或TAB分割，输出文本中的1、4项 awk '&#123;print $1,$4&#125;' log.txt dirname在命令行状态下单纯执行1cd `dirname $0` 是毫无意义的。 因为他返回当前路径的”.”。这个命令写在脚本文件里才有作用，他返回这个脚本文件放置的目录，并可以根据这个目录来定位所要运行程序的相对位置（绝对位置除外）。 参考/Users/zhouxiaowu/Dropbox/commonShell 运行 dirnameDemo.sh 1234BASE_DIR=`dirname $0`echo $BASE_DIRcd `dirname $0`echo `pwd` 运行结果: 12./Users/zhouxiaowu/Dropbox/commonShell 这样就可以知道一些和脚本一起部署的文件的位置了，只要知道相对位置就可以根据这个目录来定位，而可以不用关心绝对位置。这样脚本的可移植性就提高了，扔到任何一台服务器，（如果是部署脚本）都可以执行。 sed1sed [-hnV][-e&lt;script&gt;][-f&lt;script文件&gt;][文本文件] 参数说明12345- -e&lt;script&gt;或--expression=&lt;script&gt; 以选项中指定的script来处理输入的文本文件。- -f&lt;script文件&gt;或--file=&lt;script文件&gt; 以选项中指定的script文件来处理输入的文本文件。- -h或--help 显示帮助。- -n或--quiet或--silent 仅显示script处理后的结果。- -V或--version 显示版本信息。 动作说明123456- a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～- c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！- d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；- i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；- p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～- s ：取代，可以直接进行取代的工作，通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 批量替换文件内容12345格式: sed -i "s/查找字段/替换字段/g" `grep 查找字段 -rl 路径`（centos测试有效，mac未生效）替换/root/test目录下的所有文件，book替换为apple sed -i "s/book/apple/g" `grep book -rl /root/test` 在testfile文件的第四行后添加一行 1sed -e 4a\newLine testfile 全部替换，并不会改变文件内容 123sed 's/book/books/g' filesed -e 's/book/books/g' file 从第2处开始替换 1echo sksksksksksk | sed 's/sk/SK/2g' 列印行号，同时，请将第 2~5 行删除 1nl /etc/passwd | sed '2,5d' 只要删除第 2 行 1nl /etc/passwd | sed '2d' 要删除第 3 到最后一行 1nl /etc/passwd | sed '3,$d' 用户123456w 查看活动用户id &lt;用户名&gt; 查看指定用户信息last 查看用户登录日志cut -d: -f1 /etc/passwd 查看系统所有用户cut -d: -f1 /etc/group 查看系统所有组crontab -l 查看当前用户的计划任务 命令行操作123ctrl+a 跳到行首ctrl+e 跳到行尾ctrl+u 删除整行 输出重定向123456789101112date &gt; test.log 标准输出覆盖方式date &gt;&gt; test.log 标准输出追加方式datea 2&gt;test.log 错误输出覆盖方式，&gt;后要紧挨着文件datea 2&gt;&gt;test.log 错误输出追加方式,&gt;后要紧挨着文件ifconfig &gt;&gt; test.log 2&gt;&amp;1 如果是正确输出留空格，错误输出到标准输出中，紧挨着ifconfig &amp;&gt;&gt; test.log 以追加的方式，错误和正确都输出到文件ifconfig &gt;&gt; 文件1 2&gt;&gt;文件2 以追加的方式，正确和错误分别到不同的文件ls &amp;&gt;/dev/null 正确和错误都到null 输入重定向 wc命令，输完，ctrl+d 统计 wc &lt; test.log 统计文件的行、单词、字符 管道符逻辑与或12345678910date ; ls ; 分号，顺序执行ls &amp;&amp; date 命令1 &amp;&amp; 命令2 命令1正确执行，才会执行2ll || date 命令1正确执行，命令2不会执行lsasdfsf &amp;&amp; echo "yes" || echo "no" 判断命令是否正确ls || echo "no" &amp;&amp; echo "yes" 等同于 （ls || echo "no"） &amp;&amp; echo "yes" 管道符12ll | morenetstat -an | grep ESTABLISHED | wc -l 统计多少行 统配符123456ls aa* * 0或多个字符ls aa? 一个ls aa[0-9] 一个选项ls aa[0-9][0-9]ls aa[^0-9] 取非ls aa[^0-9]* 变量，反引号，$()1234aa=123echo $aa 输出123echo "$aa" 123echo '$aa' '$aa' 12aa=`ls` 反引号，先执行结果，再赋值变量echo $aa $() 单小括号12aa=$(ls) 和反引号一样，先执行结果，再赋值变量echo $aa shell脚本查当前脚本所在路径1script_pwd = $( cd $(dirname $0) &amp;&amp; pwd ) 条件判断文件存在、权限判断 [ ]1234567-d 文件是否存在，为目录-e 文件是否存在-f 文件是否存在，为文件-r 文件是否存在，有读权限 不会区分当前用户是否有读权限-w 文件是否存在，有写权限-x 文件是否存在，有可执行权限 [] 在shell中是个命令，它左右必须有空格,才能识别里面的字符串 123[ -f hello.sh ] &amp;&amp; echo "yes" || echo "no" 测试文件是否存在 注意不能颠倒 &amp;&amp; || 顺序[ -w hello.sh ] &amp;&amp; echo "yes" || echo "no" 文件比较123-nf 新-ef 相同-of 旧 1[ ./hello.sh -ef ./hello.sh ] &amp;&amp; echo yes || echo no 两个文件是否相同 整数比较123456-eq 相等-ne 不等-gt 大于-lt 小于-ge 大于等于-le 小于等于 1[ 23 -ge 22 ] &amp;&amp; echo yes || echo no 整数比较 字符串比较1234-z 为空-n 不为空== 相等!= 不等 12name=hhh[ -n "$name" ] &amp;&amp; echo yes || echo no 不为空，输出yes 123aa=22 ; bb=22[ "$aa"=="$bb" ] &amp;&amp; echo yes || echo no 字符串比较是否相等[ "$aa" -eq "$bb" ] &amp;&amp; echo yes || echo no 数值整数比较 与或非条件123-a 与-o 或! 非 12aa=11[ -n "$aa" -a "$aa" -gt 23 ] &amp;&amp; echo yes || echo no 字符串不为空，数值大于23，输出yes if语句单分支 12345678910if [ 条件 ] ；then 程序fi或者 ， [] 等于 testif [ 条件 ] then 程序fi 判断当前用户 Dropbox/commonShell/isZhouxiaowu.sh 123456789101112#!/bin/bash#判断是否zhouxiaowu用户#获取当前的用户名u=$(env | grep USER= | cut -d "=" -f 2)echo $u#判断是否等于zhouxiaowuif [ "$u" == "zhouxiaowu" ] ; then echo "yes is zhouxiaowu!"fi 获取磁盘使用量，做告警Dropbox/commonShell/diskWarning.sh 123456789#!/bin/bash#获取磁盘的使用量，awk获取第5个单词，cut按%字符分隔，取第1个amount=$(df -h | grep disk1 | awk '&#123;print $5&#125;' | cut -d "%" -f 1)echo $amountif [ $amount -gt 90 ] ; then echo "磁盘使用量超过90%"fi 双分支 123456if [ 条件 ] then 执行语句 else 执行语句fi 判读是否目录Dropbox/commonShell/isDir.sh 12345678910111213#!/bin/bash# 输入读取read -t 30 -p "文件名：" dir# echo $dir# 判断是否目录if [ -d "$dir" ] then echo " is dir" else echo " is not dir"fi 判断tomcat是否启动 Dropbox/commonShell/isTomcatStarted.sh 多分支 123456789if [ 条件1 ] then 执行语句elif [ 条件2 ] then 执行语句else 执行语句fi 1echo $? 输出脚本的exit 返回 case语句12345678910case $变量 in "值1") 执行语句 ;; "值2") 执行语句 ;; *) 默认语句esac for语句1234for 变量 in 值1 值2 值3 ... do 执行语句 done 1234for(( i=0;i&lt;=100;i=i+1 )) do 执行语句 done 写在一行 1for i in ` seq 10000 `; do echo "hello sxt $i" &gt;&gt; test.txt;done 批量解压文件 Dropbox/commonShell/for_tar.sh 1234567891011121314#!/bin/bashcd /Users/zhouxiaowu/install/test_tarls *.tar.gz &gt; ls.logls *.tgz &gt;&gt; ls.logfor i in $( cat ls.log ) do echo "file is $i" tar -zxf $i &gt; /dev/null 2&gt;&amp;1 donerm ls.log 注意 i 不需要 $，引用变量才需要，定义和赋值变量不需要 1到100求和 12345678910#!/bin/bashs=0for(( i=0;i&lt;=100;i=i+1 )) do s=$(( $s+$i )) doneecho $s while语句1234while [ 条件语句 ] do 执行语句 done 1到100求和 123456789101112#!/bin/bashi=1s=0while [ $i -le 100 ] do s=$(( $s+$i )) i=$(( $i+1 )) doneecho $s 注意赋值 s=$(( $s+$i )) until语句 条件不成立执行 1234until [ 条件语句 ] do 执行语句 done 1234567891011121314#!/bin/bash# 从1到100求和s=0i=1until [ $i -gt 100 ] do s=$(( $s+$i )) i=$(( $i+1 )) doneecho "the sum is $s" 变量1env 查看环境变量 123bashbashpstree 查看pstree 1234#系统下的所有变量setset -u 报错提示unset aa 删除变量 1234567# 不能有空格# 字母和下划线开头，字母数字下划线组成# 自定义变量只对当前shell生效x=5# 变量调用echo $x PATH环境变量 PS1环境变量 12➜ ~ echo $PS1$&#123;ret_status&#125; %&#123;$fg[cyan]%&#125;%c%&#123;$reset_color%&#125; $(git_prompt_info) 变量叠加1234x=123# 一般用这种x="$x"456x=$(x)789 $@,$0,$1,$2的含义解释1$? 最后运行的命令的结束代码（返回值），正确为0,不确定非0 12345$$ 查看Shell本身的PID$! 查看Shell后台Process的PID#!/bin/bashecho "pid is $$" 1234567$0 Shell本身的文件名$1～$n 添加到Shell的各参数值。$1是第1参数、$2是第2参数…。$- 使用Set命令设定的Flag一览$* 所有参数列表。如"$*"用「"」括起来的情况、以"$1 $2 … $n"的形式输出所有参数。$@ 所有参数列表。如"$@"用「"」括起来的情况、以"$1" "$2" … "$n" 的形式输出所有参数。$# 添加到Shell的参数个数 1234567891011#!/bin/bashfor i in "$*" do echo $i donefor y in "$@" do echo $y done 1234567➜ commonShell ./param3.sh 1 2 3 4 51 2 3 4 5 $*1 $@2345 1234567891011#!/bin/bashprintf "The complete list is %s\n" "$$"printf "The complete list is %s\n" "$!"printf "The complete list is %s\n" "$?"printf "The complete list is %s\n" "$*"printf "The complete list is %s\n" "$@"printf "The complete list is %s\n" "$#" 个数2printf "The complete list is %s\n" "$0" 输出Dropbox/commonShell/var.shprintf "The complete list is %s\n" "$1" 输出qqprintf "The complete list is %s\n" "$2" 输出123 12345678➜ ~ Dropbox/commonShell/var.sh qq 123The complete list is 1626The complete list isThe complete list is 0The complete list is qq 123 $*输出The complete list is qq $@输出The complete list is 123 点号12345678. /lib/init/vars.sh. /lib/lsb/init-functions&lt;/span&gt;以往执行文件时都是用./file_name的形式，查阅了资料得知：1、 如果我们要执行某个文件，但是此文件不可执行，此时我们要用chmod u+x file_name来使文件具有可执行权限2、可是有时我们不想更改此文件的执行权限，但又想执行此文件，可以采用(点号--空格--文件名)的形式来执行一个脚本（只有root用户才可以这么做） 语系变量locale12345678910localeLANG="zh_CN.UTF-8" 定义系统主语系LC_COLLATE="zh_CN.UTF-8"LC_CTYPE="zh_CN.UTF-8"LC_MESSAGES="zh_CN.UTF-8"LC_MONETARY="zh_CN.UTF-8"LC_NUMERIC="zh_CN.UTF-8"LC_TIME="zh_CN.UTF-8"LC_ALL= 定义整体语系 12345echo $LANG 查看系统当前语系local -a | more 查看linux支持的所有语系zhcon 插件 read123456789101112131415#!/bin/bash# -p提示 -t时间内输入 name变量read -p "please input your name : " -t 30 nameecho $name# -s 安全输入read -p "please input your passwd : " -s passwdecho -e "\n"echo $passwd# -n 输入字符个数read -p "please input sex M/F : " -n 1 sexecho -e "\n"echo $sex 数值运算$(( $1+$2 )) 双小括号注意两边留空格 12345678#!/bin/bashnum1=$1num2=$2#数值计算sum=$(( $1 + $2 ))echo "sum is $sum" 1234echo $(( (11+3)*3/2 )) 21echo $(( 10%3 )) 1echo $(( 1&amp;&amp;0 )) 0echo $(( 1||0 )) 1 $[运算符]` 中括号1dd=$[$aa+$bb] $(expr $aa + $bb)1dd=$(expr $aa + $bb) +两侧必须有空格 declare变量声明12345678declare [+/-][选项] 变量名- 设定+ 取消变量的类型熟悉性-a 数组-i integer-x 环境变量-r 只读-p 输出类型 declare -p cc 定义数组 12345678movie[0]=aamovie[1]=bbecho $&#123;movie&#125; 输出aa,第0个echo $&#123;movie[1]&#125; 第1个echo $&#123;movie[*]&#125; 全部declare -a movie[2]=live 环境变量 123456declare -x test=123和export test 相似declare -p 查看全部变量declare -xr test=456 只读 环境变量declare +r test 提示只读 变量置换方式 ${y-新值}大括号，默认值12345678x=$&#123;y-新值&#125; y没有设置，x=新值；y存在，y为空值,x为空;设置y,x$yx=$&#123;y-2&#125;echo $x 为2y=""x=$&#123;y-2&#125;echo $x 为空 其它1、查看所有安装的软件包 1rpm -qa 2、查看环境变量 1env 3、Mac 删除git文件夹，删除svn文件夹 1234567cd到该文件夹//删除文件夹下的所有 .svn 文件find . -name ".svn" | xargs rm -Rf//删除文件夹下的所有 .git 文件find . -name ".git" | xargs rm -Rf 更多资料：https://app.yinxiang.com/Home.action#n=b0fcd794-072a-4fab-9ac6-012b7b0ad147&amp;ses=4&amp;sh=2&amp;sds=5&amp;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器异常案例]]></title>
    <url>%2F2018%2F05%2F13%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BC%82%E5%B8%B8%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[####1.某应用load&gt;7,ssh感到输入命令后,要等待1、2秒 才开始执行 top命令查看cpu占用率,约70%,不至于导致ssh中命令响应变慢 tsar查看最近的网络流量，正常 iostat 1，发现(虚拟机)磁盘tps达到500+非常高 jstack观察java中一个线程频繁操作磁盘 lsof命令观察打开文件，并排查代码发现配置项有误导致磁盘上出现很多小的零碎文件，引发频繁的随机访问，修改配置项后问题解决￼￼ ####2.应用Load&gt;10，GC正常，活跃线程数很多，CPU 100% ps -efL， 显示所有活跃线程ID和对应时间 根据对应线程SPID找出jstack中的执行栈 定位到问题代码，发现一个没同步保护的HashMap频繁并发put/get导致死循环 12注意：通常cpu使用率达到了100%，一般是某些线程在某种条件下进入死循环，退不出来 ####3.容灾演习之后服务无法启动 df –h 命令 /home 100%占用，日志文件巨大 删掉由于断网引起的大量重连日志，重启 ####4.￼某应用机器load狂飙100+，报警不断 收集各个系统指标，发现除了load之外没有异常，load&gt;进程数，应用响应正常 jstack中Runnable状态线程很多“atjava.io.UnixFileSystem.getBooleanAttributes0(Native Method)” ps –Tel 打印所有线程状态，发现大量怨妇进程（状态D，既无法中断又无法继续） 根据僵尸进程ID再次查找jstack中对应代码，为blocked的文件访问栈 df命令hang住 联系PE同学得知NAS故障,修复后重启OK ####5.Java进程健在，应用运行一段时间失去响应 jstat各个区域内存正常，应用服务器系统资源正常 查看应用默认日志文件发现一行“WARN [common] 服务器 已停止运行:12201” jstack发现有线程“JBoss Shutdown Hook”健在，查找代码发现居然有二方包代码在抛出异常后调用system.exit(0) ￼￼￼]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm堆参数调整]]></title>
    <url>%2F2018%2F05%2F13%2Fjvm%E5%A0%86%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4%2F</url>
    <content type="text"><![CDATA[偶然发现线上通过obelisk发布的应用默认没有配置堆大小等jvm参数 下面是社区的一个线上dubbo应用的jvm参数： 123-XX:CICompilerCount=3 -XX:InitialHeapSize=130023424 -XX:+ManagementServer -XX:MaxHeapSize=2063597568 -XX:MaxNewSize=687865856 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=42991616 -XX:OldSize=87031808 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC注：考虑安全性，部分数据删除 采用默认值，新生代只有600多M，堆区总大小也只有2个G 社区这边的线上机器基本都是标配4核8G，上面的配置太浪费，如果活动期间有较高并发量，估计新生代会不足，挤压老年代，持续gc，很容易雪崩。 线上jvm参数调整 1-Xms5020m -Xmx5020m -Xmn2500m -XX:PermSize=96m -XX:MaxPermSize=256m -XX:ParallelGCThreads=4 -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSMaxAbortablePrecleanTime=5000 -XX:+CMSClassUnloadingEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=80 ======================== 用了两台线上机做测试，配置一样 12192.168.16.116（参数未调整）192.168.18.62 （参数调整） 发布上线后，beta了一天，对比结果如下： 192.168.16.116（未调整参数），一天发生了YGC4000多次，整个gc时间26s 192.168.18.62 （参数调整），一天YGC只有300多次，整个gc时间只有5s 如果并发量大的情况下，估计这个差异会更大，支持的最大QPS应该会有很大提升，如果要准确数据的话可以性能压测对比下]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线上问题排查]]></title>
    <url>%2F2018%2F05%2F13%2Fjava%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[常用命令【优先】top查看负载，找到CPU过高的程序进程 【优先】top -Hp [进程id]查看该进程的所有线程，找到占用cpu较高的线程 【优先】jstack [进程id] &gt; js.txt打印当前线程堆栈，根据线程id（转换为16进制 printf %x ）找到CPU较高的线程堆栈 jstat -gcutil [进程id] 1000每隔1000秒打印jvm内存GC信息 jmap -histo [进程id] &gt; jmap.txt查看当前jvm内存里对象的实例数和内存数 【优先】jmap -dump:format=b,file=dump.bin [进程id]查看当前jvm内存里对象的实例数和内存数 堆内存dump文件分析 命令：jmap -dump:format=b,file=dump.bin [进程id] 工具：MAT FULL_GC问题定位 top 查看负载，找到CPU过高的程序进程 top -Hp [进程id] 查看该进程的所有线程，找到占用cpu较高的线程 jstack [进程id] &gt; js.txt 打印当前线程堆栈，根据线程id（转换为16进制 printf %x ）找到CPU较高的线程堆栈 三部基本可以定位到程序的一些问题。 当时发现，占用cpu较高的线程，基本都是GC线程 4、jstat -gcutil [进程id] 1000 每隔1000秒打印jvm内存GC信息， S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比 S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比 E 年轻代中Eden（伊甸园）已使用的占当前容量百分比 O old代已使用的占当前容量百分比 P perm代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) jmap -histo [进程id] &gt; jmap.txt 查看当前jvm内存里对象的实例数和内存数 6、看GC日志 启动脚本里添加gclog配置 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:gc.log 筛选Full GC log 堆内存dump文件分析 命令：jmap -dump:format=b,file=aa.bin 1232134 工具：MAT]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[anatomy]]></title>
    <url>%2F2018%2F05%2F13%2Fanatomy%2F</url>
    <content type="text"><![CDATA[简介anatomy 是阿里同学开发的一款用于JVM进程执行过程中的异常诊断工具，可以在不中断程序执行的情况下轻松完成问题排查工作。 纯Java实现的开源项目 安装使用便捷 方法级问题诊断 Groovy表达式展开变对象，方便你观察入参、出参、异常、当前对象的各种属性细节 接下来结合线上应用，列举常用的几个排查问题命令如何使用1、安装： 1curl -sLk http://ompc.oss.aliyuncs.com/greys/install.sh|sh 2、启动 123greys.sh &lt;PID&gt;注：PID：目标Java进程ID 3、help 1234567help 注：所有命令help watch注：help命令同时也支持对其他命令的一个解释说明，比如我们键入help watch，包含（用途说明、参数列表、实际例子） 4、sc 搜索所有已经加载到JVM中的Class信息。 1sc -d *RecommendManagerImpl 使用场景： 主要是用于排查一个应用可能存在同一个jar包的多个版本，而不同版本的类的方法可能会有实现上的差异，可以通过这种方式确认JVM中加载的是哪一个jar下的类。 5、monitor 方法层面的性能监控，非实时返回的命令，则是不断的等待目标Java进程返回信息，直到用户输入Ctrl+D为止 123monitor -c 5 *TimelineReadServiceImpl getEditorRecPost注：-c : 统计周期，默认值为120秒 使用场景： 线上反馈某个接口突然响应较慢，但又缺乏全链路维度节点的监控，可以通过该命令能定位到具体哪个方法耗时较长，有效缩小排查范围。 6、trace 统计整个调用链路上的所有性能开销和追踪调用链路。 1trace -n 2 *TimelineReadServiceImpl queryRecPageTimeLine 使用场景： 定位查找某一接口响应较慢，主要是损耗在哪一个环节。 另外也可以做为性能优化的参考标准，了解一个接口下面每个环节的消耗时间，从而判断是否合理，有没有优化的空间 7、watch 观察到指定方法的调用情况 能观察到的范围：入参、返回值、抛出异常，通过编写groovy表达式进行对应变量的查看。详细使用手册可以通过命令help watch 1234567891011watch -b *TimelineReadServiceImpl queryRecPageTimeLine params[0]注：打印完整的入参信息watch -b *TimelineReadServiceImpl queryRecPageTimeLine params[0] 'params[0].uid&gt;2894731' 注：带上groovy表达式，uid&gt;2894731watch -s *TimelineReadServiceImpl queryRecPageTimeLine params[0]+returnObj 'params[0].uid==3680667'注：当请求的uid为3680667时，打印入参和返回结果 8、 jvm 查看当前JVM的信息，无参数 参考资料https://github.com/oldmanpushcart/greys-anatomy/wiki/Commands#help]]></content>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用脚本]]></title>
    <url>%2F2018%2F05%2F13%2F%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[PS： 本仓库的脚本（如Java相关脚本）在阿里等公司（如随身云，见awesome-scripts仓库说明）的线上生产环境部署使用。如果你的公司有部署使用，欢迎使用通过提交Issue告知，方便互相交流反馈～ :cupid: :beginner: 快速下载&amp;使用1source &lt;(curl -fsSL https://raw.githubusercontent.com/oldratlee/useful-scripts/master/test-cases/self-installer.sh) 更多下载&amp;使用方式，参见下载使用。 :books: 使用文档:coffee: Java相关脚本 show-busy-java-threads 用于快速排查Java的CPU性能问题(top us值过高)，自动查出运行的Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用。 show-duplicate-java-classes 找出jar文件和class目录中的重复类。用于排查Java类冲突问题。 find-in-jars 在目录下所有jar文件里，查找类或资源文件。 :shell: Shell相关脚本Shell使用加强： c 原样命令行输出，并拷贝标准输出到系统剪贴板，省去CTRL+C操作，优化命令行与其它应用之间的操作流。 coat 彩色cat出文件行，方便人眼区分不同的行。 a2l 按行彩色输出参数，方便人眼查看。 ap and rp 批量转换文件路径为绝对路径/相对路径，会自动跟踪链接并规范化路径。 tcp-connection-state-counter 统计各个TCP连接状态的个数。用于方便排查系统连接负荷问题。 xpl and xpf 在命令行中快速完成 在文件浏览器中 打开/选中 指定的文件或文件夹的操作，优化命令行与其它应用之间的操作流。 Shell开发/测试加强： echo-args 输出脚本收到的参数，在控制台运行时，把参数值括起的括号显示成 红色，方便人眼查看。用于调试脚本参数输入。 console-text-color-themes.sh 显示Terminator的全部文字彩色组合的效果及其打印方式，用于开发Shell的彩色输出。 parseOpts.sh 命令行选项解析库，加强支持选项有多个值（即数组）。 :watch: VCS相关脚本目前VCS的脚本都是svn分支相关的操作。使用更现代的Git吧！ :boom: 因为不推荐使用svn，这里不再列出有哪些脚本了，如果你有兴趣可以点上面链接去看。]]></content>
      <categories>
        <category>shell脚本</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java后端架构师技术图谱]]></title>
    <url>%2F2018%2F05%2F08%2Fjava%E5%90%8E%E7%AB%AF%E6%9E%B6%E6%9E%84%E5%B8%88%E6%8A%80%E6%9C%AF%E5%9B%BE%E8%B0%B1%2F</url>
    <content type="text"><![CDATA[最后更新于20180502 [TOC] 数据结构队列 《java队列——queue详细分析》 非阻塞队列：ConcurrentLinkedQueue(无界线程安全)，采用CAS机制（compareAndSwapObject原子操作）。 阻塞队列：ArrayBlockingQueue(有界)、LinkedBlockingQueue（无界）、DelayQueue、PriorityBlockingQueue，采用锁机制；使用 ReentrantLock 锁。 《LinkedList、ConcurrentLinkedQueue、LinkedBlockingQueue对比分析》 集合 《Java Set集合的详解》 链表、数组 《Java集合详解–什么是List》 字典、关联数组 《Java map 详解 - 用法、遍历、排序、常用API等》 栈 《java数据结构与算法之栈（Stack）设计与实现》 《Java Stack 类》 《java stack的详细实现分析》 Stack 是线程安全的。 内部使用数组保存数据，不够时翻倍。 树二叉树每个节点最多有两个叶子节点。 《二叉树》 完全二叉树 《完全二叉树》 叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 平衡二叉树左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 《浅谈数据结构-平衡二叉树》 《浅谈算法和数据结构: 八 平衡查找树之2-3树》 二叉查找树（BST）二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。 《浅谈算法和数据结构: 七 二叉查找树》 红黑树 《最容易懂得红黑树》 添加阶段后，左旋或者右旋从而再次达到平衡。 《浅谈算法和数据结构: 九 平衡查找树之红黑树》 B-，B+，B*树MySQL是基于B+树聚集索引组织表 《B-树，B+树，B*树详解》 《B-树，B+树与B*树的优缺点比较》 B+ 树的叶子节点链表结构相比于 B- 树便于扫库，和范围检索。LSM 树 LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的。Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。 《LSM树 VS B+树》 B+ 树读性能好，但由于需要有序结构，当key比较分散时，磁盘寻道频繁，造成写性能。 LSM 是将一个大树拆分成N棵小树，先写到内存（无寻道问题，性能高），在内存中构建一颗有序小树（有序树），随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历（二分查找）所有的小树，但在每颗小树内部数据是有序的。 《LSM树（Log-Structured Merge Tree）存储引擎》 极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。 优化方式：Bloom filter 替代二分查找；compact 小数位大树，提高查询性能。 Hbase 中，内存中达到一定阈值后，整体flush到磁盘上、形成一个文件（B+数），HDFS不支持update操作，所以Hbase做整体flush而不是merge update。flush到磁盘上的小树，定期会合并成一个大树。 BitSet经常用于大规模数据的排重检查。 《Java Bitset类》 《Java BitSet（位集）》 常用算法 《常见排序算法及对应的时间复杂度和空间复杂度》 排序、查找算法 《常见排序算法及对应的时间复杂度和空间复杂度》 选择排序 《Java中的经典算法之选择排序（SelectionSort）》 每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。 冒泡排序 《冒泡排序的2种写法》 相邻元素前后交换、把最大的排到最后。 时间复杂度 O(n²) 插入排序 《排序算法总结之插入排序》 快速排序 《坐在马桶上看算法：快速排序》 一侧比另外一次都大或小。归并排序 《图解排序算法(四)之归并排序》 分而治之，分成小份排序，在合并(重建一个新空间进行复制)。 希尔排序TODO 堆排序 《图解排序算法(三)之堆排序》 排序过程就是构建最大堆的过程，最大堆：每个结点的值都大于或等于其左右孩子结点的值，堆顶元素是最大值。 计数排序 《计数排序和桶排序》 和桶排序过程比较像，差别在于桶的数量。 桶排序 《【啊哈！算法】最快最简单的排序——桶排序》 《排序算法（三）：计数排序与桶排序》 桶排序将[0,1)区间划分为n个相同的大小的子区间，这些子区间被称为桶。 每个通单独进行排序，然后再遍历每个桶。 基数排序按照个位、十位、百位、…依次来排。 《排序算法系列：基数排序》 《基数排序》 二分查找 《二分查找(java实现)》 要求待查找的序列有序。 时间复杂度 O(logN)。 《java实现二分查找-两种方式》 while + 递归。Java 中的排序工具 《Arrays.sort和Collections.sort实现原理解析》 Collections.sort算法调用的是合并排序。 Arrays.sort() 采用了2种排序算法 – 基本类型数据使用快速排序法，对象数组使用归并排序。 布隆过滤器常用于大数据的排重，比如email，url 等。核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。优点：空间和时间效率都很高。缺点：随着存入的元素数量增加，误算率随之增加。 《布隆过滤器 – 空间效率很高的数据结构》 《大量数据去重：Bitmap和布隆过滤器(Bloom Filter)》 《基于Redis的布隆过滤器的实现》 基于 Redis 的 Bitmap 数据结构。 《网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用》 使用Java中的 BitSet 类 和 加权和hash算法。 字符串比较KMP 算法KMP：Knuth-Morris-Pratt算法（简称KMP）核心原理是利用一个“部分匹配表”，跳过已经匹配过的元素。 《字符串匹配的KMP算法》 深度优先、广度优先 《广度优先搜索BFS和深度优先搜索DFS》 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 回溯算法 《 五大常用算法之四：回溯法》 剪枝算法 《α-β剪枝算法》 动态规划 《详解动态规划——邹博讲动态规划》 《动态规划算法的个人理解》 朴素贝叶斯 《带你搞懂朴素贝叶斯分类算法》 P(B|A)=P(A|B)P(B)/P(A) 《贝叶斯推断及其互联网应用1》 《贝叶斯推断及其互联网应用2》 推荐算法 《推荐算法综述》 《TOP 10 开源的推荐系统简介》 最小生成树算法 《算法导论–最小生成树（Kruskal和Prim算法）》 最短路径算法 《Dijkstra算法详解》 并发多线程 《40个Java多线程问题总结》 线程安全 《Java并发编程——线程安全及解决机制简介》 一致性、事务事务 ACID 特性 《数据库事务ACID特性》 事务的隔离级别 未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。 读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。 可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。 序列化：所有事物串行处理（牺牲了效率） 《理解事务的4种隔离级别》 数据库事务的四大特性及事务隔离级别 《MySQL的InnoDB的幻读问题 》 幻读的例子非常清楚。 通过 SELECT … FOR UPDATE 解决。 《一篇文章带你读懂MySQL和InnoDB》 图解脏读、不可重复读、幻读问题。 MVCC 《【mysql】关于innodb中MVCC的一些理解》 innodb 中 MVCC 用在 Repeatable-Read 隔离级别。 MVCC 会产生幻读问题（更新时异常。） 《轻松理解MYSQL MVCC 实现机制》 通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间 每次只操作比当前版本小（或等于）的 行。 锁Java中的锁和同步类 《Java中的锁分类》 主要包括 synchronized、ReentrantLock、和 ReadWriteLock。 《Java并发之AQS详解》 《Java中信号量 Semaphore》 有数量控制 申请用 acquire，申请不要则阻塞；释放用 release。 《java开发中的Mutex vs Semaphore》 简单的说 就是Mutex是排它的，只有一个可以获取到资源， Semaphore也具有排它性，但可以定义多个可以获取的资源的对象。 公平锁 &amp; 非公平锁公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。 《公平锁与非公平锁》 默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。 悲观锁悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。 《【MySQL】悲观锁&amp;乐观锁》 乐观锁的方式：版本号+重试方式 悲观锁：通过 select … for update 进行行锁(不可读、不可写，share 锁可读不可写)。 《Mysql查询语句使用select.. for update导致的数据库死锁分析》 mysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。 锁相同数据的不同索引条件可能会引起死锁。 《Mysql并发时经典常见的死锁原因及解决方法》 乐观锁 &amp; CAS 《乐观锁的一种实现方式——CAS》 和MySQL乐观锁方式相似，只不过是通过和原值进行比较。 ABA 问题由于高并发，在CAS下，更新后可能此A非彼A。通过版本号可以解决，类似于上文Mysql 中提到的的乐观锁。 《Java CAS 和ABA问题》 《Java 中 ABA问题及避免》 AtomicStampedReference 和 AtomicStampedReference。 CopyOnWrite容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。 《JAVA中写时复制(Copy-On-Write)Map实现》 实现读写分离，读取发生在原始数据上，写入发生在副本上。 不用加锁，通过最终一致实现一致性。 《聊聊并发-Java中的Copy-On-Write容器》 RingBuffer 《线程安全的无锁RingBuffer的实现【一个读线程，一个写线程】》 可重入锁 &amp; 不可重入锁 《可重入锁和不可重入锁》 通过简单代码举例说明可重入锁和不可重入锁。 可重入锁指同一个线程可以再次获得之前已经获得的锁。 可重入锁可以用户避免死锁。 Java中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock 《ReenTrantLock可重入锁（和synchronized的区别）总结》 synchronized 使用方便，编译器来加锁，是非公平锁。 ReenTrantLock 使用灵活，锁的公平性可以定制。 相同加锁场景下，推荐使用 synchronized。 互斥锁 &amp; 共享锁互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。 《ReadWriteLock场景应用》 死锁 《“死锁”四个必要条件的合理解释》 互斥、持有、不可剥夺、不可剥夺。 Java如何查看死锁？ JConsole 可以识别死锁。 java多线程系列：死锁及检测 jstack 可以显示死锁。 操作系统计算机原理 《操作系统基础知识——操作系统的原理，类型和结构》 CPU多级缓存典型的 CPU 有三级缓存，距离核心越近，速度越快，空间越小。L1 一般 32k，L2 一般 256k，L3 一般12M。内存速度需要200个 CPU 周期，CPU 缓存需要1个CPU周期。 《从Java视角理解CPU缓存和伪共享》 进程TODO 线程 《线程的生命周期及状态转换详解》 协程 《终结python协程—-从yield到actor模型的实现》 线程的调度是由操作系统负责，协程调度是程序自行负责 与线程相比，协程减少了无谓的操作系统切换. 实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换. Linux 《Linux 命令大全》 设计模式设计模式的六大原则 《设计模式的六大原则》 开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。 里氏代换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。 依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。 接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。 迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。 合成复用原则：尽量使用合成/聚合,而不是使用继承。 23种常见设计模式 《设计模式》 《23种设计模式全解析》 应用场景 《细数JDK里的设计模式》 结构型模式： 适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。 桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC； 组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。 装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。 享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。 代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy 创建模式: 抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。 建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。 工厂方法：就是 一个返* 回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。 原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。 单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。 行为模式： 责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。 命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。 解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。 迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。 中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。 空对象模式：如 java.util.Collections#emptyList()。 观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。 模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。 《Spring-涉及到的设计模式汇总》 《Mybatis使用的设计模式》 单例模式 《单例模式的三种实现 以及各自的优缺点》 《单例模式－－反射－－防止序列化破坏单例模式》 使用枚举类型。 责任链模式TODO MVC 《MVC 模式》 模型(model)－视图(view)－控制器(controller) IOC 《理解 IOC》 《IOC 的理解与解释》 正向控制：传统通过new的方式。反向控制，通过容器注入对象。 作用：用于模块解耦。 DI：Dependency Injection，即依赖注入，只关心资源使用，不关心资源来源。 AOP 《轻松理解AOP(面向切面编程)》 《Spring AOP详解》 《Spring AOP的实现原理》 Spring AOP使用的动态代理，主要有两种方式：JDK动态代理和CGLIB动态代理。 《Spring AOP 实现原理与 CGLIB 应用》 Spring AOP 框架对 AOP 代理类的处理原则是：如果目标对象的实现类实现了接口，Spring AOP 将会采用 JDK 动态代理来生成 AOP 代理类；如果目标对象的实现类没有实现接口，Spring AOP 将会采用 CGLIB 来生成 AOP 代理类 UML 《UML教程》 微服务思想 《微服务架构设计》 《微服务架构技术栈选型手册》 康威定律 《微服务架构的理论基础 - 康威定律》 定律一：组织沟通方式会通过系统设计表达出来，就是说架构的布局和组织结构会有相似。 定律二：时间再多一件事情也不可能做的完美，但总有时间做完一件事情。一口气吃不成胖子，先搞定能搞定的。 定律三：线型系统和线型组织架构间有潜在的异质同态特性。种瓜得瓜，做独立自治的子系统减少沟通成本。 定律四：大的系统组织总是比小系统更倾向于分解。合久必分，分而治之。 《微服务架构核⼼20讲》 运维 &amp; 统计 &amp; 技术支持常规监控 《腾讯业务系统监控的修炼之路》 监控的方式：主动、被动、旁路(比如舆情监控) 监控类型： 基础监控、服务端监控、客户端监控、监控、用户端监控 监控的目标：全、块、准 核心指标：请求量、成功率、耗时 《开源还是商用？十大云运维监控工具横评》 Zabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。 《监控报警系统搭建及二次开发经验》 命令行监控工具 《常用命令行监控工具》 top、sar、tsar、nload 《20个命令行工具监控 Linux 系统性能》 《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》 APMAPM — Application Performance Management 《Dapper，大规模分布式系统的跟踪系统》 CNCF OpenTracing，中文版 主要开源软件，按字母排序 Apache SkyWalking CAT CNCF jaeger Pinpoint Zipkin 《开源APM技术选型与实战》 主要基于 Google的Dapper（大规模分布式系统的跟踪系统） 思想。 统计分析 《流量统计的基础：埋点》 常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度 《APP埋点常用的统计工具、埋点目标和埋点内容》 第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。 《美团点评前端无痕埋点实践》 所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。 持续集成(CI/CD) 《持续集成是什么？》 《8个流行的持续集成工具》 Jenkins 《使用Jenkins进行持续集成》 环境分离开发、测试、生成环境分离。 《开发环境、生产环境、测试环境的基本理解和区》 自动化运维Ansible 《Ansible中文权威指南》 《Ansible基础配置和企业级项目实用案例》 puppet 《自动化运维工具——puppet详解》 chef 《Chef 的安装与使用》 测试TDD 理论 《深度解读 - TDD（测试驱动开发）》 基于测试用例编码功能代码，XP（Extreme Programming）的核心实践. 好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈； 单元测试 《Java单元测试之JUnit篇》 《JUnit 4 与 TestNG 对比》 TestNG 覆盖 JUnit 功能，适用于更复杂的场景。 《单元测试主要的测试功能点》 模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。 压力测试 《Apache ab 测试使用指南》 《大型网站压力测试及优化方案》 《10大主流压力/负载/性能测试工具推荐》 《真实流量压测工具 tcpcopy应用浅析》 《nGrinder 简易使用教程》 全链路压测 《京东618：升级全链路压测方案，打造军演机器人ForceBot》 《饿了么全链路压测的探索与实践》 《四大语言，八大框架｜滴滴全链路压测解决之道》 《全链路压测经验》 A/B 、灰度、蓝绿测试 《技术干货 | AB 测试和灰度发布探索及实践》 《nginx 根据IP 进行灰度发布》 《蓝绿部署、A/B 测试以及灰度发布》 虚拟化 《VPS的三种虚拟技术OpenVZ、Xen、KVM优缺点比较》 KVM 《KVM详解，太详细太深入了，经典》 《【图文】KVM 虚拟机安装详解》 Xen 《Xen虚拟化基本原理详解》 OpenVZ 《开源Linux容器 OpenVZ 快速上手指南》 容器技术Docker 《几张图帮你理解 docker 基本原理及快速入门》 《Docker 核心技术与实现原理》 《Docker 教程》 云技术OpenStack 《OpenStack构架知识梳理》 DevOps 《一分钟告诉你究竟DevOps是什么鬼？》 《DevOps详解》 文档管理 Confluence-收费文档管理系统 GitLab? Wiki 中间件Web ServerNginx 《Ngnix的基本学习-多进程和Apache的比较》 Nginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。 事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。 《nginx与Apache的对比以及优缺点》 nginx只适合静态和反向代理，不适合处理动态请求。 OpenResty 官方网站 《浅谈 OpenResty》 通过 Lua 模块可以在Nginx上进行开发。 Apache Httpd 官方网站 Tomcat架构原理 《TOMCAT原理详解及请求过程》 《Tomcat服务器原理详解》 《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》 《四张图带你了解Tomcat系统架构》 《JBoss vs. Tomcat: Choosing A Java Application Server》 Tomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Srping。 Jboss 实现全部了JEE特性，软件开源免费、文档收费。 调优方案 《Tomcat 调优方案》 启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）； 《tomcat http协议与ajp协议》 《AJP与HTTP比较和分析》 AJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。 并发高时，AJP协议优于HTTP协议。 Jetty 《Jetty 的工作原理以及与 Tomcat 的比较》 《jetty和tomcat优势比较》 架构比较:Jetty的架构比Tomcat的更为简单。 性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I/O请求上更占优势，Tomcat默认采用BIO处理I/O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。 其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。 缓存 《缓存失效策略（FIFO 、LRU、LFU三种算法的区别）》 本地缓存 《HashMap本地缓存》 《EhCache本地缓存》 堆内、堆外、磁盘三级缓存。 可按照缓存空间容量进行设置。 按照时间、次数等过期策略。 《Guava Cache》 简单轻量、无堆外、磁盘缓存。 《Nginx本地缓存》 《Pagespeed—懒人工具，服务器端加速》 客户端缓存 《浏览器端缓存》 主要是利用 Cache-Control 参数。 《H5 和移动端 WebView 缓存机制解析与实战》 服务端缓存Memcached 《Memcached 教程》 《深入理解Memcached原理》 采用多路复用技术提高并发性。 slab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。 《Memcached软件工作原理》 《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》 《memcache 中 add 、 set 、replace 的区别》 区别在于当key存在还是不存在时，返回值是true和false的。 《memcached全面剖析》 Redis 《Redis 教程》 《redis底层原理》 使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。 使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。 《Redis持久化方式》 RDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。 AOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。 也可以两者结合使用。 《分布式缓存–序列3–原子操作与CAS乐观锁》 架构 《Redis单线程架构》 回收策略 《redis的回收策略》 Tair 官方网站 《Tair和Redis的对比》 特点：可以配置备份节点数目，通过异步同步到备份节点 一致性Hash算法。 架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。 几种存储引擎: MDB，完全内存性，可以用来存储Session等数据。 Rdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作 LDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。 Tair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。 消息队列 《消息队列-推/拉模式学习 &amp; ActiveMQ及JMS学习》 RabbitMQ 消费者默认是推模式（也支持拉模式）。 Kafka 默认是拉模式。 Push方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。 Pull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。 《Kafka、RabbitMQ、RocketMQ等消息中间件的对比 —— 消息发送性能和区别》 消息总线消息总线相当于在消息队列之上做了一层封装，统一入口，统一管控、简化接入成本。 《消息总线VS消息队列》 消息的顺序 《如何保证消费者接收消息的顺序》 RabbitMQ支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。 《RabbitMQ的应用场景以及基本原理介绍》 《消息队列之 RabbitMQ》 《RabbitMQ之消息确认机制（事务+Confirm）》 RocketMQJava实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。 《RocketMQ 实战之快速入门》 ActiveMQ纯Java实现，兼容JMS，可以内嵌于Java应用中。 《ActiveMQ消息队列介绍》 Kafka高吞吐量、采用拉模式。适合高IO场景，比如日志同步。 官方网站 《各消息队列对比，Kafka深度解析，众人推荐，精彩好文！》 《Kafka分区机制介绍与示例》 Redis 消息推送生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。 《Redis学习笔记之十：Redis用作消息队列》 ZeroMQ TODO 定时调度单机定时调度 《linux定时任务cron配置》 《Linux cron运行原理》 fork 进程 + sleep 轮询 《Quartz使用总结》 《Quartz源码解析 —- 触发器按时启动原理》 《quartz原理揭秘和源码解读》 定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。 分布式定时调度 《这些优秀的国产分布式任务调度系统，你用过几个？》 opencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares 《Quartz任务调度的基本实现原理》 Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的 RPC 《从零开始实现RPC框架 - RPC原理及实现》 核心角色：Server: 暴露服务的服务提供方、Client: 调用远程服务的服务消费方、Registry: 服务注册与发现的注册中心。 《分布式RPC框架性能大比拼 dubbo、motan、rpcx、gRPC、thrift的性能比较》 Dubbo 官方网站 dubbo实现原理简单介绍 SPI TODO Thrift 官方网站 《Thrift RPC详解》 支持多语言，通过中间语言定义接口。 gRPC服务端可以认证加密，在外网环境下，可以保证数据安全。 官方网站 《你应该知道的RPC原理》 数据库中间件Sharding Jdbc 官网 日志系统日志搜集 《从零开始搭建一个ELKB日志收集系统》 《用ELK搭建简单的日志收集分析系统》 《日志收集系统-探究》 配置中心 Apollo - 携程开源的配置中心应用 Spring Boot 和 Spring Cloud 支持推、拉模式更新配置 支持多种语言 《基于zookeeper实现统一配置管理》 《 Spring Cloud Config 分布式配置中心使用教程》 servlet 3.0 异步特性可用于配置中心的客户端 《servlet3.0 新特性——异步处理》 API 网关主要职责：请求转发、安全认证、协议转换、容灾。 《API网关那些儿》 《谈API网关的背景、架构以及落地方案》 《使用Zuul构建API Gateway》 《HTTP API网关选择之一Kong介绍》 网络协议OSI 七层协议 《OSI七层协议模型、TCP/IP四层模型学习笔记》 TCP/IP 《深入浅出 TCP/IP 协议》 《TCP协议中的三次握手和四次挥手》 HTTP 《http协议详解(超详细)》 HTTP2.0 《HTTP 2.0 原理详细分析》 《HTTP2.0的基本单位为二进制帧》 利用二进制帧负责传输。 多路复用。 HTTPS 《https原理通俗了解》 使用非对称加密协商加密算法 使用对称加密方式传输数据 使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改。 《八大免费SSL证书-给你的网站免费添加Https安全加密》 网络模型 《web优化必须了解的原理之I/o的五种模型和web的三种工作模式》 五种I/O模型：阻塞I/O，非阻塞I/O，I/O复用、事件(信号)驱动I/O、异步I/O，前四种I/O属于同步操作，I/O的第一阶段不同、第二阶段相同，最后的一种则属于异步操作。 三种 Web Server 工作方式：Prefork(多进程)、Worker方式(线程方式)、Event方式。 《select、poll、epoll之间的区别总结》 select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。 select 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。 select，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。 poll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。 《select，poll，epoll比较 》 在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 《深入理解Java NIO》 NIO 是一种同步非阻塞的 IO 模型。同步是指线程不断轮询 IO 事件是否就绪，非阻塞是指线程在等待 IO 的时候，可以同时做其他任务 《BIO与NIO、AIO的区别》 《两种高效的服务器设计模型：Reactor和Proactor模型》 Epoll 《epoll使用详解（精髓）》 Java NIO 《深入理解Java NIO》 《Java NIO编写Socket服务器的一个例子》 kqueue 《kqueue用法简介》 连接和短连接 《TCP/IP系列——长连接与短连接的区别》 框架 《Netty原理剖析》 Reactor 模式介绍。 Netty 是 Reactor 模式的一种实现。 零拷贝（Zero-copy） 《对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解》 多个物理分离的buffer，通过逻辑上合并成为一个，从而避免了数据在内存之间的拷贝。 序列化(二进制协议)Hessian 《Hessian原理分析》Binary-RPC;不仅仅是序列化 Protobuf 《Protobuf协议的Java应用例子》Goolge出品、占用空间和效率完胜其他序列化类库，如Hessian；需要编写 .proto 文件。 《Protocol Buffers序列化协议及应用》 * 关于协议的解释；缺点：可读性差; 《简单的使用 protobuf 和 protostuff》 protostuff 的好处是不用写 .proto 文件，Java 对象直接就可以序列化。 数据库基础理论数据库设计的三大范式 《数据库的三大范式以及五大约束》 第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）； MySQL原理 《MySQL的InnoDB索引原理详解》 《MySQL存储引擎－－MyISAM与InnoDB区别》 两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁 《myisam和innodb索引实现的不同》 InnoDB 《一篇文章带你读懂Mysql和InnoDB》 优化 《MySQL36条军规》 《MYSQL性能优化的最佳20+条经验》 《SQL优化之道》 《mysql数据库死锁的产生原因及解决办法》 《导致索引失效的可能情况》 《 MYSQL分页limit速度太慢优化方法》 原则上就是缩小扫描范围。 索引聚集索引, 非聚集索引 《MySQL 聚集索引/非聚集索引简述》 《MyISAM和InnoDB的索引实现》 MyISAM 是非聚集，InnoDB 是聚集 复合索引 《复合索引的优点和注意事项》 自适应哈希索引(AHI) 《InnoDB存储引擎——自适应哈希索引》 explain 《MySQL 性能优化神器 Explain 使用分析》 NoSQLMongoDB MongoDB 教程 《Mongodb相对于关系型数据库的优缺点》 优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越； 缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方； Hbase 《简明 HBase 入门教程（开篇）》 《深入学习HBase架构原理》 《传统的行存储和（HBase）列存储的区别》 《Hbase与传统数据库的区别》 空数据不存储，节省空间，且适用于并发。 《HBase Rowkey设计》 rowkey 按照字典顺序排列，便于批量扫描。 通过散列可以避免热点。 搜索引擎搜索引擎原理 《倒排索引–搜索引擎入门》 Lucene 《Lucene入门简介》 Elasticsearch 《Elasticsearch学习，请先看这一篇！》 《Elasticsearch索引原理》 Solr 《 Apache Solr入门教程》 《elasticsearch与solr比较》 sphinx 《Sphinx 的介绍和原理探索》 性能性能优化方法论 《15天的性能优化工作，5方面的调优经验》 代码层面、业务层面、数据库层面、服务器层面、前端优化。 《系统性能优化的几个方面》 容量评估 《联网性能与容量评估的方法论和典型案例》 《互联网架构，如何进行容量设计？》 评估总访问量、评估平均访问量QPS、评估高峰QPS、评估系统、单机极限QPS CDN 网络 《CDN加速原理》 《国内有哪些比较好的 CDN？》 连接池 《主流Java数据库连接池比较与开发配置实战》 性能调优 《九大Java性能调试工具，必备至少一款》 大数据流式计算Storm 官方网站 《最详细的Storm入门教程》 Flink 《Flink之一 Flink基本原理介绍》 Kafka Stream 《Kafka Stream调研：一种轻量级流计算模式》 应用场景例如： 广告相关实时统计； 推荐系统用户画像标签实时更新； 线上服务健康状况实时监测； 实时榜单； 实时数据统计。 Hadoop 《用通俗易懂的话说下hadoop是什么,能做什么》 《史上最详细的Hadoop环境搭建》 HDFS 《【Hadoop学习】HDFS基本原理》 MapReduce 《用通俗易懂的大白话讲解Map/Reduce原理》 《 简单的map-reduce的java例子》 Yarn 《初步掌握Yarn的架构及原理》 Spark 《Spark(一): 基本架构及原理》 安全web 安全XSS 《xss攻击原理与解决方法》CSRF 《CSRF原理及防范》 SQL 注入 《SQL注入》 Hash Dos 《邪恶的JAVA HASH DOS攻击》 利用JsonObjet 上传大Json，JsonObject 底层使用HashMap；不同的数据产生相同的hash值，使得构建Hash速度变慢，耗尽CPU。 《一种高级的DoS攻击-Hash碰撞攻击》 《关于Hash Collision DoS漏洞：解析与解决方案》 脚本注入 《上传文件漏洞原理及防范》 漏洞扫描工具 《DVWA》 W3af OpenVAS详解 验证码 《验证码原理分析及实现》 《详解滑动验证码的实现原理》 滑动验证码是根据人在滑动滑块的响应时间，拖拽速度，时间，位置，轨迹，重试次数等来评估风险。 《淘宝滑动验证码研究》 DDoS 防范 《学习手册：DDoS的攻击方式及防御手段》 《免费DDoS攻击测试工具大合集》 用户隐私信息保护 用户密码非明文保存，加动态slat。 身份证号，手机号如果要显示，用 “*” 替代部分字符。 联系方式在的显示与否由用户自己控制。 TODO 《个人隐私包括哪些》 《在互联网上，隐私的范围包括哪些？》 《用户密码保存》 序列化漏洞 《Lib之过？Java反序列化漏洞通用利用分析》 加密解密对称加密 《常见对称加密算法》 DES、3DES、Blowfish、AES DES 采用 56位秘钥，Blowfish 采用1到448位变长秘钥，AES 128，192和256位长度的秘钥。 DES 秘钥太短（只有56位）算法目前已经被 AES 取代，并且 AES 有硬件加速，性能很好。 哈希算法 《常用的哈希算法》 MD5 和 SHA-1 已经不再安全，已被弃用。 目前 SHA-256 是比较安全的。 《基于Hash摘要签名的公网URL签名验证设计方案》 非对称加密 《常见非对称加密算法》 RSA、DSA、ECDSA(螺旋曲线加密算法) 和 RSA 不同的是 DSA 仅能用于数字签名，不能进行数据加密解密，其安全性和RSA相当，但其性能要比RSA快。 256位的ECC秘钥的安全性等同于3072位的RSA秘钥。 《区块链的加密技术》 服务器安全 《Linux强化论：15步打造一个安全的Linux服务器》 数据安全数据备份TODO 网络隔离内外网分离TODO 登录跳板机在内外环境中通过跳板机登录到线上主机。 《搭建简易堡垒机》 授权、认证RBAC 《基于组织角色的权限设计》 《权限系统与RBAC模型概述》 《Spring整合Shiro做权限控制模块详细案例分析》 OAuth2.0 《理解OAuth 2.0》 双因素认证（2FA）2FA - Two-factor authentication，用于加强登录验证 常用做法是 登录密码 + 手机验证码（或者令牌Key，类似于与网银的 USB key） 【《双因素认证（2FA）教程》】(http://www.ruanyifeng.com/blog/2017/11/2fa-tutorial.html) 单点登录(SSO) 《单点登录原理与简单实现》 CAS单点登录框架 常用开源框架开源协议 《开源协议的选择》 如何选择一个开源软件协议 日志框架Log4j、Log4j2 《log4j 详细讲解》 《log4j2 实际使用详解》 《Log4j1,Logback以及Log4j2性能测试对比》 Log4J 异步日志性能优异。 Logback 《最全LogBack 详解、含java案例和配置说明》 ORM 《ORM框架使用优缺点》 主要目的是为了提高开发效率。 MyBatis： 《mybatis缓存机制详解》 一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效 二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。 《MyBatis学习之代码生成器Generator》 网络框架TODO Web 框架Spring 家族Spring Spring 简明教程 Spring Boot 官方网站 《Spring Boot基础教程》 Spring Cloud Spring Boot 中文索引站 Spring Cloud 中文文档 《Spring Cloud基础教程》 工具框架 《Apache Commons 工具类介绍及简单使用》 《Google guava 中文教程》 分布式设计扩展性设计 《架构师不可不知的十大可扩展架构》 总结下来，通用的套路就是分布、缓存及异步处理。 《可扩展性设计之数据切分》 水平切分+垂直切分 利用中间件进行分片如，MySQL Proxy。 利用分片策略进行切分，如按照ID取模。 《说说如何实现可扩展性的大型网站架构》 分布式服务+消息队列。 《大型网站技术架构（七）–网站的可扩展性架构》 稳定性 &amp; 高可用 《系统设计：关于高可用系统的一些技术方案》 可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。 隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。 解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。 限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。 降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。 熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。 自动化测试：通过完善的测试，减少发布引起的故障。 灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。 《关于高可用的系统》 设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。 硬件负载均衡 《转！！负载均衡器技术Nginx和F5的优缺点对比》 主要是和F5对比。 《软/硬件负载均衡产品 你知多少？》 软件负载均衡 《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS 《DNS负载均衡》 配置简单，更新速度慢。 《Nginx负载均衡》 简单轻量、学习成本低；主要适用于web应用。 《借助LVS+Keepalived实现负载均衡 》 配置比较负载、只支持到4层，性能较高。 《HAProxy用法详解 全网最详细中文文档》 支持到七层（比如HTTP）、功能比较全面，性能也不错。 《Haproxy+Keepalived+MySQL实现读均衡负载》 主要是用户读请求的负载均衡。 《rabbitmq+haproxy+keepalived实现高可用集群搭建》 限流 《谈谈高并发系统的限流》 计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。 漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。 令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。 Nginx 限流：通过 limit_req 等模块限制并发连接数。 应用层容灾 《防雪崩利器：熔断器 Hystrix 的原理与使用》 雪崩效应原因：硬件故障、硬件故障、程序Bug、重试加大流量、用户大量请求。 雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。 Hystrix设计原则： 资源隔离：Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。 熔断开关：服务的健康状况 = 请求失败数 / 请求总数，通过阈值设定和滑动窗口控制开关。 命令模式：通过继承 HystrixCommand 来包装服务调用逻辑。 《缓存穿透，缓存击穿，缓存雪崩解决方案分析》 《缓存击穿、失效以及热点key问题》 主要策略：失效瞬间：单机使用锁；使用分布式锁；不过期； 热点数据：热点数据单独存储；使用本地缓存；分成多个子key； 跨机房容灾 《“异地多活”多机房部署经验谈》 通过自研中间件进行数据同步。 《异地多活（异地双活）实践经验》 注意延迟问题，多次跨机房调用会将延时放大数倍。 建房间专线很大概率会出现问题，做好运维和程序层面的容错。 不能依赖于程序端数据双写，要有自动同步方案。 数据永不在高延迟和较差网络质量下，考虑同步质量问题。 核心业务和次要业务分而治之，甚至只考虑核心业务。 异地多活监控部署、测试也要跟上。 业务允许的情况下考虑用户分区，尤其是游戏、邮箱业务。 控制跨机房消息体大小，越小越好。 考虑使用docker容器虚拟化技术，提高动态调度能力。 容灾技术及建设经验介绍 容灾演练流程 《依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验》 常见故障画像 案例：预案有效性、预案有效性、故障复现、架构容灾测试、参数调优、参数调优、故障突袭、联合演练。 平滑启动 平滑重启应用思路1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用 《JVM安全退出（如何优雅的关闭java服务）》推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。 《常见Java应用如何优雅关闭》Java、Srping、Dubbo 优雅关闭方式。 数据库扩展读写分离模式 《Mysql主从方案的实现》 《搭建MySQL主从复制经典架构》 《Haproxy+多台MySQL从服务器(Slave) 实现负载均衡》 《DRBD+Heartbeat+Mysql高可用读写分离架构》 DRDB 进行磁盘复制，避免单点问题。 《MySQL Cluster 方式》 分片模式 《分库分表需要考虑的问题及方案》 中间件： 轻量级：sharding-jdbc、TSharding；重量级：Atlas、MyCAT、Vitess等。 问题：事务、Join、迁移、扩容、ID、分页等。 事务补偿：对数据进行对帐检查;基于日志进行比对;定期同标准数据来源进行同步等。 分库策略：数值范围；取模；日期等。 分库数量：通常 MySQL 单库 5千万条、Oracle 单库一亿条需要分库。 《MySql分表和表分区详解》 分区：是MySQL内部机制，对客户端透明，数据存储在不同文件中，表面上看是同一个表。 分表：物理上创建不同的表、客户端需要管理分表路由。 服务治理服务注册与发现 《永不失联！如何实现微服务架构中的服务发现？》 客户端服务发现模式：客户端直接查询注册表，同时自己负责负载均衡。Eureka 采用这种方式。 服务器端服务发现模式：客户端通过负载均衡查询服务实例。 《SpringCloud服务注册中心比较:Consul vs Zookeeper vs Etcd vs Eureka》 CAP支持：Consul（CA）、zookeeper（cp）、etcd（cp） 、euerka（ap） 作者认为目前 Consul 对 Spring cloud 的支持比较好。 《基于Zookeeper的服务注册与发现》 优点：API简单、Pinterest，Airbnb 在用、多语言、通过watcher机制来实现配置PUSH，能快速响应配置变化。 服务路由控制 《分布式服务框架学习笔记4 服务路由》 原则：透明化路由 负载均衡策略：随机、轮询、服务调用延迟、一致性哈希、粘滞连接 本地路由有限策略：injvm(优先调用jvm内部的服务)，innative(优先使用相同物理机的服务),原则上找距离最近的服务。 配置方式：统一注册表；本地配置；动态下发。 分布式一致CAP 与 BASE 理论 《从分布式一致性谈到CAP理论、BASE理论》 一致性分类：强一致(立即一致)；弱一致(可在单位时间内实现一致，比如秒级)；最终一致(弱一致的一种，一定时间内最终一致) CAP：一致性、可用性、分区容错性(网络故障引起) BASE：Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性） BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 分布式锁 《分布式锁的几种实现方式》 基于数据库的分布式锁：优点：操作简单、容易理解。缺点：存在单点问题、数据库性能够开销较大、不可重入； 基于缓存的分布式锁：优点：非阻塞、性能好。缺点：操作不好容易造成锁无法释放的情况。 Zookeeper 分布式锁：通过有序临时节点实现锁机制，自己对应的节点需要最小，则被认为是获得了锁。优点：集群可以透明解决单点问题，避免锁不被释放问题，同时锁可以重入。缺点：性能不如缓存方式，吞吐量会随着zk集群规模变大而下降。 《基于Zookeeper的分布式锁》 清楚的原理描述 + Java 代码示例。 《jedisLock—redis分布式锁实现》 基于 setnx(set if ont exists)，有则返回false，否则返回true。并支持过期时间。 《Memcached 和 Redis 分布式锁方案》 利用 memcached 的 add（有别于set）操作，当key存在时，返回false。 分布式一致性算法PAXOS 《分布式系列文章——Paxos算法原理与推导》 《Paxos–&gt;Fast Paxos–&gt;Zookeeper分析》 《【分布式】Zookeeper与Paxos》 Zab 《Zab：Zookeeper 中的分布式一致性协议介绍》 Raft 《Raft 为什么是更易理解的分布式一致性算法》 三种角色：Leader（领袖）、Follower（群众）、Candidate（候选人） 通过随机等待的方式发出投票，得票多的获胜。 Gossip 《Gossip算法》 两阶段提交、多阶段提交 《关于分布式事务、两阶段提交协议、三阶提交协议》 幂等 《分布式系统—幂等性设计》 幂等特性的作用：该资源具备幂等性，请求方无需担心重复调用会产生错误。 常见保证幂等的手段：MVCC（类似于乐观锁）、去重表(唯一索引)、悲观锁、一次性token、序列号方式。 分布式一致方案 《分布式系统事务一致性解决方案》 《保证分布式系统数据一致性的6种方案》 分布式 Leader 节点选举 《利用zookeeper实现分布式leader节点选举》 TCC(Try/Confirm/Cancel) 柔性事务 《传统事务与柔性事务》 基于BASE理论：基本可用、柔性状态、最终一致。 解决方案：记录日志+补偿（正向补充或者回滚）、消息重试(要求程序要幂等)；“无锁设计”、采用乐观锁机制。 分布式文件系统 说说分布式文件存储系统-基本架构 ？ 《各种分布式文件系统的比较》 ？ HDFS：大批量数据读写，用于高吞吐量的场景，不适合小文件。 FastDFS：轻量级、适合小文件。 唯一ID 生成全局唯一ID 《高并发分布式系统中生成全局唯一Id汇总》 Twitter 方案（Snowflake 算法）：41位时间戳+10位机器标识（比如IP，服务器名称等）+12位序列号(本地计数器) Flicker 方案：MySQL自增ID + “REPLACE INTO XXX:SELECT LAST_INSERT_ID();” UUID：缺点，无序，字符串过长，占用空间，影响检索性能。 MongoDB 方案：利用 ObjectId。缺点：不能自增。 《TDDL 在分布式下的SEQUENCE原理》 在数据库中创建 sequence 表，用于记录，当前已被占用的id最大值。 每台客户端主机取一个id区间（比如 1000~2000）缓存在本地，并更新 sequence 表中的id最大值记录。 客户端主机之间取不同的id区间，用完再取，使用乐观锁机制控制并发。 一致性Hash算法 《一致性哈希算法》 设计思想 &amp; 开发模式DDD(Domain-driven Design - 领域驱动设计) 《浅谈我对DDD领域驱动设计的理解》 概念：DDD 主要对传统软件开发流程(分析-设计-编码)中各阶段的割裂问题而提出，避免由于一开始分析不明或在软件开发过程中的信息流转不一致而造成软件无法交付（和需求方设想不一致）的问题。DDD 强调一切以领域（Domain）为中心，强调领域专家（Domain Expert）的作用，强调先定义好领域模型之后在进行开发，并且领域模型可以指导开发（所谓的驱动）。 过程：理解领域、拆分领域、细化领域，模型的准确性取决于模型的理解深度。 设计：DDD 中提出了建模工具，比如聚合、实体、值对象、工厂、仓储、领域服务、领域事件来帮助领域建模。 《领域驱动设计的基础知识总结》 领域（Doamin）本质上就是问题域，比如一个电商系统，一个论坛系统等。 界限上下文（Bounded Context）：阐述子域之间的关系，可以简单理解成一个子系统或组件模块。 领域模型（Domain Model）：DDD的核心是建立（用通用描述语言、工具—领域通用语言）正确的领域模型；反应业务需求的本质，包括实体和过程；其贯穿软件分析、设计、开发 的整个过程；常用表达领域模型的方式：图、代码或文字； 领域通用语言：领域专家、开发设计人员都能立即的语言或工具。 经典分层架构：用户界面/展示层、应用层、领域层、基础设施层，是四层架构模式。 使用的模式： 关联尽量少，尽量单项，尽量降低整体复杂度。 实体（Entity）：领域中的唯一标示，一个实体的属性尽量少，少则清晰。 值对象（Value Object）：没有唯一标识，且属性值不可变，小二简单的对象，比如Date。 领域服务（Domain Service）： 协调多个领域对象，只有方法没有状态(不存数据)；可以分为应用层服务，领域层服务、基础层服务。 聚合及聚合根（Aggregate，Aggregate Root）：聚合定义了一组具有内聚关系的相关对象的集合；聚合根是对聚合引用的唯一元素；当修改一个聚合时，必须在事务级别；大部分领域模型中，有70%的聚合通常只有一个实体，30%只有2~3个实体；如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互； 工厂（Factory）：类似于设计模式中的工厂模式。 仓储（Repository）：持久化到DB，管理对象，且只对聚合设计仓储。 《领域驱动设计(DDD)实现之路》 聚合：比如一辆汽车（Car）包含了引擎（Engine）、车轮（Wheel）和油箱（Tank）等组件，缺一不可。 《领域驱动设计系列（2）浅析VO、DTO、DO、PO的概念、区别和用处》 命令查询职责分离(CQRS)CQRS — Command Query Responsibility Seperation 《领域驱动设计系列 (六)：CQRS》 核心思想：读写分离（查询和更新在不同的方法中），不同的流程只是不同的设计方式，CQ代码分离，分布式环境中会有明显体现（有冗余数据的情况下），目的是为了高性能。 《DDD CQRS架构和传统架构的优缺点比较》 最终一致的设计理念；依赖于高可用消息中间件。 《CQRS架构简介》 一个实现 CQRS 的抽象案例。 《深度长文：我对CQRS/EventSourcing架构的思考》 CQRS 模式分析 + 12306 抢票案例 贫血，充血模型 《贫血，充血模型的解释以及一些经验》 失血模型：老子和儿子分别定义，相互不知道，二者实体定义中完全没有业务逻辑，通过外部Service进行关联。 贫血模型：老子知道儿子，儿子也知道老子；部分业务逻辑放到实体中；优点：各层单项依赖，结构清楚，易于维护；缺点：不符合OO思想，相比于充血模式，Service层较为厚重； 充血模型：和贫血模型类似，区别在于如何划分业务逻辑。优点：Service层比较薄，只充当Facade的角色，不和DAO打交道、复合OO思想；缺点：非单项依赖，DO和DAO之间双向依赖、和Service层的逻辑划分容易造成混乱。 肿胀模式：是一种极端情况，取消Service层、全部业务逻辑放在DO中；优点：符合OO思想、简化了分层；缺点：暴露信息过多、很多非DO逻辑也会强行并入DO。这种模式应该避免。 作者主张使用贫血模式。 Actor 模式TODO 响应式编程ReactorTODO RxJavaTODO Vert.xTODO DODAF2.0 《DODAF2.0方法论》 《DODAF2.0之能力视角如何落地》 ServerlessTODO Service MeshTODO 《什么是Service Mesh？》 项目管理架构评审 《架构设计之如何评审架构设计说明书》 《人人都是架构师：非功能性需求》 重构 《架构之重构的12条军规》 代码规范TODO 代码 Review制度还是制度!另外，每个公司需要根据自己的需求和目标制定自己的 check list 《为什么你做不好 Code Review？》 代码 review 做的好，在于制度建设。 《从零开始Code Review》 《Code Review Checklist》 《Java Code Review Checklist》 《如何用 gitlab 做 code review》 RUP 《运用RUP 4+1视图方法进行软件架构设计》 看板管理 《说说看板在项目中的应用》 SCRUMSCRUM - 争球 3个角色:Product Owner(PO) 产品负责人;Scrum Master（SM），推动Scrum执行;Team 开发团队。 3个工件：Product Backlog 产品TODOLIST，含优先级;Sprint Backlog 功能开发 TODO LIST；燃尽图； 五个价值观：专注、勇气、公开、承诺、尊重。 《敏捷项目管理流程-Scrum框架最全总结！》 《敏捷其实很简单3—敏捷方法之scrum》 敏捷开发TODO 极限编程（XP）XP - eXtreme Programming 《主流敏捷开发方法：极限编程XP》 是一种指导开发人员的方法论。 4大价值： 沟通：鼓励口头沟通，提高效率。 简单：够用就好。 反馈：及时反馈、通知相关人。 勇气：提倡拥抱变化，敢于重构。 5个原则：快速反馈、简单性假设、逐步修改、提倡更改（小步快跑）、优质工作（保证质量的前提下保证小步快跑）。 5个工作：阶段性冲刺；冲刺计划会议；每日站立会议；冲刺后review；回顾会议。 结对编程边写码，边review。能够增强代码质量、减少bug。 《结对编程》 FMEA管理模式TODO 通用业务术语TODO 技术趋势TODO 政策、法规TODO 法律严格遵守刑法253法条我国刑法第253条之一规定： 国家机关或者金融、电信、交通、教育、医疗等单位的工作人员，违反国家规定，将本单位在履行职责或者提供服务过程中获得的公民个人信息，出售或者非法提供给他人，情节严重的，处3年以下有期徒刑或者拘役，并处或者单处罚金。 窃取或者以其他方法非法获取上述信息，情节严重的，依照前款的规定处罚。 单位犯前两款罪的，对单位判处罚金，并对其直接负责的主管人员和其他直接责任人员，依照各该款的规定处罚。 最高人民法院、最高人民检察院关于执行《中华人民共和国刑法》确定罪名的补充规定（四）规定：触犯刑法第253条之一第1款之规定，构成“出售、非法提供公民个人信息罪”；触犯刑法第253条之一第2款之规定，构成“非法获取公民个人信息罪” 《非法获取公民个人信息罪》 架构师素质 《架构师画像》 业务理解和抽象能力 NB的代码能力 全面：1. 在面对业务问题上，架构师脑海里是否会浮现出多种技术方案；2. 在做系统设计时是否考虑到了足够多的方方面面；3. 在做系统设计时是否考虑到了足够多的方方面面； 全局：是否考虑到了对上下游的系统的影响。 权衡：权衡投入产出比；优先级和节奏控制； 《关于架构优化和设计，架构师必须知道的事情》 要去考虑的细节：模块化、轻耦合、无共享架构；减少各个组件之前的依懒、注意服务之间依懒所有造成的链式失败及影响等。 基础设施、配置、测试、开发、运维综合考虑。 考虑人、团队、和组织的影响。 《如何才能真正的提高自己，成为一名出色的架构师？》 《架构师的必备素质和成长途径》 素质：业务理解、技术广度、技术深度、丰富经验、沟通能力、动手能力、美学素养。 成长路径：2年积累知识、4年积累技能和组内影响力、7年积累部门内影响力、7年以上积累跨部门影响力。 《架构设计师—你在哪层楼？》 第一层的架构师看到的只是产品本身 第二层的架构师不仅看到自己的产品，还看到了整体的方案 第三层的架构师看到的是商业价值 团队管理TODO 招聘资讯行业资讯 36kr Techweb 公众号列表TODO 博客团队博客 阿里中间件博客 美团点评技术团队博客 个人博客 阮一峰的网络日志 酷壳 - COOLSHELL-陈皓 hellojava-阿里毕玄 Cm’s Blog 程序猿DD-翟永超-《Spring Cloud微服务实战》作者 综合门户、社区国内： CSDN 老牌技术社区、不必解释。 51cto.com ITeye 偏 Java 方向 博客园 ChinaUnix 偏 Linux 方向 开源中国社区 深度开源 伯乐在线 涵盖 IT职场、Web前端、后端、移动端、数据库等方面内容，偏技术端。 ITPUB 腾讯云— 云+社区 阿里云— 云栖社区 IBM DeveloperWorks 开发者头条 LinkedKeeper 国外： DZone Reddit 问答、讨论类社区 segmentfault 问答+专栏 知乎 stackoverflow 行业数据分析 艾瑞网 QUEST MOBILE 国家数据 专项网站 测试: 领测国际 测试窝 TesterHome 运维: * [运维派](http://www.yunweipai.com/) * [Abcdocker](https://www.abcdocker.com/) Java: ImportNew 专注于 Java 技术分享 HowToDoInJava 英文博客 安全 红黑联盟 FreeBuf 大数据 中国大数据 其他专题网站： DockerInfo 专注于 Docker 应用及咨询、教程的网站。 Linux公社 Linux 主题社区 其他类 程序员技能图谱 推荐参考书在线电子书 《深入理解Spring Cloud与微服务构建》 《阿里技术参考图册-研发篇》 《阿里技术参考图册-算法篇》 《2018美团点评技术年货（合辑）》70M InfoQ《架构师》月刊 《架构师之路》 纸质书开发方面 《阿里巴巴Java开发手册》京东 淘宝 架构方面 《软件架构师的12项修炼：技术技能篇》京东 淘宝 《架构之美》京东 淘宝 《分布式服务架构》京东 淘宝 《聊聊架构》 京东 淘宝 《云原生应用架构实践》京东 淘宝 《亿级流量网站架构核心技术》京东 淘宝 《淘宝技术这十年》京东 淘宝 《企业IT架构转型之道-中台战略思想与架构实战》 京东 淘宝 技术管理方面 《CTO说》京东 淘宝 《技术管理之巅》京东 淘宝 《网易一千零一夜：互联网产品项目管理实战》京东 淘宝 基础理论 《数学之美》京东 淘宝 《编程珠玑》京东 淘宝 工具方面TODO 大数据方面技术资源开源资源 github Apache 软件基金会 手册、文档、教程国内： W3Cschool Runoob.com HTML 、 CSS、XML、Java、Python、PHP、设计模式等入门手册。 Love2.io 很多很多中文在线电子书，是一个全新的开源技术文档分享平台。 gitbook.cn 付费电子书。 ApacheCN AI、大数据方面系列中文文档。 国外： Quick Code 免费在线技术教程。 gitbook.com 有部分中文电子书。 Cheatography Cheat Sheets 大全，单页文档网站。 在线课堂 学徒无忧 极客时间 segmentfault 斯达克学院 牛客网 极客学院 51CTO学院 会议、活动 QCon ArchSummit GITC全球互联网技术大会 活动发布平台: 活动行 常用APP 极客时间 得到 找工作 Boss直聘 拉勾网 猎聘 100Offer 工具 极客搜索 技术文章搜索引擎。 代码托管 Coding 码云 文件服务 七牛 又拍云 综合云服务商 阿里云 腾讯云 百度云 新浪云 金山云 亚马逊云(AWS) 谷歌云 微软云 VPS Linode]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedBlockingQueue]]></title>
    <url>%2F2018%2F05%2F08%2FLinkedBlockingQueue%2F</url>
    <content type="text"><![CDATA[锁分离take和put分别两个ReentrantLock锁 1234567891011/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition();]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java并发包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发包目录]]></title>
    <url>%2F2018%2F05%2F08%2Fjava%E5%B9%B6%E5%8F%91%E5%8C%85%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[原子类锁工具类CyclicBarrier1234567891011121314151617181920212223242526272829303132public class StartGame implements Runnable&#123; private String player; private CyclicBarrier barrier; public StartGame(String player, CyclicBarrier barrier) &#123; this.player = player; this.barrier = barrier; &#125; @Override public void run() &#123; try &#123; System.out.println(this.getPlayer()+" 开始匹配玩家..."); findOtherPlayer(); barrier.await(); System.out.println(this.getPlayer()+" 进行选择角色..."); choiceRole(); System.out.println(this.getPlayer()+" 角色选择完毕等待其他玩家..."); barrier.await(); System.out.println(this.getPlayer()+" 开始游戏,进行游戏加载..."); loading(); System.out.println(this.getPlayer()+" 游戏加载完毕等待其他玩家加载完成..."); barrier.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 123456789101112131415161718public class GameMain &#123; public static void main(String[] args) &#123; CyclicBarrier barrier = new CyclicBarrier(5); for(int i=0;i&lt;5;i++)&#123; Thread player1 = new Thread(new StartGame(String.valueOf(i+1),barrier)); player1.start(); &#125; try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 集合类ConcurrentHashMapLinkedBlockingQueuehttps://zhouxiaowu.coding.me/2018/05/08/LinkedBlockingQueue/ 锁优化 【ok】死锁重现与排查 ThreadLocal一.什么是ThreadLocal?ThreadLocal 是在 java.lang.包下的 在jdk1.2里引入进来 主要是给每个线程分配该线程本身的本地变量 该变量是该线程独有的 别的线程是访问不了的。 二. ThreadLocal的实现原理：最关键的是在Thread类里有一个ThreadLocal.ThreadLocalMap threadLocals的属性，也就是说 一个线程对象生成的时候会有一个对应私有属性 threadLocals 生成 这个属性是一个 ThreadLocalMap 也就是MAP ，看ThreadLocal类的get方法： 12345678910public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; &#125; return setInitialValue(); &#125; 通过传入当前线程对象t会取得当前线程的 ThreadLocalMap 这个ThreadLocalMap key是ThreadLocal对象 值是我们传入的值OBJ,通过传入当前的ThreadLocal的对象tl（代码里的this）会取得该key对应的value就是我们set就去的对象 从而实现一个线程 有自己的独有的ThreadLocalMap 一个ThreadLocal可以取回自己作为key对应value(OBJ) 。ThreadLocalMap 可以多个key=&gt;value(一个线程实例化多个ThreadLocal)。都是通过传递当前的Thread对象和当前的ThreadLocal对象实现取得唯一的值的。 具体如何实现请看源代码（ThreadLocal类 Thread类 ThreadLocal类里的内部类ThreadLocalMap）的各个方法 尤其是ThreadLocal类 的get() set() remove() 等方法。 三.使用场景：基本上需要在一个线程里保存上下文信息的 需要上下文切换的 比如session cookie等都可以用这个 spring 等框架也广泛使用了该技术。 四.注意事项： 在使用ThreadLocal的时候set完后线程执行完需要显性调用remove方法清除 不然在有线程池模式的WEB服务器下tomcat会出现 内存溢出和用户上下错乱（比如A用户拿到了B用户的SESSION）虽然同一个线程在执行到SET的时候会覆盖之前保留的值但是你无法控制其他人是否在SET之前有调用了。所以一定要在线程执行后remove. PS:webx的filter和invoke都是递归调用的 第一个filter都是最先执行最后收尾的 invoke也类似。 123456789101112131415161718192021public final class MyContext &#123; /** * 绑定线程 */ private static final ThreadLocal&lt;EventContext&gt; LOCAL_CONTEXT = ThreadLocal.withInitial(() -&gt; new EventContext()); private MyContext() &#123; &#125; public static EventContext getContext() &#123; return LOCAL_CONTEXT.get(); &#125; public static void setContext(EventContext context) &#123; LOCAL_CONTEXT.set(context); &#125; //最后filter调用 public static void clearContext() &#123; LOCAL_CONTEXT.remove(); &#125; 使用示例最近在我们的web项目中servlet需要频繁创建SimpleDateFormat这个对象，进行日期格式化。因为创建这个对象本身很费时的，而且我们也知道SimpleDateFormat本身不是线程安全的，也不能缓存一个共享的SimpleDateFormat实例，为此我们想到使用ThreadLocal来给每个线程缓存一个SimpleDateFormat实例，提高性能。同时因为每个Servlet会用到不同pattern的时间格式化类，所以我们对应每一种pattern生成了一个ThreadLocal实例。 12345678910111213141516171819202122232425262728public class DateFormatFactory &#123;private static final Map&lt;DatePattern, ThreadLocal&lt;DateFormat&gt;&gt; pattern2ThreadLocal;static &#123; DatePattern[] patterns = DatePattern.values(); int len = patterns.length; pattern2ThreadLocal = new HashMap&lt;DatePattern, ThreadLocal&lt;DateFormat&gt;&gt;(len); for (int i = 0; i &lt; len; i++) &#123; DatePattern datePattern = patterns[i]; final String pattern = datePattern.pattern; pattern2ThreadLocal.put(datePattern, new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(pattern); &#125; &#125;); &#125;&#125;//获取DateFormatpublic static DateFormat getDateFormat(DatePattern pattern) &#123; ThreadLocal&lt;DateFormat&gt; threadDateFormat = pattern2ThreadLocal.get(pattern); //不需要判断threadDateFormat是否为空 return threadDateFormat.get();&#125; 1234567891011public enum DatePattern &#123;TimePattern("yyyy-MM-dd HH:mm:ss"),DatePattern("yyyy-MM-dd"),public String pattern;private DatePattern(String pattern) &#123; this.pattern = pattern;&#125;]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java并发包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁项目汇总]]></title>
    <url>%2F2018%2F05%2F06%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[基于dubbo的分布式工程开发规范实例工程，分布式跟踪、ID生成、分布式事务、分布式治理、分表分库、分布式锁、选举、API文档生成器… https://github.com/Frankenjoy123/j360-dubbo-app-all 各种锁汇总，乐观锁、悲观锁、分布式锁、互斥锁、读写锁、分段锁、类锁等，很不错的总结 https://github.com/Frankenjoy123/Lock-Learning 汇总java生态圈常用技术框架、开源中间件，系统架构、项目管理、经典架构案例、数据库、常用三方库、线上运维等知识 https://github.com/aalansehaiyang/technology-talk]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zookeeper实现分布式锁一]]></title>
    <url>%2F2018%2F05%2F06%2F%E4%BD%BF%E7%94%A8zookeeper%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[一、分布式锁介绍​ 分布式锁主要用于在分布式环境中保护跨进程、跨主机、跨网络的共享资源实现互斥访问，以达到保证数据的一致性。 二、架构介绍​ 在介绍使用Zookeeper实现分布式锁之前，首先看当前的系统架构图 ​ ​ 解释： 左边的整个区域表示一个Zookeeper集群，locker是Zookeeper的一个持久节点，node_1、node_2、node_3是locker这个持久节点下面的临时顺序节点。client_1、client_2、client_n表示多个客户端，Service表示需要互斥访问的共享资源。 三、分布式锁获取思路​ 1．获取分布式锁的总体思路 ​ 在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。客户端调用createNode方法在locker下创建临时顺序节点， 然后调用getChildren(“locker”)来获取locker下面的所有子节点，注意此时不用设置任何Watcher。客户端获取到所有的子节点path之后，如果发现自己在之 前创建的子节点序号最小，那么就认为该客户端获取到了锁。如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁， 此时客户端需要找到比自己小的那个节点，然后对其调用exist()方法，同时对其注册事件监听器。之后，让这个被关注的节点删除，则客户端的Watcher会 收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如皋是则获取到了锁，如果不是则重复以上步骤继续获取到比自己小的一个 节点并注册监听。当前这个过程中还需要许多的逻辑判断。 2．获取分布式锁的核心算法流程 ​ 下面同个一个流程图来分析获取分布式锁的完整算法，如下：​ ​ https://img-blog.csdn.net/20160716210945194?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center ​ 解释：客户端A要获取分布式锁的时候首先到locker下创建一个临时顺序节点（node_n），然后立即获取locker下的所有（一级）子节点。 此时因为会有多个客户端同一时间争取锁，因此locker下的子节点数量就会大于1。对于顺序节点，特点是节点名称后面自动有一个数字编号， 先创建的节点数字编号小于后创建的，因此可以将子节点按照节点名称后缀的数字顺序从小到大排序，这样排在第一位的就是最先创建的顺序节点， 此时它就代表了最先争取到锁的客户端！此时判断最小的这个节点是否为客户端A之前创建出来的node_n，如果是则表示客户端A获取到了锁， 如果不是则表示锁已经被其它客户端获取，因此客户端A要等待它释放锁，也就是等待获取到锁的那个客户端B把自己创建的那个节点删除。 此时就通过监听比node_n次小的那个顺序节点的删除事件来知道客户端B是否已经释放了锁，如果是，此时客户端A再次获取locker下的所有子节点， 再次与自己创建的node_n节点对比，直到自己创建的node_n是locker的所有子节点中顺序号最小的，此时表示客户端A获取到了锁！ 四、基于Zookeeper的分布式锁的代码实现1．定义分布式锁接口​ 定义的分布式锁接口如下： 123456789101112131415161718192021222324252627282930313233343536373839public interface DistributedLock &#123; /**获取锁，如果没有得到就等待*/ public void acquire() throws Exception; /** * 获取锁，直到超时 * @param time超时时间 * @param unit time参数的单位 * @return是否获取到锁 * @throws Exception */ public boolean acquire (long time, TimeUnit unit) throws Exception; /** * 释放锁 * @throws Exception */ public void release() throws Exception;&#125; ​ 2．定义一个简单的互斥锁​ 定义一个互斥锁类，实现以上定义的锁接口，同时继承一个基类BaseDistributedLock，该基类主要用于与Zookeeper交互， ​ 包含一个尝试获取锁的方法和一个释放锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117/**锁接口的具体实现，主要借助于继承的父类BaseDistributedLock来实现的接口方法 * 该父类是基于Zookeeper实现分布式锁的具体细节实现*/public class SimpleDistributedLockMutex extends BaseDistributedLock implements DistributedLock &#123; /*用于保存Zookeeper中实现分布式锁的节点，如名称为locker：/locker， *该节点应该是持久节点，在该节点下面创建临时顺序节点来实现分布式锁 */ private final String basePath; /*锁名称前缀，locker下创建的顺序节点例如都以lock-开头，这样便于过滤无关节点 *这样创建后的节点类似：lock-00000001，lock-000000002*/ private staticfinal String LOCK_NAME ="lock-"; /*用于保存某个客户端在locker下面创建成功的顺序节点，用于后续相关操作使用（如判断）*/ private String ourLockPath; /** * 用于获取锁资源，通过父类的获取锁方法来获取锁 * @param time获取锁的超时时间 * @param unit time的时间单位 * @return是否获取到锁 * @throws Exception */ private boolean internalLock (long time, TimeUnit unit) throws Exception &#123; //如果ourLockPath不为空则认为获取到了锁，具体实现细节见attemptLock的实现 ourLockPath = attemptLock(time, unit); return ourLockPath !=null; &#125; /** * 传入Zookeeper客户端连接对象，和basePath * @param client Zookeeper客户端连接对象 * @param basePath basePath是一个持久节点 */ public SimpleDistributedLockMutex(ZkClientExt client, String basePath)&#123; /*调用父类的构造方法在Zookeeper中创建basePath节点，并且为basePath节点子节点设置前缀 *同时保存basePath的引用给当前类属性*/ super(client,basePath,LOCK_NAME); this.basePath = basePath; &#125; /**获取锁，直到超时，超时后抛出异常*/ public void acquire() throws Exception &#123; //-1表示不设置超时时间，超时由Zookeeper决定 if (!internalLock(-1,null))&#123; throw new IOException("连接丢失!在路径:'"+basePath+"'下不能获取锁!"); &#125; &#125; /** * 获取锁，带有超时时间 */ public boolean acquire(long time, TimeUnit unit) throws Exception &#123; return internalLock(time, unit); &#125; /**释放锁*/ public void release()throws Exception &#123; releaseLock(ourLockPath); &#125;&#125; ​ 3. 分布式锁的实现细节获取分布式锁的重点逻辑在于BaseDistributedLock，实现了基于Zookeeper实现分布式锁的细节。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public class BaseDistributedLock &#123; private final ZkClientExt client; private final String path; private final String basePath; private final String lockName; private static final Integer MAX_RETRY_COUNT = 10; public BaseDistributedLock(ZkClientExt client, String path, String lockName)&#123; this.client = client; this.basePath = path; this.path = path.concat("/").concat(lockName); this.lockName = lockName; &#125; private void deleteOurPath(String ourPath) throws Exception&#123; client.delete(ourPath); &#125; private String createLockNode(ZkClient client, String path) throws Exception&#123; return client.createEphemeralSequential(path, null); &#125; /** * 获取锁的核心方法 * @param startMillis * @param millisToWait * @param ourPath * @return * @throws Exception */ private boolean waitToLock(long startMillis, Long millisToWait, String ourPath) throws Exception&#123; boolean haveTheLock = false; boolean doDelete = false; try&#123; while ( !haveTheLock ) &#123; //该方法实现获取locker节点下的所有顺序节点，并且从小到大排序 List&lt;String&gt; children = getSortedChildren(); String sequenceNodeName = ourPath.substring(basePath.length()+1); //计算刚才客户端创建的顺序节点在locker的所有子节点中排序位置，如果是排序为0，则表示获取到了锁 int ourIndex = children.indexOf(sequenceNodeName); /*如果在getSortedChildren中没有找到之前创建的[临时]顺序节点，这表示可能由于网络闪断而导致 *Zookeeper认为连接断开而删除了我们创建的节点，此时需要抛出异常，让上一级去处理 *上一级的做法是捕获该异常，并且执行重试指定的次数 见后面的 attemptLock方法 */ if ( ourIndex&lt;0 )&#123; throw new ZkNoNodeException("节点没有找到: " + sequenceNodeName); &#125; //如果当前客户端创建的节点在locker子节点列表中位置大于0，表示其它客户端已经获取了锁 //此时当前客户端需要等待其它客户端释放锁， boolean isGetTheLock = ourIndex == 0; //如何判断其它客户端是否已经释放了锁？从子节点列表中获取到比自己次小的哪个节点，并对其建立监听 String pathToWatch = isGetTheLock ? null : children.get(ourIndex - 1); if ( isGetTheLock )&#123; haveTheLock = true; &#125;else&#123; //如果次小的节点被删除了，则表示当前客户端的节点应该是最小的了，所以使用CountDownLatch来实现等待 String previousSequencePath = basePath .concat( "/" ) .concat( pathToWatch ); final CountDownLatch latch = new CountDownLatch(1); final IZkDataListener previousListener = new IZkDataListener() &#123; //次小节点删除事件发生时，让countDownLatch结束等待 //此时还需要重新让程序回到while，重新判断一次！ public void handleDataDeleted(String dataPath) throws Exception &#123; latch.countDown(); &#125; public void handleDataChange(String dataPath, Object data) throws Exception &#123; // ignore &#125; &#125;; try&#123; //如果节点不存在会出现异常 client.subscribeDataChanges(previousSequencePath, previousListener); if ( millisToWait != null )&#123; millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if ( millisToWait &lt;= 0 )&#123; doDelete = true; // timed out - delete our node break; &#125; latch.await(millisToWait, TimeUnit.MICROSECONDS); &#125;else&#123; latch.await(); &#125; &#125;catch ( ZkNoNodeException e )&#123; //ignore &#125;finally&#123; client.unsubscribeDataChanges(previousSequencePath, previousListener); &#125; &#125; &#125; &#125;catch ( Exception e )&#123; //发生异常需要删除节点 doDelete = true; throw e; &#125;finally&#123; //如果需要删除节点 if ( doDelete )&#123; deleteOurPath(ourPath); &#125; &#125; return haveTheLock; &#125; private String getLockNodeNumber(String str, String lockName) &#123; int index = str.lastIndexOf(lockName); if ( index &gt;= 0 )&#123; index += lockName.length(); return index &lt;= str.length() ? str.substring(index) : ""; &#125; return str; &#125; private List&lt;String&gt; getSortedChildren() throws Exception &#123; try&#123; List&lt;String&gt; children = client.getChildren(basePath); Collections.sort( children, new Comparator&lt;String&gt;()&#123; public int compare(String lhs, String rhs)&#123; return getLockNodeNumber(lhs, lockName).compareTo(getLockNodeNumber(rhs, lockName)); &#125; &#125; ); return children; &#125;catch(ZkNoNodeException e)&#123; client.createPersistent(basePath, true); return getSortedChildren(); &#125; &#125; protected void releaseLock(String lockPath) throws Exception&#123; deleteOurPath(lockPath); &#125; protected String attemptLock(long time, TimeUnit unit) throws Exception&#123; final long startMillis = System.currentTimeMillis(); final Long millisToWait = (unit != null) ? unit.toMillis(time) : null; String ourPath = null; boolean hasTheLock = false; boolean isDone = false; int retryCount = 0; //网络闪断需要重试一试 while ( !isDone )&#123; isDone = true; try&#123; //createLockNode用于在locker（basePath持久节点）下创建客户端要获取锁的[临时]顺序节点 ourPath = createLockNode(client, path); /** * 该方法用于判断自己是否获取到了锁，即自己创建的顺序节点在locker的所有子节点中是否最小 * 如果没有获取到锁，则等待其它客户端锁的释放，并且稍后重试直到获取到锁或者超时 */ hasTheLock = waitToLock(startMillis, millisToWait, ourPath); &#125;catch ( ZkNoNodeException e )&#123; if ( retryCount++ &lt; MAX_RETRY_COUNT )&#123; isDone = false; &#125;else&#123; throw e; &#125; &#125; &#125; if ( hasTheLock )&#123; return ourPath; &#125; return null；｝]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zookeeper实现分布式锁二]]></title>
    <url>%2F2018%2F05%2F06%2F%E4%BD%BF%E7%94%A8zookeeper%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[推荐一个工具基于redis和zookeeper分布式工具集-包括:分布式锁实现,分布式速率限制器,分布式ID生成器等.https://github.com/yujiasun/Distributed-Kit/blob/master/README.md 1.分布式锁的由来在程序开发过程中不得不考虑的就是并发问题。在java中对于同一个jvm而言，jdk已经提供了lock和同步等。但是在分布式情况下，往往存在多个进程对一些资源产生竞争关系，而这些进程往往在不同的机器上，这个时候jdk中提供的已经不能满足。分布式锁顾明思议就是可以满足分布式情况下的并发锁。 下面我们讲解怎么利用zk实现分布式锁。 2.实现思路：2.1 zk简单介绍：ZooKeeper是Apache软件基金会的一个软件项目，他为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。在 ZooKeeper 中，节点类型可以分为持久节点（PERSISTENT ）、临时节点（EPHEMERAL），以及时序节点（SEQUENTIAL ），具体在节点创建过程中，一般是组合使用，可以生成 4 种节点类型：持久节点（PERSISTENT），持久顺序节点（PERSISTENT_SEQUENTIAL），临时节点（EPHEMERAL），临时顺序节点（EPHEMERAL_SEQUENTIAL）；具体节点含义，谷歌之。 2.2 利用zk实现：当很多进程需要访问共享资源时，我们可以通过zk来实现分布式锁。主要步骤是：1.建立一个节点，假如名为：lock 。节点类型为持久节点（PERSISTENT）2.每当进程需要访问共享资源时，会调用分布式锁的lock()或tryLock()方法获得锁，这个时候会在第一步创建的lock节点下建立相应的顺序子节点，节点类型为临时顺序节点（EPHEMERAL_SEQUENTIAL），通过组成特定的名字name+lock+顺序号。3.在建立子节点后，对lock下面的所有以name开头的子节点进行排序，判断刚刚建立的子节点顺序号是否是最小的节点，假如是最小节点，则获得该锁对资源进行访问。4.假如不是该节点，就获得该节点的上一顺序节点，并给该节点是否存在注册监听事件。同时在这里阻塞。等待监听事件的发生，获得锁控制权。5.当调用完共享资源后，调用unlock（）方法，关闭zk，进而可以引发监听事件，释放该锁。实现的分布式锁是严格的按照顺序访问的并发锁。 3.代码实现：下面将讲解使用java实现分布式锁：1.建立类DistributedLock，实现java.util.concurrent.locks.Lock;和org.apache.zookeeper.Watcher接口2.实现lock下面的方法：主要包括lock，tryLock，unlock等3.实现watcher接口下的process方法。4.在构造器中对zk进行初始化。5.详细见代码注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170package cn.wpeace.zktest;import java.io.IOException;import java.util.ArrayList;import java.util.Collections;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.Watcher.Event.KeeperState;import org.apache.zookeeper.data.Stat;/** * @author peace * */public class DistributedLock implements Lock, Watcher&#123; private ZooKeeper zk; private String root = "/locks";//根 private String lockName;//竞争资源的标志 private String waitNode;//等待前一个锁 private String myZnode;//当前锁 private CountDownLatch latch;//计数器 private CountDownLatch connectedSignal=new CountDownLatch(1); private int sessionTimeout = 30000; /** * 创建分布式锁,使用前请确认config配置的zookeeper服务可用 * @param config 192.168.1.127:2181 * @param lockName 竞争资源标志,lockName中不能包含单词_lock_ */ public DistributedLock(String config, String lockName)&#123; this.lockName = lockName; // 创建一个与服务器的连接 try &#123; zk = new ZooKeeper(config, sessionTimeout, this); connectedSignal.await(); Stat stat = zk.exists(root, false);//此去不执行 Watcher if(stat == null)&#123; // 创建根节点 zk.create(root, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT); &#125; &#125; catch (IOException e) &#123; throw new LockException(e); &#125; catch (KeeperException e) &#123; throw new LockException(e); &#125; catch (InterruptedException e) &#123; throw new LockException(e); &#125; &#125; /** * zookeeper节点的监视器 */ public void process(WatchedEvent event) &#123; //建立连接用 if(event.getState()==KeeperState.SyncConnected)&#123; connectedSignal.countDown(); return; &#125; //其他线程放弃锁的标志 if(this.latch != null) &#123; this.latch.countDown(); &#125; &#125; public void lock() &#123; try &#123; if(this.tryLock())&#123; System.out.println("Thread " + Thread.currentThread().getId() + " " +myZnode + " get lock true"); return; &#125; else&#123; waitForLock(waitNode, sessionTimeout);//等待锁 &#125; &#125; catch (KeeperException e) &#123; throw new LockException(e); &#125; catch (InterruptedException e) &#123; throw new LockException(e); &#125; &#125; public boolean tryLock() &#123; try &#123; String splitStr = "_lock_"; if(lockName.contains(splitStr)) throw new LockException("lockName can not contains \\u000B"); //创建临时子节点 myZnode = zk.create(root + "/" + lockName + splitStr, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE,CreateMode.EPHEMERAL_SEQUENTIAL); System.out.println(myZnode + " is created "); //取出所有子节点 List&lt;String&gt; subNodes = zk.getChildren(root, false); //取出所有lockName的锁 List&lt;String&gt; lockObjNodes = new ArrayList&lt;String&gt;(); for (String node : subNodes) &#123; String _node = node.split(splitStr)[0]; if(_node.equals(lockName))&#123; lockObjNodes.add(node); &#125; &#125; Collections.sort(lockObjNodes); if(myZnode.equals(root+"/"+lockObjNodes.get(0)))&#123; //如果是最小的节点,则表示取得锁 System.out.println(myZnode + "==" + lockObjNodes.get(0)); return true; &#125; //如果不是最小的节点，找到比自己小1的节点 String subMyZnode = myZnode.substring(myZnode.lastIndexOf("/") + 1); waitNode = lockObjNodes.get(Collections.binarySearch(lockObjNodes, subMyZnode) - 1);//找到前一个子节点 &#125; catch (KeeperException e) &#123; throw new LockException(e); &#125; catch (InterruptedException e) &#123; throw new LockException(e); &#125; return false; &#125; public boolean tryLock(long time, TimeUnit unit) &#123; try &#123; if(this.tryLock())&#123; return true; &#125; return waitForLock(waitNode,time); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return false; &#125; private boolean waitForLock(String lower, long waitTime) throws InterruptedException, KeeperException &#123; Stat stat = zk.exists(root + "/" + lower,true);//同时注册监听。 //判断比自己小一个数的节点是否存在,如果不存在则无需等待锁,同时注册监听 if(stat != null)&#123; System.out.println("Thread " + Thread.currentThread().getId() + " waiting for " + root + "/" + lower); this.latch = new CountDownLatch(1); this.latch.await(waitTime, TimeUnit.MILLISECONDS);//等待，这里应该一直等待其他线程释放锁 this.latch = null; &#125; return true; &#125; public void unlock() &#123; try &#123; System.out.println("unlock " + myZnode); zk.delete(myZnode,-1); myZnode = null; zk.close(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; &#125; public void lockInterruptibly() throws InterruptedException &#123; this.lock(); &#125; public Condition newCondition() &#123; return null; &#125; public class LockException extends RuntimeException &#123; private static final long serialVersionUID = 1L; public LockException(String e)&#123; super(e); &#125; public LockException(Exception e)&#123; super(e); &#125; &#125;&#125; 4.测试：1.下载我的工程代码：点击下载2.或者直接使用该类： DistributedLock lock = new DistributedLock(“192.168.1.127:2181”,”lock”); lock.lock(); //共享资源 if(lock != null) lock.unlock();123453.执行步骤：1.启动zk:zkServer.sh start2.启动测试代码3.执行结果：0506]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用redis实现分布式锁实践]]></title>
    <url>%2F2018%2F05%2F06%2F%E4%BD%BF%E7%94%A8redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[分布式锁在多实例部署,分布式系统中经常会使用到,这是因为基于jvm的锁无法满足多实例中锁的需求,本篇将讲下redis如何通过Lua脚本实现分布式锁,不同于网上的redission,完全是手动实现的 我们先来看一个无锁的情况下会导致什么问题: 这是一个普通的更新用户年龄的功能,各层代码如下,访问controller层,一个更新,一个查询 这是service层,我们使用contdownlatch发令枪来模拟线程同时并发的情况,发令枪设为32,即32个线程同时去请求修改年龄, 这里使用线程池来提交多线程任务,看代码知道,这里我们已经有了判断年龄的操作,当查询用户查询大于0时,才去调更新用户年龄-1的方法,等下看看有没有用 这里是sql,可以看到两个sql,一个查询用户年龄,一个会执行用户年龄每次减1 , 这里是用户数据,我们可以看到,用户UID为UR12324的用户,他的年龄是30,接着我们来调32个线程来操作减他年龄 我们请求下这个方法 然后看看结果: 可以看到库中年龄已被减为-2,在未加锁的情况下,查询较验并没有什么作用,此时如果加个synchronized或lock锁肯定能避免这种情况,但我们本文讨论的是多实例或分布式环境中,此加锁方式仍然会产生问题,感兴趣的可以试下是不是 下面我们开始实现一个redis分布式锁,来避免这种情况发生,先说说实现思路: 1,线程请求访问前先调用加锁的方法,加锁就去里生成一个随机数同时保存在线程本地变量和redis的某key中,此key设有效期为200ms,具体值根据业务执行时间自行调整,加锁成功; 2.其它线程试着访问拿出它本地变量与redis中某key进行比较,如果不一致,则说明有锁,此线程休眠一段时间,再试着加锁; 3.加锁成功的线程在操作结束后删掉它持有锁(用lua实现,保证原子性,在它比对和删除锁的过程中,其它线程不会加锁成功),让其它线程再次加锁以执行任务; 说明:锁的时间为200ms可预防线程挂掉之后死锁,200ms后会自动释放 下面看看我们写的锁代码: 片段1:使用redislock 实现lock来复写它的方法 片段2:试着加锁的方法 片段3:解锁方法,此处首先从线程本地变量获取它的随机数,然后调用lua脚本,与redis中key相比较,如果相同则删除,否则返回0; 此为lua脚本方法,用此方法可以保证判断和删除的原子性,在此过程中没有线程可以操作此key 到此为止,我们锁基本写完,来测试下有没有用: 我们在此方法前后分别加入加锁和解锁方法,使用方式和lock锁一样, 我们重新把年龄恢复到30后来测试一下吧 先看看日志 这里可以看到各个线程争夺锁的情况,再看看执行结果 这里我们可以看到虽然是32个线程并发执行,但此值并不会变为负数,加锁成功. 我们可以看到最后2个线程并没有执行方法 此时说明加锁成功,大家可以在分布式环境中测试更明显,有关极端情况下解锁失败后应该做什么也可以由我们自己决定,比redission要灵活,带锁的redis最好是单实例,在集群中可能会出问题,有机会我们再用zk实现下.]]></content>
      <categories>
        <category>缓存</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RateLimit使用guava来做接口限流]]></title>
    <url>%2F2018%2F04%2F25%2FRateLimit-%E4%BD%BF%E7%94%A8guava%E6%9D%A5%E5%81%9A%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81%2F</url>
    <content type="text"><![CDATA[一、问题描述 某天A君突然发现自己的接口请求量突然涨到之前的10倍，没多久该接口几乎不可使用，并引发连锁反应导致整个系统崩溃。如何应对这种情况呢？生活给了我们答案：比如老式电闸都安装了保险丝，一旦有人使用超大功率的设备，保险丝就会烧断以保护各个电器不被强电流给烧坏。同理我们的接口也需要安装上“保险丝”，以防止非预期的请求对系统压力过大而引起的系统瘫痪，当流量过大时，可以采取拒绝或者引流等机制。 二、常用的限流算法​ 常用的限流算法有两种：漏桶算法和令牌桶算法，这篇博文介绍得比较清晰（过载保护算法浅析）。 ​ 漏桶算法思路很简单，请求先进入到漏桶里，漏桶以一定的速度出水，当水请求过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。 图1 漏桶算法示意图 ​ 对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。如图2所示，令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。 图2 令牌桶算法示意图 三、限流工具类RateLimiter google开源工具包guava提供了限流工具类RateLimiter，该类基于“令牌桶算法”，非常方便使用。该类的接口描述请参考：RateLimiter接口描述，具体的使用请参考：RateLimiter使用实践。 RateLimiter 使用Demo 1234567891011121314151617181920212223242526272829303132333435363738package ratelimite;import com.google.common.util.concurrent.RateLimiter;public class RateLimiterDemo &#123; public static void main(String[] args) &#123; testNoRateLimiter(); testWithRateLimiter(); &#125; public static void testNoRateLimiter() &#123; Long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10; i++) &#123; System.out.println("call execute.." + i); &#125; Long end = System.currentTimeMillis(); System.out.println(end - start); &#125; public static void testWithRateLimiter() &#123; Long start = System.currentTimeMillis(); RateLimiter limiter = RateLimiter.create(10.0); // 每秒不超过10个任务被提交 for (int i = 0; i &lt; 10; i++) &#123; limiter.acquire(); // 请求RateLimiter, 超过permits会被阻塞 System.out.println("call execute.." + i); &#125; Long end = System.currentTimeMillis(); System.out.println(end - start); &#125;&#125; 四 Guava并发：ListenableFuture与RateLimiter示例概念 ​ ListenableFuture顾名思义就是可以监听的Future，它是对java原生Future的扩展增强。我们知道Future表示一个异步计算任务，当任务完成时可以得到计算结果。如果我们希望一旦计算完成就拿到结果展示给用户或者做另外的计算，就必须使用另一个线程不断的查询计算状态。这样做，代码复杂，而且效率低下。使用ListenableFuture Guava帮我们检测Future是否完成了，如果完成就自动调用回调函数，这样可以减少并发程序的复杂度。 ​ 推荐使用第二种方法，因为第二种方法可以直接得到Future的返回值，或者处理错误情况。本质上第二种方法是通过调动第一种方法实现的，做了进一步的封装。 另外ListenableFuture还有其他几种内置实现： SettableFuture：不需要实现一个方法来计算返回值，而只需要返回一个固定值来做为返回值，可以通过程序设置此Future的返回值或者异常信息 CheckedFuture： 这是一个继承自ListenableFuture接口，他提供了checkedGet()方法，此方法在Future执行发生异常时，可以抛出指定类型的异常。 ​ RateLimiter类似于JDK的信号量Semphore，他用来限制对资源并发访问的线程数，本文介绍RateLimiter使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import com.google.common.util.concurrent.FutureCallback;import com.google.common.util.concurrent.Futures;import com.google.common.util.concurrent.ListenableFuture;import com.google.common.util.concurrent.ListeningExecutorService;import com.google.common.util.concurrent.MoreExecutors;import com.google.common.util.concurrent.RateLimiter;public class ListenableFutureDemo &#123; public static void main(String[] args) &#123; testRateLimiter(); testListenableFuture(); &#125; /** * RateLimiter类似于JDK的信号量Semphore，他用来限制对资源并发访问的线程数 */ public static void testRateLimiter() &#123; ListeningExecutorService executorService = MoreExecutors .listeningDecorator(Executors.newCachedThreadPool()); RateLimiter limiter = RateLimiter.create(5.0); // 每秒不超过4个任务被提交 for (int i = 0; i &lt; 10; i++) &#123; limiter.acquire(); // 请求RateLimiter, 超过permits会被阻塞 final ListenableFuture&lt;Integer&gt; listenableFuture = executorService .submit(new Task("is "+ i)); &#125; &#125; public static void testListenableFuture() &#123; ListeningExecutorService executorService = MoreExecutors .listeningDecorator(Executors.newCachedThreadPool()); final ListenableFuture&lt;Integer&gt; listenableFuture = executorService .submit(new Task("testListenableFuture")); //同步获取调用结果 try &#123; System.out.println(listenableFuture.get()); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; catch (ExecutionException e1) &#123; e1.printStackTrace(); &#125; //第一种方式 listenableFuture.addListener(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println("get listenable future's result " + listenableFuture.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, executorService); //第二种方式 Futures.addCallback(listenableFuture, new FutureCallback&lt;Integer&gt;() &#123; @Override public void onSuccess(Integer result) &#123; System.out .println("get listenable future's result with callback " + result); &#125; @Override public void onFailure(Throwable t) &#123; t.printStackTrace(); &#125; &#125;); &#125;&#125;class Task implements Callable&lt;Integer&gt; &#123; String str; public Task(String str)&#123; this.str = str; &#125; @Override public Integer call() throws Exception &#123; System.out.println("call execute.." + str); TimeUnit.SECONDS.sleep(1); return 7; &#125;&#125;]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React16 从零打造电商后台管理系统]]></title>
    <url>%2F2018%2F04%2F21%2FReact16-%E4%BB%8E%E9%9B%B6%E6%89%93%E9%80%A0%E7%94%B5%E5%95%86%E5%90%8E%E5%8F%B0%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[基础知识 dns-prefetch 提前fetch charles 抓包 WebStorage sessionStorage 12window.sessionStorage.setItem('test',123)window.sessionStorage.getItem('test') localStorage 1window.localStorage 项目初始化node v8.11.3 yarn 1.2.1 12mkdir admin-v2-feyarn init webpack1yarn add webpack@3.10.0 --dev 1yarn add webpack-dev-server 2.9.7 webpack.config.js 123456789const path = require('path');module.exports = &#123; entry: './src/app.js', output: &#123; path: path.resolve(__dirname, './dist'), filename: 'app.js' &#125;&#125;; 执行 1./node_modules/.bin/webpack HtmlWebpackPlugin 1yarn add html-webpack-plugin@2.30.1 --dev https://webpack.docschina.org/plugins/html-webpack-plugin/#src/components/Sidebar/Sidebar.jsx 1234567891011var HtmlWebpackPlugin = require('html-webpack-plugin');var path = require('path');module.exports = &#123; entry: 'index.js', output: &#123; path: path.resolve(__dirname, './dist'), filename: 'index_bundle.js' &#125;, plugins: [new HtmlWebpackPlugin()]&#125;; babel处理 12yarn add babel-core@6.26.0 --devyarn add babel-preset-env@1.6.1 babel-loader@7.1.2 --dev 1yarn add babel-preset-react@6.24.1 --dev css处理 1yarn add react@16.2.0 react-dom@16.2.0 1yarn add style-loader@0.19.1 css-loader@0.28.8 --dev index.css文件独立 https://webpack.docschina.org/plugins/extract-text-webpack-plugin/#src/components/Sidebar/Sidebar.jsx 1yarn add extract-text-webpack-plugin@3.0.2 --dev sass处理 12yarn add sass-loader@6.0.6 --devyarn add node-sass@4.7.2 --dev 提取sass文件 https://webpack.docschina.org/plugins/extract-text-webpack-plugin/#%E6%8F%90%E5%8F%96-sass-%E6%88%96-less 图片处理 1yarn add file-loader@1.1.6 url-loader@0.6.2 --dev 字体库 http://fontawesome.dashgame.com/ 1yarn add font-awesome webpack-dev server 1yarn add webpack-dev-server@2.9.7 --dev 12345678910output: &#123; path: path.resolve(__dirname, './dist'), publicPath: '/dist', filename: 'js/app.js'&#125;, // webpack-dev server devServer: &#123; &#125; 1./node_modules/.bin/webpack-dev-server package.json配置脚本 1234"scripts" : &#123; "dev" : "node_modules/.bin/webpack-dev-server", "dist" : "node_modules/.bin/webpack"&#125; react-router1yarn add react-router-dom@4.2.2 参数匹配，/a/:id 123456789ReactDOM.render( &lt;Router&gt; &lt;Wrapper&gt; &lt;Route path="/a/:id" component=&#123;ComponentA&#125;/&gt; &lt;Route path="/b" component=&#123;ComponentB&#125;/&gt; &lt;/Wrapper&gt; &lt;/Router&gt; , document.getElementById('app')); 读取参数 1this.props.match.params.id bootcdnhttps://www.bootcdn.cn/]]></content>
      <categories>
        <category>前端</category>
        <category>react</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hive常用HIVE QL]]></title>
    <url>%2F2018%2F04%2F13%2Fhive%E5%B8%B8%E7%94%A8HIVE-QL%2F</url>
    <content type="text"><![CDATA[hive创建数据库 1CREATE DATABASE|SCHEMA [IF NOT EXISTS] &lt;database name&gt;;1 hive创建表 hive里一般有两种表的结构，表和外部表，以下分别是两种表的创建代码： 1234CREATE TABLE phone_info(id int,name String,storage String,price double)ROW FORMAT DELIMITED //代表一行是一条记录FIELDS TERMINATED BY '\t'//列是按照table键分开STORED AS TEXTFILE[SEQUENCEFILE];//二种最常见的存储格式，一般可以不写1234 12345CREATE EXTERNAL TABLE phone_external(id int,name String,price double)ROW FORMAT DELIMITEDFIELDS TERMINATED BY '\t'STORED AS TEXTFILELOCATION '&lt;/xudong/phone.txt&gt;';//这里填写外部表数据的hdfs地址12345 hive表中导入数据 hive表中导入数据有四种常见的方式：（1）从本地文件系统中导入到hive表假设本地文件系统中文件存在的目录为/home/xudong 1load data local inpath '/home/xudong/xxx.txt' into table phone_info;1 （2）从hdfs上导入数据到hive表假设hdfs上的目录为/user/xudong/data 1load data inpath '/user/xudong/data/xxx.txt' into table phone_info;1 注：和本地文件导入不同是没有local关键字（3）从别的表中查询出相应的数据并导入hive表中 1INSERT INTO phone_info_like SELECT * FROM phone_info;1 （4）在创建表的时候通过别的表查询出相应的记录并插入到所创建的表中。 1234CREATE TABLE temp_infoASSELECT id phone_id，name phone_name,price FROM phone_infoSORT BY phone_id;1234 hive删除表 1DROP TABLE IF EXISTS phone_info;1 hive创建临时表存储中间结果 12345CREATE TABLE temp_infoASSELECT id phone_id，name phone_name,price FROM phone_infoSORT BY phone_id;12345 hive简单的查询语句 1234SELECT * FROM temp_info;SELECT id phone_id,name phone_name FROM phone_info;SELECT a.ip,a.name,b.username FROM phone_info a INNER JOIN user b on (a.ip=b.ip);1234 hive批量插入数据到表 1234CREATE TABLE phone_info_like LIKE phone_info;//复制表的结构INSERT INTO phone_info_like SELECT * FROM phone_info;INSERT OVERWRITE phoen_info_like SELECT * FROM phone_info;//into是追加数据，overwrite是覆盖以及存在的数据，属于重复性校验1234 hive分区表 12345678CREATE TABLE part_table(id int,name String,ip String,city String,date String)PARTITIONED BY (part_flag String)//这里的分区字段可以是表中字段也可以是指定的字段ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';load data local inpath '/home/xudong/test.txt' into table part_table partition(part_flag='part1');load data local inpath '/home/xudong/test1.txt' into table part_table partition(part_flag='part2');select * from part_table where part_flag='part1';]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hive数据去重]]></title>
    <url>%2F2018%2F04%2F11%2Fhive%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D%2F</url>
    <content type="text"><![CDATA[distinct会整条数据去重，有一项是不同的整条数据就算不同的，不会去掉，按照某一个字段去重需要如下方法 hive数据去重，并根据需求取其中一条 数据案例： name adx tran_id cost tsck 5 125.168.10.0 33.00 1407234660ck 5 187.18.99.00 33.32 1407234661ck 5 125.168.10.0 33.24 1407234661只需要前两行的记录，因为第三行的tran_id和第一行的重复了，所以需要将最后面一行重复的去掉。 方案一：12345selectt1.tran_id,[t2.name](http://t2.name/),t2.costfrom (selectdistinct tran_id from table) t1join table t2 ont1.tran_id=t2.tran_id 分析：如果使用distinct的话，需要把tran_id放在第一列，查出来的数据很不友好。 方案二：123456789select* from(​ select *,row_number() over (partition by tran_id order by timestamp asc) num from table ) twheret.num=1; 分析： row_number() over (partition by tran_idorder by timestamp desc) num 取num=1 的意思是先根据tran_id进行分组，并在分组内部按timestamp 降序排序，row_number()函数计算的值就表示某个tran_id组内部排序后的顺序编号（该编号在一个组内是连续并且唯一的) 。所以最后直接去每个分组内的第一个（num=1）即可。 PS： ROW_NUMBER() OVER函数的基本用法语法：ROW_NUMBER() OVER(PARTITION BY COLUMN ORDER BY COLUMN)简单的说row_number()从1开始，为每一个分组记录返回一个数字，这里的ROW_NUMBER() OVER (ORDER BY xlh DESC) 是先把xlh列降序，再为降序以后的每条xlh记录返回一个序号。示例：xlh row_num1700 11500 21085 3710 4row_number() OVER (PARTITION BY COL1 ORDERBY COL2) 表示根据COL1分组，在分组内部根据 COL2排序，而此函数计算的值就表示每组内部排序后的顺序编号（该编号在组内是连续并且唯一的) 。 实例： 数据显示为empid deptid salary 1 10 5500.002 10 4500.003 20 1900.004 20 4800.005 40 6500.006 40 14500.007 40 44500.008 50 6500.009 50 7500.00需求：根据部门分组，显示每个部门的工资等级预期结果：empid deptid salary rank 1 10 5500.00 12 10 4500.00 24 20 4800.00 13 20 1900.00 27 40 44500.00 16 40 14500.00 25 40 6500.00 39 50 7500.00 18 50 6500.00 2SQL脚本：1SELECT *, Row_Number() OVER (partition by deptidORDER BY salary desc) rank FROM employee]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spark Pandas UDFs]]></title>
    <url>%2F2018%2F04%2F11%2FSpark-Pandas-UDFs%2F</url>
    <content type="text"><![CDATA[配置所有运行节点安装 pyarrow ，需要 &gt;= 0.8 为什么会有 pandas UDF在过去的几年中，python 正在成为数据分析师的默认语言。一些类似 pandas,numpy,statsmodel,scikit-learn 被大量使用，逐渐成为主流的工具包。同时，spark 也成为了大数据处理的标准，为了让数据分析师能够使用 spark ，Spark在 0.7 版本增加了 python api，也支持了 udf (user-defined functions)。 这些 udf 对每条记录都会操作一次，同时数据需要在 JVM 和 Python 中传输，因此有了额外的序列化和调用开销。因此很多数据 pipelines 用 Java 和 Scala 中定义 UDF，然后在 python 中调用它们。 Pandas Udf 构建在 Apache Arrow 之上，带来了低开销，高性能的UDF。 每个系统都有自己的存储格式，70%-80%的时间花费在序列化和反序列化上 Apache Arrow 一个跨平台的数据层，用来加速大数据分析速度。 在内存中以列式存储。 一些限制 不支持所有的 sparkSQL 数据类型，包括 BinaryType，MapType, ArrayType，TimestampType 和嵌套的 StructType。 pandas udf 和 udf 不能混用。 使用方式1. spark df &amp; pandas dfspark df 与 pandas df 相互转化性能优化，需要开启配置，默认为关闭。 配置项： 1spark.sql.execution.arrow.enabled true 相互转化 123456789import numpy as npimport pandas as pd//初始化 pandas DFpdf = pd.DataFrame(np.random.rand(100000, 3))// pdf -&gt; sdf%time df = spark.createDataFrame(pdf)// sdf -&gt; pdf%time result_pdf = df.select("*").toPandas() 性能对比： execution.arrow.enabled pdf -&gt; sdf sdf -&gt; pdf false 4980ms 722ms true 72ms 79ms tips: 即便是提高了转化的速度，pandas df 依旧是单机在 driver 中执行的，不应该返回大量的数据。 2. pandas UDFs(Vectorized UDFs)pandas udf 的入参和返回值类型都为 pandas.Series 注册 udf方法1： 123456789from pyspark.sql.functions import pandas_udfdef plus_one(a): return a + 1//df_udfplus_one_pd_udf = pandas_udf(plus_one, returnType=LongType())//sql udfspark.udf.register('plus_one',plus_one_pd_udf) 方法2： 12345678910from pyspark.sql.functions import pandas_udf//默认为 PandasUDFType.SCALAR 类型@pandas_udf('long')def plus_one(a): return a + 1spark.udf.register('plus_one',plus_one)spark.udf.register可以接受一个 SQL_BATCHED_UDF 或 SQL_SCALAR_PANDAS_UDF 方法。 使用 pandas udf 后，物理执行计划会从 BatchEvalPython 变为 ArrowEvalPython，可以使用 explain() 检查 pandas udf 是否生效。 Scalar Pandas UDFs1234567891011121314151617import pandas as pdfrom pyspark.sql.functions import col, pandas_udf,udffrom pyspark.sql.types import LongTypedef multiply_func(a, b): return a * bmultiply_pd = pandas_udf(multiply_func, returnType=LongType())multiply = udf(multiply_func, returnType=LongType())x = pd.Series([1, 2, 3] * 10000)df = spark.createDataFrame(pd.DataFrame(x, columns=["x"]))%timeit df.select(multiply_pd(col("x"), col("x"))).count()%timeit df.select(multiply(col("x"), col("x"))).count() Grouped Map Pandas UDFs计算均方差 1234567891011121314151617181920212223from pyspark.sql.functions import pandas_udf, PandasUDFTypedf = spark.createDataFrame( [(1, 1.0), (1, 2.0), (2, 3.0), (2, 5.0), (2, 10.0)], ("id", "v"))@pandas_udf("id long, v double", PandasUDFType.GROUPED_MAP)def substract_mean(pdf): # pdf is a pandas.DataFrame v = pdf.v return pdf.assign(v=v - v.mean())df.groupby("id").apply(substract_mean).show()+---+----+| id| v|+---+----+| 1|-0.5|| 1| 0.5|| 2|-3.0|| 2|-1.0|| 2| 4.0|+---+----+ 测试用例数据准备： 10M-row DataFrame , 2列，一列Int类型，一列Double类型 123df = spark.range(0, 10 * 1000 * 1000).withColumn('id', (col('id') / 10000).cast('integer')).withColumn('v', rand())df.cache()df.count() Plus one12345678from pyspark.sql.functions import pandas_udf, PandasUDFType# 输入和输出都是 doubles 类型的 pandas.Series@pandas_udf('double', PandasUDFType.SCALAR)def pandas_plus_one(v): return v + 1df.withColumn('v2', pandas_plus_one(df.v)) Cumulative Probability123456789import pandas as pdfrom scipy import stats@pandas_udf('double')def cdf(v): return pd.Series(stats.norm.cdf(v))df.withColumn('cumulative_probability', cdf(df.v)) Subtract Mean123456# 输入和输出类型都是 pandas.DataFrame@pandas_udf(df.schema, PandasUDFType.GROUPED_MAP)def subtract_mean(pdf): return pdf.assign(v=pdf.v - pdf.v.mean())df.groupby('id').apply(subtract_mean) Scalar 和 Grouped map 的一些区别 … Scalar Grouped map udf 入参类型 pandas.Series pandas.DataFrame udf 返回类型 pandas.Series pandas.DataFrame 聚合语义 无 groupby 的子句 返回大小 与输入一致 rows 和 columns 都可以和入参不同 返回类型声明 pandas.Series 的 DataType pandas.DataFrame 的 StructType 性能对比 类型 udf pandas udf plus_one 2.54s 1.28s cdf 2min 2s 1.52s Subtract Mean 1min 8s 4.4s 配置和测试方法环境 Spark 2.3 Anaconda 4.4.0 (python 2.7.13) 运行模式 local[10] 参考http://spark.apache.org/docs/latest/sql-programming-guide.html#grouped-map https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html https://www.slideshare.net/PyData/improving-pandas-and-pyspark-performance-and-interoperability-with-apache-arrow]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Grafana mysql体验]]></title>
    <url>%2F2018%2F04%2F09%2FGrafana-mysql%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[介绍在时序分析及监控展现领域，Grafana无疑是开源解决方案中的翘楚，其灵活的插件机制，支持各种漂亮的面板、丰富的数据源以及强大的应用。典型的面板有Graph、Text、Singlestat、PieChart、Table、Histogram等，支持的数据源有ES、Graphite、InfluxDB、OpenTSDB、MySQL、Druid 、Prometheus、SimpleJson等，提供的应用有Zabbix、K8s等 +Elasticsearch印象中Grafana是 InfluxDB 可视化工具，但基于Grafana良好的架构，DataSource可以变得多样性了，现在是支持ElasticSearch作为DataSource的。 Grafana的安装也非常简单，解压启动就可以了。DataSource都是动态添加上去的。Grafana作为一个纯粹的可视化工具，灵活性做到了极致。使用ElasticSearch作为DataSource，指定对应的Index，就可以建立DashBoard就行数据可视化了。相比Kibana，Grafana的template功能能把数据按照任意的维度进行切分展示，这就是它的强大之处。 部署Github地址：https://github.com/Grafana/Grafana 下载https://grafana.com/grafana/download mac安装 | 12 | brew updatebrew install grafana || —- | ——————————- || | | http://docs.grafana.org/installation/mac/http://docs.grafana.org/installation/configuration/ 启动Grafana | 12345678910111213 | 要启动Grafana使用自制服务首先确保安装了自制软件/服务。brew tap homebrew/services然后开始Grafana使用：brew services start grafana- 配置配置文件应该位于/usr/local/etc/grafana/grafana.ini。- 日志日志文件应该位于/usr/local/var/log/grafana/grafana.log。- 插件如果你想手动安装一个插件放在这里：/usr/local/var/lib/grafana/plugins。- 数据库默认的sqlite数据库位于 /usr/local/var/lib/grafana || —————– | ———————————————————— || | | 汉化(非必要) | 12 | git clone https://github.com/moonstack/grafana-for-chinese.git备份原有的 /public/app/boot.js /public/app/features/org/prefs_control.js 再将master中的两个文件覆盖到对应的目录 刷新浏览器即可 || —- | ———————————————————— || | | https://github.com/moonstack/grafana-for-chinesehttps://github.com/heruihong/gf-frontend 访问http://0.0.0.0:3000/ ，默认账号/密码：admin/admin 添加数据源http://docs.grafana.org/features/datasources/elasticsearch/http://docs.grafana.org/features/datasources/mysql/ 导入dashboard/查看dashboardhttps://grafana.com/dashboards?dataSource=mysqlhttps://grafana.com/dashboards?dataSource=elasticsearch 制图(mysql)Grafana + mysql数据源 - laomei - CSDN博客http://blog.csdn.net/sweatott/article/details/78278011 图表数据展示规则 - edit - Metrics 123456789 SELECTDATE_FORMAT(gmt_create,’%Y-%m-%d’),UNIX_TIMESTAMP(DATE_FORMAT(gmt_create,’%Y-%m-%d’)) as time_sec, – x轴:时间count(treaty_no) as value, – y轴:数值partner_code as metric – y轴分组:数据分组FROM treatyWHERE 1=1group by DATE_FORMAT(gmt_create,’%Y-%m-%d’)ORDER BY id ASC 更多文档见:http://docs.grafana.org/features/datasources/mysql/ 各报表面板设置http://docs.grafana.org/features/panels/graph/ 图表http://docs.grafana.org/features/panels/singlestat/ 仪图 templating 模板http://docs.grafana.org/reference/templating/http://docs.grafana.org/features/datasources/mysql/#query-variable mysql的查询表达式 在查询中使用变量http://docs.grafana.org/features/datasources/mysql/#using-variables-in-queries | 123456789 | SELECTDATE_FORMAT(gmt_create,’%Y-%m-%d’),UNIX_TIMESTAMP(DATE_FORMAT(gmt_create,’%Y-%m-%d’)) as time_sec, – x轴:时间count(treaty_no) as value, – y轴:数值partner_code as metric – y轴分组:数据分组FROM treatyWHERE 1=1 and partner_code in ($partner)group by DATE_FORMAT(gmt_create,’%Y-%m-%d’)ORDER BY id ASC || ——— | ———————————————————— || | | 效果 报警http://docs.grafana.org/alerting/notifications/ Grafana添加Webhook channelhttps://www.tuicool.com/articles/VZf6JjF [图表-alert]设置数据触警规则 [图表-alert]Notifications 定义发送渠道 问题安装grafana,Homebrew出现”go: version missing for “gotools” resource!”的解决方案 12 ➜ Desktop brew install grafanaError: go: version missing for “gotools” resource! 尝试解决: 12 git -C “$(brew –repo)” fetch –tagsbrew update –force 或 git -C &quot;$(brew --repo)&quot; fetch --tags brew update --forcehttp://blog.csdn.net/lanadeus/article/details/78271240https://github.com/Homebrew/homebrew-core/issues/19221https://blog.labbit.jp/%E8%AC%8E%E3%82%A8%E3%83%A9%E3%83%BCgotools%E3%81%AE%E8%A7%A3%E6%B6%88%E6%B3%95/ 实际解决: 重装brew 1 /usr/bin/ruby -e “$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)” 新建template query 错误 12 TemplatingTemplate variables could not be initialized: sql: Scan error on column index 0: unsupported Scan, storing driver.Value type into type *string 原因: 存在null值解决: where column is not null 参考基于Grafana+SimpleJson的灵活报表解决方案https://www.tuicool.com/articles/EBjUfmi 监控数据的可视化分析神器 Grafana - 推酷https://www.tuicool.com/articles/VZf6JjF Kibana and Grafana - 推酷https://www.tuicool.com/articles/rURRF3U 使用Prometheus+Grafana搭建监控系统实践 - 推酷https://www.tuicool.com/articles/QZRjAv3 监控数据的可视化分析神器 Grafana - 推酷 - OneAlert 云告警https://www.tuicool.com/articles/VZf6JjF grafana + influxdb + telegraf , 构建linux性能监控平台 - 推酷https://www.tuicool.com/articles/nyM3qyq]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Kibana + Elasticsearch体验]]></title>
    <url>%2F2018%2F04%2F09%2FKibana-Elasticsearch%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[安装kibana下载https://www.elastic.co/downloads/kibanawget https://artifacts.elastic.co/downloads/kibana/kibana-6.1.3-darwin-x86_64.tar.gz 准备elasticsearch服务见: Elasticsearch相关.md ElasticsearchKibana安装非常方便，官网下载，并配置下ES的URL就可以连上了。Kibana使用的时候会有副作用，它会在你的ES里面创建一个它所需要的Index，并会有较为频繁的query。如果是生产环境，ES存的是核心数据要慎用了。安装好启动指定需要分析的Index，就能看到以下几个Tab 配置 config/kibana.yml 1234567891011 server.port: 5601# The host to bind the server to.server.host: “”# If you are running kibana behind a proxy, and want to mount it at a path,# specify that path here. The basePath can’t end in a slash.# server.basePath: “”# The Elasticsearch instance to use for all your queries.elasticsearch.url: “http://0.0.0.0:9200“ #这里是elasticsearch的访问地址 汉化https://github.com/anbai-inc/Kibana_Hanizationpython main.py &lt;kibana目录&gt; 启动 12 ./kibana //不能关闭终端nohup ./kibana &gt; /nohub.out &amp; //可关闭终端，在nohup.out中查看log 访问 http://0.0.0.0:5601/ 使用新建索引模式http://0.0.0.0:5601/app/kibana#/management/kibana/indices 新建图表&amp;设置xy轴数据列http://0.0.0.0:5601/app/kibana#/visualize/new?_g=() 仪表盘集成图表 参考Kibana and Grafana - 推酷https://www.tuicool.com/articles/rURRF3U kibana介绍 - CSDN博客http://blog.csdn.net/eff666/article/details/63251710?locationNum=3&amp;fps=1]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式一致性算法paxos]]></title>
    <url>%2F2018%2F04%2F09%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95paxos%2F</url>
    <content type="text"><![CDATA[随着大型网站的各种高并发访问、海量数据处理等场景越来越多，如何实现网站的高可用、易伸缩、可扩展、安全等目标就显得越来越重要。为了解决这样一系列问题，大型网站的架构也在不断发展。提高大型网站的高可用架构，不得不提的就是分布式。在关于分布式事务、两阶段提交协议、三阶提交协议一文中主要用于解决分布式一致性问题的集中协议，那么这篇文章主要讲解业内公认的比较难的也是最行之有效的paxos算法。 我认为对paxos算法讲解的最清楚的就是维基百科了。但是要看懂维基百科中的介绍需要很强的数学思维（paxos毕竟是一个算法），而且有很多关于定理的推论、证明等过程。那么本篇文章主要站在程序的角度，通俗的，循序渐进的讲解到底什么是paxos算法。 背景Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos. 意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。 Paxos算法是莱斯利·兰伯特（Leslie Lamport，就是 LaTeX 中的”La”，此人现在在微软研究院）于1990年提出的一种基于消息传递的一致性算法。为描述 Paxos 算法，Lamport 讲述了这样一个故事： 在古希腊有一个岛屿叫做Paxos，这个岛屿通过议会的形式修订法律。执法者（legislators，后面称为牧师priest）在议会大厅（chamber）中表决通过法律，并通过服务员传递纸条的方式交流信息，每个执法者会将通过的法律记录在自己的账目（ledger）上。问题在于执法者和服务员都不可靠，他们随时会因为各种事情离开议会大厅、服务员也有可能重复传递消息（或者直接彻底离开），并随时可能有新的执法者（或者是刚暂时离开的）回到议会大厅进行法律表决，因此，议会协议要求保证上述情况下可以能够正确的修订法律并且不会产生冲突。 什么是paxos算法Paxos 算法是分布式一致性算法用来解决一个分布式系统如何就某个值(决议)达成一致的问题。 人们在理解paxos算法是会遇到一些困境，那么接下来，我们带着以下几个问题来学习paxos算法： 1、paxos到底在解决什么问题？ 2、paxos到底如何在分布式存储系统中应用？ 3、paxos的核心思想是什么？ paxos解决了什么问题在关于分布式一致性的探究中我们提到过，分布式的一致性问题其实主要是指分布式系统中的数据一致性问题。所以，为了保证分布式系统的一致性，就要保证分布式系统中的数据是一致的。 在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。 所以，paxos算法主要解决的问题就是如何保证分布式系统中各个节点都能执行一个相同的操作序列。 上图中，C1是一个客户端，N1、N2、N3是分布式部署的三个服务器，初始状态下N1、N2、N3三个服务器中某个数据的状态都是S0。当客户端要向服务器请求处理操作序列：op1op2op3时（op表示operation）（这里把客户端的写操作简化成向所有服务器发送相同的请操作序列，实际上可能通过Master/Slave模式处理）。如果想保证在处理完客户端的请求之后，N1、N2、N3三个服务器中的数据状态都能从S0变成S1并且一致的话（或者没有执行成功，还是S0状态），就要保证N1、N2、N3在接收并处理操作序列op1op2op3时，严格按照规定的顺序正确执行opi，要么全部执行成功，要不就全部都不执行。 所以，针对上面的场景，paxos解决的问题就是如何依次确定不可变操作opi的取值，也就是确定第i个操作什么，在确定了opi的内容之后，就可以让各个副本执行opi操作。 Paxos算法详解Paxos是一个十分巧妙的一致性算法，但是他也十分难以理解，就连他的作者Lamport都被迫对他做过多种讲解。我认为对paxos算法讲解的最清楚的就是维基百科了。但是要看懂维基百科中的介绍需要很强的数学思维（paxos毕竟是一个算法），而且有很多关于定理的推论、证明等过程。那么本篇文章主要站在程序的角度，通俗的，循序渐进的讲解到底什么是paxos算法。 我们先把前面的场景简化，把我们现在要解决的问题简化为如何确定一个不可变变量的取值（每一个不可变变量可以标识一个操作序列中的某个操作，当确保每个操作都正确之后，就可以按照顺序执行这些操作来保证数据能够准确无误的从一个状态转变成另外一个状态了）。 接下来，请跟我一步一步的学习paxos算法。 要学习paxos算法，我们就要从他要解决的问题出发，假如没有paxos算法，当我们面对如何确定一个不可变变量的取值这样一个吻问题的时候，我们应该如何解决呢？ 这里暂不介绍paxos中的角色的概念，读者可以自行从维基百科中了解。不了解的话也可以直接往下看，看着看着就了解了。 问题抽象我们把确定一个不可变变量的取值问题定义成： 设计一个系统，来存储名称为var的变量。 var的取值可以是任意二进制数 系统内部由多个Accepter组成,负责管理和存储var变量。 系统对外提供api,用来设置var变量的值propose(var,V) =&gt; &lt;ok,f&gt; or &lt;error&gt; 将var的值设置为V，系统会返回ok和系统中已经确定的取值f，或者返回error。 外部有多个Proposer机器任意请求系统，调用系统API(propose(var,V) =&gt; &lt;ok,f&gt; or &lt;error&gt;)来设置var变量的值。 如果系统成功的将var设置成了V，那么返回的f应该就是V的值。否则，系统返回的f就是其他的Proposer设置的值。 > 系统需要保证var的取值满足一致性 如果var没有被设置过，那么他的初始值为null 一旦var的值被设置成功，则不可被更改，并且可以一直都能获取到这个值 系统需要满足容错特性 可以容忍任意proposer出现故障可以容忍少数acceptor故障（半数以下） 暂时忽略网络分化问题和acceptor故障导致var丢失的问题。 到这里，问题已经抽象完成了，读者可以再仔细看看上面的系统描述。如果这样设置一个系统，是不是就可以保证变量var的不可变性了呢？ 这里还是再简单讲解一下，上面的系统确实可以保证变量var的不可变性。 因为var的初始值为null，当有proposer请求接口propose（var，v）设置var的值的时候，系统会将var设置为v，并返回f（f==v）。 var变量被初始化以后，再有proposer请求propose(var,v)设置var的值的时候，系统会直接返回系统中已有的var的值f，而放弃proposer提供的v。 系统难点要设计以上系统存在以下难点： 1、管理多个proposer并发执行 2、容忍var变量的不可变性 3、容忍任意Proposer的故障 4、容忍半数以下的acceptor的故障 解决方案一先考虑整个系统由单个acceptor组成。通过类似互斥锁的方式来管理并发的proposer的请求。 proposer向acceptor申请acceptor的互斥访问权，当取得互斥访问权之后才能调用api给var变量赋值。accepter向proposer发放互斥访问权，谁取得了互斥访问权，acceptor就接收谁的请求。这样通过互斥访问的机制，proposer就要按照获取互斥访问权的顺序来请求系统。一旦acceptor接收到一个proposer请求，并成功给var变量赋值之后，就不再允许其他的proposer设置var变量的值。每当再有proposer来请求设置var变量的值的时候，acceptor就会将var里面现有的值返回给他。 基于互斥访问权的acceptor的实现 acceptor会保存变量var的值和一个互斥锁Lock。 提供接口prepare() 加互斥锁，给予var的互斥访问权，并返回当前var的取值 提供接口release() 用于释放互斥访问权 提供接口accept(var, v) 如果已经加锁，并且当前var没有值，则将var的值设置成v，并释放锁。 proposer采用两阶段来实现 Step1、通过调用prepare接口来获取互斥性访问权和当前var的取值 如果无法获取到互斥性访问权，则返回，并不能进入到下一个阶段，因为其他proposer获取到了互斥性访问权。 Step2、根据当前var的取值f选择执行 1、如果f的取值为null，说明没有被设置过值，则调用接口accept(var ,v)来将var的取值设置成v，并释放掉互斥性访问权。2、如果f的取值不为null，说明var已经被其他proposer设置过值，则调用release接口释放掉互斥性访问权。 总结：方案一通过互斥访问的方式来保证所有的proposer能够串行的访问acceptor，这样其实并没有解决多个proposer并发执行的问题。只是想办法绕开了并发执行。虽然可以在一定程度上保证var变量的取值是确定的。但是一旦获取到互斥访问权的proposer在执行过程中出现故障，那么就会导致所有其他proposer无法再获取到互斥访问权，就会发生死锁。。所以，方案一不仅效率低、而且还会产生死锁问题，不能容忍任意Proposer出现故障。在之前提到的四个系统难点中，方案一可以解决难点1和难点2，但是无法解决难点3和难点4。 解决方案二通过引入抢占式访问权来取代互斥访问权。acceptor有权让任意proposer的访问权失效，然后将访问权发放给其他的proposer。 在方案二中，proposer向acceptor发出的每次请求都要带一个编号（epoch），且编号间要存在全序关系。一旦acceptor接收到proposer的请求中包含一个更大的epoch的时候，马上让旧的epoch失效，不再接受他们提交的取值。然后给新的epoch发放访问权，让他可以设置var变量的值。 为了保证var变量取值的不变性，不同epoch的proposer之前遵守后者认同前者的原则： 在确保旧的epoch已经失效后，并且旧的epoch没有设置var变量的值，新的epoch会提交自己的值。当旧的epoch已经设置过var变量的取值，那么新的epoch应该认同旧的epoch设置过的值，并不在提交新的值。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式系统的CAP理论]]></title>
    <url>%2F2018%2F04%2F09%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84CAP%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[2000年7月，加州大学伯克利分校的Eric Brewer教授在ACM PODC会议上提出CAP猜想。2年后，麻省理工学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP。之后，CAP理论正式成为分布式计算领域的公认定理。 CAP理论概述一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 CAP的定义Consistency 一致性一致性指“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。分布式的一致性 对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。 从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。如果能容忍后续的部分或者全部访问不到，则是弱一致性。如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。 Availability 可用性可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。 对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。也就是，该系统使用的任何算法必须最终终止。当同时要求分区容忍性时，这是一个很强的定义：即使是严重的网络错误，每个请求必须终止。 好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。可用性通常情况下可用性和分布式数据冗余，负载均衡等有着很大的关联。 Partition Tolerance分区容错性分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 分区容错性和扩展性紧密相关。在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，或者是机器之间有网络异常，将分布式系统分隔未独立的几个部分，各个部分还能维持分布式系统的运作，这样就具有好的分区容错性。 CAP的证明 如上图，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B2和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。 在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。 如上图，是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库Vo为V1，分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。 这里，可以定义N1和N2的数据库V之间的数据是否一样为一致性；外部对N1和N2的请求响应为可用行；N1和N2之间的网络环境为分区容错性。这是正常运作的场景，也是理想的场景，然而现实是残酷的，当错误发生的时候，一致性和可用性还有分区容错性，是否能同时满足，还是说要进行取舍呢？ 作为一个分布式系统，它和单机系统的最大区别，就在于网络，现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。 假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？有二种选择，第一，牺牲数据一致性，响应旧的数据V0给用户；第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。 这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。 CAP权衡通过CAP理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此CA的系统更多的是允许分区后各子系统依然保持CA。 CP without A：如果不要求A（可用），相当于每个请求都需要在Server之间强一致，而P（分区）会导致同步时间无限延长，如此CP也是可以保证的。很多传统的数据库分布式事务都属于这种模式。 AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。 对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CA，舍弃P。貌似这几年国内银行业发生了不下10起事故，但影响面不大，报到也不多，广大群众知道的少。还有一种是保证CP，舍弃A。例如网络故障事只读不写。 孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[maven使用手册]]></title>
    <url>%2F2018%2F03%2F28%2Fmaven%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[依赖机制1、A-&gt;B-&gt;C-&gt;X(1.0)，A-&gt;D-&gt;X(2.0)，此时两条依赖路径上有两个版本的X，此时遵循路径最近者优先，因此X(2.0)将被解析使用 2、A-&gt;B-&gt;Y(1.0)，A-&gt;C-&gt;Y(2.0)，Y(1.0)和Y(2.0)的依赖长度是一样的，从Maven2.0.9开始，此时遵循第一声明者优先，即顺序最靠前的那个依赖优先 依赖树查看1mvn dependency:tree -Dincludes=org.apache.httpcomponents:httpclient 参考 http://maven.apache.org/plugins/maven-dependency-plugin/tree-mojo.html 排除依赖传递性依赖会给项目隐式地引入很多依赖，这极大地简化了项目依赖的管理，但是有时候这种特性也会带来问题。比如有种情况： 1当前项目依赖A，A由于某些原因依赖了另外一个类库的SNAPSHOT版本，那么这个SNAPSHOT就会成为当前项目的传递性依赖，二SNAPSHOT的不稳定性将直接影响到当前的项目，此时就需要排除该SNAPSHOT，并且在当前项目中声明该类库的某个正式发布的版本 1234567891011&lt;dependency&gt; &lt;groupId&gt;com.alibaba.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;3.2.7&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;apache-lang&lt;/groupId&gt; &lt;artifactId&gt;commons-lang&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; settings.xmlproxyproxy表示Maven的代理，看一下写法： 123456789101112&lt;proxies&gt; &lt;proxy&gt; &lt;id&gt;optional&lt;/id&gt; &lt;active&gt;true&lt;/active&gt; &lt;protocol&gt;http&lt;/protocol&gt; &lt;username&gt;proxyuser&lt;/username&gt; &lt;password&gt;proxypass&lt;/password&gt; &lt;host&gt;proxy.host.net&lt;/host&gt; &lt;port&gt;80&lt;/port&gt; &lt;nonProxyHosts&gt;local.net|some.host.com&lt;/nonProxyHosts&gt; &lt;/proxy&gt;&lt;/proxies&gt; 需要proxy是因为很多时候你所在的公司基于安全因素考虑，要求你使用通过安全认证的代理访问因特网。这种情况下，就需要为Maven配置HTTP代理，才能让它正常访问外部仓库，以下载所需要的资源。proxies下可以配置多个proxy元素，如果声明了多个proxy元素，则默认情况下第一个被激活的proxy会生效。active为true表示激活该代理，protocol表示使用的代理协议，当然最重要的是指定正确的主机名（host）和端口（port），如果代理服务器需要认证则配置username和password，nonProxyHost元素表示指定哪些主机名不需要代理，可以用”|”分隔多个主机名，也支持通配符”*”。 repositoryrepository表示Maven的中央仓库，因为尽管默认的远程仓库中的构件非常庞大，但是总归会有不满足我们需求的时候，这时候就要用到别的中央仓库了。看一下写法： 1234567891011&lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://192.168.1.6:8081/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt;&lt;/repository&gt; 可以声明多个repository。id必须是唯一的，尤其注意，Maven自带的中央仓库使用的id为central，如果其他仓库声明也用该id，就会覆盖中央仓库的配置。releases和snapshots比较重要，前者表示开启仓库的发布版本下载支持，后者表示关闭仓库的快照版本下载支持，这样一来，Maven就会去仓库下载发布版本的构件而不会下载快照版本的构件了。 server大部分远程仓库无须认证就可以访问，但是有时候处于安全方面的因素考虑，需要提供认证信息才能访问一些远程仓库，处于安全考虑，认证信息一般只放在settings.xml中，server就是认证元素。看一下配置： 12345&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;deployment&lt;/username&gt; &lt;password&gt;deployment&lt;/password&gt;&lt;/server&gt; 这里的关键是id，这个id必须与需要认证的repository元素的id完全一致才行，换句话说，正式这个id将认证信息和仓库配置联系在了一起。 mirror如果仓库X可以提供仓库Y存储的所有内容，那么就可以认为仓库X是仓库Y的一个镜像（mirror），换句话说，任何一个可以从Y中获取到的构件够可以从X中获取到。举个例子，”http://maven.net.cn/content/groups/public/&quot;是中央仓库&quot;http://repo1.maven.org/maven2/&quot;在中国的镜像，由于地理位置的因素，该镜像往往能够提供比中央仓库更快的服务，这就是为什么要使用mirror的原因。 看一下mirror的配置： 123456&lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;internal nexus repository&lt;/name&gt; &lt;url&gt;http://192.168.1.6:8081/nexus/content/groups/public&lt;/url&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;&lt;/mirror&gt; 该例子中，mirrof为*，表示该配置为所有中央仓库的镜像，任何对于中央仓库的请求都会转至该镜像。另外三个元素id、name、url与一般仓库配置无异，表示该镜像仓库的唯一标识符、名称以及地址。类似的，如果该镜像需要认证，也可以基于该id配置仓库认证。 maven deploy指定文件deploy 1mvn clean deploy -f pom-deploy.xml]]></content>
      <categories>
        <category>java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[安全技术--哈希算法密码破解之彩虹表]]></title>
    <url>%2F2018%2F03%2F27%2F%E5%AE%89%E5%85%A8%E6%8A%80%E6%9C%AF-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%AF%86%E7%A0%81%E7%A0%B4%E8%A7%A3%E4%B9%8B%E5%BD%A9%E8%99%B9%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[[基础技能] 安全技术——哈希算法密码破解之彩虹表(Rainbow Table)学习1、基础知识刚刚学习过数字签名的相关知识，以及数字签名的伪造技术，而伪造数字签名归根结底就是密码破解的一个过程，然而直接破解的速度是非常缓慢的，所以有人想出一种办法，直接建立出一个数据文件，里面事先记录了采用和目标采用同样算法计算后生成的Hash散列数值，在需要破解的时候直接调用这样的文件进行比对，破解效率就可以大幅度地，甚至成百近千近万倍地提高，这样事先构造的Hash散列数据文件在安全界被称之为Table。 其实简单理解就是使用一个大型数据字典来进行快速匹配暴力破解的方法，以空间来换取时间的方法。 具体的需要一些基础知识做支撑： 1、哈希算法哈希（Hash）算法是单向散列算法，它把某个较大的集合P映射到另一个较小的集合Q中，假如这个算法叫H，那么就有Q = H（P）。对于P中任何一个值p都有唯一确定的q与之对应，但是一个q可以对应多个p。作为一个有用的Hash算法，H还应该满足： H(p)速度比较快； 给出一个q，很难算出一个p满足q = H(p)；即单向性。 给出一个p1，很难算出一个不等于p1的p2使得 H(p1)=H(p2)；强弱碰撞性。 正因为有这样的特性，Hash算法经常被用来保存密码————这样不会泄露密码明文，又可以校验输入的密码是否正确。常用的 Hash算法有MD5、SHA1等。 2、破解HASH 破解Hash的任务就是，对于给出的一个q，反算出一个p来满足q = H(p)。即直接采用碰撞的方法来打破它的强弱碰撞性。通常我们能想到的办法有两种： 1、暴力破解法，把P中的每一个p都算一下H(p)，直到结果等于q； 2、查表法，使用一个大型字典，把每个p和对应的q都记录下来，按q做一下索引，直接查找匹配。 两种办法理论上都是可以的，但是前一种需要大量时间，后一种需要大量存储。这种单纯的开销是很巨大的，所以目前我们认为Hash是足够安全的，十几位以上的密码也是强度足够的。 3、彩虹表 时空的平衡 对于HASH的传统做法是把H(X)的所有输出穷举，查找H(X[y])==H(P)，得出P==X[y]。而彩虹表则是使用散列链的方式进行。 “散列链”是为了降低传统做法空间要求的技术，想法是定义一个衰减函数 R 把散列值变换成另一字符串。通过交替运算H函数和R函数，形成交替的密码和散列值链条。 2、详解当面对要破解的哈希函数H，首先定义一个约简函数（reduction function）R，该函数的定义域和值域需要和哈希函数相反，通过该函数可以将哈希值约简为一个与原文相同格式的值（”plain text” value）。需要强调的是，由于哈希函数H是不可逆的，所以对于密文进行R运算几乎不可能得到明文原文。例如，五位字母明文“zhihu”进行H运算后得到了“D2A82C9A”，而对“D2A82C9A”进行R运算后得到另一个五位字母格式的值“vfkkd”。因为这个值落在H的定义域中，因此可以对它继续进行H运算。就这样，将H运算、R运算、H运算……这个过程反复地重复下去，重复一个特定的次数 k 以后，就得到一条哈希链，例如k为2时得到： 要生成一个表，我们选择一组随机的初始密码，每一个密码计算一个固定长度K的链，并只存储每一个链的第一个和最后一个密码。第一密码被称为始点，最后一个被称为末点。在上面例举的链中，“zhihu”就是始点，“crepa”就是末点，其他密码（或散列值）并不被保存。 造表过程： 查表过程： 参考： 彩虹表破解开机密码、MD5算法等的原理http://www.91ri.org/7593.html]]></content>
      <categories>
        <category>安全</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java工程师成神之路]]></title>
    <url>%2F2018%2F03%2F23%2Fjava%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[一、基础篇JVM JVM内存结构堆、栈、方法区、直接内存、堆和栈区别 Java内存模型内存可见性、重排序、顺序一致性、volatile、锁、final 垃圾回收内存分配策略、垃圾收集器（G1）、GC算法、GC参数、对象存活的判定 JVM参数及调优Java对象模型oop-klass、对象头 HotSpot即时编译器、编译优化 类加载机制classLoader、类加载过程、双亲委派（破坏双亲委派）、模块化（jboss modules、osgi、jigsaw） 虚拟机性能监控与故障处理工具jps, jstack, jmap、jstat, jconsole, jinfo, jhat, javap, btrace、TProfiler 编译与反编译 javac 、javap 、jad 、CRF Java基础知识 阅读源代码String、Integer、Long、Enum、BigDecimal、ThreadLocal、ClassLoader &amp; URLClassLoader、ArrayList &amp; LinkedList、 HashMap &amp; LinkedHashMap &amp; TreeMap &amp; CouncurrentHashMap、HashSet &amp; LinkedHashSet &amp; TreeSet Java中各种变量类型熟悉Java String的使用，熟悉String的各种函数JDK 6和JDK 7中substring的原理及区别、 replaceFirst、replaceAll、replace区别、 String对“+”的重载、 String.valueOf和Integer.toString的区别、 字符串的不可变性 自动拆装箱Integer的缓存机制 熟悉Java中各种关键字transient、instanceof、volatile、synchronized、final、static、const 原理及用法。 集合类常用集合类的使用 ArrayList和LinkedList和Vector的区别 SynchronizedList和Vector的区别 HashMap、HashTable、ConcurrentHashMap区别 Java 8中stream相关用法 apache集合处理工具类的使用 不同版本的JDK中HashMap的实现的区别以及原因 枚举枚举的用法、枚举与单例、Enum类 Java IO&amp;Java NIO，并学会使用bio、nio和aio的区别、三种IO的用法与原理、netty Java反射与javassist反射与工厂模式、 java.lang.reflect.* Java序列化什么是序列化与反序列化、为什么序列化 序列化底层原理 序列化与单例模式 protobuf 为什么说序列化并不安全 注解元注解、自定义注解、Java中常用注解使用、注解与反射的结合 JMS什么是Java消息服务、JMS消息传送模型 JMXjava.lang.management.*、 javax.management.* 泛型泛型与继承 类型擦除 泛型中K T V E object等的含义、泛型各种用法 单元测试junit、mock、mockito、内存数据库（h2） 正则表达式java.lang.util.regex.* 常用的Java工具库commons.lang, commons.*... guava-libraries netty 什么是API&amp;SPI异常异常类型、正确处理异常、自定义异常 时间处理时区、时令、Java中时间API 编码方式解决乱码问题、常用编码方式 语法糖Java中语法糖原理、解语法糖 Java并发编程 什么是线程，与进程的区别阅读源代码，并学会使用Thread、Runnable、Callable、ReentrantLock、ReentrantReadWriteLock、Atomic*、Semaphore、CountDownLatch、、ConcurrentHashMap、Executors 线程池自己设计线程池、submit() 和 execute() 线程安全死锁、死锁如何排查、Java线程调度、线程安全和内存模型的关系 锁CAS、乐观锁与悲观锁、数据库相关锁机制、分布式锁、偏向锁、轻量级锁、重量级锁、monitor、锁优化、锁消除、锁粗化、自旋锁、可重入锁、阻塞锁、死锁 死锁volatilehappens-before、编译器指令重排和CPU指令重 synchronizedsynchronized是如何实现的？ synchronized和lock之间关系 不使用synchronized如何实现一个线程安全的单例 sleep 和 waitwait 和 notifynotify 和 notifyAllThreadLocal写一个死锁的程序写代码来解决生产者消费者问题守护线程守护线程和非守护线程的区别以及用法 二、 进阶篇Java底层知识 字节码、class文件格式CPU缓存，L1，L2，L3和伪共享尾递归位运算用位运算实现加、减、乘、除、取余 设计模式 了解23种设计模式会使用常用设计模式单例、策略、工厂、适配器、责任链。 实现AOP实现IOC不用synchronized和lock，实现线程安全的单例模式nio和reactor设计模式网络编程 tcp、udp、http、https等常用协议三次握手与四次关闭、流量控制和拥塞控制、OSI七层模型、tcp粘包与拆包 http/1.0 http/1.1 http/2之前的区别Java RMI，Socket，HttpClientcookie 与 sessioncookie被禁用，如何实现session 用Java写一个简单的静态文件的HTTP服务器 实现客户端缓存功能，支持返回304 实现可并发下载一个文件 使用线程池处理客户端请求 使用nio处理客户端请求 支持简单的rewrite规则 上述功能在实现的时候需要满足“开闭原则” 了解nginx和apache服务器的特性并搭建一个对应的服务器用Java实现FTP、SMTP协议进程间通讯的方式什么是CDN？如果实现？什么是DNS？反向代理框架知识 Servlet线程安全问题Servlet中的filter和listenerHibernate的缓存机制Hiberate的懒加载Spring Bean的初始化Spring的AOP原理自己实现Spring的IOCSpring MVCSpring Boot2.0Spring Boot的starter原理，自己实现一个starter Spring Security应用服务器 JBosstomcatjettyWeblogic工具 git &amp; svnmaven &amp; gradle 三、 高级篇新技术 Java 8lambda表达式、Stream API、 Java 9Jigsaw、Jshell、Reactive Streams Java 10局部变量类型推断、G1的并行Full GC、ThreadLocal握手机制 Spring 5响应式编程 Spring Boot 2.0性能优化 使用单例、使用Future模式、使用线程池、选择就绪、减少上下文切换、减少锁粒度、数据压缩、结果缓存 线上问题分析 dump获取线程Dump、内存Dump、gc情况 dump分析分析死锁、分析内存泄露 自己编写各种outofmemory，stackoverflow程序HeapOutOfMemory、 Young OutOfMemory、MethodArea OutOfMemory、ConstantPool OutOfMemory、DirectMemory OutOfMemory、Stack OutOfMemory Stack OverFlow 常见问题解决思路内存溢出、线程死锁、类加载冲突 使用工具尝试解决以下问题，并写下总结当一个Java程序响应很慢时如何查找问题、 当一个Java程序频繁FullGC时如何解决问题、 如何查看垃圾回收日志、 当一个Java应用发生OutOfMemory时该如何解决、 如何判断是否出现死锁、 如何判断是否存在内存泄露 编译原理知识 编译与反编译Java代码的编译与反编译Java的反编译工具词法分析，语法分析（LL算法，递归下降算法，LR算法），语义分析，运行时环境，中间代码，代码生成，代码优化操作系统知识Linux的常用命令进程同步缓冲区溢出分段和分页虚拟内存与主存数据库知识MySql 执行引擎MySQL 执行计划如何查看执行计划，如何根据执行计划进行SQL优化 SQL优化事务事务的隔离级别、事务能不能实现锁的功能 数据库锁行锁、表锁、使用数据库锁实现乐观锁、 数据库主备搭建binlog内存数据库h2 常用的nosql数据库redis、memcached 分别使用数据库锁、NoSql实现分布式锁性能调优数据结构与算法知识 简单的数据结构栈、队列、链表、数组、哈希表、 树二叉树、字典树、平衡树、排序树、B树、B+树、R树、多路树、红黑树 排序算法各种排序算法和时间复杂度 深度优先和广度优先搜索 全排列、贪心算法、KMP算法、hash算法、海量数据处理 大数据知识Zookeeper基本概念、常见用法 Solr，Lucene，ElasticSearch在linux上部署solr，solrcloud，，新增、删除、查询索引 Storm，流式计算，了解Spark，S4在linux上部署storm，用zookeeper做协调，运行storm hello world，local和remote模式运行调试storm topology。 Hadoop，离线计算HDFS、MapReduce 分布式日志收集flume，kafka，logstash数据挖掘，mahout网络安全知识什么是XSSXSS的防御 什么是CSRF什么是注入攻击SQL注入、XML注入、CRLF注入 什么是文件上传漏洞加密与解密MD5，SHA1、DES、AES、RSA、DSA 什么是DOS攻击和DDOS攻击memcached为什么可以导致DDos攻击、什么是反射型DDoS SSL、TLS，HTTPS如何通过Hash碰撞进行DOS攻击用openssl签一个证书部署到apache或nginx 四、架构篇分布式 数据一致性、服务治理、服务降级 分布式事务2PC、3PC、CAP、BASE、 可靠消息最终一致性、最大努力通知、TCC Dubbo服务注册、服务发现，服务治理 分布式数据库怎样打造一个分布式数据库、什么时候需要分布式数据库、mycat、otter、HBase 分布式文件系统mfs、fastdfs 分布式缓存缓存一致性、缓存命中率、缓存冗余 微服务 SOA、康威定律 ServiceMeshDocker &amp; KubernetsSpring BootSpring Cloud高并发 分库分表CDN技术消息队列ActiveMQ 监控 监控什么CPU、内存、磁盘I/O、网络I/O等 监控手段进程监控、语义监控、机器资源监控、数据波动 监控数据采集日志、埋点 Dapper负载均衡 tomcat负载均衡、Nginx负载均衡 DNS DNS原理、DNS的设计 CDN 数据一致性 五、 扩展篇云计算 IaaS、SaaS、PaaS、虚拟化技术、openstack、Serverlsess 搜索引擎 Solr、Lucene、Nutch、Elasticsearch 权限管理 Shiro 区块链 哈希算法、Merkle树、公钥密码算法、共识算法、Raft协议、Paxos 算法与 Raft 算法、拜占庭问题与算法、消息认证码与数字签名 比特币挖矿、共识机制、闪电网络、侧链、热点问题、分叉 以太坊超级账本人工智能 数学基础、机器学习、人工神经网络、深度学习、应用场景。 常用框架TensorFlow、DeepLearning4J 其他语言 Groovy、Python、Go、NodeJs、Swift、Rust 六、 推荐书籍 《深入理解Java虚拟机》 《Effective Java》 《深入分析Java Web技术内幕》 《大型网站技术架构》 《代码整洁之道》 《Head First设计模式》 《maven实战》 《区块链原理、设计与应用》 《Java并发编程实战》 《鸟哥的Linux私房菜》 《从Paxos到Zookeeper》 《架构即未来》]]></content>
      <categories>
        <category>java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL开发规范]]></title>
    <url>%2F2018%2F03%2F13%2FMySQL%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[一. 命名规范 库名、表名、字段名必须使用小写字母，并采用下划线分割 为了统一规范， 库名、表名、字段名使用小写字母，禁用关键字（index,order等）。 前缀命令规范 视图以view_开头，事件以event_开头，触发器以trig_开头，存储过程以proc_开头，函数以func_开头，应用上面禁用 普通索引以idx_各个列名简称，唯一索引以uk_各个列名简称命名，中间用_隔开。如 idx_col1_col2_col3(col1,col2,col3)，如果列过长，用简写 临时表以tmp_实体表名，线上禁用，备份表以bak_日期_实体表名，尽可能备份至HDFS 库名、表名、字段名禁止超过32个字符，需见名知意库名、表名、字段名支持最多32个字符，但为了统一规范、易于辨识以及减少传输量，禁止超过32个字符，例：业务名称/实体_表作用 按日期时间分表须符合_YYYYMMDD格式按月或日生成的表，以_YYYYMM[DD]方式命名。 二. 库表基础规范 使用Innodb存储引擎所有表必须使用默认存储引擎InnoDB。 表编码方式统一使用UTF8或UTF8MB4的创建索引时utf8比utf8mb4少一个字节，所以明确没有emoj时，尽量使用utf8。 所有表都要添加注释所有字段必需要有注释，包括表注释，并标注简单意义 控制单表字段数量 单表字段数上限50左右，再多的话考虑垂直分表，一是冷热数据分离，二是大字段分离，三是常在一起做条件和返回列的不分离。 表字段控制少而精，可以提高IO效率，内存缓存更多有效数据，从而提高响应速度和并发能力，后续 alter table 也更快。 所有表都必须要显式指定主键 双活的表必须禁用自增主键【snowflake】，InnoDB表实际是一棵索引组织表，顺序存储可以提高存取效率，充分利用磁盘空间。还有对一些复杂查询可能需要自连接来优化时需要用到。 需要全局唯一主键时，gmt_create这类的能使用主键排序的尽量使用主键做分页排序，不浪费索引 少数情况可以使用联合唯一主键，需与DBA协商 不使用外键外键严重影响数据库性能，增加表维护复杂度，所以线上禁用外键 字段名称统一 每张表原则上必须含有gmt_create,gmt_modify，gmt_create为创建时间。gmt_modify属性为NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP，gmt_create属性为NOT NULL DEFAULT CURRENT_TIMESTAMP，统一放至字段最后 所有相同意义的表采用统一字段名称，并且字段类型一致，这样应用与维护人员见字段知其含义，方便理解 简单单表数据量控制在1000w以内 尽量保证单表存储空间小于10GB 建表时不要加入COLLATE相关内容 三. 字段规范 char、varchar、text等字符串类型定义 对于长度基本固定的列，如果该列恰好更新又特别频繁，适合char varchar虽然存储变长字符串，但不可太小也不可太大。UTF8最多能存21844个汉字，或65532个英文 TEXT类型与VARCHAR都类似，存储可变长度，最大限制也是2^16，但是它20bytes以后的内容是在数据页以外的空间存储（row_format=dynamic），对它的使用需要多一次寻址，没有默认值。 把text/blob拆到另一个表中，如果只存不读的禁用，建议直接存HDFS BLOB可以看出varbinary的扩展版本，内容以二进制字符串存储，无字符集，区分大小写，有一种经常提但不用的场景：不要在数据库里存储图片。 字符集为utf8，varchar类型最大只能创建索引为前255字节；字符集为utf8mb4，varchar类型最大只能创建索引为前191字节。所以字段造型时首选int，如果varchar时字段做查询的越小越好，长度不要超过191。 int、tinyint、decimal等数字类型定义 使用tinyint来代替 enum和booleanENUM类型在需要修改或增加枚举值时，需要在线DDL，成本较高；ENUM列值如果含有数字类型，可能会引起默认值混淆tinyint使用1个字节，一般用于status,type,flag的列 建议使用 UNSIGNED 存储非负数值相比不使用 unsigned，可以扩大一倍使用数值范围 int使用固定4个字节存储，int(11)与int(4)只是显示宽度的区别 使用int存储IPv4地址，可节省 9%+的数据存储空间 使用Decimal 代替float/double存储精确浮点数对于货币、金额这样的类型，可以使用（货币使用bigint+币种+最小单位），如果精度不高，可以使用decimal(9,2)。float默认只能能精确到6位有效数字 timestamp与datetime选择 datetime 和 timestamp类型所占的存储空间不同，前者8个字节，后者4个字节，这样造成的后果是两者能表示的时间范围不同。前者范围为1000-01-01 00:00:00 ~ 9999-12-31 23:59:59，后者范围为 1970-01-01 00:00:00 到 2037-12-31 23:59:59。所以 TIMESTAMP 支持的范围比 DATATIME 要小。 timestamp可以在insert/update行时，自动更新时间字段（如 NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP），但一个表只能有一个这样的定义。 timestamp显示与时区有关，内部总是以 UTC 毫秒 来存的。还受到严格模式的限制 优先使用timestamp，datetime也没问题，timestamp精度可以到秒后6位，即timestamp(6) where条件里不要对时间列上使用时间函数 建议字段都定义为NOT NULL加上default值 如果是索引字段，一定要定义为not null 。因为null值会影响cordinate统计，影响优化器对索引的选择 如果不能保证insert时一定有值过来，定义时使用default ‘’ ，或 0 上面两条如果需要双机房同步，那同步的表新增或更改必须为NULL，再行初始化数据 类型选择原则Int-&gt;char-&gt;varchar-&gt;text，从左到右性能越差 四. 索引规范 索引个数限制 索引是双刃剑，会增加维护负担，增大IO压力，索引占用空间是成倍增加的 单张表的索引数量控制在5个以内，索引的大小尽量比表小。若单张表多个字段在查询需求上都要单独用到索引，需要经过DBA评估。 避免冗余索引 InnoDB表是一棵索引组织表，主键是和数据放在一起的聚集索引，普通索引最终指向的是主键地址，所以把主键做最后一列是多余的。如id作为主键，联合索引(user_id,id)上的id就完全多余 (a,b,c)、(a,b)，后者为冗余索引。可以利用前缀索引来达到加速目的，减轻维护负担 索引创建原则 尽可能选择过滤效果好的列上创建索引 索引选择性计算方法（基数 ÷ 数据行数）Selectivity = Cardinality / Total Rows = select count(distinct col1)/count(*) from tbname，越接近1说明col1上使用索引的过滤效果越好 如果某列为sex，数据倾斜比较大，male占比99%，female占比1%，而每次查询都为female，则需要创建该列的索引 最左前缀原则 mysql使用联合索引时，从左向右匹配，遇到断开或者范围查询时，无法用到后续的索引列比如索引idx_c1c2c3 (c1,c2,c3)，相当于创建了(c1)、(c1,c2)、(c1,c2,c3)三个索引，where条件包含上面三种情况的字段比较则可以用到索引，但像 where c1=a and c3=c 只能用到c1列的索引，像 c2=b and c3=c等情况就完全用不到这个索引 遇到范围查询(&gt;、&lt;、between、like)也会停止索引匹配，比如 c1=a and c2 &gt; 2 and c3=c，只有c1,c2列上的比较能用到索引，(c1,c2,c3)排列的索引才可能会都用上 where条件里面字段的顺序与索引顺序无关，mysql优化器会自动调整顺序 mysql的optimizer_switch，可以配置icp，mrr等特性。mrr为多个字段做合并，如已存在c1,c2,c3索引，查询时c1=’a’ and/or c2=’b’，则会使用到索引合并，如果大部分查询没有c1和c2同时存在，则建议创建单列索引 前缀索引 前缀索引尽量第一列区分度高，这样如果优化器判断时会比较准确 ,A列1000个不同值，B列有100000个不同值，这样建议索引创建时idx_B_A(B,A) 合理使用覆盖索引减少IOINNODB存储引擎中，secondary index(非主键索引，又称为辅助索引、二级索引)没有直接存储行地址，而是存储主键值。如果用户需要查询secondary index中所不包含的数据列，则需要先通过secondary index查找到主键值，然后再通过主键查询到其他数据列，因此需要查询两次。覆盖索引则可以在一个索引中获取所有需要的数据列，从而避免回表进行二次查找，节省IO因此效率较高。例如SELECT email，uid FROM user_email WHERE uid=xx，如果uid不是主键，适当时候可以将索引添加为index(uid，email)，以获得性能提升。 不要在频繁更新的列上创建索引 五. SQL设计 杜绝直接 SELECT * 读取全部字段即使需要所有字段，减少网络带宽消耗，能有效利用覆盖索引，表结构变更对程序基本无影响 能确定返回结果只有一条时，使用 limit 1在保证数据不会有误的前提下，能确定结果集数量时，多使用limit，尽快的返回结果。 建议不要使用隐式类型转换 禁止在where条件列上使用函数 会导致索引失效，如lower(email)，f_qq % 4。可放到右边的常量上计算 返回小结果集不是很大的情况下，可以对返回列使用函数，简化程序开发，但尽量不要使用函数索引 使用like模糊匹配，%不要放首位会导致索引失效，有这种搜索需求是，考虑其它方案，如es全文搜索 使用join时，where条件尽量使用充分利用同一表上的索引 如 select t1.a,t2.b * from t1,t2 where t1.a=t2.a and t1.b=123 and t2.c= 4 ，如果t1.c与t2.c字段相同，那么t1上的索引(b,c)就只用到b了。此时如果把where条件中的t2.c=4改成t1.c=4，那么可以用到完整的索引 这种情况可能会在字段冗余设计（反范式）时出现 正确选取inner join和left join 少用或不用子查询，改用joinmysql 5.6版本只支持nest loop，让mysql自已判断需要使用的索引 考虑使用union all，少使用union，注意考虑去重 union all不去重，而少了排序操作，速度相对比union要快，如果没有去重的需求，优先使用union all 如果UNION结果中有使用limit，在2个子SQL可能有许多返回值的情况下，各自加上limit。如果还有order by，请找DBA。 IN的内容尽量不超过200个超过200个值使用批量的方式，否则一次执行会影响数据库的并发能力，因为单SQL只能且一直占用单CPU，而且可能导致主从复制延迟 拒绝大事务比如在一个事务里进行多个select，多个update，如果是高频事务，会严重影响MySQL并发能力，因为事务持有的锁等资源只在事务rollback/commit时才能释放。但同时也要权衡数据写入的一致性。 避免使用is null, is not null这样的比较 杜绝危险SQL 去掉where 1=1 这样无意义或恒真的条件，如果遇到update/delete或遭到sql注入就恐怖了 SQL中不允许出现DDL语句。一般也不给予create/alter这类权限 编写SQL 慎用分组、聚合 ​ 在编写SQL中，原则上不能使用以下方法，尽可能将这些逻辑交由应用实现 ​ 1、group by having2、count/sum/avg etc.3、order by 非id4、3张及3张以上表做嵌套5、left join/ right join6、select * from7、无where条件的查询 使用建议 order by .. limit这种查询更多的是通过索引去优化，但order by的字段有讲究，比如主键id与gmt_create都是顺序递增，那就可以考虑order by id而非 gmt_create 。 c1 &lt; a order by c2与上面不同的是，order by之前有个范围查询，由前面的内容可知，用不到类似(c1,c2)的索引，但是可以利用(c2,c1)索引。另外还可以改写成join的方式实现。 分页优化建议使用合理的分页方式以提高分页效率，大页情况下不使用跳跃式分页假如有类似下面分页语句:SELECT FROM table1 ORDER BY ftime DESC LIMIT 10000,10;这种分页方式会导致大量的io，因为MySQL使用的是提前读取策略。推荐分页方式：SELECT FROM table1 WHERE ftime &lt; last_time ORDER BY ftime DESC LIMIT 10即传入上一次分页的界值 SELECT * FROM table as t1 inner JOIN (SELECT id FROM table ORDER BY time LIMIT 10000，10) as t2 ON t1.id=t2.id count计数 首先count()、count(1)、count(col1)是有区别的，count()表示整个结果集有多少条记录，count(1)表示结果集里以primary key统计数量，绝大多数情况下count()与count(1)效果一样的，但count(col1)表示的是结果集里 col1 列 NOT null 的记录数。优先采用count() 大数据量count是消耗资源的操作，甚至会拖慢整个库，查询性能问题无法解决的，应从产品设计上进行重构。例如当频繁需要count的查询，考虑使用汇总表 遇到distinct的情况，group by方式可能效率更高。 delete,update语句改成select再explain 涉及到复杂sql时，务必先参考已有索引设计，先explain 简单SQL拆分，不以代码处理复杂为由。 比如 OR 条件： f_phone=’10000’ or f_mobile=’10000’，两个字段各自有索引，可以使用索引合并使用两个索引。不过建议拆分成2个sql，或者union all，如果非要用mysql索引实现，则需要创建两列单列索引，打开index_merge_union后会转义成union。 先explain的好处是可以为了利用索引，增加更多查询限制条件 减少与数据库交互的次数，尽量采用批量SQL语句 INSERT ... ON DUPLICATE KEY UPDATE ...，插入行后会导致在一个UNIQUE索引或PRIMARY KEY中出现重复值，则执行旧行UPDATE，如果不重复则直接插入，影响1行。 REPLACE INTO类似，但它是冲突时删除旧行。INSERT IGNORE相反，保留旧行，丢弃要插入的新行。 INSERT INTO VALUES(),(),()，合并插入。 隐式类型使用注意事项 两个参数至少有一个是 NULL 时，比较的结果也是 NULL，例外是使用 &lt;=&gt; 对两个 NULL 做比较时会返回 1，这两种情况都不需要做类型转换 两个参数都是字符串，会按照字符串来比较，不做类型转换 两个参数都是整数，按照整数来比较，不做类型转换 十六进制的值和非数字做比较时，会被当做二进制串 有一个参数是 TIMESTAMP 或 DATETIME，并且另外一个参数是常量，常量会被转换为 timestamp 有一个参数是 decimal 类型，如果另外一个参数是 decimal 或者整数，会将整数转换为 decimal 后进行比较，如果另外一个参数是浮点数，则会把 decimal 转换为浮点数进行比较 所有其他情况下，两个参数都会被转换为浮点数再进行比较。 例：A列为int类型时，A=’123’隐式转换后可以使用索引；A为char类型时，A=123隐式转换后无法使用索引 任何新的select,update,delete上线，建议都要先explain，看索引使用情况尽量避免extra列出现：Using File Sort，Using Temporary，rows超过1000的要谨慎上线。explain解读 type：ALL, index, range, ref, eq_ref, const, system（从左到右，性能从差到好） possible_keys：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用 key：表示MySQL实际决定使用的键（索引）如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX ref：表示选择 key 列上的索引，哪些列或常量被用于查找索引列上的值 rows：根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 Extra``Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序” 查询条件（包括DML中的条件）及每个条件占比数据量： where login_id=1 100%不同值 算法：count(distinct login_id) / count(1) where user_name=1 and status=1 order by id desc limit 5 80%不同值，算法：count(distinct user_name,status) / count(1) 原则上大于20%以上就要创建下索引]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java范型使用小结]]></title>
    <url>%2F2018%2F03%2F08%2Fjava%E8%8C%83%E5%9E%8B%E9%80%9A%E9%85%8D%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[范型通配符 &lt;? extends Hero&gt; ArrayList heroList&lt;? extends Hero&gt; 表示只能放子类所以 可以确凿的是，从heroList取出来的对象，一定是可以转型成Hero的 &lt;? super Hero&gt; ArrayList heroList&lt;? super Hero&gt; 表示heroList的泛型可能是HeroheroList的泛型可能是Object可以往里面插入Hero以及Hero的子类但是取出来有风险，因为不确定取出来是Hero还是Object 泛型通配符? 泛型通配符? 代表任意泛型既然?代表任意泛型，那么换句话说，这个容器什么泛型都有可能所以只能以Object的形式取出来并且不能往里面放对象，因为不知道到底是一个什么泛型的容器 一、泛型由来Java语言类型包括八种基本类型(byte short int long float double boolean char)和复杂类型，复杂类型包括类和数组。早期Java版本（1.4之前）如果要代指某个泛化类对象，只能使用Object，这样写出来的代码需要增加强转，而且缺少类型检查，代码缺少健壮性。在1.5之后，Java引入了泛型(Generic)的概念，提供了一套抽象的类型表示方法。利用泛型，我们可以：1、表示多个可变类型之间的相互关系：HashMap表示类型T与S的映射，HashMap表示T的子类与T的映射关系 2、细化类的能力：ArrayList 可以容纳任何指定类型T的数据，当T代指人，则是人的有序列表，当T代指杯子，则是杯子的有序列表，所有对象个体可以共用相同的操作行为 3、复杂类型被细分成更多类型：List和List是两种不同的类型，这意味着List listP = new ArrayList()是不可编译的。后面会提到，这种检查基于编译而非运行，所以说是不可编译并非不可运行，因为运行时ArrayList不保留Cup信息。另外要注意，即使People继承自Object，List listO = new ArrayList()也是不可编译的，应理解为两种不同类型。因为listO可以容纳任意类型，而实例化的People列表只能接收People实例，这会破坏数据类型完整性。 4、简化代码实现：假设有一个执行过程，对不同类型的数据，进行某些流程一致的处理，不引入泛型的实现方法为：[java] view plain copypublic void addToArray(Integer data, Integer array[], int pos) { array[pos] = data;}public void addToArray(Long data, Long array[], int pos) { array[pos] = data;}这是一种典型的多态行为——重载，但是不够简化。引入泛型的写法更优雅：[java] view plain copypublic void addToArray(T data, T array[], int pos) { array[pos] = data;} 二、泛型定义与使用（泛型类和泛型方法）1、泛型参数的命名风格：1）尽量用简便的命名来命名泛型，若类型无特定意义，尽量使用一个字符2）尽量使用全大写来命名泛型形参，以此与其他类型区分开3）单字母的泛型建议用T命名，如果有多个泛型，可以取T周围的大写字母，注意，如果泛型本身有意义，可以不遵守这一条，比如缓存管理CacheManager，该类负责管理缓存查询条件与数据的映射，用单字母就不太合适，使用多字母更好4）对于泛型函数或者泛型内部类在某个泛型类中出现的情况，建议泛型函数和内部类的泛型形参名称与外层类的泛型名称保持不同，否则容易引起混淆。类似这种：[java] view plain copypublic class GenericClass { public void testGenericMethod(T t) { }} 其实testGenericMethod方法的形参与外面GenericClass的形参完全没有关系。换句话说，泛型方法的泛型是优先使用方法泛型定义的。这种更应该写成：[java] view plain copypublic class GenericClass { public void testGenericMethod(S s) { }} 2、泛型存在两种用法：泛型类和泛型方法 1）泛型类定义泛型类时，在类名后加&lt;&gt;，尖括号内可以定义一个或多个泛型参数，并指定泛型参数的取值范围，多个参数用逗号(,)分割泛型类中定义的泛型全类可用（静态方法、静态代码块、静态成员变量除外）父类定义的泛型参数子类无法继承，所以子类得自己写[java] view plain copypublic class GenericClass { T data; void setData(T t) { data = t; } T getData() { return data; }} 2）泛型方法定义泛型方法，在方法修饰符后，返回参数前加上&lt;&gt;，尖括号内可以定义一个或多个泛型参数，并指定泛型参数取值范围，多个参数用逗号(,)分割泛型方法中定义的泛型作用域在方法内[java] view plain copypublic class GenericMethodClass { public T setData(T t, S s) { //do something return t; }} 定义泛型方法，更多是为了表达返回值和方法形参间的关系，本例中方法第一个参数T继承AClass，第二个参数S继承T，返回值是第一个参数。如果仅仅是为了实现了多态，应优先使用通配符。类似如下：[java] view plain copypublic void addList(List&lt;?&gt; list) { //todo} 3、定义了多个泛型类型参数时，一定要在使用时都指定类型，否则会编译出错。 4、对泛型类的类型参数赋值包含两种方法：1）类变量或实例化：List listS;listS = new ArrayList(); 2）继承public class MyList extends ArrayList implements IMyInterface {}S是对ArrayList内部定义的泛型E的赋值。 5、对泛型方法的赋值：[java] view plain copypublic T testMethod1(T t, List list) {} public T testMethod2(List list1, List list2){} People n = null; List list1 = null;testMethod1(n, list1);//此时泛型参数T为People List list2 = null;testMethod2(list1, list2);//编译报错 三、通配符1）上述泛型赋值都是赋予泛型参数确定值，我们还可以赋予泛型参数不确定值，也就是通配符?。使用通配符?表示一个未知的类型。类似如下：List&lt;?&gt; list;存放任意的对象List&lt;? extends AClass&gt; listSubAClass; //存放AClass的子类List&lt;? extends BClass&gt; listSuperBClass; //存放BClass的父类 2）通配符通常与泛型关键字一起使用。 3）在Java集合框架中，对于未知类型的容器类，只能读取其中元素，不能添加元素。这是因为，对不确定的参数类型，编译器无法识别添加元素的类型和容器的类型是否兼容，唯一的例外是NULL。同时，其读取的元素只能用Object来存储。 4）通配符不能用在泛型类和泛型方法声明中，类似如下：[java] view plain copypublic class GenericClass&lt;?&gt; { //编译错误 public &lt;?&gt; void testGenericMethod(? t) { //编译错误 }} 四、泛型关键字1、泛型关键字有二个 extends和super，分别表示类型上界和类型下界T extends AClass 表示T继承自AClass类? super AClass 表示?是AClass的父类，注意：super只能与通配符?搭配使用，我们不能写：public class GenericClass { //错误}此例子中super换成extends是正确的，表示泛型T继承自AClass，T换成通配符?也是可以的，表示未知类型的下界是AClass。 2、通配符与泛型关键字组合使用 举两个例子：下界：[java] view plain copyList&lt;? super People&gt; list = new ArrayList&lt;&gt;();People people = new People();list.add(people);People data= list.get(0 ); //编译出错，报错Object不能转为People 上界：[java] view plain copyList&lt;? extends People&gt; list = new ArrayList&lt;&gt;();People people = new People();list.add(people);// 编译出错，不能向容器中添加确定的元素People data= list.get( 0); 总结就是：上界添加(add)受限，下界查询(get)受限 五、泛型实现原理1、Java泛型是编译时技术，在运行时不包含类型信息，仅其实例中包含类型参数的定义信息。2、Java利用编译器擦除（erasure，前端处理）实现泛型，基本上就是泛型版本源码到非泛型版本源码的转化。3、擦除去掉了所有的泛型类内所有的泛型类型信息，所有在尖括号之间的类型信息都被扔掉.举例来说：List类型被转换为List，所有对类型变量String的引用被替换成类型变量的上限(通常是Object)。而且，无论何时结果代码类型不正确，会插入一个到合适类型的转换。[java] view plain copy T badCast(T t, Object o) {return (T) o; // unchecked warning}这说明String类型参数在List运行时并不存在。它们也就不会添加任何的时间或者空间上的负担。但同时，这也意味着你不能依靠他们进行类型转换。 4、一个泛型类被其所有调用共享对于上文中的GenericClass，在编译后其内部是不存入泛型信息的，也就是说：[java] view plain copyGenericClass gclassA = new GenericClass();GenericClass gclassB = new GenericClass();gClassA.getClass() == gClassB.getClass()这个判断返回的值是true，而非false，因为一个泛型类所有实例运行时具有相同的运行时类，其实际类型参数被擦除了。 那么是不是GenericClass里完全不存AClass的信息呢？这个也不是，它内部存储的是泛型向上父类的引用，比如：GenericClass, 其编译后内部存储的泛型替代是Charsequence，而不是Object。 那么我们编码时的泛型的类型判断是怎么实现的呢？其实这个过程是编译时检查的，也就是说限制gClassA.add(new BClass()) 这样的使用的方式的主体，不是运行时代码，而是编译时监测。 泛型的意义就在于，对所有其支持的类型参数，有相同的行为，从而可以被当作不同类型使用；类的静态变量和方法在所有实例间共享使用，所以不能使用泛型。 5、泛型与instanceof泛型擦除了类型信息，所以使用instanceof检查某个实例是否是特定类型的泛型类是不可行的：GenericClass genericClass = new GenericClass();if (genericClass instanceof GenericClass) {} // 编译错误 同时：GenericClass class1 = (GenericClass) genericClass； //会报警告 六、Class与泛型（摘自网络）从Java1.5后Class类就改为了泛型实现，Class类内定义的泛型T指的是Class对象代表的类型。比如说String.class类型代表Class，People.class类型代表Class。主要用于提高反射代码的类型安全。 Class类的newInstance返回泛型T的对象，故而可以在反射时创建更精确的类型。举例来说：假定你要写一个工具方法来进行一个数据库查询，给定一个SQL语句，并返回一个数据库中符合查询条件的对象集合(collection)。一个方法是显式的传递一个工厂对象，像下面的代码：[java] view plain copyinterface Factory { public T[] make();}public Collection select(Factory factory, String statement) { Collection result = new ArrayList(); / run sql query using jdbc / for ( int i=0; i&lt;10; i++ ) { / iterate over jdbc results / T item = factory.make(); / use reflection and set all of item’s fields from sql results / result.add( item ); } return result;} 你可以这样调用：[java] view plain copyselect(new Factory() { public EmpInfo make() { return new EmpInfo(); } } , ”selection string”);也可以声明一个类 EmpInfoFactory 来支持接口 Factory：[java] view plain copyclass EmpInfoFactory implements Factory { … public EmpInfo make() { return new EmpInfo(); }}然后调用：[java] view plain copyselect(getMyEmpInfoFactory(), “selection string”); 这个解决方案的缺点是它需要下面的二者之一：调用处那冗长的匿名工厂类，或为每个要使用的类型声明一个工厂类并传递其对象给调用的地方这很不自然。使用class类型参数值是非常自然的，它可以被反射使用。没有泛型的代码可能是：[java] view plain copyCollection emps = sqlUtility.select(EmpInfo.class, ”select from emps”);…public static Collection select(Class c, String sqlStatement) { Collection result = new ArrayList(); / run sql query using jdbc / for ( / iterate over jdbc results / ) { Object item = c.newInstance(); / use reflection and set all of item’s fields from sql results */ result.add(item); } return result; }} 但是这不能给我们返回一个我们要的精确类型的集合。现在Class是泛型的，我们可以写：[java] view plain copyCollection emps=sqlUtility.select(EmpInfo.class, ”select from emps”);…public static Collection select(Classc, String sqlStatement) { Collection result = new ArrayList(); / run sql query using jdbc / for ( / iterate over jdbc results / ) { T item = c.newInstance(); / use reflection and set all of item’s fields from sql results */ result.add(item); } return result;} 籍此以类型安全的方式获取我们需要的集合。这项技术是一个非常有用的技巧，在处理注释(annotations)的新API中被广泛使用。 七、容器与泛型Java泛型的最深入人心的应用就是容器（Collections）了。容器不需要考虑它要装什么东西，它的职责就是表达它装的东西的集合所具有的功能。因此是天然的泛型支持者。在没有泛型时，如果要封装一个列表，简化应该是这样的：[java] view plain copypublic class ArrayList { Object[] array = new Object[10]; int i = 0; public void add(Object object) { array[i++] = object; } public Object get(int index) { return array[index]; } } 这意味着我们把元素存进去，取出来还要强转，类型安全无法保证（存入一个Integer再存一个Long，转出时强转成Integer就崩溃了）。用泛型可以在编译时保证不能存入非泛型支持的数据，保证类型安全。按照我们之前说的，ArrayList内不存储泛型信息，而是存储泛型的最近父类，对ArrayList而言就是Object，所以其内部代码是：[java] view plain copypublic class ArrayList { Object[] array = new Object[10]; int i = 0; public void add(T object) { array[i++] = object; } public T get(int index) { return (T)array[index]; } } 保证我们加进去和取出来的数据都是经过类型检查的。 八、总结1、泛型是Java为类型安全而做的一个优化，它在内部保证了数据类型一致性，细化了可变参数的类型，且能更好的表示类型间的相关性。2、泛型是编译时技术，其起作用的时机是编译时，完善的编译器会报告错误的泛型使用，保证代码不能编译通过。3、平常写代码时，要认真思考是否有使用泛型的必要。通常来讲，如果方法或类描述的是数据类型无关的逻辑，且其数据类型可变时，则应该使用泛型。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[influxdb用法]]></title>
    <url>%2F2018%2F03%2F07%2Finfluxdb%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言 influxdb是目前比较流行的时间序列数据库。 何谓时间序列数据库？什么是时间序列数据库，最简单的定义就是数据格式里包含Timestamp字段的数据，比如某一时间环境的温度，CPU的使用率等。但是，有什么数据不包含Timestamp呢？几乎所有的数据其实都可以打上一个Timestamp字段。时间序列数据的更重要的一个属性是如何去查询它，包括数据的过滤，计算等等。 InfluxdbInfluxdb是一个开源的分布式时序、时间和指标数据库，使用go语言编写，无需外部依赖。它有三大特性： 时序性（Time Series）：与时间相关的函数的灵活使用（诸如最大、最小、求和等）； 度量（Metrics）：对实时大量数据进行计算； 事件（Event）：支持任意的事件数据，换句话说，任意事件的数据我们都可以做操作。 同时，它有以下几大特点： schemaless(无结构)，可以是任意数量的列； min, max, sum, count, mean, median 一系列函数，方便统计； Native HTTP API, 内置http支持，使用http读写； Powerful Query Language 类似sql； Built-in Explorer 自带管理工具。 Influxdb安装 注：本文使用的influxdb version是1.0.2 在讲解具体的安装步骤之前，先说说influxdb的两个http端口：8083和8086 port 8083：管理页面端口，访问localhost:8083可以进入你本机的influxdb管理页面； port 8086：http连接influxdb client端口，一般使用该端口往本机的influxdb读写数据。 OS X 12brew updatebrew install influxdb Docker Image 1docker pull influxdb Ubuntu &amp; Debian 12wget https://dl.influxdata.com/influxdb/releases/influxdb_1.0.2_amd64.debsudo dpkg -i influxdb_1.0.2_amd64.deb RedHat &amp; CentOS 12wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.2.x86_64.rpmsudo yum localinstall influxdb-1.0.2.x86_64.rpm Standalone Linux Binaries (64-bit) 12wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.2_linux_amd64.tar.gztar xvfz influxdb-1.0.2_linux_amd64.tar.gz Standalone Linux Binaries (32-bit) 12wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.2_linux_i386.tar.gztar xvfz influxdb-1.0.2_linux_i386.tar.gz Standalone Linux Binaries (ARM) 12wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.2_linux_armhf.tar.gztar xvfz influxdb-1.0.2_linux_armhf.tar.gz How to start？安装完之后，如何启动呢？ 1sudo service influxdb start 到这里influxdb安装启动完成，可以访问influxdb管理页面：本地管理页面，该版本没有登录用户及密码，可以自行设置读写的用户名和密码。 如何在命令行使用安装完毕之后，如何在命令行使用呢？ influxdb在命令行中使用 influxdb基本操作 名词解释在具体的讲解influxdb的相关操作之前先说说influxdb的一些专有名词，这些名词代表什么。 influxdb相关名词 database：数据库； measurement：数据库中的表； points：表里面的一行数据。 influxDB中独有的一些概念Point由时间戳（time）、数据（field）和标签（tags）组成。 time：每条数据记录的时间，也是数据库自动生成的主索引； fields：各种记录的值； tags：各种有索引的属性。 还有一个重要的名词：series所有在数据库中的数据，都需要通过图表来表示，series表示这个表里面的所有的数据可以在图标上画成几条线（注：线条的个数由tags排列组合计算出来）举个简单的小栗子：有如下数据： error_time 它的series为： error_time_series influxdb基本操作 数据库与表的操作可以直接在web管理页面做操作，当然也可以命令行。 1234567891011121314#创建数据库create database "db_name"#显示所有的数据库show databases#删除数据库drop database "db_name"#使用数据库use db_name#显示该数据库中所有的表show measurements#创建表，直接在插入数据的时候指定表名insert test,host=127.0.0.1,monitor_name=test count=1#删除表drop measurement "measurement_name" 增 ​ 向数据库中插入数据。 通过命令行 12use testDbinsert test,host=127.0.0.1,monitor_name=test count=1 通过http接口 1curl -i -XPOST 'http://127.0.0.1:8086/write?db=testDb' --data-binary 'test,host=127.0.0.1,monitor_name=test count=1' 读者看到这里可能会观察到插入的数据的格式貌似比较奇怪，这是因为influxDB存储数据采用的是Line Protocol格式。那么何谓Line Protoco格式？ Line Protocol格式：写入数据库的Point的固定格式。在上面的两种插入数据的方法中都有这样的一部分： 1test,host=127.0.0.1,monitor_name=test count=1 其中： test：表名； host=127.0.0.1,monitor_name=test：tag； count=1：field 想对此格式有详细的了解参见官方文档 查 ​ 查询数据库中的数据。 通过命令行 1select * from test order by time desc 通过http接口 1curl -G 'http://localhost:8086/query?pretty=true' --data-urlencode "db=testDb" --data-urlencode "q=select * from test order by time desc" influxDB是支持类sql语句的，具体的查询语法都差不多，这里就不再做详细的赘述了。 数据保存策略（Retention Policies）influxDB是没有提供直接删除数据记录的方法，但是提供数据保存策略，主要用于指定数据保留时间，超过指定时间，就删除这部分数据。 查看当前数据库Retention Policies 1show retention policies on "db_name" retention_policies 创建新的Retention Policies 1create retention policy "rp_name" on "db_name" duration 3w replication 1 default 12345- rp_name：策略名；- db_name：具体的数据库名；- 3w：保存3周，3周之前的数据将被删除，influxdb具有各种事件参数，比如：h（小时），d（天），w（星期）；- replication 1：副本个数，一般为1就可以了；- default：设置为默认策略 修改Retention Policies 1alter retention policy "rp_name" on "db_name" duration 30d default 删除Retention Policies 1drop retention policy "rp_name" 连续查询（Continous Queries） ​ 当数据超过保存策略里指定的时间之后就会被删除，但是这时候可能并不想数据被完全删掉，怎么办？ ​ influxdb提供了联系查询，可以做数据统计采样。 查看数据库的Continous Queries 1show continuous queries continuous_queries. 创建新的Continous Queries 1create continous query cq_name on db_name begin select sum(count) into new_table_name from table_name group by time(30m) end 123456- cq_name：连续查询名字；- db_name：数据库名字；- sum(count)：计算总和；- table_name：当前表名；- new_table_name：存新的数据的表名；- 30m：时间间隔为30分钟 删除Continous Queries 1drop continous query cp_name on db_name 用户管理可以直接在web管理页面做操作，也可以命令行。 1234567#显示用户show users#创建用户create user "username" with password 'password'#创建管理员权限用户create user "username" with password 'password' with all privileges#删除用户drop user "username"]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>influxdb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型FAQ]]></title>
    <url>%2F2018%2F03%2F06%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[什么是内存模型http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html 在多核系统中，处理器一般有一层或者多层的缓存，这些的缓存通过加速数据访问（因为数据距离处理器更近）和降低共享内存在总线上的通讯（因为本地缓存能够满足许多内存操作）来提高CPU性能。缓存能够大大提升性能，但是它们也带来了许多挑战。例如，当两个CPU同时检查相同的内存地址时会发生什么？在什么样的条件下它们会看到相同的值？ 在处理器层面上，内存模型定义了一个充要条件，“让当前的处理器可以看到其他处理器写入到内存的数据”以及其他处理器可以看到当前处理器写入到内存的数据”。有些处理器有很强的内存模型(strong memory model)，能够让所有的处理器在任何时候任何指定的内存地址上都可以看到完全相同的值。而另外一些处理器则有较弱的内存模型（weaker memory model），在这种处理器中，必须使用内存屏障（一种特殊的指令）来刷新本地处理器缓存并使本地处理器缓存无效，目的是为了让当前处理器能够看到其他处理器的写操作或者让其他处理器能看到当前处理器的写操作。这些内存屏障通常在lock和unlock操作的时候完成。内存屏障在高级语言中对程序员是不可见的。 在强内存模型下，有时候编写程序可能会更容易，因为减少了对内存屏障的依赖。但是即使在一些最强的内存模型下，内存屏障仍然是必须的。设置内存屏障往往与我们的直觉并不一致。近来处理器设计的趋势更倾向于弱的内存模型，因为弱内存模型削弱了缓存一致性，所以在多处理器平台和更大容量的内存下可以实现更好的可伸缩性 “一个线程的写操作对其他线程可见”这个问题是因为编译器对代码进行重排序导致的。例如，只要代码移动不会改变程序的语义，当编译器认为程序中移动一个写操作到后面会更有效的时候，编译器就会对代码进行移动。如果编译器推迟执行一个操作，其他线程可能在这个操作执行完之前都不会看到该操作的结果，这反映了缓存的影响。 此外，写入内存的操作能够被移动到程序里更前的时候。在这种情况下，其他的线程在程序中可能看到一个比它实际发生更早的写操作。所有的这些灵活性的设计是为了通过给编译器，运行时或硬件灵活性使其能在最佳顺序的情况下来执行操作。在内存模型的限定之内，我们能够获取到更高的性能。 123456789101112Class Reordering &#123; int x = 0, y = 0; public void writer() &#123; x = 1; y = 2; &#125; public void reader() &#123; int r1 = y; int r2 = x; &#125;&#125; 让我们看在两个并发线程中执行这段代码，读取Y变量将会得到2这个值。因为这个写入比写到X变量更晚一些，程序员可能认为读取X变量将肯定会得到1。但是，写入操作可能被重排序过。如果重排序发生了，那么，就能发生对Y变量的写入操作，读取两个变量的操作紧随其后，而且写入到X这个操作能发生。程序的结果可能是r1变量的值是2，但是r2变量的值为0。 Java内存模型描述了在多线程代码中哪些行为是合法的，以及线程如何通过内存进行交互。它描述了“程序中的变量“ 和 ”从内存或者寄存器获取或存储它们的底层细节”之间的关系。Java内存模型通过使用各种各样的硬件和编译器的优化来正确实现以上事情。 Java包含了几个语言级别的关键字，包括：volatile, final以及synchronized，目的是为了帮助程序员向编译器描述一个程序的并发需求。Java内存模型定义了volatile和synchronized的行为，更重要的是保证了同步的java程序在所有的处理器架构下面都能正确的运行。 其他语言，像C++，也有内存模型吗大部分其他的语言，像C和C++，都没有被设计成直接支持多线程。这些语言对于发生在编译器和处理器平台架构的重排序行为的保护机制会严重的依赖于程序中所使用的线程库（例如pthreads），编译器，以及代码所运行的平台所提供的保障。 #JSR133是什么 从1997年以来，人们不断发现Java语言规范的17章定义的Java内存模型中的一些严重的缺陷。这些缺陷会导致一些使人迷惑的行为（例如final字段会被观察到值的改变）和破坏编译器常见的优化能力。 Java内存模型是一个雄心勃勃的计划，它是编程语言规范第一次尝试合并一个能够在各种处理器架构中为并发提供一致语义的内存模型。不过，定义一个既一致又直观的内存模型远比想象要更难。JSR133为Java语言定义了一个新的内存模型，它修复了早期内存模型中的缺陷。为了实现JSR133，final和volatile的语义需要重新定义。 完整的语义见：http://www.cs.umd.edu/users/pugh/java/memoryModel，但是正式的语义不是小心翼翼的，它是令人惊讶和清醒的，目的是让人意识到一些看似简单的概念（如同步）其实有多复杂。幸运的是，你不需要懂得这些正式语义的细节——JSR133的目的是创建一组正式语义，这些正式语义提供了volatile、synchronzied和final如何工作的直观框架。 JSR 133的目标包含了： 保留已经存在的安全保证（像类型安全）以及强化其他的安全保证。例如，变量值不能凭空创建：线程观察到的每个变量的值必须是被其他线程合理的设置的。 正确同步的程序的语义应该尽量简单和直观。 应该定义未完成或者未正确同步的程序的语义，主要是为了把潜在的安全危害降到最低。 程序员应该能够自信的推断多线程程序如何同内存进行交互的。 能够在现在许多流行的硬件架构中设计正确以及高性能的JVM实现。 应该能提供 安全地初始化的保证。如果一个对象正确的构建了（意思是它的引用没有在构建的时候逸出，那么所有能够看到这个对象的引用的线程，在不进行同步的情况下，也将能看到在构造方法中中设置的final字段的值。 应该尽量不影响现有的代码 重排序意味着什么？在很多情况下，访问一个程序变量（对象实例字段，类静态字段和数组元素）可能会使用不同的顺序执行，而不是程序语义所指定的顺序执行。编译器能够自由的以优化的名义去改变指令顺序。在特定的环境下，处理器可能会次序颠倒的执行指令。数据可能在寄存器，处理器缓冲区和主内存中以不同的次序移动，而不是按照程序指定的顺序。 例如，如果一个线程写入值到字段a，然后写入值到字段b，而且b的值不依赖于a的值，那么，处理器就能够自由的调整它们的执行顺序，而且缓冲区能够在a之前刷新b的值到主内存。有许多潜在的重排序的来源，例如编译器，JIT以及缓冲区。 编译器，运行时和硬件被期望一起协力创建好像是顺序执行的语义的假象，这意味着在单线程的程序中，程序应该是不能够观察到重排序的影响的。但是，重排序在没有正确同步了的多线程程序中开始起作用，在这些多线程程序中，一个线程能够观察到其他线程的影响，也可能检测到其他线程将会以一种不同于程序语义所规定的执行顺序来访问变量。 大部分情况下，一个线程不会关注其他线程正在做什么，但是当它需要关注的时候，这时候就需要同步了。 旧的内存模型有什么问题旧的内存模型中有几个严重的问题。这些问题很难理解，因此被广泛的违背。例如，旧的存储模型在许多情况下，不允许JVM发生各种重排序行为。旧的内存模型中让人产生困惑的因素造就了JSR-133规范的诞生。 例如，一个被广泛认可的概念就是，如果使用final字段，那么就没有必要在多个线程中使用同步来保证其他线程能够看到这个字段的值。尽管这是一个合理的假设和明显的行为，也是我们所期待的结果。实际上，在旧的内存模型中，我们想让程序正确运行起来却是不行的。在旧的内存模型中，final字段并没有同其他字段进行区别对待——这意味着同步是保证所有线程看到一个在构造方法中初始化的final字段的唯一方法。结果——如果没有正确同步的话，对一个线程来说，它可能看到一个字段的默认值，然后在稍后的时间里，又能够看到构造方法中设置的值。这意味着，一些不可变的对象，例如String，能够改变它们值——这实在很让人郁闷。 旧的内存模型允许volatile变量的写操作和非volaitle变量的读写操作一起进行重排序，这和大多数的开发人员对于volatile变量的直观感受是不一致的，因此会造成迷惑。 最后，我们将看到的是，程序员对于程序没有被正确同步的情况下将会发生什么的直观感受通常是错误的。JSR-133的目的之一就是要引起这方面的注意。 There were several serious problems with the old memory model. It was difficult to understand, and therefore widely violated. For example, the old model did not, in many cases, allow the kinds of reorderings that took place in every JVM. This confusion about the implications of the old model was what compelled the formation of JSR-133. One widely held belief, for example, was that if final fields were used, then synchronization between threads was unnecessary to guarantee another thread would see the value of the field. While this is a reasonable assumption and a sensible behavior, and indeed how we would want things to work, under the old memory model, it was simply not true. Nothing in the old memory model treated final fields differently from any other field — meaning synchronization was the only way to ensure that all threads see the value of a final field that was written by the constructor. As a result, it was possible for a thread to see the default value of the field, and then at some later time see its constructed value. This means, for example, that immutable objects like String can appear to change their value — a disturbing prospect indeed. The old memory model allowed for volatile writes to be reordered with nonvolatile reads and writes, which was not consistent with most developers intuitions about volatile and therefore caused confusion. Finally, as we shall see, programmers’ intuitions about what can occur when their programs are incorrectly synchronized are often mistaken. One of the goals of JSR-133 is to call attention to this fact. 没有正确同步的含义是什么没有正确同步的代码对于不同的人来说可能会有不同的理解。在Java内存模型这个语义环境下，我们谈到“没有正确同步”，我们的意思是： 一个线程中有一个对变量的写操作， 另外一个线程对同一个变量有读操作， 而且写操作和读操作没有通过同步来保证顺序。 当这些规则被违反的时候，我们就说在这个变量上有一个“数据竞争”(data race)。一个有数据竞争的程序就是一个没有正确同步的程序。 Incorrectly synchronized code can mean different things to different people. When we talk about incorrectly synchronized code in the context of the Java Memory Model, we mean any code where there is a write of a variable by one thread, there is a read of the same variable by another thread and the write and read are not ordered by synchronization When these rules are violated, we say we have a data race on that variable. A program with a data race is an incorrectly synchronized program. 同步会干些什么呢同步有几个方面的作用。最广为人知的就是互斥 ——一次只有一个线程能够获得一个监视器，因此，在一个监视器上面同步意味着一旦一个线程进入到监视器保护的同步块中，其他的线程都不能进入到同一个监视器保护的块中间，除非第一个线程退出了同步块。 但是同步的含义比互斥更广。同步保证了一个线程在同步块之前或者在同步块中的一个内存写入操作以可预知的方式对其他有相同监视器的线程可见。当我们退出了同步块，我们就释放了这个监视器，这个监视器有刷新缓冲区到主内存的效果，因此该线程的写入操作能够为其他线程所见。在我们进入一个同步块之前，我们需要获取监视器，监视器有使本地处理器缓存失效的功能，因此变量会从主存重新加载，于是其它线程对共享变量的修改对当前线程来说就变得可见了。 依据缓存来讨论同步，可能听起来这些观点仅仅会影响到多处理器的系统。但是，重排序效果能够在单一处理器上面很容易见到。对编译器来说，在获取之前或者释放之后移动你的代码是不可能的。当我们谈到在缓冲区上面进行的获取和释放操作，我们使用了简述的方式来描述大量可能的影响。 新的内存模型语义在内存操作（读取字段，写入字段，锁，解锁）以及其他线程的操作（start 和 join）中创建了一个部分排序，在这些操作中，一些操作被称为happen before其他操作。当一个操作在另外一个操作之前发生，第一个操作保证能够排到前面并且对第二个操作可见。这些排序的规则如下： 线程中的每个操作happens before该线程中在程序顺序上后续的每个操作。 解锁一个监视器的操作happens before随后对相同监视器进行锁的操作。 对volatile字段的写操作happens **before后续对相同volatile字段的读取操作。 线程上调用start()方法happens **before这个线程启动后的任何操作。 一个线程中所有的操作都happens before从这个线程join()方法成功返回的任何其他线程。（注意思是其他线程等待一个线程的jion()方法完成，那么，这个线程中的所有操作happens **before其他线程中的所有操作） 这意味着：任何内存操作，这个内存操作在退出一个同步块前对一个线程是可见的，对任何线程在它进入一个被相同的监视器保护的同步块后都是可见的，因为所有内存操作happens before释放监视器以及释放监视器happens before获取监视器。 其他如下模式的实现被一些人用来强迫实现一个内存屏障的，不会生效： 1synchronized (new Object()) &#123;&#125; 这段代码其实不会执行任何操作，你的编译器会把它完全移除掉，因为编译器知道没有其他的线程会使用相同的监视器进行同步。要看到其他线程的结果，你必须为一个线程建立happens before关系。 重点注意：对两个线程来说，为了正确建立happens before关系而在相同监视器上面进行同步是非常重要的。以下观点是错误的：当线程A在对象X上面同步的时候，所有东西对线程A可见，线程B在对象Y上面进行同步的时候，所有东西对线程B也是可见的。释放监视器和获取监视器必须匹配（也就是说要在相同的监视器上面完成这两个操作），否则，代码就会存在“数据竞争”。 Synchronization has several aspects. The most well-understood is mutual exclusion — only one thread can hold a monitor at once, so synchronizing on a monitor means that once one thread enters a synchronized block protected by a monitor, no other thread can enter a block protected by that monitor until the first thread exits the synchronized block. But there is more to synchronization than mutual exclusion. Synchronization ensures that memory writes by a thread before or during a synchronized block are made visible in a predictable manner to other threads which synchronize on the same monitor. After we exit a synchronized block, we release the monitor, which has the effect of flushing the cache to main memory, so that writes made by this thread can be visible to other threads. Before we can enter a synchronized block, we acquire the monitor, which has the effect of invalidating the local processor cache so that variables will be reloaded from main memory. We will then be able to see all of the writes made visible by the previous release. Discussing this in terms of caches, it may sound as if these issues only affect multiprocessor machines. However, the reordering effects can be easily seen on a single processor. It is not possible, for example, for the compiler to move your code before an acquire or after a release. When we say that acquires and releases act on caches, we are using shorthand for a number of possible effects. The new memory model semantics create a partial ordering on memory operations (read field, write field, lock, unlock) and other thread operations (start and join), where some actions are said to happen before other operations. When one action happens before another, the first is guaranteed to be ordered before and visible to the second. The rules of this ordering are as follows: Each action in a thread happens before every action in that thread that comes later in the program’s order. An unlock on a monitor happens before every subsequent lock on that same monitor. A write to a volatile field happens before every subsequent read of that same volatile. A call to start() on a thread happens before any actions in the started thread. All actions in a thread happen before any other thread successfully returns from a join()on that thread. This means that any memory operations which were visible to a thread before exiting a synchronized block are visible to any thread after it enters a synchronized block protected by the same monitor, since all the memory operations happen before the release, and the release happens before the acquire. Another implication is that the following pattern, which some people use to force a memory barrier, doesn’t work: 1synchronized (new Object()) &#123;&#125; This is actually a no-op, and your compiler can remove it entirely, because the compiler knows that no other thread will synchronize on the same monitor. You have to set up a happens-before relationship for one thread to see the results of another. Important Note: Note that it is important for both threads to synchronize on the same monitor in order to set up the happens-before relationship properly. It is not the case that everything visible to thread A when it synchronizes on object X becomes visible to thread B after it synchronizes on object Y. The release and acquire have to “match” (i.e., be performed on the same monitor) to have the right semantics. Otherwise, the code has a data race. 在新的Java内存模型中，final字段是如何工作的How can final fields appear to change their values?One of the best examples of how final fields’ values can be seen to change involves one particular implementation of the String class. A String can be implemented as an object with three fields — a character array, an offset into that array, and a length. The rationale for implementing String this way, instead of having only the character array, is that it lets multiple String and StringBufferobjects share the same character array and avoid additional object allocation and copying. So, for example, the method String.substring() can be implemented by creating a new string which shares the same character array with the original String and merely differs in the length and offset fields. For a String, these fields are all final fields. 12String s1 = "/usr/tmp";String s2 = s1.substring(4); The string s2 will have an offset of 4 and a length of 4. But, under the old model, it was possible for another thread to see the offset as having the default value of 0, and then later see the correct value of 4, it will appear as if the string “/usr” changes to “/tmp”. The original Java Memory Model allowed this behavior; several JVMs have exhibited this behavior. The new Java Memory Model makes this illegal. 一个对象的final字段值是在它的构造方法里面设置的。假设对象被正确的构造了，一旦对象被构造，在构造方法里面设置给final字段的的值在没有同步的情况下对所有其他的线程都会可见。另外，引用这些final字段的对象或数组都将会看到final字段的最新值。 对一个对象来说，被正确的构造是什么意思呢？简单来说，它意味着这个正在构造的对象的引用在构造期间没有被允许逸出。（参见安全构造技术）。换句话说，不要让其他线程在其他地方能够看见一个构造期间的对象引用。不要指派给一个静态字段，不要作为一个listener注册给其他对象等等。这些操作应该在构造方法之后完成，而不是构造方法中来完成。 1234567891011121314151617181920class FinalFieldExample &#123; final int x; int y; static FinalFieldExample f; public FinalFieldExample() &#123; x = 3; y = 4; &#125; static void writer() &#123; f = new FinalFieldExample(); &#125; static void reader() &#123; if (f != null) &#123; int i = f.x; int j = f.y; &#125; &#125;&#125; 上面的类展示了final字段应该如何使用。一个正在执行reader方法的线程保证看到f.x的值为3，因为它是final字段。它不保证看到f.y的值为4，因为f.y不是final字段。如果FinalFieldExample的构造方法像这样： 123456public FinalFieldExample() &#123; // bad! x = 3; y = 4; // bad construction - allowing this to escape global.obj = this;&#125; 那么，从global.obj中读取this的引用线程不会保证读取到的x的值为3。 能够看到字段的正确的构造值固然不错，但是，如果字段本身就是一个引用，那么，你还是希望你的代码能够看到引用所指向的这个对象（或者数组）的最新值。如果你的字段是final字段，那么这是能够保证的。因此，当一个final指针指向一个数组，你不需要担心线程能够看到引用的最新值却看不到引用所指向的数组的最新值。重复一下，这儿的“正确的”的意思是“对象构造方法结尾的最新的值”而不是“最新可用的值”。 现在，在讲了如上的这段之后，如果在一个线程构造了一个不可变对象之后（对象仅包含final字段），你希望保证这个对象被其他线程正确的查看，你仍然需要使用同步才行。例如，没有其他的方式可以保证不可变对象的引用将被第二个线程看到。使用final字段的程序应该仔细的调试，这需要深入而且仔细的理解并发在你的代码中是如何被管理的。 如果你使用JNI来改变你的final字段，这方面的行为是没有定义的。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac 中文版man安装]]></title>
    <url>%2F2018%2F03%2F05%2Fmac-%E4%B8%AD%E6%96%87%E7%89%88man%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Mac 10.13 安装中文版 man 命令本文参考于 《Mac 安装man命令中文文档》，但原文提供的链接以及安装的版本比较老旧。因此重新整理新版在这边提供给大家。 为什么需要 man 以及 man 怎么使用linux 或者 mac 系统的命令行工具非常多，可是我们不能记住所有的这些命令，通常只能记住一些我们常用的。遇到不常用的我们需要来查询一下这个命令是怎么使用的。这时候我们就需要使用到 man 命令了。 使用方法也非常简单，例如我们不清楚 ls 这个命令的使用方法，我们就可以在命令行中输入 1man ls1 来查看这个命令的详情。 但是默认情况下，输出的内容是英文的。可能很多英文不好的朋友希望有中文版本的 man ，这篇博文就是告诉大家，如何在 mac上安装中文版本的的 man。 至于 linux 系统则非常简单，查看 https://github.com/man-pages-zh/manpages-zh 中对应的版本，即可用简单的命令安装。 下载 manpages-zh 编辑安装首先，我们打开上面的 github 地址，点击 releases 下载最新版本的 tar.gz 源码包。目前我下载到的是 1.6.3.2 版本的。 因为需要编译安装，所以你电脑上需要有编译工具，运行下面两个命令安装 12brew install automakebrew install opencc12 我这边是需要安装这两个编译工具，如果你下面编译出错，会提示你需要安装说明编辑工具的。利用 brew 安装即可。 如果你电脑没有安装 brew 工具，请参考 http://blog.csdn.net/FungLeo/article/details/57567538 这篇博文安装 好，准备工作做好，我们接着来。 12345678910111213141516171819202122# 进入下载目录cd ~/Downloads/# 下载最新版本的源码包wget https://github.com/man-pages-zh/manpages-zh/archive/v1.6.3.2.tar.gz# 解压源码包(atool命令，推荐安装这个工具，统一所有压缩文档的命令）atool -x v1.6.3.2.tar.gz# 或者使用这个命令解压tar zxvf v1.6.3.2.tar.gz# 进入源码包文件夹cd manpages-zh-1.6.3.2/# 编译安装 1autoreconf --install --force# 编译安装 2./configure# 编译安装 3make# 编译安装 4sudo make install# 配置别名echo "alias cman='man -M /usr/local/share/man/zh_CN'" &gt;&gt; ~/.bash_profile# 使别名生效. ~/.bash_profile12345678910111213141516171819202122 这样，我们就安装上了中文版本的 man 工具了。我们可以使用 1cman ls1 来查看中文版本的解释了。但是由于 mac 上的 groff 工具比较老，所以中文会出现乱码。我们来解决一下这个问题。 安装 groff 新版本解决中文乱码的问题首先，我们到 http://git.savannah.gnu.org/cgit/groff.git 这个页面下载 1.22 版本的 groff 安装包。我这边用命令行下载，你如果直接复制我的命令，不能下载，请到上面的地址去看看下载地址是否发生变化。 1234567891011121314# 进入下载目录cd ~/Downloads/# 下载1.22版本的源码包wget http://git.savannah.gnu.org/cgit/groff.git/snapshot/groff-1.22.tar.gz# 解压atool -x groff-1.22.tar.gz# 进入目录cd groff-1.22# 编译安装./configuresudo makesudo make install# 添加配置sudo vim /etc/man.conf1234567891011121314 进入编辑之后，在文件末尾添加 1NROFF preconv -e UTF8 | /usr/local/bin/nroff -Tutf8 -mandoc -c1 最后 :wq 保存退出 然后，我们在输入 1cman ls1 就可以看到中文版本的命令介绍了。]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JFR使用方法]]></title>
    <url>%2F2018%2F02%2F07%2Fjmc%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[JFR使用方式按照下面三个步骤操作； 选定一台机器，登陆上去，并找到要监控的进程PID 将附件文件(*.jfc)放入到 /usr/install/java/jdk1.8.0_60/jre/lib/jfr 目录，注意，这个配置文件是在官方配置上增加了对异常数据的采集。推荐使用。 执行下列命令，其中请自行替换： 这样就好了，如上，等待2分钟＋20秒，/tmp/pid.jfr文件就生成好了，这个文件直接导入JMC工具即可 12345678jcmd &lt;pid&gt; VM.unlock_commercial_features #先解锁技能jcmd &lt;pid&gt; JFR.start name=myrec settings=tongdun delay=20s duration=2m filename=/tmp/pid.jfr#其中，delay参数表示profile延迟启动时间，duration表示持续采集时间，这里设置为2分钟#settings表示使用哪种采集配置，这里用的就是第二步中放入的tongdun.jfc配置，它默认有一个名为profile的配置，如果不想采集异常信息，也可以直接用它。#注意，采集数据生成后请执行下列命令移除这个采集jcmd &lt;pid&gt; JFR.stop name=myrec]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[jdk之线上高内存占用]]></title>
    <url>%2F2018%2F02%2F07%2Fjdk%E4%B9%8B%E7%BA%BF%E4%B8%8A%E9%AB%98%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021#找到占用内存高的java进程top#查看堆使用情况jmp -heap [pid]#查看占用内存高的对象jmp -histo:live [pid] | head -n 100#查看占用内存高的对象,dump成文件，线下分析jmap -dump:live,format=b,file=xxx.xxx [pid]#查看进程的线程情况ps p [pid] -L -o pcpu,pmem,pid,tid,time,tname,cmd#线程id打印成16进制printf "%x\n" [tid]#输出java进程堆栈到文件jstack -l [pid] &gt; jstack.log#vim 查找16进制的tid， runnable正常状态，WAITING一直等那个条件发生，TIMED_WAITING定时的那个条件不到来也将定时唤醒自己vim jstack.log jmap命令有下面几种常用的用法： •jmap [pid] •jmap -histo:live [pid] &gt;a.log •jmap -dump:live,format=b,file=xxx.xxx [pid] 用得最多是后面两个。其中，jmap -histo:live [pid] 可以查看当前Java进程创建的活跃对象数目和占用内存大小。 jmap -dump:live,format=b,file=xxx.xxx [pid] 则可以将当前Java进程的内存占用情况导出来，方便用专门的内存分析工具（例如：MAT）来分析。 这个命令对于分析是否有内存泄漏很有帮助。具体怎么使用可以查看本博的另一篇文章：利用Eclipse Memory Analyzer Tool（MAT）分析内存泄漏 首先看一下一个java进程的jmap输出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[lex@chou ~]$ jmap -heap 837Attaching to process ID 837, please wait...Debugger attached successfully.Server compiler detected.JVM version is 20.10-b01using thread-local object allocation.Parallel GC with 2 thread(s)Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 4294967296 (4096.0MB) NewSize = 1310720 (1.25MB) MaxNewSize = 17592186044415 MB OldSize = 5439488 (5.1875MB) NewRatio = 2 SurvivorRatio = 8 PermSize = 21757952 (20.75MB) MaxPermSize = 85983232 (82.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 41025536 (39.125MB) used = 18413552 (17.560531616210938MB) free = 22611984 (21.564468383789062MB) 44.883147900858624% usedFrom Space: capacity = 4325376 (4.125MB) used = 3702784 (3.53125MB) free = 622592 (0.59375MB) 85.60606060606061% usedTo Space: capacity = 4521984 (4.3125MB) used = 0 (0.0MB) free = 4521984 (4.3125MB) 0.0% usedPS Old Generation capacity = 539820032 (514.8125MB) used = 108786168 (103.74657440185547MB) free = 431033864 (411.06592559814453MB) 20.152302906758376% usedPS Perm Generation capacity = 85983232 (82.0MB) used = 60770232 (57.95500946044922MB) free = 25213000 (24.04499053955078MB) 70.67684080542588% used 然后再用ps看看： 123[lex@chou ~]$ ps -p 837 -o vsz,rss VSZ RSS7794992 3047320 关于这里的几个generation网上资料一大把就不细说了，这里算一下求和可以得知前者总共给Java环境分配了644M的内存，而ps输出的VSZ和RSS分别是7.4G和2.9G，这到底是怎么回事呢？前面jmap输出的内容里，MaxHeapSize 是在命令行上配的，-Xmx4096m，这个java程序可以用到的最大堆内存。VSZ是指已分配的线性空间大小，这个大小通常并不等于程序实际用到的内存大小，产生这个的可能性很多，比如内存映射，共享的动态库，或者向系统申请了更多的堆，都会扩展线性空间大小，要查看一个进程有哪些内存映射，可以使用 pmap 命令来查看： 12345678910111213141516[lex@chou ~]$ pmap -x 837837: javaAddress Kbytes RSS Dirty Mode Mapping0000000040000000 36 4 0 r-x-- java0000000040108000 8 8 8 rwx-- java00000000418c9000 13676 13676 13676 rwx-- [ anon ]00000006fae00000 83968 83968 83968 rwx-- [ anon ]0000000700000000 527168 451636 451636 rwx-- [ anon ]00000007202d0000 127040 0 0 ----- [ anon ]......00007f55ee124000 4 4 0 r-xs- az.png00007fff017ff000 4 4 0 r-x-- [ anon ]ffffffffff600000 4 0 0 r-x-- [ anon ]---------------- ------ ------ ------total kB 7796020 3037264 3023928 这里可以看到很多anon，这些表示这块内存是由mmap分配的。 RSZ是Resident Set Size，常驻内存大小，即进程实际占用的物理内存大小， 在现在这个例子当中，RSZ和实际堆内存占用差了2.3G，这2.3G的内存组成分别为： JVM本身需要的内存，包括其加载的第三方库以及这些库分配的内存 NIO的DirectBuffer是分配的native memory 内存映射文件，包括JVM加载的一些JAR和第三方库，以及程序内部用到的。上面 pmap 输出的内容里，有一些静态文件所占用的大小不在Java的heap里，因此作为一个Web服务器，赶紧把静态文件从这个Web服务器中人移开吧，放到nginx或者CDN里去吧。 JIT， JVM会将Class编译成native代码，这些内存也不会少，如果使用了Spring的AOP，CGLIB会生成更多的类，JIT的内存开销也会随之变大，而且Class本身JVM的GC会将其放到Perm Generation里去，很难被回收掉，面对这种情况，应该让JVM使用ConcurrentMarkSweep GC，并启用这个GC的相关参数允许将不使用的class从Perm Generation中移除， 参数配置： -XX:+UseConcMarkSweepGC -X:+CMSPermGenSweepingEnabled -X:+CMSClassUnloadingEnabled，如果不需要移除而Perm Generation空间不够，可以加大一点： -X:PermSize=256M -X:MaxPermSize=512M JNI，一些JNI接口调用的native库也会分配一些内存，如果遇到JNI库的内存泄露，可以使用valgrind等内存泄露工具来检测 线程栈，每个线程都会有自己的栈空间，如果线程一多，这个的开销就很明显了 jmap/jstack 采样，频繁的采样也会增加内存占用，如果你有服务器健康监控，记得这个频率别太高，否则健康监控变成致病监控了。 关于JVM的几个GC堆和GC的情况，可以用jstat来监控，例如监控进程837每隔1000毫秒刷新一次，输出20次： 1234[lex@chou ~]$ jstat -gcutil 837 1000 20 S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 80.43 24.62 87.44 98.29 7101 119.652 40 19.719 139.371 0.00 80.43 33.14 87.44 98.29 7101 119.652 40 19.719 139.371 几个字段分别含义如下： S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比 S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比 E 年轻代中Eden（伊甸园）已使用的占当前容量百分比 O old代已使用的占当前容量百分比 P perm代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) 结论因此如果正常情况下jmap输出的内存占用远小于 RSZ，可以不用太担心，除非发生一些严重错误，比如PermGen空间满了导致OutOfMemoryError发生，或者RSZ太高导致引起系统公愤被OOM Killer给干掉，就得注意了，该加内存加内存，没钱买内存加交换空间，或者按上面列的组成部分逐一排除。这几个内存指标之间的关系是：VSZ &gt;&gt; RSZ &gt;&gt; Java程序实际使用的堆大小 12 使用top命令查看系统资源的使用情况，命令： top 如图可以看到java的进程内存使用率较高，java进程的内存使用率达到了70%+ 2.定位线程问题（通过命令查看9718进程的线程情况），命令： ps p 9718 -L -o pcpu,pmem,pid,tid,time,tname,cmd 由此可以看到这PID：9718的进程产生了很多线程。接下来就可以通过jstack查看内存使用的堆栈。 查看内存使用的堆栈：在这里我们挑选了TID=9720的线程进行分析，首先需要将9731这个id转换为16进制。需输入如下命令， printf “%x\n” 9731 接下需要使用16进制的2603 将PID为9718的堆栈信息打印到jstack.log中，命令： jstack -l 9718 &gt; jstack.log 5. 查看堆栈信息文件，命令：vim jstack.log 在进行搜索TID为2603的相关信息。如图： 可以看到这个线程状态为：WAITING。通过查看文件分析 看到大量 Java Thread State。 说明它在等待另一个条件的发生，来把自己唤醒，或者干脆它是调用了 sleep(N)。 此时线程状态大致为以下几种： java.lang.Thread.State: WAITING (parking)：一直等那个条件发生； java.lang.Thread.State: TIMED_WAITING (parking或sleeping)：定时的，那个条件不到来，也将定时唤醒自己。 6.代码优化：将文件发送给开发。优化下线程]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes之使用minikube本地部署]]></title>
    <url>%2F2018%2F01%2F30%2Fkubernetes%E4%B9%8B%E4%BD%BF%E7%94%A8minikube%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[目录 kubernetes 介绍 环境、软件准备 kubectl 安装 minikube 安装 部署运行实例 1、kubernetes 介绍 Kubernetes 是 Google 开源的容器集群管理系统，它构建在目前流行的 Docker 技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等一整套功能。而就在日前 DockerCon 欧洲大会上， Docker 宣布拥抱支持 Kubernetes，Docker 公司计划提供一个无缝平台，同时支持包含 Swarm 和 Kubernetes 集群的异构部署。minikube 是一个使我们很容易在本地运行 kubernetes 的工具，他是通过在本机 VM 里运行一个单节点集群，大大方便学习和使用 kubernetes。 2、环境、软件准备 本次演示环境，我是在本机 MAC OS 以及虚拟机 Linux Centos7 上操作，以下是安装的软件及版本： Docker: version 17.09.0-ce Oracle VirtualBox: version 5.1.20 r114628 (Qt5.6.2) Minikube: version v0.22.2 Kuberctl: Client Version: v1.8.1 Server Version: v1.7.5 注意：Minikube 启动的单节点 k8s Node 实例是需要运行在本机的 VM 虚拟机里面，所以需要提前安装好 VM，这里我选择 Oracle VirtualBox。k8s 运行底层使用 Docker 容器，所以本机需要安装好 Docker 环境，这里忽略 Docker、VirtualBox 的安装过程，着重介绍下 Minikube 和 Kuberctl 的安装。 3、 kubectl 安装 kubectl 是 Kubernetes 的命令行工具，我们可以使用该工具查看集群资源，创建、更新、删除各个组件等等，同时提供了非常详细的使用文档，非常方便，那我们在本机 Mac 上安装一下。 安装方式有两种： 一、通过 curl 安装 12345678910111、安装最新版curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/darwin/amd64/kubectl# 安装指定版本，例如 v1.8.0curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.8.0/bin/darwin/amd64/kubectl2、赋二进制文件执行权限chmod +x ./kubectl3、将二进制文件移到 PATH 中sudo mv ./kubectl /usr/local/bin/kubectl1234567891011 二、通过 Homebrew 安装 1brew install kubectl1 安装完毕后，执行 kubectl version 查看版本以及是否安装成功。我们可以通过 kubectl help 查看说明文档。 4、minikube 安装 minikube 是一个使我们很容易在本地运行 kubernetes 的工具，他是通过在本机 VM 里运行一个单节点 kubernetes 集群，这对于新手想了解和学习 kubernetes 提供了很大的帮助。所以在安装 minikube 之前我们需要在本机先安装 VM，这里我选择 VirtualBox 忽略安装过程，以下是可选 VM 列表： OS X: xhyve driver, VirtualBox, VMware Fusion. Linux: VirtualBox, KVM Windows: VirtualBox, Hyper-V minikube 的安装也很简单。 1、curl 方式安装 12345OSX 系统：curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.22.3/minikube-darwin-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/Linux 系统：curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.22.3/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/12345 2、若上边地址被墙了，可以去 GitHub 上下载安装包，在执行。 下载最新版安装包，各系统对应地址如下： minikube-darwin-amd64 minikube-linux-amd64 minikube-installer.exe 然后执行 chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/，即可完成安装。安装完毕后，执行 minikube version 查看版本以及是否安装成功。我们可以通过 minikube help 查看说明文档。 5、部署运行实例 好了，环境我们已经安装完毕，现在来演示运行一个实例，这里我已 tomcat 镜像为例，演示部署服务，发布服务，扩容缩容服务等操作。 123456789101112131415161718192021222324252627282930313233341、创建并启动 minikube 虚拟机$ minikube startStarting local Kubernetes cluster...Running pre-create checks...Creating machine...Starting local Kubernetes cluster...2、创建 hello-minikube 部署$ kubectl run hello-minikube --image=tomcat:8.0 --port=8080deployment "hello-minikube" created3、发布服务 hello-minikube$ kubectl expose deployment hello-minikube --type=NodePortservice "hello-minikube" exposed4、查看 pods$ kubectl get podsNAME READY STATUS RESTARTS AGEhello-minikube-598805112-3bzmf 1/1 ContainerCreating 0 5s注意：刚开始时，pod 没有完全创建好的时候，状态是 ContainerCreating，当部署完成后，状态就变成 Running。$ kubectl get podsNAME READY STATUS RESTARTS AGEhello-minikube-598805112-3bzmf 1/1 Running 0 25s5、获取服务地址$ minikube service hello-minikube --urlhttp://192.168.99.102:30724$ minikube service hello-minikube 将直接打开地址到默认浏览器上。6、停止 minikube 虚拟机$ minikube stopStopping local Kubernetes cluster...Stopping "minikube"...12345678910111213141516171819202122232425262728293031323334 注意：在部署过程中可能会出现问题，大部分跟网络相关，下载 images 时会超时报错，解决办法是一安装翻墙工具，二是替代需要翻墙下载的 images。以下是我本机实验遇到的问题，以及解决方法。 问题一：命令行下载 tomcat:8.0 镜像，执行 docker pull tomcat:8.0 没有任何反应，初步分析可能是 minikube 虚拟机里没有连接到本地 docker 服务。 12345$ minikube docker-envexport DOCKER_TLS_VERIFY="1"export DOCKER_HOST="tcp://192.168.99.102:2376"export DOCKER_CERT_PATH="/Users/wanyang3/.minikube/certs"export DOCKER_API_VERSION="1.23"12345 执行 eval $(minikube docker-env)，即设置 minikube 虚拟机的 docker 环境变量即可。 问题二：执行完毕上边 2 和 3 步骤后，发现 hello-minikube 服务并没有成功启动。 123$ kubectl get podsNAME READY STATUS RESTARTS AGEhello-minikube-598805112-3bzmf 0/1 ContainerCreating 0 15s123 发现 hello-minikube 的状态一直是 ContainerCreating，并且 READY 为 0/1，通过 minikube logs 查看日志可以看出，有一个镜像 gcr.io/google_containers/pause-amd64:3.0 显示拉取失败，分析原因应该是 gcr.io 这个地址被墙了。 123456# 替换镜像$ docker pull visenzek8s/pause-amd64:3.0$ docker tag visenzek8s/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0# 显式设置拉取策略为 IfNotPresent$ kubectl run hello-minikube --image=tomcat:8.0 --port=8080 --image-pull-policy=IfNotPresent 123456 方案就是替换该镜像，然后可以设置拉取策略为优先本地获取，本地没有再去远程获取。因为这里服务启动策略为 always，会定时自动重新拉取，所以一旦本地拉取该镜像后，我们会发现上边 hello-minikube 一会就启动成功了。 下边介绍一下 kubectl 一些其他常用操作。 1、创建资源的两种方式 1.1 通过 Yaml 或 Json 文件创建 12$ kubectl create -f &lt;file_path&gt;/xxx.yaml | &lt;file_path&gt;/xxx.json --[options]eg：kubectl create -f ./redis.yaml12 简单的 redis.yaml 示例： 123456789101112131415161718192021222324252627282930313233apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: hello-redis namespace: my-kubespec: replicas: 2 template: metadata: labels: group: hello-scm my-kube: hello-redis k8s-app: redis spec: containers: - name: redis image: redis:latest---apiVersion: v1kind: Servicemetadata: labels: group: hello-scm kubernetes.io/cluster-service: 'true' kubernetes.io/name: hello-redis name: hello-redis namespace: my-kubespec: ports: - port: 6379 targetPort: 6379 selector: k8s-app: redis123456789101112131415161718192021222324252627282930313233 yaml 文件要符合 kubernetes 的规范，可以参考官网对 yaml 语法定义，可以自学一下，这里就不展开来说了。 1.2 指定镜像启动 12$ kubectl run --image=xxxx:xx --[options]eg: kubectl run hello-minikube --image=tomcat:8.0 --port=8080 12 2、复制多个部署 pod 12345678910$ kubectl scale --replicas=3 deployment/hello-minikubedeployment "hello-minikube" scaled$ kubectl get podsNAME READY STATUS RESTARTS AGEhello-minikube-598805112-3bzmf 1/1 Running 1 1dhello-minikube-598805112-vrskz 1/1 Running 1 1dhello-minikube-598805112-xwq55 1/1 Running 1 1d也可以在启动时，指定复制数量$ kubectl run hello-minikube --image=tomcat:8.0 --port=8080 --replicas=312345678910 3、暴露 pod (po), service (svc), replicationcontroller (rc), deployment (deploy), replicaset (rs) 成新的服务 123456789$ kubectl expose po | svc | rc | delpoy | rs --[options]eg：kubectl expose deployment hello-minikube --type=NodePort # 暴露名称为 hello-minikube 部署为类型为 NodePort 的服务eg：kubectl expose rc hello-nginx --port=80 --target-port=8000 --type=NodePort # 暴漏名称为 nginx 的副本为指定服务端口80，连接该服务端口8000，类型为 NodePort 的服务$ kubectl get serviceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEhello-minikube NodePort 10.0.0.176 &lt;none&gt; 8080:30724/TCP 1dhello-nginx NodePort 10.0.0.94 &lt;none&gt; 80:8000/TCP 1dkubernetes ClusterIP 10.0.0.1 &lt;none&gt; 443/TCP 1d123456789 4、重新加载某个资源 12$ kubectl apply -f &lt;file_path&gt;/xxx.yaml | &lt;file_path&gt;/xxx.json --[options]eg：kubectl apply -f ./redis.yaml12 5、查看 pod, service, replicationcontroller, deployment, replicaset 各种类型资源信息列表 12$ kubectl get po | svc | rc | deploy | rs # 查看默认 namespace 下各类型资源信息列表$ kubectl get po | svc | rc | deploy | rs --all-namespaces # 查看所有 namespace 下各类型资源信息列表12 6、查看 pod, service, replicationcontroller, deployment, replicaset 各种类型资源日志信息或描述信息 12345678$ kubectl logs &lt;resource_type&gt;/&lt;resource_name&gt; [options]eg：kubectl logs -f po/hello-minikube-598805112-3bzmf # 查看指定 pod 的日志eg：kubectl logs deploy/hello-nginx -n my-kube # 查看指定 delpoy 和 namespace 的日志$ kubectl describe &lt;resource_type&gt;/&lt;resource_name&gt; [options]eg：kubectl describe pods # 查看所有 pod 的描述信息eg：kubectl describe po/hello-minikube-598805112-3bzmf # 查看指定 pod 的描述信息eg：kubectl describe deploy/hello-nginx -n my-kube # 查看指定 delpoy 和 namespace 的描述信息12345678 7、查看集群信息 12$ kubectl cluster-infoKubernetes master is running at https://192.168.99.102:844312 好了，先介绍这么多，下一篇继续介绍下通过 minikube 安装 Kubernetes Dashboard 并集成 Heapster 插件。 参考资料 Running Kubernetes Locally via Minikube Install Minikube Install and Set Up kubectl github minikube]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kubernates docker 常用命令]]></title>
    <url>%2F2018%2F01%2F27%2Fkubernates-docker-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[minikube命令1234#启动虚拟机minikube startminikube stop k8s命令123456789101112131415161718192021222324252627282930kubectl podkubectl get podkubectl get pod XXX &gt; aavim aakubectl get pod hello-minikube-5df766f774-ws8fk -o yamlkubectl edit pod hello-minikube-5df766f774-ws8fkkubectl describe pod XXX //结合pod和eventkubectl get eventkubectl get serviceskubectl get services hello-minikube -o yamlkubectl get rskubectl describe rskubectl config rename-context mini minikube2kubectl create -f ./**.yaml -f ***.yamlwget https://.../k8s.tar.gzexample guestbooksudo docker imagesfront-images 换成nginx 12345678910111213141516171819202122232425262728293031323334353637383940414243444546471 api service 、2etcd 步 create_timestamp3 schedule -&gt; api service6 启动docker1. 3 node 1node down load balancer -&gt; api server 分发到另外两台 etcd2. scheduler/CM 死的node主，需要选举3. kubelet sysmtem 进程死掉自动拉起vimdiff aa bbkubectl get rskubectl get deployment##扩容或缩容kubectl scale --replicas=2 deployment/frontendsudo docker run XXXkubectl get pod --all-name-spacekubectl logs xxx##寻取帮助kubectl logs -h## busybox终端kubectl run -i --tty busyboxkubectl attach XXX -ikubectl top podkubectl delete deployment XXXkubectl delete pod XXX用于查错skubectl cluster-info dump --out-directory=tmp k8s 安装docker https://docs.docker.com/install/linux/docker-ce/ubuntu/ 从github上下载minikube二进制 https://github.com/kubernetes/minikube/releases 墙内安装kubectl https://www.kubernetes.org.cn/installkubectl 123bin dpkg-deb -x kubelet.deb tmpcd tmpcp ./usr/bin/kubectl /usr/local/bin 启动minikube，绕过gcr.io下无法下载镜像的问题  观察日志/var/lib/localkube/*.err  docker pull kubernetes/pause  docker pull grrywlsn/kubernetes-addon-manager:v1.8.0 Kubectl、Kubeadm国内下载地址： https://mirrors.ustc.edu.cn/kubernetes/apt/pool/ 安装和设置kubectl https://www.kubernetes.org.cn/installkubectl # Kubectl 客户端的下载和配置http://blog.csdn.net/csdn_duomaomao/article/details/76159874 dockerquick start https://docs.docker.com/docker-for-mac/#explore-the-application-and-run-examples 1234567891011121314docker infodocker versiondocker psdocker imagesdocker run hello-worlddocker run -d -p 80:80 --name webserver nginxdocker stop webserverdocker start webserverdocker ps -a#删除容器 stop and remove the running containerdocker rm -f webserver#删除镜像docker rmi nginx Some good commands to try are docker version to check that you have the latest release installed, and docker ps and docker run hello-world to verify that Docker is running. docker 中文镜像安装环境：Apple macOS Sierra 10.12.3安装步骤：1. 下载Docker for Mac。官方下载链接：https://download.docker.com/mac/stable/Docker.dmg 2. 安装Docker for Mac并启动。3. 检查版本信息。1$ docker --version1 4. 配置阿里云Docker镜像加速器。Docker在国内下载镜像的速度太慢，经常失败，所以使用阿里云提供的容器镜像仓库服务。如果不愿意配置镜像，直接进入https://dev.aliyun.com/search.html中寻找镜像使用。 接下来介绍阿里云Docker镜像加速器，使用加速器将会提升您在国内获取Docker官方镜像的速度！ 进入阿里云容器Hub服务的控制台，并申请成为开发者。 点击左侧的加速器帮助页面就会显示您的专属加速器地址。 复制地址您的专属加速器地址，将地址填入Docker的配置中，路径如下：Preferences–&gt;Daemon–&gt;Basic–&gt;Registry mirrors，然后重启。 分享两个自己的加速器地址：https://7r4uvc15.mirror.aliyuncs.comhttp://5ae05a04.m.daocloud.io 7. 确认Docker是否安装成功。1$ sudo docker run hello-world1 这个命令会下载一个测试用的镜像并启动一个容器运行它。 quick start###docker container 12345678910111213141516docker build -t friendlyhello . # Create image using this directory's Dockerfiledocker run -p 4000:80 friendlyhello # Run "friendlyname" mapping port 4000 to 80docker run -d -p 4000:80 friendlyhello # Same thing, but in detached modedocker container ls # List all running containersdocker container ls -a # List all containers, even those not runningdocker container stop &lt;hash&gt; # Gracefully stop the specified containerdocker container kill &lt;hash&gt; # Force shutdown of the specified containerdocker container rm &lt;hash&gt; # Remove specified container from this machinedocker container rm $(docker container ls -a -q) # Remove all containersdocker image ls -a # List all images on this machinedocker image rm &lt;image id&gt; # Remove specified image from this machinedocker image rm $(docker image ls -a -q) # Remove all images from this machinedocker login # Log in this CLI session using your Docker credentialsdocker tag &lt;image&gt; username/repository:tag # Tag &lt;image&gt; for upload to registrydocker push username/repository:tag # Upload tagged image to registrydocker run username/repository:tag # Run image from a registry ###docker service 12345678docker stack ls # List stacks or appsdocker stack deploy -c &lt;composefile&gt; &lt;appname&gt; # Run the specified Compose filedocker service ls # List running services associated with an appdocker service ps &lt;service&gt; # List tasks associated with an appdocker inspect &lt;task or container&gt; # Inspect task or containerdocker container ls -q # List container IDsdocker stack rm &lt;appname&gt; # Tear down an applicationdocker swarm leave --force # Take down a single node swarm from the manager 需要https://api.github.com/repos/boot2docker/boot2docker/releases/latest 下载，”html_url”: “https://github.com/boot2docker/boot2docker/releases/tag/v17.07.0-ce“ ###swarm集群 1234567891011121314151617181920212223242526272829docker-machine create --virtualbox-boot2docker-url ~/.docker/machine/cache/boot2docker.iso manager1mv boot2docker.iso /Users/zhouxiaowu/.docker/machine/cache/docker-machine create --virtualbox-boot2docker-url ~/.docker/machine/cache/boot2docker.iso myvm1docker-machine create --virtualbox-boot2docker-url ~/.docker/machine/cache/boot2docker.iso myvm210513 docker-machine ssh myvm1 "docker swarm init --advertise-addr 192.168.99.101"10514 docker-machine ls10515 docker-machine ssh myvm2 " docker swarm join --token SWMTKN-1-13x2fyyubrz6b0k0p86bpt0rjydu59ze8a7g4q6n4yn1aip7so-96zlikwtz3h7mmpa18ilu0i6g 192.168.99.101:2377"10516 docker-machine ssh myvm1 "docker node ls"10520 docker-machine env myvm110521 eval $(docker-machine env myvm1)10526 docker stack deploy -c docker-compose.yml getstartedlab10527 docker stack ls10529 docker stack ps getstartedlab10530 docker container ls10569 docker stack ls10570 docker stack rm getstartedlab10571 docker-machine env -u10572 eval $(docker-machine env -u) 笔记1234567891011find namelsoflsof -p 2951viewulimit -n 1000cd var/logminikube logs &gt;aavim aakubectl get pods --all-namespaces]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mybatis中#和$的区别]]></title>
    <url>%2F2018%2F01%2F15%2Fmybatis%E4%B8%AD-%E5%92%8C-%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[今天在工作中有个点击排序的功能调试了许久，终寻因，总结之。 需求是这样的，页面有个table，有一列的上下箭头可点击并排序。对于这种需求，我的mybatis.xml的sql配置写成了如下： ORDER BY columnName #{map.ColumnNameSort} ColumnNameSort即前端传的排序方式，asc或者desc。 然后，预计它的输出应该是类似于下面这样的 ORDER BY columnName desc 但是，真正跑起来时，排序的效果一直没出现，经常一番查找，发现是mybatis 的’#{}’传值的问题，它将sql语句编译成了如下 ORDER BY columnName ‘desc’ 或者 ORDER BY columnName ‘asc’ 这样，desc或者asc就成了字符串而不是关键字，sql语句的意思是columnName的别名是desc或者asc，没加排序关键字时默认是正序排序，成了如下 ORDER BY columnName “desc” asc 或者 ORDER BY columnName “asc” asc 排序没效果的问题找到原因了，解决之，mybatis提供了另一种绑定参数的方式–${param}，将sql配置改为 ORDER BY columnName ${map.ColumnNameSort} 这样一来，mybatis会直接将ColumnNameSort的值加入sql中，不会转义。正确结果： ORDER BY columnName desc 最后，对于mybatis中#和$绑定参数的区别做个总结，避免以后类似的问题发生。 ＃{}将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。如：order by #{id}，如果传入的值是111,那么解析成sql时的值为order by “111”, 如果传入的值是id，则解析成的sql为order by “id”。 ${}将传入的数据直接显示生成在sql中。如：order by ${id}，如果传入的值是111,那么解析成sql时的值为order by 111, 如果传入的值是id，则解析成的sql为order by id。 ‘#’方式 能够很大程度防止sql注入。 $方式无法防止Sql注入。 $方式一般用于传入数据库对象，例如传入表名. 一般能用#的就别用$. ps:在使用mybatis中还遇到&lt;![CDATA[]]&gt;的用法，在该符号内的语句，将不会被当成字符串来处理，而是直接当成sql语句，比如要执行一个存储过程。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql update使用子查询]]></title>
    <url>%2F2018%2F01%2F11%2FMysql-update%E4%BD%BF%E7%94%A8%E5%AD%90%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[今天我像以前操作Oracle写了一个update sql: 12update device_user a set a.scene_id=nullwhere a.id not in(select min(t.id) from device_user t group by t.device_id);12 根据子查询的结果，更新表中的一个字段。 在mysql数据库中执行后报错： 12Error Code: 1093. You can't specify target table 'a' for update in FROM clause12 一直没弄明白这个错误，然后经过多次度娘后，发现mysql update时，更新的表不能在set和where中用于子查询。 修改上面的sql为mysql数据库支持的方式： 1234update device_user du,(select id from device_user where id not in(select min(t.id) from device_user t group by t.device_id)) bset du.scene_id=nullwhere du.id=b.id;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM堆内存和非堆内存]]></title>
    <url>%2F2018%2F01%2F02%2FJVM%E5%A0%86%E5%86%85%E5%AD%98%E5%92%8C%E9%9D%9E%E5%A0%86%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[堆和非堆内存 按照官方的说法：“Java 虚拟机具有一个堆(Heap)，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。 JVM主要管理两种类型的内存：堆和非堆。 Heap memory Code Cache Eden Space Survivor Space Tenured Gen non-heap memory Perm Gen native heap?(I guess) 堆内存 Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。对象的堆内存由称为垃圾回收器的自动内存管理系统回收。 堆的大小可以固定，也可以扩大和缩小。堆的内存不需要是连续空间。 非堆内存 Java 虚拟机管理堆之外的内存（称为非堆内存）。 Java 虚拟机具有一个由所有线程共享的方法区。方法区属于非堆内存。它存储每个类结构，如运行时常数池、字段和方法数据，以及方法和构造方法的代码。它是在 Java 虚拟机启动时创建的。 方法区在逻辑上属于堆，但 Java 虚拟机实现可以选择不对其进行回收或压缩。与堆类似，方法区的大小可以固定，也可以扩大和缩小。方法区的内存不需要是连续空间。 除了方法区外，Java 虚拟机实现可能需要用于内部处理或优化的内存，这种内存也是非堆内存。例如，JIT 编译器需要内存来存储从 Java 虚拟机代码转换而来的本机代码，从而获得高性能。 几个基本概念 PermGen space：全称是Permanent Generation space，即永久代。就是说是永久保存的区域,用于存放Class和Meta信息，Class在被Load的时候被放入该区域，GC(Garbage Collection)应该不会对PermGen space进行清理，所以如果你的APP会LOAD很多CLASS的话，就很可能出现PermGen space错误。 Heap space：存放Instance。 Java Heap分为3个区，Young即新生代，Old即老生代和Permanent。 Young保存刚实例化的对象。当该区被填满时，GC会将对象移到Old区。Permanent区则负责保存反射对象。 堆内存分配 JVM初始分配的堆内存由-Xms指定，默认是物理内存的1/64； JVM最大分配的堆内存由-Xmx指定，默认是物理内存的1/4。 默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制； 空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。 因此服务器一般设置-Xms、-Xmx 相等以避免在每次GC 后调整堆的大小。 说明：如果-Xmx 不指定或者指定偏小，应用可能会导致java.lang.OutOfMemory错误，此错误来自JVM，不是Throwable的，无法用try…catch捕捉。 非堆内存分配 \1. JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64； \2. 由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。 还有一说：MaxPermSize缺省值和-server -client选项相关，-server选项下默认MaxPermSize为64m，-client选项下默认MaxPermSize为32m。这个我没有实验。 \3. XX:MaxPermSize设置过小会导致java.lang.OutOfMemoryError: PermGen space 就是内存益出。 \4. 为什么会内存益出： 这一部分内存用于存放Class和Meta的信息，Class在被 Load的时候被放入PermGen space区域，它和存放Instance的Heap区域不同。 GC(Garbage Collection)不会在主程序运行期对PermGen space进行清理，所以如果你的APP会LOAD很多CLASS 的话,就很可能出现PermGen space错误。 \5. 这种错误常见在web服务器对JSP进行pre compile的时候。 JVM内存限制(最大值) \1. 首先JVM内存限制于实际的最大物理内存，假设物理内存无限大的话，JVM内存的最大值跟操作系统有很大的关系。简单的说就32位处理器虽然可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G，Linux系统下为2G-3G），而64bit以上的处理器就不会有限制了。 \2. 为什么有的机器我将-Xmx和-XX:MaxPermSize都设置为512M之后Eclipse可以启动，而有些机器无法启动？ 通过上面对JVM内存管理的介绍我们已经了解到JVM内存包含两种：堆内存和非堆内存，另外JVM最大内存首先取决于实际的物理内存和操作系统。所以说设置VM参数导致程序无法启动主要有以下几种原因： 参数中-Xms的值大于-Xmx，或者-XX:PermSize的值大于-XX:MaxPermSize； -Xmx的值和-XX:MaxPermSize的总和超过了JVM内存的最大限制，比如当前操作系统最大内存限制，或者实际的物理内存等等。说到实际物理内存这里需要说明一点的是，如果你的内存是1024MB，但实际系统中用到的并不可能是1024MB，因为有一部分被硬件占用了。 \3. 如果你有一个双核的CPU，也许可以尝试这个参数: -XX:+UseParallelGC 让GC可以更快的执行。（只是JDK 5里对GC新增加的参数） \4. 如果你的WEB APP下都用了大量的第三方jar，其大小超过了服务器jvm默认的大小，那么就会产生内存益出问题了。解决方法： 设置MaxPermSize大小。 增加服务器启动的JVM参数设置： -Xms128m -Xmx256m -XX:PermSize=128M -XX:MaxNewSize=256m -XX:MaxPermSize=256m 如tomcat，修改TOMCAT_HOME/bin/catalina.sh，在echo “Using CATALINA_BASE: $CATALINA_BASE”上面加入以下行：JAVA_OPTS=”-server -XX:PermSize=64M -XX:MaxPermSize=128m \5. 建议：将相同的第三方jar文件移置到tomcat/shared/lib目录下，这样可以减少jar 文档重复占用内存 JVM内存设置参数 内存设置参数 说明： 如果-Xmx不指定或者指定偏小，应用可能会导致java.lang.OutOfMemory错误，此错误来自JVM不是Throwable的，无法用try…catch捕捉。 PermSize和MaxPermSize指明虚拟机为java永久生成对象（Permanate generation）如，class对象、方法对象这些可反射（reflective）对象分配内存限制，这些内存不包括在Heap（堆内存）区之中。 -XX:MaxPermSize分配过小会导致：java.lang.OutOfMemoryError: PermGen space。 MaxPermSize缺省值和-server -client选项相关：-server选项下默认MaxPermSize为64m、-client选项下默认MaxPermSize为32m。 申请一块内存的过程 JVM会试图为相关Java对象在Eden中初始化一块内存区域 当Eden空间足够时，内存申请结束。否则到下一步 JVM试图释放在Eden中所有不活跃的对象（这属于1或更高级的垃圾回收）；释放后若Eden空间仍然不足以放入新对象，则试图将部分Eden中活跃对象放入Survivor区/OLD区 Survivor区被用来作为Eden及OLD的中间交换区域，当OLD区空间足够时，Survivor区的对象会被移到Old区，否则会被保留在Survivor区 当OLD区空间不够时，JVM会在OLD区进行完全的垃圾收集（0级） 完全垃圾收集后，若Survivor及OLD区仍然无法存放从Eden复制过来的部分对象，导致JVM无法在Eden区为新对象创建内存区域，则出现”out of memory错误” resin服务器典型的响应时间优先型的jvm配置： -Xmx2000M -Xms2000M -Xmn500M -XX:PermSize=250M -XX:MaxPermSize=250M -Xss256K -XX:+DisableExplicitGC -XX:SurvivorRatio=1 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:+CMSClassUnloadingEnabled -XX:LargePageSizeInBytes=128M -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=60 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+PrintClassHistogram -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -Xloggc:log/gc.log 内存回收算法 Java中有四种不同的回收算法，对应的启动参数为: –XX:+UseSerialGC –XX:+UseParallelGC –XX:+UseParallelOldGC –XX:+UseConcMarkSweepGC Serial Collector 大部分平台或者强制 java -client 默认会使用这种。 young generation算法 = serial old generation算法 = serial (mark-sweep-compact) 这种方法的缺点很明显, stop-the-world, 速度慢。服务器应用不推荐使用。 Parallel Collector 在linux x64上默认是这种，其他平台要加 java -server 参数才会默认选用这种。 young = parallel，多个thread同时copy old = mark-sweep-compact = 1 优点：新生代回收更快。因为系统大部分时间做的gc都是新生代的，这样提高了throughput(cpu用于非gc时间) 缺点：当运行在8G/16G server上old generation live object太多时候pause time过长 Parallel Compact Collector (ParallelOld) young = parallel = 2 old = parallel，分成多个独立的单元，如果单元中live object少则回收，多则跳过 优点：old old generation上性能较 parallel 方式有提高 缺点：大部分server系统old generation内存占用会达到60%-80%, 没有那么多理想的单元live object很少方便迅速回收，同时compact方面开销比起parallel并没明显减少。 Concurrent Mark-Sweep(CMS) Collector young generation = parallel collector = 2 old = cms 同时不做 compact 操作。 优点：pause time会降低, pause敏感但CPU有空闲的场景需要建议使用策略4. 缺点：cpu占用过多，cpu密集型服务器不适合。另外碎片太多，每个object的存储都要通过链表连续跳n个地方，空间浪费问题也会增大。 内存监控方法 jmap -heap 查看java 堆（heap）使用情况 jmap -heap pid using thread-local object allocation. Parallel GC with 4 thread(s) #GC 方式 Heap Configuration: #堆内存初始化配置 MinHeapFreeRatio=40 #对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio=70 #对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize=512.0MB #对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1.0MB #对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize =4095MB #对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 4.0MB #对应jvm启动参数-XX:OldSize=:设置JVM堆的‘老生代’的大小 NewRatio = 8 #对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 #对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize= 16.0MB #对应jvm启动参数-XX:PermSize=:设置JVM堆的‘永生代’的初始大小 MaxPermSize=64.0MB #对应jvm启动参数-XX:MaxPermSize=:设置JVM堆的‘永生代’的最大大小 Heap Usage: #堆内存分步 PS Young Generation Eden Space: #Eden区内存分布 capacity = 20381696 (19.4375MB) #Eden区总容量 used = 20370032 (19.426376342773438MB) #Eden区已使用 free = 11664 (0.0111236572265625MB) #Eden区剩余容量 99.94277218147106% used #Eden区使用比率 From Space: #其中一个Survivor区的内存分布 capacity = 8519680 (8.125MB) used = 32768 (0.03125MB) free = 8486912 (8.09375MB) 0.38461538461538464% used To Space: #另一个Survivor区的内存分布 capacity = 9306112 (8.875MB) used = 0 (0.0MB) free = 9306112 (8.875MB) 0.0% used PS Old Generation #当前的Old区内存分布 capacity = 366280704 (349.3125MB) used = 322179848 (307.25464630126953MB) free = 44100856 (42.05785369873047MB) 87.95982001825573% used PS Perm Generation #当前的 “永生代” 内存分布 capacity = 32243712 (30.75MB) used = 28918584 (27.57891082763672MB) free = 3325128 (3.1710891723632812MB) 89.68751488662348% used JVM内存监控工具 &lt;%@ page import=”java.lang.management.*” %&gt; &lt;%@ page import=”java.util.*” %&gt; JVM Memory Monitor​ Memory MXBean​ Heap Memory Usage&lt;%=ManagementFactory.getMemoryMXBean().getHeapMemoryUsage()%&gt;​ Non-Heap Memory Usage&lt;%=ManagementFactory.getMemoryMXBean().getNonHeapMemoryUsage()%&gt;​ ​ Memory Pool MXBeans&lt;%​ Iterator iter = ManagementFactory.getMemoryPoolMXBeans().iterator();​ while (iter.hasNext()) {​ MemoryPoolMXBean item = (MemoryPoolMXBean) iter.next();%&gt;​ ​ &lt;%= item.getName() %&gt;​ Type&lt;%= item.getType() %&gt;​ Usage&lt;%= item.getUsage() %&gt;​ Peak Usage&lt;%= item.getPeakUsage() %&gt;​ Collection Usage&lt;%= item.getCollectionUsage() %&gt;​ &lt;%} %&gt;]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL select子查询引用变量]]></title>
    <url>%2F2017%2F12%2F28%2FMySQL-select%E5%AD%90%E6%9F%A5%E8%AF%A2%E5%BC%95%E7%94%A8%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[示例一前几天看别人的代码中看到在字段中使用select子查询的方法，第一次见这种写法，然后研究了一下，记录下来 大概的形式是这样的: 1select a .*,(select b.another_field from b where a.id=b.aid) another_field from a where 1 limit 10; 下面还是以实例来说明，要不然不好理解，新建两张表，一张是商品表，另外一张是商品的评论表 商品表： 123456CREATE TABLE `product` ( `id` int(11) NOT NULL AUTO_INCREMENT, `product_name` varchar(30) CHARACTER SET utf8 NOT NULL, `price` float NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB; 评论表： 1234567CREATE TABLE `comment` ( `id` int(11) NOT NULL AUTO_INCREMENT, `entity_id` int(11) NOT NULL, `content` varchar(100) CHARACTER SET utf8 NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB; 然后插入一些数据： 123456789INSERT INTO `product` (`id`, `product_name`, `price`) VALUES(1, '肉松饼', 5),(2, '可乐', 5),(3, '鸡翅', 12),(4, '杯子', 42);INSERT INTO `comment` (`id`, `entity_id`, `content`) VALUES(1, 1, '味道还不错'),(2, 1, '还行啊'),(3, 3, '很实用哦'); 下面我们用子查询的方式来查出商品的信息以及每个商品的评论数量 1SELECT product.*,(select count(comment.id) from comment where product.id=comment.entity_id) comment_count FROM `product` limit 5; 查询结果如下： id product_name price comment_count 1 肉松饼 5 2 2 可乐 5 0 3 鸡翅 12 1 4 杯子 42 0 对于这种查询，可以分成两部来理解，首先忽略整个select子查询，查出商品表中的数据，然后根据商品的id执行子查询，对于一个商品id,子查询只能返回一条数据，如果子查询返回多条数据则会出错，另外，每一条select子查询只能查询一个字段。 另外的列子，查出每个商品信息以及商品的最新评论内容： 1SELECT product.*,(select comment.content from comment where product.id=comment.entity_id order by comment.id desc limit 1) comment_count FROM `product` limit 5; 查询结果如下： id product_name price last_comment 1 肉松饼 5 还行啊 2 可乐 5 NULL 3 鸡翅 12 很实用哦 4 杯子 42 NULL 示例二 billing分两步看， 不看字查询bi.id not in () , 相当于查询出所有的status为1的id，和记录 SELECT substring_index(group_concat(id ORDER BY product_start_time desc) , ‘,’ , 1)​ FROM cash_billing_item​ WHERE status = 1​ GROUP BY product_no, customer_no SELECT SUBSTRING_INDEX(‘15,151,152,16’,’,’,1); ==&gt;得到结果为： 15 然后每一条记录的bi.product_no 和bi.customer_no，分别和select的结果比较 123456789101112131415161718192021222324252627SELECT bi.idFROM cash_billing_item biWHERE bi.id and bi.status = 1 and bi.id not in ( SELECT substring_index(group_concat(id ORDER BY product_start_time desc) , ',' , 1) FROM cash_billing_item WHERE product_no = bi.product_no AND customer_no = bi.customer_no and status = 1 GROUP BY product_no, customer_no ); UPDATE cash_billing_item bi, ( SELECT bi.id FROM cash_billing_item bi WHERE bi.id and bi.status = 1 and bi.id not in ( SELECT group_concat(id ORDER BY product_start_time desc) FROM cash_billing_item WHERE product_no = bi.product_no AND customer_no = bi.customer_no and status = 1 GROUP BY product_no, customer_no ) ) temp SET bi.status = 2 WHERE bi.id = temp.id; cash_billing_item_copy 123456789101112131415161718192021222324252627282930313233343536373839404142create table cash_billing_item_copy( id bigint(11) unsigned auto_increment comment '自增id' primary key, customer_no varchar(64) null comment '客户编号', product_id int not null comment '产品表pk', product_start_time timestamp null comment '产品生效时间', gmt_create timestamp default CURRENT_TIMESTAMP not null comment '创建时间', gmt_modify timestamp default CURRENT_TIMESTAMP not null comment '修改时间') comment '从账务系统推来的计费项';INSERT INTO cash_billing_item_copy (customer_no, product_id, product_start_time) VALUES ('ct2',1,'2017-12-27 00:00:00');SELECT * FROM cash_billing_item_copy;SELECT group_concat(id ORDER BY product_start_time DESC), customer_no , product_idFROM cash_billing_item_copyGROUP BY customer_no , product_id;SELECT c.id FROM cash_billing_item_copy cWHERE c.id AND c.id NOT IN ( SELECT substring_index(group_concat(id ORDER BY product_start_time DESC), ',', 1) FROM cash_billing_item_copy GROUP BY customer_no, product_id );SELECT SUBSTRING_INDEX('15,151,152,16',',',1);]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React生命周期]]></title>
    <url>%2F2017%2F12%2F27%2FReact%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[前言学习React，生命周期很重要，我们了解完生命周期的各个组件，对写高性能组件会有很大的帮助. Ract生命周期React 生命周期分为三种状态 1. 初始化 2.更新 3.销毁 初始化 1、getDefaultProps() 设置默认的props，也可以用dufaultProps设置组件的默认属性. 2、getInitialState() 在使用es6的class语法时是没有这个钩子函数的，可以直接在constructor中定义this.state。此时可以访问this.props 3、componentWillMount() 组件初始化时只调用，以后组件更新不调用，整个生命周期只调用一次，此时可以修改state。 4、 render() react最重要的步骤，创建虚拟dom，进行diff算法，更新dom树都在此进行。此时就不能更改state了。 5、componentDidMount() 组件渲染之后调用，只调用一次。 更新 6、componentWillReceiveProps(nextProps) 组件初始化时不调用，组件接受新的props时调用。 7、shouldComponentUpdate(nextProps, nextState) react性能优化非常重要的一环。组件接受新的state或者props时调用，我们可以设置在此对比前后两个props和state是否相同，如果相同则返回false阻止更新，因为相同的属性状态一定会生成相同的dom树，这样就不需要创造新的dom树和旧的dom树进行diff算法对比，节省大量性能，尤其是在dom结构复杂的时候 8、componentWillUpdata(nextProps, nextState) 组件初始化时不调用，只有在组件将要更新时才调用，此时可以修改state 9、render() 组件渲染 10、componentDidUpdate() 组件初始化时不调用，组件更新完成后调用，此时可以获取dom节点。 卸载 11、componentWillUnmount() 组件将要卸载时调用，一些事件监听和定时器需要在此时清除。 结束语以上就是React 的生命周期，大家可以自行写下code测试一下，在这里我就不贴code 了。 下面所写的，只适合前端的React。（React也支持后端渲染，而且和前端有点小区别，不过我没用过。） 相关函数简单地说，React Component通过其定义的几个函数来控制组件在生命周期的各个阶段的动作。 在ES6中，一个React组件是用一个class来表示的（具体可以参考官方文档），如下： 1234// 定义一个TodoList的React组件，通过继承React.Component来实现class TodoList extends React.Component &#123; ...&#125; 这几个生命周期相关的函数有： 1constructor(props, context) 构造函数，在创建组件的时候调用一次。 1void componentWillMount() 在组件挂载之前调用一次。如果在这个函数里面调用setState，本次的render函数可以看到更新后的state，并且只渲染一次。 1void componentDidMount() 在组件挂载之后调用一次。这个时候，子主键也都挂载好了，可以在这里使用refs。 1void componentWillReceiveProps(nextProps) props是父组件传递给子组件的。父组件发生render的时候子组件就会调用componentWillReceiveProps（不管props有没有更新，也不管父子组件之间有没有数据交换）。 1bool shouldComponentUpdate(nextProps, nextState) 组件挂载之后，每次调用setState后都会调用shouldComponentUpdate判断是否需要重新渲染组件。默认返回true，需要重新render。在比较复杂的应用里，有一些数据的改变并不影响界面展示，可以在这里做判断，优化渲染效率。 1void componentWillUpdate(nextProps, nextState) shouldComponentUpdate返回true或者调用forceUpdate之后，componentWillUpdate会被调用。 1void componentDidUpdate() 除了首次render之后调用componentDidMount，其它render结束之后都是调用componentDidUpdate。 componentWillMount、componentDidMount和componentWillUpdate、componentDidUpdate可以对应起来。区别在于，前者只有在挂载的时候会被调用；而后者在以后的每次更新渲染之后都会被调用。 1ReactElement render() render是一个React组件所必不可少的核心函数（上面的其它函数都不是必须的）。记住，不要在render里面修改state。 1void componentWillUnmount() 组件被卸载的时候调用。一般在componentDidMount里面注册的事件需要在这里删除。 更新方式在react中，触发render的有4条路径。 以下假设shouldComponentUpdate都是按照默认返回true的方式。 首次渲染Initial Render 调用this.setState （并不是一次setState会触发一次render，React可能会合并操作，再一次性进行render） 父组件发生更新（一般就是props发生改变，但是就算props没有改变或者父子组件之间没有数据交换也会触发render） 调用this.forceUpdate 下面是我对React组件四条更新路径地总结： React组件更新路径.png 注意，如果在shouldComponentUpdate里面返回false可以提前退出更新路径。 一个React组件生命周期的测试例子代码比较简单，没有逻辑，只是在每个相关函数里面alert一下。点击链接来试试这个例子。源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112class LifeCycle extends React.Component &#123; constructor(props) &#123; super(props); alert("Initial render"); alert("constructor"); this.state = &#123;str: "hello"&#125;; &#125; componentWillMount() &#123; alert("componentWillMount"); &#125; componentDidMount() &#123; alert("componentDidMount"); &#125; componentWillReceiveProps(nextProps) &#123; alert("componentWillReceiveProps"); &#125; shouldComponentUpdate() &#123; alert("shouldComponentUpdate"); return true; // 记得要返回true &#125; componentWillUpdate() &#123; alert("componentWillUpdate"); &#125; componentDidUpdate() &#123; alert("componentDidUpdate"); &#125; componentWillUnmount() &#123; alert("componentWillUnmount"); &#125; setTheState() &#123; let s = "hello"; if (this.state.str === s) &#123; s = "HELLO"; &#125; this.setState(&#123; str: s &#125;); &#125; forceItUpdate() &#123; this.forceUpdate(); &#125; render() &#123; alert("render"); return( &lt;div&gt; &lt;span&gt;&#123;"Props:"&#125;&lt;h2&gt;&#123;parseInt(this.props.num)&#125;&lt;/h2&gt;&lt;/span&gt; &lt;br /&gt; &lt;span&gt;&#123;"State:"&#125;&lt;h2&gt;&#123;this.state.str&#125;&lt;/h2&gt;&lt;/span&gt; &lt;/div&gt; ); &#125;&#125;class Container extends React.Component &#123; constructor(props) &#123; super(props); this.state = &#123; num: Math.random() * 100 &#125;; &#125; propsChange() &#123; this.setState(&#123; num: Math.random() * 100 &#125;); &#125; setLifeCycleState() &#123; this.refs.rLifeCycle.setTheState(); &#125; forceLifeCycleUpdate() &#123; this.refs.rLifeCycle.forceItUpdate(); &#125; unmountLifeCycle() &#123; // 这里卸载父组件也会导致卸载子组件 React.unmountComponentAtNode(document.getElementById("container")); &#125; parentForceUpdate() &#123; this.forceUpdate(); &#125; render() &#123; return ( &lt;div&gt; &lt;a href="javascript:;" className="weui_btn weui_btn_primary" onClick=&#123;this.propsChange.bind(this)&#125;&gt;propsChange&lt;/a&gt; &lt;a href="javascript:;" className="weui_btn weui_btn_primary" onClick=&#123;this.setLifeCycleState.bind(this)&#125;&gt;setState&lt;/a&gt; &lt;a href="javascript:;" className="weui_btn weui_btn_primary" onClick=&#123;this.forceLifeCycleUpdate.bind(this)&#125;&gt;forceUpdate&lt;/a&gt; &lt;a href="javascript:;" className="weui_btn weui_btn_primary" onClick=&#123;this.unmountLifeCycle.bind(this)&#125;&gt;unmount&lt;/a&gt; &lt;a href="javascript:;" className="weui_btn weui_btn_primary" onClick=&#123;this.parentForceUpdate.bind(this)&#125;&gt;parentForceUpdateWithoutChange&lt;/a&gt; &lt;LifeCycle ref="rLifeCycle" num=&#123;this.state.num&#125;&gt;&lt;/LifeCycle&gt; &lt;/div&gt; ); &#125;&#125;ReactDom.render( &lt;Container&gt;&lt;/Container&gt;, document.getElementById('container'));]]></content>
      <categories>
        <category>前端</category>
        <category>react</category>
      </categories>
      <tags>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端指南-react快速开发]]></title>
    <url>%2F2017%2F12%2F23%2F%E5%89%8D%E7%AB%AF%E6%8C%87%E5%8D%97-react%E5%BF%AB%E9%80%9F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[React项目开发通过 npm 使用 React如果你的系统还不支持 Node.js 及 NPM 可以参考我们的 Node.js 教程。 我们建议在 React 中使用 CommonJS 模块系统，比如 browserify 或 webpack，本教程使用 webpack。 国内使用 npm 速度很慢，你可以使用淘宝定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm: 12$ npm install -g cnpm --registry=https://registry.npm.taobao.org$ npm config set registry https://registry.npm.taobao.org 这样就可以使用 cnpm 命令来安装模块了： 1$ cnpm install [name] 更多信息可以查阅：http://npm.taobao.org/。 使用 create-react-app 快速构建 React 开发环境create-react-app 是来自于 Facebook，通过该命令我们无需配置就能快速构建 React 开发环境。 create-react-app 自动创建的项目是基于 Webpack + ES6 。 执行以下命令创建项目： 12345678$ cnpm install -g create-react-app$ create-react-app my-app$ cd my-app/$ npm startyarn startyarn build 1234567891011121314151617 yarn start Starts the development server. yarn build Bundles the app into static files for production. yarn test Starts the test runner. yarn eject Removes this tool and copies build dependencies, configuration files and scripts into the app directory. If you do this, you can’t go back!We suggest that you begin by typing: cd billing-monitor-web yarn start 使用yarn构建前端1234563425 npm install yarn -g //全局安装yarn,不在package.json文件3426 ls3427 yarn add serve -g //全局安装serve,有个服务容器3428 lsysq3429 yarn start //启动项目yarn build 构建前端 node项目开发##进入工程目录 1cd $&#123;project_path&#125; ##从git中获取最新代码 12git pullgit checkout $&#123;tag_name&#125; ##运行npm install 1npm install 查看pm2进程id1pm2 list 停止原服务 1pm2 delete $&#123;pm2_ID&#125; 启动服务 切换NODE_VERSION 1nvm use $&#123;node_version&#125; 启动服务 1NODE_ENV=$&#123;env&#125; pm2 start $&#123;main_script&#125; 检查服务运行情况 12pm2 list #查看当前所有运行服务pm2 logs $&#123;pm2_ID&#125; #查看某服务的日志 123456$&#123;project_path&#125;: ~/lss_core$&#123;tag_name&#125;: release-20160705-GATEWAY-40$&#123;pm2_ID&#125;: // Get by pm2 list$&#123;node_version&#125;: 0.10.44$&#123;env&#125;: prod // dev | test | uat | prod$&#123;main_script&#125;: lss-core.js 123npm install xxx —savepm2 logs 39pm2 list]]></content>
      <categories>
        <category>前端</category>
        <category>react</category>
      </categories>
      <tags>
        <tag>前端指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux探究-硬连接与符号连接]]></title>
    <url>%2F2017%2F12%2F20%2FLinux%E6%8E%A2%E7%A9%B6-%E7%A1%AC%E8%BF%9E%E6%8E%A5%E4%B8%8E%E7%AC%A6%E5%8F%B7%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[创建硬连接1234mkdit aa.txtvim aa.txtln aa.txt aa-hard 注意无论修改aa.txt aa-hard中的任何一个，内容都会同时变化。 删除其中任何一个，另一个还会存在。 12345# 查看当前目录的字节数du -sb# 查看iNode会指向同一个ls -i 创建符号连接Symbolic1ln -s aa.txt aa-symbolic 注意符号连接如果指向目录，会直接对原目录的内容操作，增删改，要小心。 ###]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat解惑 之 CATALINA_HOME与CATALINA_BASE]]></title>
    <url>%2F2017%2F12%2F19%2FTomcat%E8%A7%A3%E6%83%91-%E4%B9%8B-CATALINA-HOME%E4%B8%8ECATALINA-BASE%2F</url>
    <content type="text"><![CDATA[看Tomcat源码一段时间一直很好奇为什么有CATALINA_HOME和CATALINA_BASE区别： 分CATALINA_HOME和CATALINA_BASE概念是为了解决这样的场景： 你需要在一台机器上面部署多个Tomcat实例，但是你又不想创建多个Tomcat的副本，换句话说就是让这些Tomcat副本拥有自己的工作目录但是共享Tomcat的代码。 关于CATALINA_HOME和CATALINA_BASE官方文档上面是这样解释的： [html] view plain copy Throughout the docs, you’ll notice there are numerous references to $CATALINA_HOME. This represents the root of your Tomcat installation. When we say, “This information can be found in your $CATALINA_HOME/README.txt file” we mean to look at the README.txt file at the root of your Tomcat install. Optionally, Tomcat may be configured for multiple instances by defining $CATALINA_BASE for each instance. If multiple instances are not configured, $CATALINA_BASE is the same as $CATALINA_HOME. 翻译过来就是CATALINA_HOME是Tomcat的安装目录，CATALINA_BASE是Tomcat的工作目录 CATALINA_BASE是和每个Tomcat实例相关的，接下来我们来一起玩一下上面描述的那个场景 描述:CATALINA_HOME是Tomcat的安装目录，CATALINA_BASE是Tomcat的工作目录作用:通过多工作目录(CATALINA_BASE),单安装目录(CATALINA_HOME). 可实现每个应用共用一个tomcat但不入侵安装目录,可以分别配置. 先下一个Tomcat的zip发布版本可以在这里下载：http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.69/bin/ 解压到F盘，然后新建两个目录 分别为tomcat ins1和tomcat ins2 把Tomcat的共享文件夹分别拷贝到tomcat ins1和tomcat ins2中，有 然后在 然后在tomcat ins1的文件夹下创建startup.bat 文件内容如下： [plain] view plain copy set “CATALINA_BASE=%cd%” set “CATALINA_HOME=F:\apache-tomcat-7.0.69” set “EXECUTABLE=%CATALINA_HOME%\bin\catalina.bat”4.5. call “%EXECUTABLE%” start 然后我们可以在tomcat ins1下的conf中的server.xml中修改http端口号分别为7070 tomcat ins2的做法和tomcat ins1一样只不过端口号改为9090 分别双击startup.bat 然后访问Tomcat你会看到：]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精细化JVM应用性能剖析工具]]></title>
    <url>%2F2017%2F12%2F19%2F%E7%B2%BE%E7%BB%86%E5%8C%96JVM%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E5%89%96%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[何为精细化？长期以来各个业务线开发饱受性能问题的困扰。 从反馈和观察来看，我们面临下面一系列的问题： 不清楚应用的运行情况，包括但不限于GC情况、热点代码、线程、异常（特别是被吞没的异常）； 不清楚应用代码执行情况，甚至不知道某个模块是否还可能会运行，尤其是对于有着一定历史的应用，可能已经有很多开发在上面贡献过代码，但随着业务发展这些功能可能已经不再被使用； 不清楚应用的IO情况，注意，这里说的绝对不仅仅是zabbix上的”磁盘IO”，而是具体到某个文件、某个端口、某个线程的IO情况； 这些问题导致的直接后果就是：对于性能优化，无从下手，只能凭经验和直觉去猜测、埋点、优化，当然，最终结果一般就是“加机器扩容”。 是时候结束这种粗放野蛮的性能分析调优了！ 值得高兴的是现在所有的JDK7以上版本已经内置了一款新型的性能剖析工具，也就是今天要重点介绍的－Java Flight Recorder，简称JFR。 JFR究竟是什么？Java Flight Recorder（JFR）本来是一个商业特性，用在生产服务器上是需要商业许可（这其实是废话，因为现在不需要许可也可以直接用）。 JFR 记录了关于 Java 运行时及运行在其内的 Java 应用程序的详细信息，记录用少量的开销完成。数据是作为时间上的数据点（称为事件）记录的。典型的事件可以是线程等待锁、GC、CPU 周期使用数据等。 在创建飞行记录时，你可以选择哪些事件应当保存，这叫做记录模板。有些模板只保存基本事件，对性能几乎没有影响。其他模板可能有轻微的性能开销，还可能触发 GC 来收集更多信息。通常，超过百分之几的开销是很罕见。飞行记录可用于调试很大范围的问题，从性能问题到内存泄漏或严重的锁竞争。 注意，JFR是一个性能数据采集工具，它把最终采集到的数据存在一个格式为jfr的文件中，由于本身并不具备数据分析或者可视化功能，所以一般我们需要配合JDK另外一个内置工具，即JMC一起使用。 JMC又是什么？它是在 JAVA 7u40 发布中加入的图形化性能监控工具，它可以直接打开由jfr生成的原始数据采集文件， 请在自己机器的命令行输入 jmc 来体验。 相比其它Profile工具有什么优点？在开发环境中，我们用VisualVM、JProfiler等，功能强大，支持图形化界面操作，可以很快定位代码问题。 但是他们对应用性能的影响也非常大，所以不适合在生产环境下使用。还有这些软件要attach到jvm进程上，生产环境一般网络隔离，很难做到。 在生产环境我们最常用的profiling工具就是java/bin下的jstack，多做几次jstack，也相当于profiling了。 jstack方便易用，但并不是特别适合来做profiling，操作频率低，会导致safepoint指标急剧增长等等。 重点来了，使用jfr不需要在现有应用上额外添加任何参数、重启进程等，直接在命令行执行即可，实时生效，100%无入侵，且稳定可靠，不影响线上应用运行。 安全性如何？由于这个工具可以直接在线上使用，那么它会有安全性问题吗？会造成客户数据泄露吗？ 答案是否定的，因为jfr采集的性能数据其实可以看作是JVM本身的元数据而不是业务数据，因此不存在任何安全性问题，可以放心使用。 使用方式看了以上这么多理（废）论（话）相信各位已经跃跃欲试，那么，JFR该如何使用？很简单，按照下面三个步骤操作； 选定一台机器，登陆上去，并找到要监控的进程PID 将附件文件(tongdun.jfc)放入到 /usr/install/java/jdk1.8.0_60/jre/lib/jfr 目录，注意，这个配置文件是在官方配置上增加了对异常数据的采集。推荐使用。 执行下列命令，其中请自行替换： 这样就好了，如上，等待2分钟＋20秒，/tmp/pid.jfr文件就生成好了，这个文件直接导入JMC工具即可 JMC信息]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[intelliJ 远程调试]]></title>
    <url>%2F2017%2F12%2F18%2FintelliJ-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[查看address为9996 1ps -ef | grep java | grep address 1admin 3052 1 19 19:02 ? 00:02:10 /usr/install/jdk1.8.0_60/bin/java -Djava.util.logging.config.file=/home/admin/billing/deploy/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms2g -Xmx2g -XX:PermSize=512m -XX:SurvivorRatio=2 -XX:+UseParallelOldGC -Dtrace.flag=true -Dtrace.output.dir=/home/admin/billing/deploy/trace/ -server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=9996,server=y,suspend=n -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8 -DdisableIntlRMIStatTask=true -Ddubbo.application.logger=slf4j -Djdk.tls.ephemeralDHKeySize=2048 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=10.57.19.253 -Djava.endorsed.dirs=/usr/install/tomcat/endorsed -classpath /usr/install/tomcat/bin/bootstrap.jar:/usr/install/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/home/admin/billing/deploy/tomcat -Dcatalina.home=/usr/install/tomcat -Djava.io.tmpdir=/home/admin/billing/deploy/tomcat/temp org.apache.catalina.startup.Bootstrap start 查看当前进程远程成功 1netstat -an | grep 9996 1tcp 0 0 10.57.19.253:9996 10.57.241.56:62655 ESTABLISHED]]></content>
      <categories>
        <category>线上故障排查</category>
      </categories>
      <tags>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2017%2F12%2F13%2Fvi-vim%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[vi状态执行命令1:! echo $JAVA_HOME 光标移动单词移动向后移动单词1w 向前移动单词1b 移动到行首10 移动到行尾 1$ 删除单行删除 删至行首1d0 删至行尾1d$ 删除当前行 1dd 多行删除 ndd 删除以当前行开始的n行 13dd 多行删除，删除1到10行 1: 1,10d 从当前行删除到倒数最后一行 1: .,$-1d 从某行开始至文本末尾全部删除，删除第8行至末尾 1: 8，$d 删除全部 1代表开始第一行，$标识结束行，d删除命令 1: 1,$d 查找位置 跳到首行 1gg 跳到尾一行 1GG 跳转到文本的第12行 1212gg / 12G:12 查找 向下查找 1/text 向上查找 1?text n重复上一次的查找命令 shift n 反向重复上一次的查找命令 文本中想查看当前行信息，可输入： ctrl + g]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>vi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[guava集合api学习]]></title>
    <url>%2F2017%2F11%2F30%2Fguava%E9%9B%86%E5%90%88api%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[1，大纲 让我们来熟悉瓜娃，并体验下它的一些API,分成如下几个部分： Introduction Guava Collection API Guava Basic Utilities IO API Cache API 2，为神马选择瓜娃？ 瓜娃是java API蛋糕上的冰激凌（精华） 高效设计良好的API. 被google的开发者设计，实现和使用。 遵循高效的java这本书的好的语法实践。 使代码更刻度，简洁，简单。 使用java 1.5的特性， 流行的API，动态的开发 它提供了大量相关的应用类，集合，多线程，比较，字符串，输入输出，缓存，网络，原生类型，数学，反射等等 百分百的单元测试，被很多的项目使用，帮助开发者专注业务逻辑而不是写java应用类 节省时间，资源，提高生产力 我的目的是为基本的java特征提供开源代码的支持，而不是自己再写一个 Apache Common库-Apache是一个很好的成熟的库，但是不支持泛型，Apache对早起的java版本很有用，（1.5之前的） java7，java8 最新的java支持一些guava的API guava最新的正式版本是14.0-rc2，这个版本需要java1.6支持. 最新的maven坐标是： com.google.guavaguava14.0-rc2 3,集合API的使用 3.1简化工作 可以简化集合的创建和初始化； 类别 原来的写法 guava的写法 集合创建 Map]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>guava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper详解]]></title>
    <url>%2F2017%2F11%2F26%2Fzookeeper%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[start123bin/zkServer.sh start$ bin/zkCli.sh -server 127.0.0.1:2181 zk client 操作stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port 伪集群搭建参考：http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html 集群配置： 1、配置文件conf/zoo.cfg，除了单机模式的配置之外，还需要新加server.x信息，如下所示。 12345678tickTime=2000dataDir=D:\09tmp\zookeeper\dataclientPort=2181initLimit=5syncLimit=2server.1=zoo1:2888:3888server.2=zoo2:2888:3888server.3=zoo3:2888:3888 ​ zoox表示的是zookeeper服务器的IP地址，第一个端口2888：在zookeeper服务器之间及和leader连接时使用，第二个端口号：3888是在进行leader选举时使用。 2、同时需要在配置项dataDir所指示目录下创建文件myid文件，其内容为该1中server.x中的x，表示该zookeeper服务器的编号。 3、为了降低更新的延迟，需要为事物日志的存放专门指定存储路径，该配置项为：dataLogDir 12345678910111213# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=D:\\09tmp\\zookeeper\\datadataLogDir=D:\\09tmp\\zookeeper\\log 伪集群配置： 1、由于所有zookeeper服务器都在一台物理机器上，因此zoo1.cfg中配置项server.x的端口信息，不能相同。且配置项dataDir和dataLogDir也需要为伪服务器单独指定。配置项clientPort在三个服务器中也要配置不同的值，示例如下： 123456789tickTime=2000dataDir=D:\09tmp\zookeeper\data\\1dataLogDir=D:\09tmp\zookeeper\log\\1clientPort=2181initLimit=5syncLimit=2server.1=localhost:2888:3888server.2=localhost:2889:3889server.3=localhost:2890:3890 2、同时需要准备zoo2.cfg和zoo3.cfg配置文件，参考1进行配置 3、在D:\09tmp\zookeeper\data\1、D:\09tmp\zookeeper\data\2和D:\09tmp\zookeeper\data\3中分别创建文件myid，里面填写对应的zookeeper服务器编号。 4、创建三个文件：zkEnv1.cmd、zkEnv2.cmd和zkEnv3.cmd分别用来指定使用不同的zoo.cfg。 5、创建三个文件：zkServer1.cmd、zkServer2.cmd和zkServer3.cmd分别用来指定不同的文件zkEnv.cmd。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mockito浅谈]]></title>
    <url>%2F2017%2F11%2F25%2FMockito%E6%B5%85%E8%B0%88%2F</url>
    <content type="text"><![CDATA[Mockito简介 什么是mock？在软件开发的世界之外, “mock”一词是指模仿或者效仿。 因此可以将“mock”理解为一个替身，替代者. 在软件开发中提及”mock”，通常理解为模拟对象或者Fake。 为什么需要Mock?Mock是为了解决units之间由于耦合而难于被测试的问题。所以mock object是unit test的一部分。 Mock的好处是什么? 提前创建测试，TDD（测试驱动开发） 这是个最大的好处吧。如果你创建了一个Mock那么你就可以在service接口创建之前写Service Tests了，这样你就能在开发过程中把测试添加到你的自动化测试环境中了。换句话说，模拟使你能够使用测试驱动开发。 团队可以并行工作 这类似于上面的那点；为不存在的代码创建测试。但前面讲的是开发人员编写测试程序，这里说的是测试团队来创建。当还没有任何东西要测的时候测试团队如何来创建测试呢？模拟并针对模拟测试！这意味着当service借口需要测试时，实际上QA团队已经有了一套完整的测试组件；没有出现一个团队等待另一个团队完成的情况。这使得模拟的效益型尤为突出了。 你可以创建一个验证或者演示程序。 由于Mocks非常高效，Mocks可以用来创建一个概念证明，作为一个示意图，或者作为一个你正考虑构建项目的演示程序。这为你决定项目接下来是否要进行提供了有力的基础，但最重要的还是提供了实际的设计决策。 为无法访问的资源编写测试 这个好处不属于实际效益的一种，而是作为一个必要时的“救生圈”。有没有遇到这样的情况？当你想要测试一个service接口，但service需要经过防火墙访问，防火墙不能为你打开或者你需要认证才能访问。遇到这样情况时，你可以在你能访问的地方使用MockService替代，这就是一个“救生圈”功能。 Mock 可以交给用户 在有些情况下，某种原因你需要允许一些外部来源访问你的测试系统，像合作伙伴或者客户。这些原因导致别人也可以访问你的敏感信息，而你或许只是想允许访问部分测试环境。在这种情况下，如何向合作伙伴或者客户提供一个测试系统来开发或者做测试呢？最简单的就是提供一个mock，无论是来自于你的网络或者客户的网络。soapUI mock非常容易配置，他可以运行在soapUI或者作为一个war包发布到你的java服务器里面。 隔离系统 有时，你希望在没有系统其他部分的影响下测试系统单独的一部分。由于其他系统部分会给测试数据造成干扰，影响根据数据收集得到的测试结论。使用mock你可以移除掉除了需要测试部分的系统依赖的模拟。当隔离这些mocks后，mocks就变得非常简单可靠，快速可预见。这为你提供了一个移除了随机行为，有重复模式并且可以监控特殊系统的测试环境。 Mockito使用示例模拟对象1234// 模拟LinkedList 的一个对象LinkedList mockedList = mock(LinkedList.class);// 此时调用get方法，会返回null，因为还没有对方法调用的返回值做模拟System.out.println(mockedList.get(0)); 模拟方法调用的返回值1234// 模拟获取第一个元素时，返回字符串first。 给特定的方法调用返回固定值在官方说法中称为stub。when(mockedList.get(0)).thenReturn("first");// 此时打印输出firstSystem.out.println(mockedList.get(0)); 模拟方法调用抛出异常1234// 模拟获取第二个元素时，抛出RuntimeExceptionwhen(mockedList.get(1)).thenThrow(new RuntimeException());// 此时将会抛出RuntimeExceptionSystem.out.println(mockedList.get(1)); 如果一个函数没有返回值类型，那么可以使用此方法模拟异常抛出 12doThrow(new RuntimeException("clear exception")).when(mockedList).clear();mockedList.clear(); 模拟调用方法时的参数匹配1234// anyInt()匹配任何int参数，这意味着参数为任意值，其返回值均是elementwhen(mockedList.get(anyInt())).thenReturn("element");// 此时打印是elementSystem.out.println(mockedList.get(999)); 模拟方法调用次数12345// 调用add一次mockedList.add("once");// 下面两个写法验证效果一样，均验证add方法是否被调用了一次verify(mockedList).add("once");verify(mockedList, times(1)).add("once"); 校验行为12345678// mock creationList mockedList = mock(List.class);// using mock objectmockedList.add("one");mockedList.clear();//verificationverify(mockedList).add("one");verify(mockedList).clear(); 模拟方法调用(Stubbing)12345678910111213//You can mock concrete classes, not just interfacesLinkedList mockedList = mock(LinkedList.class);//stubbingwhen(mockedList.get(0)).thenReturn("first");when(mockedList.get(1)).thenThrow(new RuntimeException());//following prints "first"System.out.println(mockedList.get(0));//following throws runtime exceptionSystem.out.println(mockedList.get(1));//following prints "null" because get(999) was not stubbedSystem.out.println(mockedList.get(999));verify(mockedList).get(0); 参数匹配12345678910//stubbing using built-in anyInt() argument matcherwhen(mockedList.get(anyInt())).thenReturn("element");//stubbing using custom matcher (let's say isValid() returns your own matcher implementation):when(mockedList.contains(argThat(isValid()))).thenReturn("element");//following prints "element"System.out.println(mockedList.get(999));//you can also verify using an argument matcherverify(mockedList).get(anyInt());//argument matchers can also be written as Java 8 Lambdasverify(mockedList).add(someString -&gt; someString.length() &gt; 5); 校验方法调用次数123456789101112131415161718192021//using mockmockedList.add("once");mockedList.add("twice");mockedList.add("twice");mockedList.add("three times");mockedList.add("three times");mockedList.add("three times");//following two verifications work exactly the same - times(1) is used by defaultverify(mockedList).add("once");verify(mockedList, times(1)).add("once");//exact number of invocations verificationverify(mockedList, times(2)).add("twice");verify(mockedList, times(3)).add("three times");//verification using never(). never() is an alias to times(0)verify(mockedList, never()).add("never happened");//verification using atLeast()/atMost()verify(mockedList, atLeastOnce()).add("three times");verify(mockedList, atLeast(2)).add("five times");verify(mockedList, atMost(5)).add("three times"); 模拟无返回方法抛出异常123doThrow(new RuntimeException()).when(mockedList).clear();//following throws RuntimeException:mockedList.clear(); 校验方法调用顺序1234567891011121314151617181920212223// A. Single mock whose methods must be invoked in a particular orderList singleMock = mock(List.class);//using a single mocksingleMock.add("was added first");singleMock.add("was added second");//create an inOrder verifier for a single mockInOrder inOrder = inOrder(singleMock);//following will make sure that add is first called with "was added first, then with "was added second"inOrder.verify(singleMock).add("was added first");inOrder.verify(singleMock).add("was added second");// B. Multiple mocks that must be used in a particular orderList firstMock = mock(List.class);List secondMock = mock(List.class);//using mocksfirstMock.add("was called first");secondMock.add("was called second");//create inOrder object passing any mocks that need to be verified in orderInOrder inOrder = inOrder(firstMock, secondMock);//following will make sure that firstMock was called before secondMockinOrder.verify(firstMock).add("was called first");inOrder.verify(secondMock).add("was called second");// Oh, and A + B can be mixed together at will 校验方法是否从未调用12345678//using mocks - only mockOne is interactedmockOne.add("one");//ordinary verificationverify(mockOne).add("one");//verify that method was never called on a mockverify(mockOne, never()).add("two");//verify that other mocks were not interactedverifyZeroInteractions(mockTwo, mockThree); 快速创建Mock对象123456789public class ArticleManagerTest &#123; @Mock private ArticleCalculator calculator; @Mock private ArticleDatabase database; @Mock private UserProvider userProvider; @Before public void before()&#123; MockitoAnnotations.initMocks(this); &#125;&#125; 自定义返回不同结果123456789when(mock.someMethod("some arg")) .thenThrow(new RuntimeException()) // 第一次会抛出异常 .thenReturn("foo"); // 第二次会返回这个结果//First call: throws runtime exception:mock.someMethod("some arg"); // 第一次//Second call: prints "foo"System.out.println(mock.someMethod("some arg")); // 第二次//Any consecutive call: prints "foo" as well (last stubbing wins).System.out.println(mock.someMethod("some arg")); // 第n次(n&gt; 2)，依旧以最后返回最后一个配置 对返回结果进行拦截123456789when(mock.someMethod(anyString())).thenAnswer(new Answer() &#123; Object answer(InvocationOnMock invocation) &#123; Object[] args = invocation.getArguments(); Object mock = invocation.getMock(); return "called with arguments: " + args; &#125;&#125;);//the following prints "called with arguments: foo"System.out.println(mock.someMethod("foo")); Mock函数操作可以通过doThrow(), doAnswer(), doNothing(), doReturn() and doCallRealMethod() 来自定义函数操作。 暗中调用真实对象1234567891011121314List list = new LinkedList();List spy = spy(list);//optionally, you can stub out some methods:when(spy.size()).thenReturn(100);//using the spy calls *real* methodsspy.add("one");spy.add("two");//prints "one" - the first element of a listSystem.out.println(spy.get(0));//size() method was stubbed - 100 is printedSystem.out.println(spy.size());//optionally, you can verifyverify(spy).add("one"); verify(spy).add("two"); 改变默认返回值12Foo mock = mock(Foo.class, Mockito.RETURNS_SMART_NULLS);Foo mockTwo = mock(Foo.class, new YourOwnAnswer()); 捕获函数的参数值123ArgumentCaptor&lt;Person&gt; argument = ArgumentCaptor.forClass(Person.class);verify(mock).doSomething(argument.capture());assertEquals("John", argument.getValue().getName()); 部分Mock1234567//you can create partial mock with spy() method:List list = spy(new LinkedList());//you can enable partial mock capabilities selectively on mocks:Foo mock = mock(Foo.class);//Be sure the real implementation is 'safe'.//If real implementation throws exceptions or depends on specific state of the object then you're in trouble.when(mock.someMethod()).thenCallRealMethod(); 重置Mock12345List mock = mock(List.class);when(mock.size()).thenReturn(10);mock.add(1);reset(mock);//at this point the mock forgot any interactions &amp; stubbing 序列化12345List&lt;Object&gt; list = new ArrayList&lt;Object&gt;();List&lt;Object&gt; spy = mock(ArrayList.class, withSettings() .spiedInstance(list) .defaultAnswer(CALLS_REAL_METHODS) .serializable()); 检查超时1234567891011//passes when someMethod() is called within given time spanverify(mock, timeout(100)).someMethod();//above is an alias to:verify(mock, timeout(100).times(1)).someMethod();//passes when som`eMethod() is called *exactly* 2 times within given time spanverify(mock, timeout(100).times(2)).someMethod();//passes when someMethod() is called *at least* 2 times within given time spanverify(mock, timeout(100).atLeast(2)).someMethod();//verifies someMethod() within given time span using given verification mode//useful only if you have your own custom verification modes.verify(mock, new Timeout(100, yourOwnVerificationMode)).someMethod(); Mock详情12Mockito.mockingDetails(someObject).isMock();Mockito.mockingDetails(someObject).isSpy();]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql group_cat]]></title>
    <url>%2F2017%2F11%2F16%2Fmysql-group-cat%2F</url>
    <content type="text"><![CDATA[group_concat()函数的参数是可以直接使用order by排序的。666。。下面通过例子来说明，首先看下面的t1表。 比如，我们要查看每个人的多个分数，将该人对应的多个分数显示在一起，分数要从高到底排序。可以这样写： SELECT username,GROUP_CONCAT(score ORDER BY score DESC) AS myScore FROM t1 GROUP BY username; 效果如下： 12345678910111213141516UPDATE cash_billing_item bi, ( SELECT bi.id FROM cash_billing_item bi WHERE bi.id and bi.status = 1 and bi.id not in ( SELECT group_concat(id ORDER BY product_start_time desc) FROM cash_billing_item WHERE product_no = bi.product_no AND customer_no = bi.customer_no and status = 1 GROUP BY product_no, customer_no ) ) tempSET bi.status = 2WHERE bi.id = temp.id; group_cat之后相当于还有一个SELECT substring_index(‘10,3,4,5’,’,’,1); 返回第一个10]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中decimal类型详解及类型转换]]></title>
    <url>%2F2017%2F11%2F16%2FMySQL%E4%B8%ADdecimal%E7%B1%BB%E5%9E%8B%E8%AF%A6%E8%A7%A3%E5%8F%8A%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[1select name,cast(age/(select sum(age) from boss) as decimal(32,2)) as age from boss; 其中cast是类型转换函数，decimal为一个类型 1.首先，对于精度比较高的东西，比如money，我会用decimal类型，不会考虑float,double,因为他们容易产生误差，numeric和decimal同义，numeric将自动转成decimal。 DECIMAL从MySQL 5.1引入，列的声明语法是DECIMAL(M,D)。在MySQL 5.1中，参量的取值范围如下： ·M是数字的最大数（精度）。其范围为1～65（在较旧的MySQL版本中，允许的范围是1～254），M 的默认值是10。 ·D是小数点右侧数字的数目（标度）。其范围是0～30，但不得超过M。 说明：float占4个字节，double占8个字节，decimail(M,D)占M+2个字节。 如DECIMAL(5,2) 的最大值为9 9 9 9 . 9 9，因为有7 个字节可用。 M 与D 对DECIMAL(M, D) 取值范围的影响 类型说明取值范围（MySQL &lt; 3.23）取值范围（MySQL &gt;= 3.23） MySQL &lt; 3.23 MySQL &gt;=3.23DECIMAL(4, 1) -9.9 到 99.9 -999.9 到 9999.9 DECIMAL(5,1) -99.9 到 999.9 -9999.9 到 99999.9 DECIMAL(6,1) -999.9 到 9999.9 -99999.9 到 999999.9 DECIMAL(6,2) -99.99 到 999.99 -9999.99 到 99999.99 DECIMAL(6,3) -9.999 到 99.999 -999.999 到 9999.999 在MySQL 3.23 及以后的版本中，DECIMAL(M, D) 的取值范围等于早期版本中的DECIMAL(M + 2, D) 的取值范围。 结论： 当数值在其取值范围之内，小数位多了，则直接截断小数位。 若数值在其取值范围之外，则用最大(小)值对其填充。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo直连调试]]></title>
    <url>%2F2017%2F11%2F14%2FDubbo%E7%9B%B4%E8%BF%9E%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[服务端： 123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd" default-autowire="byName"&gt; &lt;dubbo:provider group="xxx"/&gt;&lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name="sports-basic-provider"/&gt; &lt;!-- 使用zookeeper注册中心暴露服务地址 --&gt; &lt;dubbo:registry protocol="zookeeper" address="$&#123;dubbo.registry.address&#125;"/&gt; &lt;!-- 使用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name="dubbo" port="20880"/&gt; &lt;!-- basic start --&gt; &lt;dubbo:service interface="com.xxx.basic.manage.service.OrganizationService" ref="organizationService" timeout="10000"/&gt; &lt;dubbo:service interface="com.xxx.basic.manage.service.ResourceService" ref="resourceService" timeout="10000"/&gt; &lt;dubbo:service interface="com.xxx.basic.manage.service.SysRoleService" ref="sysRoleService" timeout="10000"/&gt; &lt;dubbo:service interface="com.xxx.basic.manage.service.SysUserService" ref="sysUserService" timeout="10000"/&gt;&lt;/beans&gt; 消费端： 增加url=”dubbo://localhost:20880”即可。 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd" default-autowire="byName"&gt; &lt;dubbo:application name="$&#123;dubbo.application.name&#125;"/&gt; &lt;dubbo:registry address="$&#123;dubbo.registry.address&#125;" timeout="$&#123;dubbo.consumer.timeout&#125;" /&gt; &lt;dubbo:consumer retries="$&#123;dubbo.consumer.retries&#125;" group="oa" /&gt; &lt;!-- basic start --&gt; &lt;dubbo:reference interface="com.xxx.basic.manage.service.SysRoleService" id="sysRoleService" check="false" url="dubbo://localhost:20880"/&gt; &lt;dubbo:reference interface="com.xxx.basic.manage.service.ResourceService" id="resourceService" check="false" url="dubbo://localhost:20880" /&gt; &lt;dubbo:reference interface="com.xxx.basic.manage.service.OrganizationService" id="organizationService" check="false" url="dubbo://localhost:20880" /&gt; &lt;dubbo:reference interface="com.xxx.basic.manage.service.SysUserService" id="sysUserService" check="false" url="dubbo://localhost:20880"/&gt;&lt;/beans&gt; 开发调试 我们启动远程服务提供者 我启动web-boss，这里调用是远程提供者服务 查看user-service,provider方的配置 配置consumer方调用本地dubbo服务，进行直连调试 我们启动本地 dubbo服务,以debug模式启动 在dubbo管理控制台查看dubbo服务 启动消费端，web-boss我们进行直连调试 consumer控制台信息 我们再访问登录，会发现已调用本地dubbo模式，进入debug调试模式 我们在Dubbo管理控制台把provider禁用，发现也是调用本地dubbo服务，绕过了注册中心，这就是直连提供者 我们在${user.home}下配置直接提供者属性也是可以的(推荐使用） dubbo-resolve.properties 内容 ： edu.facade.user.service.PmsUserFacade=dubbo://localhost:20880 注意点： 1、 直连提供者只需要在消费端设置 2、 ${user.home}指的是当前操作系统用户目录，如 Win7系统 Administrator的用户目录就是 C:\Users\Administrator]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JedisCommands说明]]></title>
    <url>%2F2017%2F11%2F13%2FJedisCommands%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[https://redis.io/commands/incr 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230import java.util.List;import java.util.Map;import java.util.Set;/** * Common interface for sharded and non-sharded Jedis */public interface JedisCommands &#123; /** * 存储数据到缓存中，若key已存在则覆盖 value的长度不能超过1073741824 bytes (1 GB) * * @param key * @param value * @return */ String set(String key, String value); /** * 存储数据到缓存中，并制定过期时间和当Key存在时是否覆盖。 * * @param key * @param value * @param nxxx * nxxx的值只能取NX或者XX，如果取NX，则只有当key不存在是才进行set，如果取XX，则只有当key已经存在时才进行set * * @param expx expx的值只能取EX或者PX，代表数据过期时间的单位，EX代表秒，PX代表毫秒。 * @param time 过期时间，单位是expx所代表的单位。 * @return */ String set(String key, String value, String nxxx, String expx, long time); /** * 从缓存中根据key取得其String类型的值，如果key不存在则返回null，如果key存在但value不是string类型的， * 则返回一个error。这个方法只能从缓存中取得value为string类型的值。 * * @param key * @return */ String get(String key); /** * 检查某个key是否在缓存中存在，如果存在返回true，否则返回false；需要注意的是，即使该key所对应的value是一个空字符串， * 也依然会返回true。 * * @param key * @return */ Boolean exists(String key); /** * * 如果一个key设置了过期时间，则取消其过期时间，使其永久存在。 * * @param key * @return 返回1或者0,1代表取消过期时间成功，0代表不成功(只有当key不存在时这种情况才会发生) */ Long persist(String key); /** * 返回某个key所存储的数据类型，返回的数据类型有可能是"none", "string", "list", "set", "zset", * "hash". "none"代表key不存在。 * * @param key * @return */ String type(String key); /** * 为key设置一个特定的过期时间，单位为秒。过期时间一到，redis将会从缓存中删除掉该key。 * 即使是有过期时间的key，redis也会在持久化时将其写到硬盘中，并把相对过期时间改为绝对的Unix过期时间。 * 在一个有设置过期时间的key上重复设置过期时间将会覆盖原先设置的过期时间。 * * @param key * @param seconds * @return 返回1表示成功设置过期时间，返回0表示key不存在。 */ Long expire(String key, int seconds); /** * 机制同&#123;@link expire&#125;一样，只是时间单位改为毫秒。 * * @param key * @param milliseconds * @return 返回值同 &#123;@link expire&#125;一样。 */ Long pexpire(String key, long milliseconds); /** * 与&#123;@link expire&#125;不一样，expireAt设置的时间不是能存活多久，而是固定的UNIX时间（从1970年开始算起），单位为秒。 * * @param key * @param unixTime * @return */ Long expireAt(String key, long unixTime); /** * 同&#123;@link expireAt&#125;机制相同，但单位为毫秒。 * * @param key * @param millisecondsTimestamp * @return */ Long pexpireAt(String key, long millisecondsTimestamp); /** * 返回一个key还能活多久，单位为秒 * * @param key * @return 如果该key本来并没有设置过期时间，则返回-1，如果该key不存在，则返回-2 */ Long ttl(String key); /** * 设置或者清除指定key的value上的某个位置的比特位，如果该key原先不存在，则新创建一个key，其value将会自动分配内存， * 直到可以放下指定位置的bit值。 * * @param key * @param offset * @param value true代表1，false代表0 * @return 返回原来位置的bit值是否是1，如果是1，则返回true，否则返回false。 */ Boolean setbit(String key, long offset, boolean value); /** * 设置或者清除指定key的value上的某个位置的比特位，如果该key原先不存在，则新创建一个key，其value将会自动分配内存， * 直到可以放下指定位置的bit值。 * * @param key * @param offset * @param value 只能是"1"或者"0" * @return 返回原来位置的bit值是否是1，如果是1，则返回true，否则返回false。 */ Boolean setbit(String key, long offset, String value); /** * 取得偏移量为offset的bit值。 * * @param key * @param offset * @return true代表1，false代表0 */ Boolean getbit(String key, long offset); /** * 这个命令的作用是覆盖key对应的string的一部分，从指定的offset处开始，覆盖value的长度。 * 如果offset比当前key对应string还要长， * 那这个string后面就补0以达到offset。不存在的keys被认为是空字符串，所以这个命令可以确保key有一个足够大的字符串 * 能在offset处设置value。 * * @param key * @param offset * @param value * @return 该命令修改后的字符串长度 */ Long setrange(String key, long offset, String value); /** * 获得start - end之间的子字符串，若偏移量为负数，代表从末尾开始计算，例如-1代表倒数第一个，-2代表倒数第二个 * * @param key * @param startOffset * @param endOffset * @return */ String getrange(String key, long startOffset, long endOffset); /** * 自动将key对应到value并且返回原来key对应的value。如果key存在但是对应的value不是字符串，就返回错误。 * * @param key * @param value * @return */ String getSet(String key, String value); /** * 参考 &#123;@link set(String key, String value, String nxxx, String expx, long * time)&#125; * * @param key * @param value * @return */ Long setnx(String key, String value); /** * 参考 &#123;@link set(String key, String value, String nxxx, String expx, long * time)&#125; * * @param key * @param seconds * @param value * @return */ String setex(String key, int seconds, String value); /** * 将指定key的值减少某个值 * * @param key * @param integer * @return 返回减少后的新值 */ Long decrBy(String key, long integer); /** * 将指定Key的值减少1 * * @param key * @return 返回减少后的新值 */ Long decr(String key); /** * 将指定的key的值增加指定的值 * * @param key * @param integer * @return 返回增加后的新值 */ Long incrBy(String key, long integer); /** * 将指定的key的值增加指定的值(浮点数) * * @param key * @param value * @return 返回增加后的新值 */ Double incrByFloat(String key, double value); /** * 将指定的key的值增加1 * * @param key * @return 返回增加后的新值 */ Long incr(String key); /** * 若key存在，将value追加到原有字符串的末尾。若key不存在，则创建一个新的空字符串。 * * @param key * @param value * @return 返回字符串的总长度 */ Long append(String key, String value); /** * 返回start - end 之间的子字符串(start 和 end处的字符也包括在内) * * @param key * @param start * @param end * @return 返回子字符串 */ String substr(String key, int start, int end); /** * 设置hash表里field字段的值为value。如果key不存在，则创建一个新的hash表 * * @param key * @param field * @param value * @return 如果该字段已经存在，那么将会更新该字段的值，返回0.如果字段不存在，则新创建一个并且返回1. */ Long hset(String key, String field, String value); /** * 如果该key对应的值是一个Hash表，则返回对应字段的值。 如果不存在该字段，或者key不存在，则返回一个"nil"值。 * * @param key * @param field * @return */ String hget(String key, String field); /** * 当字段不存在时，才进行set。 * * @param key * @param field * @param value * @return 如果该字段已经存在，则返回0.若字段不存在，则创建后set，返回1. */ Long hsetnx(String key, String field, String value); /** * 设置多个字段和值，如果字段存在，则覆盖。 * * @param key * @param hash * @return 设置成功返回OK，设置不成功则返回EXCEPTION */ String hmset(String key, Map&lt;String, String&gt; hash); /** * 在hash中获取多个字段的值，若字段不存在，则其值为nil。 * * @param key * @param fields * @return 按顺序返回多个字段的值。 */ List&lt;String&gt; hmget(String key, String... fields); /** * 对hash中指定字段的值增加指定的值 * * @param key * @param field * @param value * @return 返回增加后的新值 */ Long hincrBy(String key, String field, long value); /** * 判断hash中指定字段是否存在 * * @param key * @param field * @return 若存在返回1，若不存在返回0 */ Boolean hexists(String key, String field); /** * 删除hash中指定字段 * * @param key * @param field * @return 删除成功返回1， 删除不成功返回0 */ Long hdel(String key, String... field); /** * 返回 key 指定的哈希集包含的字段的数量 * * @param key * @return 哈希集中字段的数量，当 key 指定的哈希集不存在时返回 0 */ Long hlen(String key); /** * 返回 key 指定的哈希集中所有字段的名字。 * * @param key * @return 哈希集中的字段列表，当 key 指定的哈希集不存在时返回空列表。 */ Set&lt;String&gt; hkeys(String key); /** * 返回 key 指定的哈希集中所有字段的值。 * * @param key * @return 哈希集中的值的列表，当 key 指定的哈希集不存在时返回空列表。 */ List&lt;String&gt; hvals(String key); /** * 返回 key 指定的哈希集中所有的字段和值 * * @param key * @return 返回 key 指定的哈希集中所有的字段和值,若key不存在返回空map。 */ Map&lt;String, String&gt; hgetAll(String key); /** * 向存于 key 的列表的尾部插入所有指定的值。如果 key 不存在，那么会创建一个空的列表然后再进行 push 操作。 当 key * 保存的不是一个列表，那么会返回一个错误。 * * 可以使用一个命令把多个元素打入队列，只需要在命令后面指定多个参数。元素是从左到右一个接一个从列表尾部插入。 比如命令 RPUSH mylist a * b c 会返回一个列表，其第一个元素是 a ，第二个元素是 b ，第三个元素是 c。 * * @param key * @param string * @return 在 push 操作后的列表长度。 */ Long rpush(String key, String... string); /** * 将所有指定的值插入到存于 key 的列表的头部。如果 key 不存在，那么在进行 push 操作前会创建一个空列表。 如果 key * 对应的值不是一个 list 的话，那么会返回一个错误。 * * 可以使用一个命令把多个元素 push 进入列表，只需在命令末尾加上多个指定的参数。元素是从最左端的到最右端的、一个接一个被插入到 list * 的头部。 所以对于这个命令例子 LPUSH mylist a b c，返回的列表是 c 为第一个元素， b 为第二个元素， a 为第三个元素。 * * @param key * @param string * @return 在 push 操作后的列表长度。 */ Long lpush(String key, String... string); /** * 返回存储在 key 里的list的长度。 如果 key 不存在，那么就被看作是空list，并且返回长度为 0。 当存储在 key * 里的值不是一个list的话，会返回error。 * * @param key * @return key对应的list的长度。 */ Long llen(String key); /** * 返回存储在 key 的列表里指定范围内的元素。 start 和 end * 偏移量都是基于0的下标，即list的第一个元素下标是0（list的表头），第二个元素下标是1，以此类推。 * * 偏移量也可以是负数，表示偏移量是从list尾部开始计数。 例如， -1 表示列表的最后一个元素，-2 是倒数第二个，以此类推。 * * @param key * @param start * @param end * @return 指定范围里的列表元素。 */ List&lt;String&gt; lrange(String key, long start, long end); /** * 修剪(trim)一个已存在的 list，这样 list 就会只包含指定范围的指定元素。start 和 stop 都是由0开始计数的， 这里的 0 * 是列表里的第一个元素（表头），1 是第二个元素，以此类推。 * * @param key * @param start * @param end * @return */ String ltrim(String key, long start, long end); /** * 返回列表里的元素的索引 index 存储在 key 里面。 下标是从0开始索引的，所以 0 是表示第一个元素， 1 表示第二个元素，并以此类推。 * 负数索引用于指定从列表尾部开始索引的元素。在这种方法下，-1 表示最后一个元素，-2 表示倒数第二个元素，并以此往前推。 * * 当 key 位置的值不是一个列表的时候，会返回一个error。 * * @param key * @param index * @return 请求的对应元素，或者当 index 超过范围的时候返回 nil。 */ String lindex(String key, long index); /** * 设置 index 位置的list元素的值为 value。 * * 当index超出范围时会返回一个error。 * * @param key * @param index * @param value * @return 状态恢复 */ String lset(String key, long index, String value); /** * 从存于 key 的列表里移除前 count 次出现的值为 value 的元素。 这个 count 参数通过下面几种方式影响这个操作： * * count &gt; 0: 从头往尾移除值为 value 的元素。 count &lt; 0: 从尾往头移除值为 value 的元素。 count = 0: * 移除所有值为 value 的元素。 * * 比如， LREM list -2 "hello" 会从存于 list 的列表里移除最后两个出现的 "hello"。 * * 需要注意的是，如果list里没有存在key就会被当作空list处理，所以当 key 不存在的时候，这个命令会返回 0。 * * @param key * @param count * @param value * @return 返回删除的个数 */ Long lrem(String key, long count, String value); /** * 移除并且返回 key 对应的 list 的第一个元素。 * * @param key * @return 返回第一个元素的值，或者当 key 不存在时返回 nil。 */ String lpop(String key); /** * 移除并返回存于 key 的 list 的最后一个元素。 * * @param key * @return 最后一个元素的值，或者当 key 不存在的时候返回 nil。 */ String rpop(String key); /** * 添加一个或多个指定的member元素到集合的 key中.指定的一个或者多个元素member 如果已经在集合key中存在则忽略.如果集合key * 不存在，则新建集合key,并添加member元素到集合key中. * * 如果key 的类型不是集合则返回错误. * * @param key * @param member * @return 返回新成功添加到集合里元素的数量，不包括已经存在于集合中的元素. */ Long sadd(String key, String... member); /** * 返回key集合所有的元素. * * 该命令的作用与使用一个参数的SINTER 命令作用相同. * * @param key * @return 集合中的所有元素. */ Set&lt;String&gt; smembers(String key); /** * 在key集合中移除指定的元素. 如果指定的元素不是key集合中的元素则忽略 如果key集合不存在则被视为一个空的集合，该命令返回0. * * 如果key的类型不是一个集合,则返回错误. * * @param key * @param member * @return 从集合中移除元素的个数，不包括不存在的成员. */ Long srem(String key, String... member); /** * 移除并返回一个集合中的随机元素 * * 该命令与 SRANDMEMBER相似,不同的是srandmember命令返回一个随机元素但是不移除. * * @param key * @return 被移除的元素, 当key不存在的时候返回 nil . */ String spop(String key); /** * 移除并返回多个集合中的随机元素 * * @param key * @param count * @return 被移除的元素, 当key不存在的时候值为 nil . */ Set&lt;String&gt; spop(String key, long count); /** * 返回集合存储的key的基数 (集合元素的数量). * * @param key * @return 集合的基数(元素的数量),如果key不存在,则返回 0. */ Long scard(String key); /** * 返回成员 member 是否是存储的集合 key的成员. * * @param key * @param member * @return 如果member元素是集合key的成员，则返回1.如果member元素不是key的成员，或者集合key不存在，则返回0 */ Boolean sismember(String key, String member); /** * 仅提供key参数,那么随机返回key集合中的一个元素.该命令作用类似于SPOP命令, 不同的是SPOP命令会将被选择的随机元素从集合中移除, * 而SRANDMEMBER仅仅是返回该随记元素,而不做任何操作. * * @param key * @return 返回随机的元素,如果key不存在则返回nil */ String srandmember(String key); /** * 如果count是整数且小于元素的个数，返回含有 count * 个不同的元素的数组,如果count是个整数且大于集合中元素的个数时,仅返回整个集合的所有元素 * ,当count是负数,则会返回一个包含count的绝对值的个数元素的数组 * ，如果count的绝对值大于元素的个数,则返回的结果集里会出现一个元素出现多次的情况. * * @param key * @param count * @return 返回一个随机的元素数组,如果key不存在则返回一个空的数组. */ List&lt;String&gt; srandmember(String key, int count); /** * 返回key的string类型value的长度。如果key对应的非string类型，就返回错误。 * * @param key * @return key对应的字符串value的长度，或者0（key不存在） */ Long strlen(String key); /** * 该命令添加指定的成员到key对应的有序集合中，每个成员都有一个分数。你可以指定多个分数/成员组合。如果一个指定的成员已经在对应的有序集合中了， * 那么其分数就会被更新成最新的 * ，并且该成员会重新调整到正确的位置，以确保集合有序。如果key不存在，就会创建一个含有这些成员的有序集合，就好像往一个空的集合中添加一样 * 。如果key存在，但是它并不是一个有序集合，那么就返回一个错误。 * * 分数的值必须是一个表示数字的字符串，并且可以是double类型的浮点数。 * * @param key * @param score * @param member * @return 返回添加到有序集合中元素的个数，不包括那种已经存在只是更新分数的元素。 */ Long zadd(String key, double score, String member); /** * 该命令添加指定的成员到key对应的有序集合中，每个成员都有一个分数。你可以指定多个分数/成员组合。如果一个指定的成员已经在对应的有序集合中了， * 那么其分数就会被更新成最新的 * ，并且该成员会重新调整到正确的位置，以确保集合有序。如果key不存在，就会创建一个含有这些成员的有序集合，就好像往一个空的集合中添加一样 * 。如果key存在，但是它并不是一个有序集合，那么就返回一个错误。 * * 分数的值必须是一个表示数字的字符串，并且可以是double类型的浮点数。 * * @param key * @param scoreMembers * @return 返回添加到有序集合中元素的个数，不包括那种已经存在只是更新分数的元素。 */ Long zadd(String key, Map&lt;String, Double&gt; scoreMembers); /** * 返回有序集key中，指定区间内的成员。其中成员按score值递增(从小到大)来排序。具有相同score值的成员按字典序来排列。 * * 如果你需要成员按score值递减(score相等时按字典序递减)来排列，请使用ZREVRANGE命令。 * 下标参数start和stop都以0为底，也就是说，以0表示有序集第一个成员，以1表示有序集第二个成员，以此类推。 * 你也可以使用负数下标，以-1表示最后一个成员，-2表示倒数第二个成员，以此类推。 * * 超出范围的下标并不会引起错误。如果start的值比有序集的最大下标还要大，或是start &gt; * stop时，ZRANGE命令只是简单地返回一个空列表。 * 另一方面，假如stop参数的值比有序集的最大下标还要大，那么Redis将stop当作最大下标来处理。 * * @param key * @param start * @param end * @return 指定范围的元素列表 */ Set&lt;String&gt; zrange(String key, long start, long end); /** * 从集合中删除指定member元素，当key存在，但是其不是有序集合类型，就返回一个错误。 * * @param key * @param member * @return 返回的是从有序集合中删除的成员个数，不包括不存在的成员。 */ Long zrem(String key, String... member); /** * 为有序集key的成员member的score值加上增量increment。如果key中不存在member，就在key中添加一个member， * score是increment（就好像它之前的score是0.0）。如果key不存在，就创建一个只含有指定member成员的有序集合。 * * 当key不是有序集类型时，返回一个错误。 * * score值必须整数值或双精度浮点数。也有可能给一个负数来减少score的值。 * * @param key * @param score * @param member * @return member成员的新score值. */ Double zincrby(String key, double score, String member); /** * 返回有序集key中成员member的排名。其中有序集成员按score值递增(从小到大)顺序排列。排名以0为底，也就是说， * score值最小的成员排名为0。 * * 使用ZREVRANK命令可以获得成员按score值递减(从大到小)排列的排名。 * * @param key * @param member * @return 如果member是有序集key的成员，返回member的排名的整数。 如果member不是有序集key的成员，返回 nil。 */ Long zrank(String key, String member); /** * 返回有序集key中成员member的排名，其中有序集成员按score值从大到小排列。排名以0为底，也就是说，score值最大的成员排名为0。 * * 使用ZRANK命令可以获得成员按score值递增(从小到大)排列的排名。 * * @param key * @param member * @return 如果member是有序集key的成员，返回member的排名。整型数字。 如果member不是有序集key的成员，返回Bulk * reply: nil. */ Long zrevrank(String key, String member); /** * 返回有序集key中，指定区间内的成员。其中成员的位置按score值递减(从大到小)来排列。具有相同score值的成员按字典序的反序排列。 * 除了成员按score值递减的次序排列这一点外，ZREVRANGE命令的其他方面和ZRANGE命令一样。 * * @param key * @param start * @param end * @return 指定范围的元素列表(可选是否含有分数)。 */ Set&lt;String&gt; zrevrange(String key, long start, long end); /** * 返回有序集key中，指定区间内的成员。其中成员按score值递增(从小到大)来排序。具有相同score值的成员按字典序来排列。 * * 如果你需要成员按score值递减(score相等时按字典序递减)来排列，请使用ZREVRANGE命令。 * 下标参数start和stop都以0为底，也就是说，以0表示有序集第一个成员，以1表示有序集第二个成员，以此类推。 * 你也可以使用负数下标，以-1表示最后一个成员，-2表示倒数第二个成员，以此类推。 * * 超出范围的下标并不会引起错误。如果start的值比有序集的最大下标还要大，或是start &gt; * stop时，ZRANGE命令只是简单地返回一个空列表。 * 另一方面，假如stop参数的值比有序集的最大下标还要大，那么Redis将stop当作最大下标来处理。 * * 使用WITHSCORES选项，来让成员和它的score值一并返回，返回列表以value1,score1, ..., * valueN,scoreN的格式表示，而不是value1,...,valueN。客户端库可能会返回一些更复杂的数据类型，比如数组、元组等。 * * @param key * @param start * @param end * @return 指定范围的元素列表(以元组集合的形式)。 */ Set&lt;Tuple&gt; zrangeWithScores(String key, long start, long end); /** * 返回有序集key中，指定区间内的成员。其中成员的位置按score值递减(从大到小)来排列。具有相同score值的成员按字典序的反序排列。 * 除了成员按score值递减的次序排列这一点外，ZREVRANGE命令的其他方面和ZRANGE命令一样。 * * @param key * @param start * @param end * @return 指定范围的元素列表(可选是否含有分数)。 */ Set&lt;Tuple&gt; zrevrangeWithScores(String key, long start, long end); /** * 返回key的有序集元素个数。 * * @param key * @return key存在的时候，返回有序集的元素个数，否则返回0。 */ Long zcard(String key); /** * 返回有序集key中，成员member的score值。 * * 如果member元素不是有序集key的成员，或key不存在，返回nil。 * * @param key * @param member * @return member成员的score值（double型浮点数） */ Double zscore(String key, String member); /** * 对一个集合或者一个列表排序 * * 对集合，有序集合，或者列表的value进行排序。默认情况下排序只对数字排序，双精度浮点数。 * * @see #sort(String, String) * @see #sort(String, SortingParams) * @see #sort(String, SortingParams, String) * @param key * @return 假设集合或列表包含的是数字元素，那么返回的将会是从小到大排列的一个列表。 */ List&lt;String&gt; sort(String key); /** * 根据指定参数来对列表或集合进行排序. * &lt;p&gt; * &lt;b&gt;examples:&lt;/b&gt; * &lt;p&gt; * 一下是一些例子列表或者key-value: * * &lt;pre&gt; * x = [1, 2, 3] * y = [a, b, c] * * k1 = z * k2 = y * k3 = x * * w1 = 9 * w2 = 8 * w3 = 7 * &lt;/pre&gt; * * 排序: * * &lt;pre&gt; * sort(x) or sort(x, sp.asc()) * -&gt; [1, 2, 3] * * sort(x, sp.desc()) * -&gt; [3, 2, 1] * * sort(y) * -&gt; [c, a, b] * * sort(y, sp.alpha()) * -&gt; [a, b, c] * * sort(y, sp.alpha().desc()) * -&gt; [c, b, a] * &lt;/pre&gt; * * Limit (e.g. for Pagination): * * &lt;pre&gt; * sort(x, sp.limit(0, 2)) * -&gt; [1, 2] * * sort(y, sp.alpha().desc().limit(1, 2)) * -&gt; [b, a] * &lt;/pre&gt; * * 使用外部键来排序: * * &lt;pre&gt; * sort(x, sb.by(w*)) * -&gt; [3, 2, 1] * * sort(x, sb.by(w*).desc()) * -&gt; [1, 2, 3] * &lt;/pre&gt; * * Getting external keys: * * &lt;pre&gt; * sort(x, sp.by(w*).get(k*)) * -&gt; [x, y, z] * * sort(x, sp.by(w*).get(#).get(k*)) * -&gt; [3, x, 2, y, 1, z] * &lt;/pre&gt; * * @see #sort(String) * @see #sort(String, SortingParams, String) * @param key * @param sortingParameters * @return a list of sorted elements. */ List&lt;String&gt; sort(String key, SortingParams sortingParameters); /** * 返回有序集key中，score值在min和max之间(默认包括score值等于min或max)的成员。 * * @param key * @param min * @param max * @return 指定分数范围的元素个数。 */ Long zcount(String key, double min, double max); /** * 返回有序集key中，score值在min和max之间(默认包括score值等于min或max)的成员。 * * @param key * @param min * @param max * @return 指定分数范围的元素个数。 */ Long zcount(String key, String min, String max); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列 * * @param key * @param min * @param max * @return 指定分数范围的元素列表 */ Set&lt;String&gt; zrangeByScore(String key, double min, double max); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列 * * @param key * @param min * @param max * @return 指定分数范围的元素列表 */ Set&lt;String&gt; zrangeByScore(String key, String min, String max); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列, 指定返回结果的数量及区间。 * * @param key * @param min * @param max * @param offset * @param count * @return 指定分数范围的元素列表 */ Set&lt;String&gt; zrangeByScore(String key, double min, double max, int offset, int count); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列, 指定返回结果的数量及区间。 * * @param key * @param min * @param max * @param offset * @param count * @return 指定分数范围的元素列表 */ Set&lt;String&gt; zrangeByScore(String key, String min, String max, int offset, int count); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列。返回元素和其分数，而不只是元素。 * * @param key * @param min * @param max * @return */ Set&lt;Tuple&gt; zrangeByScoreWithScores(String key, double min, double max); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列, 指定返回结果的数量及区间。 返回元素和其分数，而不只是元素。 * * @param key * @param min * @param max * @param offset * @param count * @return */ Set&lt;Tuple&gt; zrangeByScoreWithScores(String key, double min, double max, int offset, int count); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列。返回元素和其分数，而不只是元素。 * * @param key * @param min * @param max * @return */ Set&lt;Tuple&gt; zrangeByScoreWithScores(String key, String min, String max); /** * 返回key的有序集合中的分数在min和max之间的所有元素（包括分数等于max或者min的元素）。元素被认为是从低分到高分排序的。 * 具有相同分数的元素按字典序排列, 指定返回结果的数量及区间。 返回元素和其分数，而不只是元素。 * * @param key * @param min * @param max * @param offset * @param count * @return */ Set&lt;Tuple&gt; zrangeByScoreWithScores(String key, String min, String max, int offset, int count); /** * 机制与zrangeByScore一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @return */ Set&lt;String&gt; zrevrangeByScore(String key, double max, double min); /** * 机制与zrangeByScore一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @return */ Set&lt;String&gt; zrevrangeByScore(String key, String max, String min); /** * 机制与zrangeByScore一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @param offset * @param count * @return */ Set&lt;String&gt; zrevrangeByScore(String key, double max, double min, int offset, int count); /** * 机制与zrangeByScoreWithScores一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @return */ Set&lt;Tuple&gt; zrevrangeByScoreWithScores(String key, double max, double min); /** * 机制与zrangeByScore一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @param offset * @param count * @return */ Set&lt;String&gt; zrevrangeByScore(String key, String max, String min, int offset, int count); /** * 机制与zrangeByScoreWithScores一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @return */ Set&lt;Tuple&gt; zrevrangeByScoreWithScores(String key, String max, String min); /** * 机制与zrangeByScoreWithScores一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @param offset * @param count * @return */ Set&lt;Tuple&gt; zrevrangeByScoreWithScores(String key, double max, double min, int offset, int count); /** * 机制与zrangeByScoreWithScores一样，只是返回结果为降序排序。 * * @param key * @param max * @param min * @param offset * @param count * @return */ Set&lt;Tuple&gt; zrevrangeByScoreWithScores(String key, String max, String min, int offset, int count); /** * 移除有序集key中，指定排名(rank)区间内的所有成员。下标参数start和stop都以0为底，0处是分数最小的那个元素。这些索引也可是负数， * 表示位移从最高分处开始数。例如，-1是分数最高的元素，-2是分数第二高的，依次类推。 * * @param key * @param start * @param end * @return 被移除成员的数量。 */ Long zremrangeByRank(String key, long start, long end); /** * 移除有序集key中，所有score值介于min和max之间(包括等于min或max)的成员。 * * 自版本2.1.6开始，score值等于min或max的成员也可以不包括在内，语法请参见ZRANGEBYSCORE命令。 * * @param key * @param start * @param end * @return 删除的元素的个数 */ Long zremrangeByScore(String key, double start, double end); /** * 移除有序集key中，所有score值介于min和max之间(包括等于min或max)的成员。 * * 自版本2.1.6开始，score值等于min或max的成员也可以不包括在内，语法请参见ZRANGEBYSCORE命令。 * * @param key * @param start * @param end * @return 删除的元素的个数 */ Long zremrangeByScore(String key, String start, String end); /** * 当插入到有序集合中的元素都具有相同的分数时，这个命令可以返回min和max指定范围内的元素的数量。 * * @param key * @param min * @param max * @return */ Long zlexcount(final String key, final String min, final String max); /** * 把 value 插入存于 key 的列表中在基准值 pivot 的前面或后面。 * * 当 key 不存在时，这个list会被看作是空list，任何操作都不会发生。 * * 当 key 存在，但保存的不是一个list的时候，会返回error。 * * @param key * @param where * @param pivot 前或后 * @param value * @return 在 insert 操作后的 list 长度。 */ Long linsert(String key, Client.LIST_POSITION where, String pivot, String value); /** * 只有当 key 已经存在并且存着一个 list 的时候，在这个 key 下面的 list 的头部插入 value。 与 LPUSH 相反，当 * key 不存在的时候不会进行任何操作。 * * @param key * @param string * @return 在 push 操作后的 list 长度。 */ Long lpushx(String key, String... string); /** * 将值 value 插入到列表 key 的表尾, 当且仅当 key 存在并且是一个列表。 和 RPUSH 命令相反, 当 key * 不存在时，RPUSHX 命令什么也不做。 * * @param key * @param string * @return 在Push操作后List的长度 */ Long rpushx(String key, String... string); /** * @deprecated unusable command, this will be removed in 3.0.0. */ @Deprecated List&lt;String&gt; blpop(String arg); /** * BLPOP 是阻塞式列表的弹出原语。 它是命令 LPOP 的阻塞版本，这是因为当给定列表内没有任何元素可供弹出的时候， 连接将被 BLPOP * 命令阻塞。 当给定多个 key 参数时，按参数 key 的先后顺序依次检查各个列表，弹出第一个非空列表的头元素。 &#123;@link http * ://www.redis.cn/commands/blpop.html&#125; * * @param timeout * @param key * @return */ List&lt;String&gt; blpop(int timeout, String key); /** * @deprecated unusable command, this will be removed in 3.0.0. */ @Deprecated List&lt;String&gt; brpop(String arg); /** * BRPOP 是一个阻塞的列表弹出原语。 它是 RPOP 的阻塞版本，因为这个命令会在给定list无法弹出任何元素的时候阻塞连接。 * 该命令会按照给出的 key 顺序查看 list，并在找到的第一个非空 list 的尾部弹出一个元素。 * * 请在 BLPOP 文档 中查看该命令的准确语义，因为 BRPOP 和 BLPOP * 基本是完全一样的，除了它们一个是从尾部弹出元素，而另一个是从头部弹出元素。 &#123;@link http * ://www.redis.cn/commands/brpop.html&#125; * * * @param timeout * @param key * @return */ List&lt;String&gt; brpop(int timeout, String key); /** * 删除一个Key,如果删除的key不存在，则直接忽略。 * * @param key * @return 被删除的keys的数量 */ Long del(String key); /** * 回显 * * @param string * @return 回显输入的字符串 */ String echo(String string); /** * 将当前数据库的 key 移动到给定的数据库 db 当中。 * * 如果当前数据库(源数据库)和给定数据库(目标数据库)有相同名字的给定 key ，或者 key 不存在于当前数据库，那么 MOVE 没有任何效果。 * * 因此，也可以利用这一特性，将 MOVE 当作锁(locking)原语(primitive)。 * * @param key * @param dbIndex * @return 移动成功返回 1 失败则返回 0 */ Long move(String key, int dbIndex); /** * 统计字符串的字节数 * * @param key * @return 字节数 */ Long bitcount(final String key); /** * 统计字符串指定起始位置的字节数 * * @param key * @param start * @param end * @return */ Long bitcount(final String key, long start, long end); /** * 迭代hash里面的元素 * * @param key * @param cursor * @return */ ScanResult&lt;Map.Entry&lt;String, String&gt;&gt; hscan(final String key, final String cursor); /** * 迭代set里面的元素 * * @param key * @param cursor * @return */ ScanResult&lt;String&gt; sscan(final String key, final String cursor); /** * 迭代zset里面的元素 * * @param key * @param cursor * @return */ ScanResult&lt;Tuple&gt; zscan(final String key, final String cursor);&#125;]]></content>
      <categories>
        <category>缓存</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elastic-job的原理简介和使用]]></title>
    <url>%2F2017%2F11%2F12%2Felastic-job%E7%9A%84%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[elastic-job是当当开源的一款非常好用的作业框架，在这之前，我们开发定时任务一般都是使用quartz或者spring-task（ScheduledExecutorService），无论是使用quartz还是spring-task，我们都会至少遇到两个痛点： 1.不敢轻易跟着应用服务多节点部署，可能会重复多次执行而引发系统逻辑的错误。 2.quartz的集群仅仅只是用来HA，节点数量的增加并不能给我们的每次执行效率带来提升，即不能实现水平扩展。 本篇博文将会自顶向下地介绍elastic-job，让大家认识了解并且快速搭建起环境。 elastic-job产品线说明elastic-job在2.x之后，出了两个产品线：Elastic-Job-Lite和Elastic-Job-Cloud。我们一般使用Elastic-Job-Lite就能够满足需求，本文也是以Elastic-Job-Lite为主。1.x系列对应的就只有Elastic-Job-Lite，并且在2.x里修改了一些核心类名，差别虽大，原理类似，建议使用2.x系列。写此博文，最新release版本为2.0.5。 elastic-job-lite原理举个典型的job场景，比如余额宝里的昨日收益，系统需要job在每天某个时间点开始，给所有余额宝用户计算收益。如果用户数量不多，我们可以轻易使用quartz来完成，我们让计息job在某个时间点开始执行，循环遍历所有用户计算利息，这没问题。可是，如果用户体量特别大，我们可能会面临着在第二天之前处理不完这么多用户。另外，我们部署job的时候也得注意，我们可能会把job直接放在我们的webapp里，webapp通常是多节点部署的，这样，我们的job也就是多节点，多个job同时执行，很容易造成重复执行，比如用户重复计息，为了避免这种情况，我们可能会对job的执行加锁，保证始终只有一个节点能执行，或者干脆让job从webapp里剥离出来，独自部署一个节点。elastic-job就可以帮助我们解决上面的问题，elastic底层的任务调度还是使用的quartz，通过zookeeper来动态给job节点分片。我们来看：很大体量的用户需要在特定的时间段内计息完成我们肯定是希望我们的任务可以通过集群达到水平扩展，集群里的每个节点都处理部分用户，不管用户数量有多庞大，我们只要增加机器就可以了，比如单台机器特定时间能处理n个用户，2台机器处理2n个用户，3台3n，4台4n…，再多的用户也不怕了。使用elastic-job开发的作业都是zookeeper的客户端，比如我希望3台机器跑job，我们将任务分成3片，框架通过zk的协调，最终会让3台机器分别分配到0,1,2的任务片，比如server0–&gt;0，server1–&gt;1，server2–&gt;2，当server0执行时，可以只查询id%3==0的用户，server1执行时，只查询id%3==1的用户，server2执行时，只查询id%3==2的用户。任务部署多节点引发重复执行在上面的基础上，我们再增加server3，此时，server3分不到任务分片，因为只有3片，已经分完了。没有分到任务分片的作业程序将不执行。如果此时server2挂了，那么server2的分片项会分配给server3，server3有了分片，就会替代server2执行。如果此时server3也挂了，只剩下server0和server1了，框架也会自动把server3的分片随机分配给server0或者server1，可能会这样，server0–&gt;0，server1–&gt;1,2。这种特性称之为弹性扩容，即elastic-job名称的由来。 代码演示我们搭建环境通过示例代码来演示上面的例子，elastic-job是不支持单机多实例的，通过zk的协调分片是以ip为单元的。很多同学上来可能就是通过单机多实例来学习，结果导致分片和预期不一致。这里没办法，只能通过多机器或者虚拟机，我们这里使用虚拟机，另外，由于资源有限，我们这里仅仅只模拟两台机器。 节点说明：本地宿主机器zookeeper、job192.168.241.1虚拟机job192.168.241.128环境说明：Java请使用JDK1.7及其以上版本。Zookeeper请使用Zookeeper3.4.6及其以上版本Elastic-Job-Lite2.0.5（2.x系列即可，最好是2.0.4及其以上）需求说明：通过两台机器演示动态分片 step1. 引入框架的jar包 123456789101112&lt;!-- 引入elastic-job-lite核心模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-core&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 使用springframework自定义命名空间时引入 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-spring&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt;&lt;/dependency&gt; step2. 编写job 123456789101112131415161718192021package com.fanfan.sample001;import com.dangdang.ddframe.job.api.ShardingContext;import com.dangdang.ddframe.job.api.simple.SimpleJob;import java.util.Date;/** * Created by fanfan on 2016/12/20. */public class MySimpleJob implements SimpleJob &#123; @Override public void execute(ShardingContext shardingContext) &#123; System.out.println(String.format("------Thread ID: %s, 任务总片数: %s, 当前分片项: %s", Thread.currentThread().getId(), shardingContext.getShardingTotalCount(), shardingContext.getShardingItem())); /** * 实际开发中，有了任务总片数和当前分片项，就可以对任务进行分片执行了 * 比如 SELECT * FROM user WHERE status = 0 AND MOD(id, shardingTotalCount) = shardingItem */ &#125;&#125; Step3. Spring配置 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:reg="http://www.dangdang.com/schema/ddframe/reg" xmlns:job="http://www.dangdang.com/schema/ddframe/job" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.dangdang.com/schema/ddframe/reg http://www.dangdang.com/schema/ddframe/reg/reg.xsd http://www.dangdang.com/schema/ddframe/job http://www.dangdang.com/schema/ddframe/job/job.xsd"&gt; &lt;!--配置作业注册中心 --&gt; &lt;reg:zookeeper id="regCenter" server-lists="192.168.241.1:2181" namespace="dd-job" base-sleep-time-milliseconds="1000" max-sleep-time-milliseconds="3000" max-retries="3" /&gt; &lt;!-- 配置作业--&gt; &lt;job:simple id="mySimpleJob" class="com.fanfan.sample001.MySimpleJob" registry-center-ref="regCenter" sharding-total-count="2" cron="0/2 * * * * ?" overwrite="true" /&gt;&lt;/beans&gt; Case1. 单节点 Case2. 增加一个节点 Case3. 断开一个节点 作业类型elastic-job提供了三种类型的作业：Simple类型作业、Dataflow类型作业、Script类型作业。这里主要讲解前两者。Script类型作业意为脚本类型作业，支持shell，python，perl等所有类型脚本，使用不多，可以参见github文档。SimpleJob需要实现SimpleJob接口，意为简单实现，未经过任何封装，与quartz原生接口相似，比如示例代码中所使用的job。Dataflow类型用于处理数据流，需实现DataflowJob接口。该接口提供2个方法可供覆盖，分别用于抓取(fetchData)和处理(processData)数据。可通过DataflowJobConfiguration配置是否流式处理。流式处理数据只有fetchData方法的返回值为null或集合长度为空时，作业才停止抓取，否则作业将一直运行下去； 非流式处理数据则只会在每次作业执行过程中执行一次fetchData方法和processData方法，随即完成本次作业。实际开发中，Dataflow类型的job还是很有好用的。 123456789101112131415161718192021222324252627282930313233343536373839package com.fanfan.sample001;import com.dangdang.ddframe.job.api.ShardingContext;import com.dangdang.ddframe.job.api.dataflow.DataflowJob;import java.util.ArrayList;import java.util.List;/** * Created by fanfan on 2016/12/23. */public class MyDataFlowJob implements DataflowJob&lt;User&gt; &#123; /* status 0：待处理 1：已处理 */ @Override public List&lt;User&gt; fetchData(ShardingContext shardingContext) &#123; List&lt;User&gt; users = null; /** * users = SELECT * FROM user WHERE status = 0 AND MOD(id, shardingTotalCount) = shardingItem Limit 0, 30 */ return users; &#125; @Override public void processData(ShardingContext shardingContext, List&lt;User&gt; data) &#123; for (User user: data) &#123; System.out.println(String.format("用户 %s 开始计息", user.getUserId())); user.setStatus(1); /** * update user */ &#125; &#125;&#125; 123&lt;job:dataflow id="myDataFlowJob" class="com.fanfan.sample001.MyDataFlowJob" registry-center-ref="regCenter" sharding-total-count="2" cron="0 0 02 * * ?" streaming-process="true" overwrite="true" /&gt; 其它功能上述介绍的是最精简常用的功能。elastic-job的功能集还不止这些，比如像作业事件追踪、任务监听等，另外，elastic-job-lite-console作为一个独立的运维平台还提供了用来查询和操作任务的web页面。这些增强的功能读者可以在github/elastic-job上自行学习，相信有了本篇博文的基础，再阅读那些文档就特别简单了。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>elastic-job</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cron详解]]></title>
    <url>%2F2017%2F11%2F10%2Fcron%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Cron表达式是一个字符串，字符串以5或6个空格隔开，分为6或7个域，每一个域代表一个含义，Cron有如下两种语法格式： Seconds Minutes Hours DayofMonth Month DayofWeek Year 或 Seconds Minutes Hours DayofMonth Month DayofWeek 每一个域可出现的字符如下：Seconds:可出现”, - /“四个字符，有效范围为0-59的整数Minutes:可出现”, - /“四个字符，有效范围为0-59的整数Hours:可出现”, - /“四个字符，有效范围为0-23的整数DayofMonth:可出现”, - / ? L W C”八个字符，有效范围为0-31的整数Month:可出现”, - /“四个字符，有效范围为1-12的整数或JAN-DEcDayofWeek:可出现”, - / ? L C #”四个字符，有效范围为1-7的整数或SUN-SAT两个范围。1表示星期天，2表示星期一， 依次类推Year:可出现”, - * /“四个字符，有效范围为1970-2099年 每一个域都使用数字，但还可以出现如下特殊字符，它们的含义是：(1)：表示匹配该域的任意值，假如在Minutes域使用, 即表示每分钟都会触发事件。 (2)?:只能用在DayofMonth和DayofWeek两个域。它也匹配域的任意值，但实际不会。因为DayofMonth和 DayofWeek会相互影响。例如想在每月的20日触发调度，不管20日到底是星期几，则只能使用如下写法： 13 13 15 20 ?, 其中最后一位只能用？，而不能使用，如果使用*表示不管星期几都会触发，实际上并不是这样。(3)-:表示范围，例如在Minutes域使用5-20，表示从5分到20分钟每分钟触发一次(4)/：表示起始时间开始触发，然后每隔固定时间触发一次，例如在Minutes域使用5/20,则意味着5分钟触发一次，而25，45等分别触发一次.(5),:表示列出枚举值值。例如：在Minutes域使用5,20，则意味着在5和20分每分钟触发一次。(6)L:表示最后，只能出现在DayofWeek和DayofMonth域，如果在DayofWeek域使用5L,意味着在最后的一个星期四触发。(7)W: 表示有效工作日(周一到周五),只能出现在DayofMonth域，系统将在离指定日期的最近的有效工作日触发事件。例如：在 DayofMonth使用5W，如果5日是星期六，则将在最近的工作日：星期五，即4日触发。如果5日是星期天，则在6日(周一)触发；如果5日在星期一 到星期五中的一天，则就在5日触发。另外一点，W的最近寻找不会跨过月份(8)LW:这两个字符可以连用，表示在某个月最后一个工作日，即最后一个星期五。(9)#:用于确定每个月第几个星期几，只能出现在DayofMonth域。例如在4#2，表示某月的第二个星期三。 举几个例子:0 0 2 1 ? 表示在每月的1日的凌晨2点调度任务0 15 10 ? * MON-FRI 表示周一到周五每天上午10：15执行作业0 15 10 ? 6L 2002-2006 表示2002-2006年的每个月的最后一个星期五上午10:15执行作]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git 教程]]></title>
    <url>%2F2017%2F11%2F08%2FGit-%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[配置作者邮件1234 git config --global --edit git config --global user.name "your name"git config --global user.email "your email" 回退到某次commit，提交远程分支123456789101112查看commit idgit loggit log --pretty=oneline本地回退git reset --hard commit_idgit reset --hard HEAD^ 回退到上个版本强推到远程：git push origin HEAD --forcegit push -f HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令 git reset --hard commit_id。 git reset --hard HEAD^ 穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。 git log --pretty=oneline 要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 git reflog 本地分支被远程覆盖123git fetch --allgit reset --hard origin/master (这里master要修改为对应的分支名)git pull git 同步github上fork的项目123456git checkout mastergit remote -vgit remote add leader git@github.com:MyCATApache/tcp-proxy.gitgit fetch leadergit merge leader/mastergit push origin master 同步远程服务器，本地复制一份origin git fetch origin 建立本地分支 dev -&gt; origin/dev git checkout -b dev origin/dev git checkout -b [分支名] [远程名]/[分支名]。 如果你有 1.6.2 以上版本的 Git，还可以用 –track 选项简化： $ git checkout --track origin/serverfix 创建分支(remeber) git branch iss53 checkout分支(remeber) git checkout iss53 创建并checkout分支 git branch -b iss53 查看所有分支 git branch -a 推送本地分支到服务器分支git push [远程名] [本地分支]:[远程分支] 删除远程分支 git branch -r -d origin/branch-name git push origin :branch-name 删除本地分支git branch -d iss53 当你在 master 下 $ git pull # 等于 fetch origin，然后 merge origin/master 当你在 develop 下 $ git pull # 等于 fetch origin，然后 merge origin/develop 在master分支中 $ git checkout -b hotfix $ vim index.html $ git commit -a -m &apos;fixed the broken email address&apos; $ git checkout master $ git merge hotfix $ git branch -d hotfix git checkout iss53 Vim index.html Git commit -a -m ‘your message’ git merge master. 可以合并master中hotfix的更新 git checkout master git merge iss53 可以用git status查看合并产生冲突的文件 git add表示解决，保存到暂存区，再git commit即可 git branch -d is53 相比git reset，它不会改变现在的提交历史。因此，git revert可以用在公共分支上，git reset应该用在私有分支上。你也可以把git revert当作撤销已经提交的更改，而git reset HEAD用来撤销没有提交的更改。就像git checkout 一样，git revert 也有可能会重写文件。所以，Git会在你执行revert之前要求你提交或者缓存你工作目录中的更改。 强制重写本地master分支 git fetch origin master git reset --hard FETCH_HEAD git clean -df 强制删除远程分支的某个文件 git rm --cached --force .idea/libraries/Maven__org_springframework_spring_core_4_1_6_RELEASE.xml ​​ git 修改remote地址12345678 方法有三种：1.修改命令git remote set-url origin [url]例如：Git remote set-url origin gitlab@gitlab.chumob.com:PHP/hasoffer.git2.先删后加git remote rm origingit remote add origin [url]3.直接修改config文件 git diff旧的在前，新的在后 git diff d1afe9 b588527d &gt; ~/Desktop/patch.diff git apply --reject ~/Desktop/patch.diff $ git diff 608e120 4abe32e --name-only $ git diff 608e120 4abe32e --name-only | xargs zip update.zip git mergetool12345678910下载diffmerge（http://download.sourcegear.com/DiffMerge/4.2.1/DiffMerge.4.2.1.1013.intel.stable.pkg）配置git确保/usr/local/bin/diffmerge存在，若不存在，建立符号链接（ln /Applications/DiffMerge.app/Contents/MacOS/DiffMerge /usr/local/bin/diffmerge）git config --global diff.tool diffmergegit config --global difftool.diffmerge.cmd "/usr/local/bin/diffmerge \"\$LOCAL\" \"\$REMOTE\""git config --global merge.tool diffmergegit config --global mergetool.diffmerge.trustExitCode truegit config --global mergetool.diffmerge.cmd "/usr/local/bin/diffmerge --merge --result=\"\$MERGED\" \"\$LOCAL\" \"\$BASE\" \"\$REMOTE\""冲突发生后使用 git mergetool 进行merge git tag$ git tag -a v1.4 -m &apos;my version 1.4&apos; $ git tag v0.1 v1.3 v1.4 git mergeGit merge –no-ff 可以保存你之前的分支历史。能够更好的查看 merge历史，以及branch 状态。 git merge 则不会显示 feature，只保留单条分支记录。 ####添加子项目12345git submodule add --name tools --force http://git.zenzet.com/lss-server/lss-data-mining-toolscd toolsgit submodule initgit submodule updategit clone --recursive https://github.com/chaconinc/MainProject git stash git stash 保存当前的工作进度。会分别对暂存区和工作区的状态进行保存 git stash save “message…” 这条命令实际上是第一条 git stash 命令的完整版 git stash list 显示进度列表。此命令显然暗示了git stash 可以多次保存工作进度，并用在恢复时候进行选择 git stash pop [–index] [] 如果不使用任何参数，会恢复最新保存的工作进度，并将恢复的工作进度从存储的工作进度列表中清除。 如果提供参数（来自 git stash list 显示的列表），则从该 &lt;stash&gt; 中恢复。恢复完毕也将从进度列表中删除 &lt;stash&gt;。 选项–index 除了恢复工作区的文件外，还尝试恢复暂存区。 git stash apply [–index] [] 除了不删除恢复的进度之外，其余和 git stash pop 命令一样 git stash clear 删除所有存储的进度 123456789101112131415git stash [save message] [-k|--no-keep-index] [--patch]这是git stash保存进度的完整命令形式使用save可以对进度添加备注# git stash save "这是保存的进度"git stash apply stash@&#123;2&#125;现在执行list，会发现后面会出现自定义的被合租# git stash liststash@&#123;0&#125;: On master: 这是保存的进度-k和--no-keep-index指定保存进度后，是否重置暂存区--patch 会显示工作区和HEAD的差异,通过编辑差异文件，排除不需要保存的内容。和git add -p命令类似 123456789git stash 对当前的暂存区和工作区状态进行保存。git stash list 列出所有保存的进度列表。git stash pop [--index] [&lt;stash&gt;] 恢复工作进度--index 参数：不仅恢复工作区，还恢复暂存区&lt;stash&gt; 指定恢复某一个具体进度。如果没有这个参数，默认恢复最新进度如：以下命令恢复编号为0的进度的工作区和暂存区# git stash pop --index stash@&#123;0&#125; git rebase在使用 Git 作为版本控制的时候，我们可能会由于各种各样的原因提交了许多临时的 commit，而这些 commit 拼接起来才是完整的任务。那么我们为了避免太多的 commit 而造成版本控制的混乱，通常我们推荐将这些 commit 合并成一个。 1,查看提交历史，git log 首先你要知道自己想合并的是哪几个提交，可以使用git log命令来查看提交历史，假如最近4条历史如下： 1234567commit 3ca6ec340edc66df13423f36f52919dfa3......commit 1b4056686d1b494a5c86757f9eaed844......commit 53f244ac8730d33b353bee3b24210b07......commit 3a4226b4a0b6fa68783b07f1cee7b688....... 历史记录是按照时间排序的，时间近的排在前面。 2,git rebase 想要合并1-3条，有两个方法 1.从HEAD版本开始往过去数3个版本 1git rebase -i HEAD~3 2.指名要合并的版本之前的版本号 1git rebase -i 3a4226b 请注意3a4226b这个版本是不参与合并的，可以把它当做一个坐标 3,选取要合并的提交 1.执行了rebase命令之后，会弹出一个窗口，头几行如下： 12345pick 3ca6ec3 '注释**********'pick 1b40566 '注释*********'pick 53f244a '注释**********' 2.将pick改为squash或者s,之后保存并关闭文本编辑窗口即可。改完之后文本内容如下： 12345pick 3ca6ec3 '注释**********'s 1b40566 '注释*********'s 53f244a '注释**********' 3.然后保存退出，Git会压缩提交历史，如果有冲突，需要修改，修改的时候要注意，保留最新的历史，不然我们的修改就丢弃了。修改以后要记得敲下面的命令： 123git add .git rebase --continue 如果你想放弃这次压缩的话，执行以下命令： 1git rebase --abort 4.如果没有冲突，或者冲突已经解决，则会出现如下的编辑窗口： 12345678# This is a combination of 4 commits.#The first commit’s message is:注释......# The 2nd commit’s message is:注释......# The 3rd commit’s message is:注释......# Please enter the commit message for your changes. Lines starting # with ‘#’ will be ignored, and an empty message aborts the commit. 5.输入wq保存并推出, 再次输入git log查看 commit 历史信息，你会发现这两个 commit 已经合并了。 git review 获取当前分支 1git symbolic-ref -q --short HEAD 在git别名里使用shell函数，$1获取第一个参数的值，$2……$n依次类推，根据自己习惯需要定制 提交review的正确语句是： git push origin HEAD:refs/for/destination_branch 意思是—把当前分支的代码推送到远程origin仓库的review分支destination_branch上去 ​ origin表示远程git服务器地址；HEAD表示当前分支；refs/for/destination_branch 表示远程review分支 下面配置的含义： 执行git review等价于git push origin HEAD:refs/for/current_branch 执行git review destination_branch等价于git push origin HEAD:refs/for/destination_branch 1`review = ``"!f() &#123; if [ -z $1 ];then currBra=`git symbolic-ref -q --short HEAD`;else currBra=$1;fi;git push origin HEAD:refs/for/$currBra; &#125;; f"` 全部配置： 1`[core]`` ``repositoryformatversion = ``0`` ``filemode = ``true`` ``bare = ``false`` ``logallrefupdates = ``true`` ``ignorecase = ``true`` ``precomposeunicode = ``true``[remote ``"origin"``]`` ``url = ssh:``//depu.shen@gerrit.tongdun.me:29418/ganghui.zeng/gerrit_test`` ``fetch = +refs/heads/*:refs/remotes/origin/*``[branch ``"master"``]`` ``remote = origin`` ``merge = refs/heads/master``[branch ``"gerrit_test1811052223a"``]`` ``remote = origin`` ``merge = refs/heads/gerrit_test1811052223``[branch ``"gerrit_test1811052223"``]`` ``remote = origin`` ``merge = refs/heads/gerrit_test1811052223``[alias]`` ``st = status`` ``review = ``"!f() &#123; if [ -z $1 ];then currBra=`git symbolic-ref -q --short HEAD`;else currBra=$1;fi;git push origin HEAD:refs/for/$currBra; &#125;; f"` 配置生效的地方，优先级由高到底： 项目配置，位于项目下的.git/config 查看git config –local –list 编辑git config –local -e 某个用户下的所有项目配置：~/.gitconfig 查看git config –global –list 编辑git config –global -e 当前系统下的所有用户所有项目配置：/etc/gitconfig 查看git config –system –list 编辑git config –system -e https://hellomin.github.io/2018/09/11/%E5%8F%AF%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E7%9A%84Git%E5%88%AB%E5%90%8D/ git diff1、工作区和本地版本库对比 git diff HEAD 查看工作区和版本库里面最新版本的所有文件的区别 git diff HEAD – file1查看工作区和版本库里面最新版本的文件file1的区别 git diff HEAD^ 查看工作区和版本库里面上个版本的所有文件的区别 git diff commitId – ./lib 查看当前工作区和某个历史版本commitId的目录lib的区别 2、暂存区和本地版本库对比 git diff –cached 查看暂存区和本地版本库最新版本所有文件的区别 git diff –cached – file1 查看暂存区和本地版本库最新版本文件file1的区别 git diff –cached commitId file1 查看已经 add 进暂存区但是尚未 commit 的内容同某一次 commit 时的内容的差异 也可以使用git diff –staged 3、工作去和暂存区对比 git diff 查看工作区和暂存区两个版本所有文件的区别 git diff – file1 查看工作区和暂存区两个版本文件file1的区别 4、比较两个历史版本直接的区别 git dff commitId1 commitId2 比较两个历史版本之间的区别 git diff commitId1:file1 commidId2:file2 比较两个历史版本之间文件的区别 5、输出自topic和master分别开发以来，master分支上的changed。 ​ git diff topic…master Changes that occurred on the master branch since when the topic branch was started off it git diff显示内容解读：http://www.ruanyifeng.com/blog/2012/08/how_to_read_diff.html git resetgit reset HEAD file 使暂存区和本地版本库保持一致，工作区不受影响。可以理解位git add的反操作 git reset –hard xxx 使工作区和当地版本库保持一致，也就是丢弃你在工作区做的工作(还没有提交到当地版本库的内容) xxx可以是：HEAD表示当前版本，HEAD^表示上一个版本，HEAD^^表示上上个版本，HEAD~10表示上10个版本；也可以是commitId 如图所示，本地修改了两个文件，现在想恢复文件，如果想一次性完成，使用命令git reset –hard HEAD,直接从当地版本库恢复，用版本库的内容覆盖工作区，这种操作只能对所有文件操作，不能针对单个文件操作。如果想恢复单个文件或多个文件，使用命令git checkout – a.txt b.txt。 这类操作要慎重，一旦完成，就会丢弃之前的修改，无法恢复 git checkoutgit checkout – file 保持工作区和暂存区文件内容一致，以暂存区为模板，撤销工作区的修改 git status结果如图，表示暂存区的内容和版本库的内容一致，所以git diff –cached时，暂存区和本地版本库内容一致，没有差异。 当通过git add file1往暂存区添加文件file1时，暂存区就比本地版本库多了个文件file1的更改。 所以要理解，下图并不是说暂存区是空的，只是说明暂存区相对于本地版本库没有差异，即和版本库内容一致 git stash：https://gist.github.com/subchen/3409a16cb46327ca7691保存当前的工作进度，切换到其他分支继续工作，然后切回原来的分支，恢复之前的工作 git stash list查看当前存储的临时状态。 git stash pop –index 1恢复相应存储区的内容，同时从这个存储区删除这个存储。 下图index值分别为0、1 注意：多个分支切换时，要恢复相应的存储区内容，指定相应的索引值恢复。只使用命令git stash pop有可能恢复成其他分支的工作。当然，也可以通过这样的方式把其他分支的工作状态复制到当前分支。 分支重命名git branch -M new_branch_name git branch -m old_name new_name 使用git status命令查看：可以知道本地的分支比本地的远程分支多了一次提交。使用git pull（git fetch+ git merge）拉取远程分支，并试图合并本地分支和刚刚更新的存储在本地的远程分支时，出现冲突 下图表示从本地和远程的共同父提交算起，本地有一次提交，远程分支有三次提交 更加上图的状态，这里其实使用git merge更为准确。 到这一步，你可以取消这次git merge操作：git merge –abort。或者解决冲突后commit，然后git push HEAD:refs/for/xxx_branch重新提交review git branch 新建分支：git branch branch_name: 以当前分支的最后一次提交作为新建分支的最后一次提交，就是当前分支的复制，提交历史/版本历史的复制 git branch branch_name commitId：以当前分支的某一次提交作为新建分支的最后一次提交，就是当前分支某次提交及之前提交历史的复制。方便从任何一个提交点检出一个新的分支。 这个功能很好用，比如我们在当前分支开发了一个新功能，但是又想尝试这个功能的另一种实现方法，此时，我们就可以从新功能提交的前一次提交的地方检出一个新的分支，重新开发，而不必把当前已经开发的新功能修改为另一种实现。 # 批量修改commit里面的用户信息和提交者信息以下代码可以修改所有commit的Author邮箱：git filter-branch –env-filter ‘export GIT_AUTHOR_EMAIL=new_author_email’ –。效果惊人哦 除了GIT_AUTHOR_EMAIL, 还有GIT_AUTHOR_NAME, GIT_COMMITTER_EMAIL, GIT_COMMITTER_NAME等参数可以修改. 谨慎操作：对于已经提交的修改，会造成本地分支和远程分支存在分歧 git checkout 切换分支或者新建分支git checkout branch_name 切换到已经创建的分支上 git checkout commitId 切换到某次提交上，记得切换后的状态是个临时状态，你所做的所有修改如果不保存到某个分支上，当你切换到其他分支时，就可能丢失。 防止丢失的方法是： 1、切换前执行命令 git branch branch_name，等于对当前的提交历史复制一份，新分支备份后，仍然在当前临时分支操作 2、切换前执行命令 git checkout -b branch_name, 等于对当前的提交历史复制一份，并同时切换到新分支 3、切换后执行命令 git branch branch_name commitId，其中commitId是切换前分支的最后一次提交commitId，切换后，命令行会提示给你：如下图所示的“6c91c0a” git checkout -b branch_name 新建分支，并切换到这个分支，新分支相当于原来分支的一个副本 git checkout -b branch_name commitId 新建分支，并切换到这个分支，新分支相当于原来分支从某次提交开始往前的所有提交历史的一个副本 另外需要注意的是：当我们在一个分支上修改完，如果没有git add/git commit提交后，或者git stash保持当前状态，是无法进行分支切换的。当时对于临时分支是可以的，而且会把历史分支的修改带到切换后的分支上，更加有意思的是，可以把修改带到任何一个其他已经存在的分支或者某一次提交commitId上或者新建的分支上 git checkout – file1 检查文件file1，注意格式 “–” 作用是明显的，因为如果存在和file1同名的分支，那么会被认为是切换分支操作，而不是检出文件操作。如图：同时存在文件test和分支test git checkout commitId – test 检查某个文件某次提交时的内容。这个功能挺有用的，比如我们开发了很久，中间提交了多次，然后忽然发现某个文件修改错了，那么就可以把这个文件恢复到以前某次提交的状态，而不用修改其他文件的修改。旧的文件版本会显示为「需要提交的更改」，允许你回滚到文件之前的版本。 参考：https://github.com/geeeeeeeeek/git-recipes/wiki/2.5-%E6%A3%80%E5%87%BA%E4%B9%8B%E5%89%8D%E7%9A%84%E6%8F%90%E4%BA%A4 git log格式化Log输出：git log –oneline 只显示提交ID和提交信息的第一行 git log –decorate 很多时候，知道每个提交关联的分支或者标签很有用。--decorate 标记让 git log 显示指向这个提交的所有引用（比如说分支、标签等） git log –all 显示所有分支的提交 git log –stat / git log -p 提供了很多选项来显示两个提交之间的差异。其中最常用的两个是 --stat 和 -p。 git shortlog 是一种特殊的 git log，它是为创建发布声明设计的。它把每个提交按作者分类，显示提交信息的第一行。这样可以容易地看到谁做了什么。 git log --graph 选项绘制一个 ASCII 图像来展示提交历史的分支结构。它经常和 --oneline 和 --decorate 两个选项一起使用，这样会更容易查看哪个提交属于哪个分支： git log branch_name/comitId 显示某个分支或者某个提交的log 过滤提交历史1234git log -3 只显示最新的3次提交git log --after="2014-7-1" --before="2014-7-4"git log --author="John"git log -- foo.py bar.py `` 1git log master..feature 其中的 master..feature 范围包含了在 feature 分支而不在 master 分支中所有的提交。换句话说，这个命令可以看出从 master 分支 fork 到 feature 分支后发生了哪些变化 过滤合并提交git log 输出时默认包括合并提交。但是，如果你的团队采用强制合并策略（意思是 merge 你修改的上游分支而不是将你的分支 rebase 到上游分支），你的项目历史中会有很多外来的提交。 你可以通过 --no-merges 标记来排除这些提交： 1git log --no-merges 另一方面，如果你只对合并提交感兴趣，你可以使用 --merges 标记： 1git log --merges 它会返回所有包含两个父节点的提交。 1git log --graph --decorate --oneline --simplify-by-decoration --all 说明： –decorate 标记会让git log显示每个commit的引用(如:分支、tag等) –oneline 一行显示 –simplify-by-decoration 只显示被branch或tag引用的commit –all 表示显示所有的branch，这里也可以选择，比如我只想显示分支ABC的关系，则将–all替换为branchA branchB branchC git界面git gui gitk不按照时间排序的提交 gitk -d不按照时间排序的提交 参考：https://github.com/geeeeeeeeek/git-recipes/wiki/5.3-Git-log-%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95 git rebase# git rebase -i HEAD~3 对最近三次的提交历史进行变基 这里顺带讲下每次commit的意思：每次commit都记录了这次commit(或者这个版本)所做的更改，如果删除了某次的commit，那么这次commit所做的更改就会丢失。举个例子： 创建并编写文件1.txt的内容，git add 1.txt，git commit -m ‘add 1.txt and edit it’，产生commitId1 创建并编写文件2.txt的内容，git add 2.txt，git commit -m ‘add 2.txt and edit it’，产生commitId2 修改文件1.txt的内容，git commit -am ‘modify 1.txt’，产生commitId3 执行命令git rebase -i HEAD~3，删除前两次提交commitId1和commitId2，结果就是：2.txt文件直接被删除，但是1.txt存在冲突，原因是commitId1的时候创建了，那么删除这个commitId1的时候，自然也会把这个文件删除，可以是commitId3的时候又修改了这个文件，而且并没有删除commitId3，因此存在修改了一个已经删除的文件的冲突 查看状态：解决办法有两种，一种是git rebase –skip丢弃commitId3所做的修改，这样1.txt文件也被删除；另一种是git add 1.txt，这样commitId1创建并修改的1.txt的内容和commitId3修改的内容都会保留下来。你可以根据提示使用命令git reset HEAD 1.txt和命令git rm 1.txt解决冲突，效果是，git reset HEAD 1.txt保留了文件1.txt以及1.txt的内容在工作区。git rm 1.txt则是删除了1.txt文件。 所有使用命令git rebase -i HEAD~n时慎重使用选项d, drop = remove commit，会删除提交历史里的文件以及修改内容。产生破坏，除非你清楚你在做什么。 选项s, squash = use commit, but meld into previous commit的作用是合并历史提交，把多个commitId合并位一个，减少无用commitId的数量。保留被合并提交的提交信息内容。 选项f, fixup = like ‘squash’, but discard this commit’s log message的作用是合并历史提交，把多个commitId合并位一个，减少无用commitId的数量。和squash的区别是，不保存被合并的提交的提交信息内容，直接删除。 另外git rebase -i HEAD~n会重新对涉及的commitId值进行修改 git showgit show commitId 显示某一次提交的内容 git diff commitId^! 显示某一次提交的内容 git log -p -n 查看最近n次提交的修改 git update-refgit update-ref refs/heads/test cac0ca 使分支test指向commitId=cac0ca 有点git reset cac0ca的效果 git symbolic-ref有点git checkout branch_name 切换分支的感觉 git symbolic-ref HEAD refs/heads/test 把HEAD里的内容变为refs/heads/test git cherry-pickgit cherry-pick commitId 把某个分支的某次提交的内容合并到当前分支 git cherry-pick -m 1 commitId 把某个分支的某次合并提交的内容合并到当前分支。意思是commitId有merge操作，如下图所示，详细介绍参考：https://segmentfault.com/q/1010000010185984；https://blog.csdn.net/zhangxiaoyang0/article/details/79299203 git rev-parsegit rev-parse –git-dir 显示版本库.git目录所在位置git rev-parse –show-toplevel 显示工作区根目录git rev-parse –show-prefix 所在目录相对于工作区根目录的相对目录git rev-parse –show-cdup 显示从当前目录后退到工作区的根的身度 12git rev-parse origin/ivs180926115904^&#123;commit&#125;git rev-parse ivs180926115904^&#123;commit&#125; 如果你想知道某个分支指向哪个特定的 SHA，或者想看任何一个例子中被简写的 SHA-1，你可以使用一个叫做 rev-parse 的 Git 探测工具。简单来说，rev-parse 是为了底层操作而不是日常操作设计的。不过，有时你想看 Git 现在到底处于什么状态时，它可能会很有用。这里你可以对你的分支运执行 rev-parse。 12$ git rev-parse topic1ca82a6dff817ec66f44342007202690a93763949 git grepgit grep –help git grep -in www在当前仓库所有文件中搜索内容‘wwww’，-i表示忽略大小写，-n表示显示搜索内容所在的行 12git ``grep` `--name-only www 搜索到的内容只显示文件名git ``grep` `-c www 显示搜索到的内容的匹配的个数 git grep www commit_id 针对某个版本进行搜索 123git ``grep` `-e 内容1 --and/--or -e 内容2 条件搜索git ``grep` `-e 内容1 --and \( -e ant -e 内容2 \)git ``grep` `--all-match -e 内容1 --or -e 内容2 --all-match表示全匹配， 全匹配和普通匹配的区别在于，全匹配必须在全文满足指定的条件。如果是全匹配，那么必须在文件中，同时具有”内容1”和”内容2”（没要同一行）。而普通匹配，只要在文件中具有”内容1”或者”内容2”中的一个即可。 http://www.softwhy.com/article-8652-1.html git cat-file -p hash_id查看某次hash值得内容 git ls-tree commit_id查看某次提交包含的内容的hash值]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件系统快捷键]]></title>
    <url>%2F2017%2F11%2F08%2FMac%E7%AC%94%E8%AE%B0%E6%9C%AC%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[mac系统12Command + K 清屏Control + C 退出命令 123456789101112131415161718⌘ Command⇧ Shift⌥ Option⌃ Control↩︎ Return/Enter⌫ Delete⌦ 向前删除键（Fn+Delete）↑ 上箭头↓ 下箭头← 左箭头→ 右箭头⇞ Page Up（Fn+↑）⇟ Page Down（Fn+↓）Home Fn + ←End Fn + →⇥ 右制表符（Tab键）⇤ 左制表符（Shift+Tab）⎋ Escape (Esc) chrome快捷键(mac)12command + R 刷新command shift R 强制刷新]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 命令]]></title>
    <url>%2F2017%2F11%2F08%2Fjava-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[12java -jar 启动jar包 指定spring profilejava -jar microservice-discovery-eureka-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOSX10.5+快捷键整理-重要]]></title>
    <url>%2F2017%2F11%2F05%2FMacOSX10.5%2B%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%95%B4%E7%90%86-%E9%87%8D%E8%A6%81%2F</url>
    <content type="text"><![CDATA[代码编辑(重要的，优先级高)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 1. shift 配合左右键，用于选中 2. Control M 移动到括号的开始结束 3. Alter command [ ] 移动到代码块的开始和结束 , 再加上shift可以选中字符 4 command 加上左右键，移动到行的结束或开头。带上shift可以选中字符 5 Alter 加上左右键，移动到上一下或下一个单词。带上shift可以选择字符 Shitft command u 切换大小写 alter command u 切换驼峰 toggle camel case command N 生成mapper及dao command alter T 生成try catch代码块 command L 跳到指定行 Alt + F8 计算变量表达式 1.Alt+⬆️/⬇️ ---------------- 选中代码 2.option+shift +⬆️/⬇️ -------------- 上下移动代码行 shitft command + 上下移动选中的代码 3.cmd+d -------------- 复制当前行到下一行- ⇞ Page Up（Fn+↑）- ⇟ Page Down（Fn+↓） 二 代码的移动 1.Alt+⬆️/⬇️ ---------------- 选中代码 2.option+shift +⬆️/⬇️ -------------- 上下移动代码 3.cmd+d -------------- 复制当前行到下一行 4.cmd+x -------------- 剪切 5.ctrl+k -------------- 删除行 6.cmd+option+l ------------- 格式化代码 7.ctrl+alt+o -------------- 清除无效的引用包 三 代码注释 1.cmd+/ --------------- 单行注释 2.cmd+option+/ ------------- 多行注释 3.ctrl+alt+/ ------------ 为方法或变量添加注释说明(个人设置的,大家根据自己习惯自行设置) 四 代码查看 1.cmd+f ----------- 查找 2.cmd+r ----------- 查找/替换 3.ctrl+o ----------- 查看该类中可以重写的方法 4.cmd+y ------------ 查看方法的方法体，在预览框中显示 5.cmd+⬅️/→ ---------- 快捷定位到行首和行尾 6.cmd+/- ----------- 展开或者折叠 7.ctrl+option+h ----------- 跟踪某个方法被调用的位置 8.cmd+option_⬅️ ------------ 代码返回(查看之前看的位置) 9.ctrl+h ----------- 查看结构类图 10.cmd+alt+b --------- 查看当前类的实现类 11.⌘O:在当前project(一个project可以含多个moudle)中搜索class,再按一次⌘O，搜索结果可包含非project中的class，如external libraries中的android.jar里的class可以在搜索文本后跟:lineNumber 从而定位到某行. 12.⌘O:在当前project(一个project可以含多个moudle)中搜索class,再按一次⌘O，搜索结果可包含非project中的class，如external libraries中的android.jar里的class可以在搜索文本后跟:lineNumber,从而定位到某行. 13.⇧⌘O:在当前project中搜索file(包含上面的class结果),再按一次⇧⌘O,搜索结果可包含非project中的flie，如external libraries中的res里的file可以在搜索文本后跟:lineNumber,从而定位到某行. 14.⌥⌘O:在当前project中搜索file(包含上面的class、file结果及method) 五 代码生成 1.cmd+n 快捷生成 get/set方法 构造器等 2.cmd+j 代码模板生成(if for foreach findViewById VIew.Gone Toast 等) 3.cmd+t try_catch if_else for 等自动生成 六 其他 1.cmd+shift+u ------------ 大小写格式化 2.ctrl+d ------------ debug 调试APP 3.ctrl+r ------------ run APP 4.ctrl+v ------------ 版本控制 1.代码相关：1.删除当前行 command+delete/command+x2.复制当前行 command+d3.移动当前行 shift+command+↑4.查找变量使用的地方 alt+f75.生成try/catch代码 alt+command+f76.跳至上方(父类)的层级 common+u7.跳至下方(子类)的层级 alt+commond+b8.查找选中的字符在工程中出现的地方 command+alt+f79.选中文本，高亮显示所有该文本，按Esc高亮消失 command+shift+F710.出现生成get,set方法的界面 ctrl+enter11.在当前文件中替换 commond+r12.在整个工程中替换 commond+shift+r13.把多行连接成一行，会去掉空格的行 control+shift+J14.导入包，自动修改 alt+enter15.格式化代码 command+alt+L16.大小写转换 command+shift+U17.注释/取消一行或着多行 command+/18.注释/…/或取消 command+alt+/19.返回最左边最右边 command+左右箭头20.调出IDEA的神器live template commond+J21.调出IDEA寄存器中保存的最近复制的N份内容，可选择性粘贴 shift + cmd + v22.神器，补全当前行，最常用的场景时补全当前行后的；号，并将光标定位到下一行 shift + cmd + enter 2.文件相关：1.查找文件 shift+shift2.显示当前文件的结构 Cmd+F123.跳转到导航栏，查看项目树 Cmd+向上键4.查看有关所有实现或者覆写了当前方法的类的结构图 shift+commond+h5.最近编辑过的文件 shift+commond+e6.显示最近打开的文件 command + E7.添加书签 F38.显示书签 command + F3 9.移动文件到其它地方 F610.拷贝文件到其它地方 F511.新建文件（选中根目录） commond+N12.选中文件来重命名 shift+f6 3.界面窗口相关：1.隐藏当前视图 shift ＋ esc2.调出setting界面 cmd + ,3.调出项目setting界面 cmd + ;4.关闭当前文件 commond+w5.退出Idea commond+Q6.万能快捷键：shift + command + A（适用于不知道快捷键，但是知道操作的部分动作。如，输入”open”会列出一系列和打开相关的操作。） mac 键盘符号 ⌘ Command ⇧ Shift ⌥ Option ⌃ Control ↩︎ Return/Enter ⌫ Delete ⌦ 向前删除键（Fn+Delete） ↑ 上箭头 ↓ 下箭头 ← 左箭头 → 右箭头 ⇞ Page Up（Fn+↑） ⇟ Page Down（Fn+↓） Home Fn + ← End Fn + → ⇥ 右制表符（Tab键） ⇤ 左制表符（Shift+Tab） ⎋ Escape (Esc)]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac chrome 快捷键]]></title>
    <url>%2F2017%2F08%2F29%2Fmac-chrome%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[12345678910111213141516⌘-Shift-J 打开“下载内容”页。⌘-Shift-Delete 打开“清除浏览数据”对话框。⌘-R 重新载入当前网页。⌘-, 停止载入当前网页。⌘-Option-I 打开“开发人员工具”。⌘-Option-J 打开“JavaScript 控制台”。⌘-Option-U 打开当前网页的源代码。⌘-D 将当前网页保存为书签。⌘-Shift-D 将所有打开的标签页以书签的形式保存在新文件夹中。⌘-Shift-F 在全屏模式下打开网页。再按一次 ⌘-Shift-F 可退出全屏模式。⌘-+ 放大网页上的所有内容。⌘ 和 - 缩小网页上的所有内容。⌘-0 将网页上的所有内容恢复到正常大小。⌘-Shift-H 在当前标签页中打开主页。空格键 向下滚动网页。⌘-Option-F 搜索网页。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS 教程]]></title>
    <url>%2F2017%2F08%2F23%2FAngularJS%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[新建前端项目1234567891011121314cnpm install -g @angular/cliwebstrom new empty project 601 ng new demo --skip-install --style=sass --routing 604 ls 605 cd demo 606 ls 608 cnpm install 609 ls 611 ng serve 612 ls 613 cd demo 614 ls 615 ng serve 常用指令12345ng-app 指令初始化一个 AngularJS 应用程序。ng-init 指令初始化应用程序数据。ng-model 指令把元素值（比如输入域的值）绑定到应用程序。&#123;&#123;4*5&#125;&#125; 表达式ng-repeat 重复元素 自定义指令使用驼峰法来命名一个指令， 但在使用它时需要以 - 分割 123456789101112131415161718&lt;runoob-directive&gt;&lt;/runoob-directive&gt;&lt;script&gt;var app = angular.module("myApp", []);app.directive("runoobDirective", function() &#123; return &#123; restrict : "A", template : "&lt;h1&gt;自定义指令!&lt;/h1&gt;" &#125;;&#125;);&lt;/script&gt;restrict 值可以是以下几种:E 作为元素名使用A 作为属性使用C 作为类名使用M 作为注释使用restrict 默认值为 EA, 即可以通过元素名和属性名来调用指令。]]></content>
      <tags>
        <tag>AngularJS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime mac快捷键]]></title>
    <url>%2F2017%2F08%2F16%2FSublime%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[json format 1cmd+ctrl+j package install 123按下CTRL + SHIFT + P并且输入Package Control: Install Package再输入Pretty JSON，按下ENTER完成安裝 查找文件名 1cmd + P]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法相关(java)]]></title>
    <url>%2F2017%2F08%2F10%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3(java)%2F</url>
    <content type="text"><![CDATA[常见的内部排序算法插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等123456789101112131415161718192021public class SortingDemo &#123; public static void main(String[] args) &#123; /* 简单排序 */ EasySort.bubbleList();// 冒泡 EasySort.bubbleArray();// 冒泡 EasySort.xuanze();// 选择 EasySort.charu();// 插入 /* 高效排序 */ QuickSort.quickSort();// 快排 MergeSort.mergeSort();// 归并排序(分治递归思想) ShellSort.shellSort();// 希尔排序(插入排序的一种高效率的实现，也叫缩小增量排序) // 堆排序(升序排序就使用大顶堆，反之使用小顶堆) /* 线性排序 */ // 计数排序 // 桶排序 // 基数排序 &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/*** 简单排序*/class EasySort &#123; /** * 冒泡排序 List * &lt;p&gt; * 算法思想：遍历待排序的数组，每次遍历比较相邻的两个元素，如果他们的排列顺序错误就交换他们的位置， * 经过一趟排序后，最大的元素会浮置数组的末端。重复操作，直到排序完成。 */ static void bubbleList() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); Collections.shuffle(list);// list随机打乱 System.out.println(list); for (int i = 0; i &lt; list.size(); i++) &#123; for (int j = 0; j &lt; list.size() - 1 - i; j++) &#123; int current = list.get(j); int comp = list.get(j + 1); if (current &gt; comp) &#123; int temp = list.get(j + 1); list.set(j + 1, list.get(j)); list.set(j, temp); &#125; &#125; System.out.println(list); &#125; &#125; /** * 冒泡排序 Array (循环最大值置顶) * &lt;p&gt; * 算法思想：遍历待排序的数组，每次遍历比较相邻的两个元素，如果他们的排列顺序错误就交换他们的位置， * 经过一趟排序后，最大的元素会浮置数组的末端。重复操作，直到排序完成。 */ static void bubbleArray() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); Collections.shuffle(list);// list随机打乱 Integer[] values = (Integer[]) list.toArray(); System.out.println(Arrays.asList(values)); for (int i = 0; i &lt; values.length; i++) &#123; for (int j = 0; j &lt; values.length - 1 - i; j++) &#123; int current = values[j]; int comp = values[j + 1]; if (current &gt; comp) &#123; int temp = values[j + 1]; values[j + 1] = values[j]; values[j] = temp; &#125; &#125; System.out.println(Arrays.asList(values)); &#125; &#125; /** * 选择排序 * &lt;p&gt; * 算法思想：重待排序的数组中选择一个最小的元素，将它与数组的第一个位置的元素交换位置。 * 然后从剩下的元素中选择一个最小的元素，将它与第二个位置的元素交换位置， * 如果最小元素就是该位置的元素，就将它和自身交换位置，依次类推，直到排序完成。 */ static void xuanze() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); Collections.shuffle(list);// list随机打乱 Integer[] values = (Integer[]) list.toArray(); System.out.println(Arrays.asList(values)); Integer[] array = values; for (int i = 0; i &lt; values.length; i++) &#123; int courrentMinIndex = i;// 当前最小值下标 // 从当前下标到最后的范围,找出最小的值 for (int j = i + 1; j &lt; values.length; j++) &#123; if (values[j] &lt; values[courrentMinIndex]) &#123; courrentMinIndex = j; &#125; &#125; // 当前位与最小值位交换 int temp = values[i]; values[i] = values[courrentMinIndex]; values[courrentMinIndex] = temp; System.out.println(Arrays.asList(array)); &#125; &#125; /** * 插入排序(优先保障currentIndex前置有序) * &lt;p&gt; * 算法思想:从数组的第二个元素开始遍历，将该元素与前面的元素比较，如果该元素比前面的元素小， * 将该元素保存进临时变量中，依次将前面的元素后移，然后将该元素插入到合适的位置。 * 每次排序完成后，索引左边的元素一定是有序的，但是还可以移动。对于倒置越少的数组，该算法的排序效率越高。 */ static void charu() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); Collections.shuffle(list);// list随机打乱 Integer[] values = (Integer[]) list.toArray(); System.out.println(Arrays.asList(values)); for (int i = 1; i &lt; values.length; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; int current = values[i]; int comp = values[j]; if (current &lt; comp) &#123; int third = values[i]; values[i] = values[j]; values[j] = third; &#125; &#125; System.out.println(Arrays.asList(values)); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/*** 快速排序*/class QuickSort &#123; /** * 快速排序的基本思想：通过一趟排序将待排序记录分割成独立的两部分，其中一部分记录的关键字均比另一部分关键字小， * 则分别对这两部分继续进行排序，直到整个序列有序。 */ static void quickSort() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); Collections.shuffle(list);// list随机打乱 System.out.println("======(分区)"); Integer[] values = (Integer[]) list.toArray(); System.out.println(Arrays.asList(values)); quickSortEasy(values, 0, values.length - 1); System.out.println("======(交换)"); values = (Integer[]) list.toArray(); System.out.println(Arrays.asList(values)); quickSortSwap(values, 0, values.length - 1); &#125; /** * 分治法-分区(方便理解) * * @param values * @param begin * @param end */ static void quickSortEasy(Integer[] values, int begin, int end) &#123; if (begin &gt;= end) return; int middleIndex = quickSortMiddleEasy(values, begin, end); System.out.printf("begin:%d end:%d middleIndex:%d(value=%d) %n", begin, end, middleIndex, values[middleIndex]); System.out.println(Arrays.asList(values));// 定位中位数时,已经完成分治 quickSortEasy(values, begin, middleIndex - 1); quickSortEasy(values, middleIndex + 1, end); &#125; static int quickSortMiddleEasy(Integer[] values, int begin, int end) &#123; // 第一步,以最低位值作为中轴,将其它数进行两边分治法.结束后,中轴位不再参与后续排序(因为位置已经确定了) // 示例:[6, 2, 1, 8, 5, 4, 9, 3, 7]中轴值为6,分治法结果[32145]6[987](交换)/[21543]6[897](分区) int middleValue = values[begin]; // 第二步,分治法.先腾出中轴值位置[0],并保持中轴值. List&lt;Integer&gt; left = new ArrayList&lt;&gt;(); List&lt;Integer&gt; right = new ArrayList&lt;&gt;(); left.addAll(Arrays.asList(Arrays.copyOfRange(values, 0, begin)));// 排序区间前 for (int i = begin; i &lt; end + 1; i++) &#123; if (values[i] &lt; middleValue) &#123; left.add(values[i]); // 排序区间左区 &#125; else if (values[i] &gt; middleValue) &#123; right.add(values[i]);// 排序区间右区 &#125; &#125; left.add(middleValue);// 排序区间中轴 int middleIndex = left.size() - 1; left.addAll(right);// 排序区间右区也合并到单个集合 left.addAll(Arrays.asList(Arrays.copyOfRange(values, end + 1, values.length)));// 排序区间后 values = left.toArray(values);// 重写原数组 return middleIndex; &#125; /** * 分治法-交换(节省内存空间) * @param values * @param begin * @param end */ static void quickSortSwap(Integer[] values, int begin, int end) &#123; if (begin &gt;= end) return; int middleIndex = getMiddle(values, begin, end); System.out.printf("begin:%d end:%d middleIndex:%d(value=%d) %n", begin, end, middleIndex, values[middleIndex]); System.out.println(Arrays.asList(values));// 定位中位数时,已经完成分治 quickSortSwap(values, begin, middleIndex - 1); quickSortSwap(values, middleIndex + 1, end); &#125; public static int getMiddle(Integer[] numbers, int low, int high) &#123; // 示例:[6, 2, 1, 8, 5, 4, 9, 3, 7]中轴值为6,分治法结果[32145]6[987](交换)/[21543]6[897](分区) int temp = numbers[low]; // 数组的第一个作为中轴 numbers[low] = null;// 原位置值已经转移,未来也会被分治法的新值覆盖,可省略.但标记null,方便理解 while (low &lt; high) &#123; while (low &lt; high &amp;&amp; numbers[high] &gt; temp) &#123;// 先最高位与中轴值比较 high--; &#125; numbers[low] = numbers[high];// 比中轴小的记录移到低端 numbers[high] = null;// 原位置值已经转移,未来也会被分治法的新值覆盖,可省略.但标记null,方便理解 while (low &lt; high &amp;&amp; numbers[low] &lt; temp) &#123; low++; &#125; numbers[high] = numbers[low]; //比中轴大的记录移到高端 numbers[low] = null;// 原位置值已经转移,未来也会被分治法的新值覆盖,可省略.但标记null,方便理解 &#125; numbers[low] = temp; //中轴记录到尾 return low; // 返回中轴的位置 &#125;&#125; 归并排序 基本思想:先递归划分子问题，然后合并结果。把待排序列看成由两个有序的子序列，然后合并两个子序列，然后把子序列看成由两个有序序列。倒着来看，其实就是先两两合并，然后四四合并，最终形成有序序列。 做法(建议sublime中编辑,方便符号对其):123int mid = (beginIndex + endIndex) / 2;// 取中位indexmiddleSort(values, beginIndex, mid);// 左侧递归再分,到不可再分middleSort(values, mid + 1, endIndex);// 右侧递归再分,到不可再分 1234567897, 6, 5, 2, 1, 3, 4, 9, 8- - - - - - - - -8- - - - -4- - -2- -1 - -3 - - - -7 - -5 - -6 比较交换,方法一:mid左侧第一位开始与mid右侧第一位开始比较,小的添加到新array.最后再按区间更新原array如:[5, 6, 7, 1, 2](中位数两侧事前已经经过排序)会拆位[5,6,7][1,2](进行合并)5&lt;&gt;1 =&gt; 1(小) tempArray=[1]5&lt;&gt;2 =&gt; 2(小) tempArray=[1,2]把没有到tempArray的大值添加进去: tempArray=[1,2,5,6,7] 见: ★面试中的排序算法总结 - 简书 - 归并排序`http://www.jianshu.com/p/c360a58db21d 比较交换,方法二(推荐): 对待合并数据[5, 6, 7][1, 2]直接仅需插入排序.123456789101112// 待合并的二分数据,已经基本有序,所有使用`插入排序`进行合并,具备更高的性能(因为移动的位置较少)且不需要更多的内存仅需一个交换变量.for (int i = beginIndex + 1; i &lt; endIndex; i++) &#123; for (int j = beginIndex; j &lt; i; j++) &#123; if (values[i] &lt; values[j]) &#123; int temp = values[j]; values[j] = values[i]; values[i] = temp; System.out.println("markNum:"+markNum++); &#125; &#125;&#125;System.out.println(Arrays.asList(values)); 见: myServer/@java/demo-sorting/SortingDemo.java12345678910111213141516171819202122232425262728293031323334353637383940/*** 归并排序*/class MergeSort &#123; static void mergeSort() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); Collections.shuffle(list);// list随机打乱 Integer[] values = (Integer[]) list.toArray(); System.out.println(Arrays.asList(values)); middleSort(values, 0, values.length); &#125; static int markNum=0; static void middleSort(Integer[] values, int beginIndex, int endIndex) &#123; if (!(beginIndex &lt; endIndex)) return; int mid = (beginIndex + endIndex) / 2;// 取中位index middleSort(values, beginIndex, mid);// 左侧递归再分,到不可再分 middleSort(values, mid + 1, endIndex);// 右侧递归再分,到不可再分 // 对最近的二分数据进行合并. 如:[5,6,7][1,2] // 待合并的二分数据,已经基本有序,所有使用`插入排序`进行合并,具备更高的性能(因为移动的位置较少)且不需要更多的内存仅需一个交换变量. for (int i = beginIndex + 1; i &lt; endIndex; i++) &#123; for (int j = beginIndex; j &lt; i; j++) &#123; if (values[i] &lt; values[j]) &#123; int temp = values[j]; values[j] = values[i]; values[i] = temp; System.out.println("markNum:"+markNum++); &#125; &#125; &#125; System.out.println(Arrays.asList(values)); &#125;&#125; 希尔排序基本思想是：先将整个待排记录序列分割成为若干子序列，分别进行直接插入排序。待整个序列中的记录基本有序时，再对全体记录进行一次直接插入排序。12345678910111213141516171819202122232425262728293031323334353637383940418, 7, 4, 1, 3, 5, 6, 2, 9length/2=4- - - - - - - - - -3, 5, 4, 1, 8, 7, 6, 2, 94/2=2- - - - - - - - - - - - - - - - - -x x 1 5 x 8 x 7 x 6 8 2 5 7 x x x 93, 1, 4, 2, 6, 5, 8, 7, 92/2=1- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -1 3 i=1 x x i=2 2 3 4 i=3 x x x 6 i=4 x x x 5 6 i=5 x x x x X 8 i=6 x x x x X 7 8 i=7 x x x x X x x x 9 i=8 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*** 希尔排序*/class ShellSort &#123; static void shellSort() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); Collections.shuffle(list);// list随机打乱 Integer[] values = (Integer[]) list.toArray();// List 转 Array System.out.println(Arrays.asList(values)); int[] valuesI = new int[values.length]; Arrays.stream(values).forEachOrdered(i -&gt; valuesI[i - 1] = values[i - 1].intValue());// 封装数组转基础数组(Integer[] 转 int[]) Arrays.stream(valuesI).forEach(value -&gt; System.out.print(value + ", "));// 打印基础类型数组(int[]) System.out.println(); int[] valuesI2 = new int[]&#123;8, 7, 4, 1, 3, 5, 6, 2, 9&#125;;// 自定义 shellSort(valuesI2); Arrays.stream(valuesI2).forEach(value -&gt; System.out.print(value + ", "));// 打印基础类型数组(int[]) &#125; /** * 希尔排序的一趟插入 * * @param arr 待排数组 * @param d 增量 */ public static void shellInsert(int[] arr, int d) &#123; System.out.println("d:" + d); for (int i = d; i &lt; arr.length; i++) &#123; int j = i - d; int temp = arr[i]; //记录要插入的数据 while (j &gt;= 0 &amp;&amp; arr[j] &gt; temp) &#123; //从后向前，找到比其小的数的位置 arr[j + d] = arr[j]; //向后挪动 j -= d; &#125; if (j != i - d) //存在比其小的数 arr[j + d] = temp; Arrays.stream(arr).forEach(value -&gt; System.out.print(value + ", "));// 打印基础类型数组(int[]) System.out.println(); &#125; &#125; public static void shellSort(int[] arr) &#123; if (arr == null || arr.length == 0) return; int d = arr.length / 2; while (d &gt;= 1) &#123; shellInsert(arr, d); d /= 2; &#125; &#125;&#125; 时间复杂度,空间复杂度,稳定性 关于时间复杂度：平方阶(O(n2))排序：各类简单排序:直接插入、直接选择和冒泡排序。线性对数阶(O(nlog2n))排序：快速排序、堆排序和归并排序。O(n1+§))排序：§是介于0和1之间的常数。线性阶(O(n))排序：基数排序，此外还有桶、箱排序。 关于稳定性：稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序；不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序。 平均时间,最坏情况,辅助存储 平均时间来看，快速排序是效率最高的。但快速排序在最坏情况下的时间性能，不如堆排序和归并排序。而后者相比较的结果是在n较大时，归并排序使用时间较少，但使用辅助空间较多。 简单排序，包括除希尔排序之外的所有冒泡排序、插入排序、简单选择排序。其中直接插入排序最简单。但序列基本有序或者n较小时，直接插入排序是好的方法。因此常将它和其他的排序方法，如快速排序、归并排序等结合在一起使用。 基数排序的时间复杂度也可以写成O(d*n)。因此它最使用于n值很大而关键字较小的的序列。若关键字也很大，而序列中大多数记录的最高关键字均不同，则亦可先按最高关键字不同，将序列分成若干小的子序列，而后进行直接插入排序。 从方法的稳定性来比较，基数排序是稳定的内排方法，所有时间复杂度为O(n^2)的简单排序也是稳定的。但是快速排序、堆排序、希尔排序等时间性能较好的排序方法都是不稳定的。稳定性需要根据具体需求选择。 上面的算法实现大多数是使用线性存储结构，像插入排序这种算法，用链表实现更好，省去了移动元素的时间。具体的存储结构，在具体的实现版本中也是不同的。 参考★面试中的排序算法总结 - 简书http://www.jianshu.com/p/c360a58db21d 排序算法图形化比较：快速排序、插入排序、选择排序、冒泡排序 - 简书http://www.jianshu.com/p/70619984fbc6完全二叉树实现优先队列与堆排序 - 简书http://www.jianshu.com/p/9a456d1b59b5 8大排序算法图文讲解http://www.jianshu.com/p/e6ad4423efcd 八大排序算法 - guisu，程序人生。 逆水行舟，不进则退。 - CSDN博客http://blog.csdn.net/hguisu/article/details/7776068]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内网docker集群环境]]></title>
    <url>%2F2017%2F08%2F03%2F%E5%86%85%E7%BD%91docker%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[Node一键接入集群，建议初始镜像使用内网centos7.2初始镜像 12345678910111213141516curl -sSL https://shipyard-project.com/deploy | ACTION=node DISCOVERY=etcd://192.168.10.165:4001 bash -内网docker集群docker registry : dr.zenzet.comdocker console : shipyard.zenzet.comdocker nodes : 192.168.10.113~115相关docker命令docker build -t gateway .docker run -d -p 6500:6500 gatewaydocker tag gateway dr.zenzet.com/gatewaydocker push dr.zenzet.com/gatewaydocker exec -it 198eb84bf118 /bin/shdocker kill 372f0742488adocker rmi -f b537edc85f45docker run -d -p 80:5000 -v /opt/registry:/tmp/registry-dev registrydocker run -d -p 6500:6500 dr.zenzet.com/gateway]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Bean的初始化启动方式]]></title>
    <url>%2F2017%2F08%2F01%2FSpring%20Bean%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[方式一: xml &lt;bean init-method=&quot;init&quot;1234&lt;bean class="cn.fraudmetrix.billing.consumer.FlowConsumer" init-method="init" destroy-method="destroy"&gt; &lt;property name="kafkaTopics" value="$&#123;billing.kafka.topics&#125;"/&gt; &lt;property name="debug" value="$&#123;billing.flow.consumer.debug&#125;"/&gt;&lt;/bean&gt; 方式二: implements InitializingBean12345678public class DisconfPropertiesFactory implements FactoryBean&lt;Properties&gt;, InitializingBean &#123; ... public void afterPropertiesSet() throws Exception &#123; if (this.singleton) &#123; this.singletonInstance = this.createProperties(); &#125; &#125; ... 方式三:注解@PostConstruct @PreDestroy12345678910111213141516171819202122232425262728package com.myapp.core.annotation.init;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;public class PersonService &#123; private String message; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; @PostConstruct public void init()&#123; System.out.println("I'm init method using @PostConstrut...."+message); &#125; @PreDestroy public void dostory()&#123; System.out.println("I'm destory method using @PreDestroy....."+message); &#125;&#125; bean factory负责bean创建的最初四步，然后移交给应用上下文做后续创建过程： 1.Spring初始化bean 2.Spring将值和其他bean的引用注入（inject）到当前bean的对应属性中； 3.如果Bean实现了BeanNameAware接口，Spring会传入bean的ID来调用setBeanName方法； 4.如果Bean实现了BeanFactoryAware接口，Spring传入bean factory的引用来调用setBeanFactory方法； 5.如果Bean实现了ApplicationContextAware接口，Spring将传入应用上下文的引用来调用setApplicationContext方法； 6.如果Bean实现了BeanPostProcessor接口，则Spring调用postProcessBeforeInitialization方法，这个方法在初始化和属性注入之后调用，在任何初始化代码之前调用； 7.如果Bean实现了InitializingBean接口，则需要调用该接口的afterPropertiesSet方法；如果在bean定义的时候设置了init-method属性，则需要调用该属性指定的初始化方法； 8.如果Bean实现了BeanPostProcessor接口，则Spring调用postProcessAfterInitialization方法 9.在这个时候bean就可以用于在应用上下文中使用了，当上下文退出时bean也会被销毁； 10.如果Bean实现了DisposableBean接口，Spring会调用destroy()方法;如果在bean定义的时候设置了destroy-method， 则此时需要调用指定的方法。 Spring实战1：Spring初探 - 简书http://www.jianshu.com/p/9370707091ef 参考13 Spring Bean init-method 和 destroy-method实例 - 简书http://www.jianshu.com/p/30a0a74cd31f 通过Spring @PostConstruct 和 @PreDestroy 方法 实现初始化和销毁bean之前进行的操作 - 安德里亚的成长 - CSDN博客http://blog.csdn.net/topwqp/article/details/8681497]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM参数配置]]></title>
    <url>%2F2015%2F10%2F07%2FJVM%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[常见配置12# 4G内存:JAVA_OPTS="$JAVA_OPTS -server -Xms2500m -Xmx2500m -XX:PermSize=256M -XX:MaxPermSize=512m" 1234567891011# 机器内存分配结构：# 核心应用占用内存（可通过监控查看出合适的大小，配置太高用不到也是浪费）# 系统及非核心应用占用内存（在核心应用未启用时，top所占用内存。此基础上还需弹性空间）# 注:日常状态内存尽量控制在70%以内,预留内存以备处理‘内存针刺’的业务# (服务器一般设置-Xms、-Xmx相等以避免在每次GC后调整堆的大小)-Xms128m #JVM初始分配的堆内存-Xmx512m #JVM最大允许分配的堆内存，按需分配-XX:PermSize=64M #JVM初始分配的非堆内存-XX:MaxPermSize=128M #JVM最大允许分配的非堆内存，按需分配 tomcat jvm配置12345678910111213141516171819202122232425# 服务端配置远程调试CATALINA_OPTS="$CATALINA_OPTS -server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5888"# jconsole，VisualVM，JMC 监控配置（rmi）# -Dcom.sun.management.jmxremote.authenticate=false 为 JMC 关闭飞行模式JAVA_OPTS="$JAVA_OPTS -Dcom.sun.management.jmxremote=true -Djava.rmi.server.hostname=121.40.84.8 -Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.managementote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false"# 配置tomcat，日常GC日志. 可记录下服务器历史的GC情况# 注意：tomcat启动后如果webapps下未自动创建sys目录，请手动创建 */webapps&gt;mkdir sys# 配置路径到webapps下，方便日志文件的下载和直接定位：# 访问：# http://121.40.87.121:8080/sys/gc.log# http://121.40.84.8:8080/sys/gc.log# 可视化工具:GCViewer可以使用网络地址直接查看CATALINA_OPTS="$CATALINA_OPTS -Xloggc:webapps/sys/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps"# jprofile服务器端配置CATALINA_OPTS="$CATALINA_OPTS -agentlib:jprofilerti=port=8849,nowait -Xbootclasspath/a:/usr/local/jprofile/jprofiler9/bin/agent.jar"# jvm shut down时,输出dump文件CATALINA_OPTS="$CATALINA_OPTS -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/apache-tomcat-7.0.59/logs/heap.dump" windows 配置12345# 服务端配置远程调试SET CATALINA_OPTS=-server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5888# jprofile服务器端配置set CATALINA_OPTS=%CATALINA_OPTS% -agentpath:G:\workTool\jprofiler9\bin\windows-x64\jprofilerti.dll=port=8849,nowait]]></content>
      <categories>
        <category>java基础</category>
      </categories>
  </entry>
</search>
